{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.DatasetManage import read_and_store_data\n",
    "from ipynb.fs.full.FeatureExtraction import feature_extraction\n",
    "from ipynb.fs.full.ClassificationPerformanceIndexes import classificationPerformanceIndexes, printClassificationPerformanceIndexes\n",
    "from ipynb.fs.full.ClassificationMethods import CompleteLSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfInd = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'MCC', 'Kappa', 'Time']\n",
    "channels = ['FP1-F7', 'F7-T7','T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'seizure']\n",
    "\n",
    "dataset = 'CHB_MIT'\n",
    "csvImportFile = 'CHB.csv'\n",
    "csvExportFile = 'CHB.csv'\n",
    "sample_rate = 256\n",
    "time_window = 2\n",
    "step = time_window * sample_rate\n",
    "\n",
    "test_ratio = 0.3\n",
    "\n",
    "pca_tolerance = 0.9\n",
    "\n",
    "undersampling_rate = 0.2\n",
    "\n",
    "oversampling_neighbors = 11\n",
    "\n",
    "k_fold = 5\n",
    "\n",
    "csvAverageFile = 'Features.csv'\n",
    "\n",
    "batch = 10\n",
    "epochs = 100\n",
    "dropout_percentage = 0.2\n",
    "loss_function = 'mean_squared_error'\n",
    "metric = 'accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestData (features, test_ratio, k_fold, perfInd):\n",
    "    x = features.loc[:, features.columns != 'seizure']\n",
    "    y = features['seizure']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_ratio, shuffle = True)\n",
    "    results = pd.DataFrame(columns = perfInd)\n",
    "    kf = KFold(n_splits = k_fold, shuffle = True)\n",
    "    return x_train, x_test, y_train, y_test, results, kf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from CHB.csv\n"
     ]
    }
   ],
   "source": [
    "print('Reading data from', csvImportFile)\n",
    "df = pd.read_csv(csvImportFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft = feature_extraction(df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv(csvAverageFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, results, kf = trainTestData (ft, test_ratio, k_fold, perfInd)\n",
    "\n",
    "x_train = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "y_train = y_train.values.astype(int)\n",
    "x_test = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_test = y_test.values.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainTestData_2 (features, perfInd):\n",
    "    x = features.loc[:, features.columns != 'seizure']\n",
    "    y = features['seizure']\n",
    "    x_1, x_test, y_1, y_test = train_test_split(x, y, test_size = 0.3, random_state=42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_1, y_1, test_size=0.2, random_state=42)\n",
    "    results = pd.DataFrame(columns = perfInd)\n",
    "    return x_train, x_test, y_train, y_test, x_val, y_val, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 1, 86)\n",
      "(313,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, x_val, y_val, results = trainTestData_2 (ft, perfInd)\n",
    "\n",
    "x_train = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "y_train = y_train.values.astype(int)\n",
    "x_val = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_val = y_test.values.astype(int)\n",
    "x_test = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_test = y_test.values.astype(int)\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "79/79 [==============================] - 4s 13ms/step - loss: 0.7802 - accuracy: 0.4856 - val_loss: 0.7559 - val_accuracy: 0.5119\n",
      "Epoch 2/800\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7676 - accuracy: 0.4856 - val_loss: 0.7450 - val_accuracy: 0.5119\n",
      "Epoch 3/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7552 - accuracy: 0.4856 - val_loss: 0.7333 - val_accuracy: 0.5119\n",
      "Epoch 4/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7417 - accuracy: 0.4856 - val_loss: 0.7212 - val_accuracy: 0.5119\n",
      "Epoch 5/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7269 - accuracy: 0.4856 - val_loss: 0.7076 - val_accuracy: 0.5119\n",
      "Epoch 6/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.7108 - accuracy: 0.4856 - val_loss: 0.6929 - val_accuracy: 0.5119\n",
      "Epoch 7/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.4856 - val_loss: 0.6759 - val_accuracy: 0.5119\n",
      "Epoch 8/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.4856 - val_loss: 0.6581 - val_accuracy: 0.5119\n",
      "Epoch 9/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6535 - accuracy: 0.4856 - val_loss: 0.6392 - val_accuracy: 0.5119\n",
      "Epoch 10/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.4856 - val_loss: 0.6208 - val_accuracy: 0.5119\n",
      "Epoch 11/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.4856 - val_loss: 0.6024 - val_accuracy: 0.5119\n",
      "Epoch 12/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5950 - accuracy: 0.4856 - val_loss: 0.5856 - val_accuracy: 0.5119\n",
      "Epoch 13/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5785 - accuracy: 0.4856 - val_loss: 0.5706 - val_accuracy: 0.5119\n",
      "Epoch 14/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.4856 - val_loss: 0.5573 - val_accuracy: 0.5119\n",
      "Epoch 15/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.4952 - val_loss: 0.5458 - val_accuracy: 0.5298\n",
      "Epoch 16/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.5623 - val_loss: 0.5358 - val_accuracy: 0.5595\n",
      "Epoch 17/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.6358 - val_loss: 0.5272 - val_accuracy: 0.6131\n",
      "Epoch 18/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.6997 - val_loss: 0.5199 - val_accuracy: 0.6369\n",
      "Epoch 19/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7668 - val_loss: 0.5133 - val_accuracy: 0.6964\n",
      "Epoch 20/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.8147 - val_loss: 0.5077 - val_accuracy: 0.7202\n",
      "Epoch 21/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.8435 - val_loss: 0.5026 - val_accuracy: 0.7560\n",
      "Epoch 22/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.8626 - val_loss: 0.4980 - val_accuracy: 0.7679\n",
      "Epoch 23/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.8850 - val_loss: 0.4938 - val_accuracy: 0.7917\n",
      "Epoch 24/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.8882 - val_loss: 0.4900 - val_accuracy: 0.8274\n",
      "Epoch 25/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.8978 - val_loss: 0.4864 - val_accuracy: 0.8333\n",
      "Epoch 26/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.9010 - val_loss: 0.4832 - val_accuracy: 0.8393\n",
      "Epoch 27/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.9042 - val_loss: 0.4802 - val_accuracy: 0.8512\n",
      "Epoch 28/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.9073 - val_loss: 0.4773 - val_accuracy: 0.8631\n",
      "Epoch 29/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.9233 - val_loss: 0.4745 - val_accuracy: 0.8690\n",
      "Epoch 30/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.9265 - val_loss: 0.4720 - val_accuracy: 0.8690\n",
      "Epoch 31/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.9297 - val_loss: 0.4696 - val_accuracy: 0.8810\n",
      "Epoch 32/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.9329 - val_loss: 0.4671 - val_accuracy: 0.8810\n",
      "Epoch 33/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.9361 - val_loss: 0.4649 - val_accuracy: 0.8810\n",
      "Epoch 34/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.9361 - val_loss: 0.4627 - val_accuracy: 0.8810\n",
      "Epoch 35/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.9361 - val_loss: 0.4607 - val_accuracy: 0.8929\n",
      "Epoch 36/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.9425 - val_loss: 0.4585 - val_accuracy: 0.8988\n",
      "Epoch 37/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.9489 - val_loss: 0.4566 - val_accuracy: 0.8988\n",
      "Epoch 38/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.9521 - val_loss: 0.4547 - val_accuracy: 0.9048\n",
      "Epoch 39/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.9553 - val_loss: 0.4528 - val_accuracy: 0.9048\n",
      "Epoch 40/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.9553 - val_loss: 0.4509 - val_accuracy: 0.9107\n",
      "Epoch 41/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.9585 - val_loss: 0.4491 - val_accuracy: 0.9167\n",
      "Epoch 42/800\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.9585 - val_loss: 0.4473 - val_accuracy: 0.9167\n",
      "Epoch 43/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.9585 - val_loss: 0.4455 - val_accuracy: 0.9167\n",
      "Epoch 44/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.9585 - val_loss: 0.4438 - val_accuracy: 0.9167\n",
      "Epoch 45/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.9617 - val_loss: 0.4421 - val_accuracy: 0.9167\n",
      "Epoch 46/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.9617 - val_loss: 0.4404 - val_accuracy: 0.9226\n",
      "Epoch 47/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.9617 - val_loss: 0.4387 - val_accuracy: 0.9226\n",
      "Epoch 48/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.9617 - val_loss: 0.4372 - val_accuracy: 0.9226\n",
      "Epoch 49/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.9617 - val_loss: 0.4354 - val_accuracy: 0.9226\n",
      "Epoch 50/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.9649 - val_loss: 0.4338 - val_accuracy: 0.9226\n",
      "Epoch 51/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.9681 - val_loss: 0.4322 - val_accuracy: 0.9226\n",
      "Epoch 52/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.9712 - val_loss: 0.4307 - val_accuracy: 0.9286\n",
      "Epoch 53/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.9712 - val_loss: 0.4291 - val_accuracy: 0.9286\n",
      "Epoch 54/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.9712 - val_loss: 0.4275 - val_accuracy: 0.9345\n",
      "Epoch 55/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.9712 - val_loss: 0.4260 - val_accuracy: 0.9345\n",
      "Epoch 56/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.9712 - val_loss: 0.4245 - val_accuracy: 0.9405\n",
      "Epoch 57/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.9712 - val_loss: 0.4230 - val_accuracy: 0.9464\n",
      "Epoch 58/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.9712 - val_loss: 0.4215 - val_accuracy: 0.9464\n",
      "Epoch 59/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.9712 - val_loss: 0.4201 - val_accuracy: 0.9524\n",
      "Epoch 60/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.9712 - val_loss: 0.4186 - val_accuracy: 0.9524\n",
      "Epoch 61/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.9712 - val_loss: 0.4171 - val_accuracy: 0.9524\n",
      "Epoch 62/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.9744 - val_loss: 0.4156 - val_accuracy: 0.9524\n",
      "Epoch 63/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.9744 - val_loss: 0.4143 - val_accuracy: 0.9524\n",
      "Epoch 64/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.9744 - val_loss: 0.4129 - val_accuracy: 0.9524\n",
      "Epoch 65/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.9776 - val_loss: 0.4114 - val_accuracy: 0.9524\n",
      "Epoch 66/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.9776 - val_loss: 0.4100 - val_accuracy: 0.9524\n",
      "Epoch 67/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.9776 - val_loss: 0.4085 - val_accuracy: 0.9524\n",
      "Epoch 68/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.9776 - val_loss: 0.4071 - val_accuracy: 0.9524\n",
      "Epoch 69/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.9776 - val_loss: 0.4055 - val_accuracy: 0.9583\n",
      "Epoch 70/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.9776 - val_loss: 0.4041 - val_accuracy: 0.9583\n",
      "Epoch 71/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.9776 - val_loss: 0.4022 - val_accuracy: 0.9583\n",
      "Epoch 72/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.9776 - val_loss: 0.4006 - val_accuracy: 0.9583\n",
      "Epoch 73/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.9776 - val_loss: 0.3990 - val_accuracy: 0.9643\n",
      "Epoch 74/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.9808 - val_loss: 0.3974 - val_accuracy: 0.9643\n",
      "Epoch 75/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.9808 - val_loss: 0.3960 - val_accuracy: 0.9643\n",
      "Epoch 76/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.9840 - val_loss: 0.3945 - val_accuracy: 0.9643\n",
      "Epoch 77/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.9840 - val_loss: 0.3931 - val_accuracy: 0.9643\n",
      "Epoch 78/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.9872 - val_loss: 0.3918 - val_accuracy: 0.9643\n",
      "Epoch 79/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.9872 - val_loss: 0.3905 - val_accuracy: 0.9643\n",
      "Epoch 80/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.9872 - val_loss: 0.3892 - val_accuracy: 0.9643\n",
      "Epoch 81/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.9872 - val_loss: 0.3880 - val_accuracy: 0.9643\n",
      "Epoch 82/800\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.9904 - val_loss: 0.3869 - val_accuracy: 0.9702\n",
      "Epoch 83/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.9904 - val_loss: 0.3860 - val_accuracy: 0.9702\n",
      "Epoch 84/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3781 - accuracy: 0.9904 - val_loss: 0.3849 - val_accuracy: 0.9702\n",
      "Epoch 85/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.9904 - val_loss: 0.3838 - val_accuracy: 0.9702\n",
      "Epoch 86/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.9904 - val_loss: 0.3829 - val_accuracy: 0.9702\n",
      "Epoch 87/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.9904 - val_loss: 0.3821 - val_accuracy: 0.9702\n",
      "Epoch 88/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.9904 - val_loss: 0.3811 - val_accuracy: 0.9702\n",
      "Epoch 89/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.9904 - val_loss: 0.3798 - val_accuracy: 0.9702\n",
      "Epoch 90/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.9904 - val_loss: 0.3787 - val_accuracy: 0.9702\n",
      "Epoch 91/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.9904 - val_loss: 0.3781 - val_accuracy: 0.9702\n",
      "Epoch 92/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.9904 - val_loss: 0.3773 - val_accuracy: 0.9702\n",
      "Epoch 93/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.9904 - val_loss: 0.3758 - val_accuracy: 0.9702\n",
      "Epoch 94/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.9904 - val_loss: 0.3744 - val_accuracy: 0.9702\n",
      "Epoch 95/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.9936 - val_loss: 0.3749 - val_accuracy: 0.9702\n",
      "Epoch 96/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.9936 - val_loss: 0.3728 - val_accuracy: 0.9821\n",
      "Epoch 97/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.9936 - val_loss: 0.3725 - val_accuracy: 0.9702\n",
      "Epoch 98/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.9936 - val_loss: 0.3705 - val_accuracy: 0.9762\n",
      "Epoch 99/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.9936 - val_loss: 0.3692 - val_accuracy: 0.9821\n",
      "Epoch 100/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.9936 - val_loss: 0.3682 - val_accuracy: 0.9762\n",
      "Epoch 101/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.9936 - val_loss: 0.3670 - val_accuracy: 0.9762\n",
      "Epoch 102/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.9968 - val_loss: 0.3657 - val_accuracy: 0.9821\n",
      "Epoch 103/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.9968 - val_loss: 0.3650 - val_accuracy: 0.9762\n",
      "Epoch 104/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.9968 - val_loss: 0.3639 - val_accuracy: 0.9762\n",
      "Epoch 105/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.9968 - val_loss: 0.3625 - val_accuracy: 0.9762\n",
      "Epoch 106/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.9968 - val_loss: 0.3619 - val_accuracy: 0.9762\n",
      "Epoch 107/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.9968 - val_loss: 0.3608 - val_accuracy: 0.9762\n",
      "Epoch 108/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.9968 - val_loss: 0.3598 - val_accuracy: 0.9762\n",
      "Epoch 109/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.9968 - val_loss: 0.3587 - val_accuracy: 0.9762\n",
      "Epoch 110/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.9968 - val_loss: 0.3578 - val_accuracy: 0.9762\n",
      "Epoch 111/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.9968 - val_loss: 0.3568 - val_accuracy: 0.9762\n",
      "Epoch 112/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.9968 - val_loss: 0.3557 - val_accuracy: 0.9762\n",
      "Epoch 113/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.9968 - val_loss: 0.3548 - val_accuracy: 0.9762\n",
      "Epoch 114/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.9968 - val_loss: 0.3539 - val_accuracy: 0.9762\n",
      "Epoch 115/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.9968 - val_loss: 0.3529 - val_accuracy: 0.9762\n",
      "Epoch 116/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.9968 - val_loss: 0.3518 - val_accuracy: 0.9762\n",
      "Epoch 117/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.9968 - val_loss: 0.3510 - val_accuracy: 0.9762\n",
      "Epoch 118/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.9968 - val_loss: 0.3500 - val_accuracy: 0.9762\n",
      "Epoch 119/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.9968 - val_loss: 0.3490 - val_accuracy: 0.9762\n",
      "Epoch 120/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.9968 - val_loss: 0.3481 - val_accuracy: 0.9762\n",
      "Epoch 121/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.9968 - val_loss: 0.3473 - val_accuracy: 0.9762\n",
      "Epoch 122/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.9968 - val_loss: 0.3463 - val_accuracy: 0.9762\n",
      "Epoch 123/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.9968 - val_loss: 0.3455 - val_accuracy: 0.9762\n",
      "Epoch 124/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.9968 - val_loss: 0.3445 - val_accuracy: 0.9762\n",
      "Epoch 125/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.9968 - val_loss: 0.3437 - val_accuracy: 0.9762\n",
      "Epoch 126/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.9968 - val_loss: 0.3428 - val_accuracy: 0.9762\n",
      "Epoch 127/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.9968 - val_loss: 0.3419 - val_accuracy: 0.9762\n",
      "Epoch 128/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.9968 - val_loss: 0.3411 - val_accuracy: 0.9762\n",
      "Epoch 129/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.9968 - val_loss: 0.3402 - val_accuracy: 0.9762\n",
      "Epoch 130/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3219 - accuracy: 0.9968 - val_loss: 0.3393 - val_accuracy: 0.9762\n",
      "Epoch 131/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.9968 - val_loss: 0.3384 - val_accuracy: 0.9762\n",
      "Epoch 132/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.9968 - val_loss: 0.3375 - val_accuracy: 0.9762\n",
      "Epoch 133/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.9968 - val_loss: 0.3366 - val_accuracy: 0.9762\n",
      "Epoch 134/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.9968 - val_loss: 0.3358 - val_accuracy: 0.9762\n",
      "Epoch 135/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.9968 - val_loss: 0.3350 - val_accuracy: 0.9762\n",
      "Epoch 136/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.9968 - val_loss: 0.3341 - val_accuracy: 0.9762\n",
      "Epoch 137/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.9968 - val_loss: 0.3338 - val_accuracy: 0.9762\n",
      "Epoch 138/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.9968 - val_loss: 0.3328 - val_accuracy: 0.9762\n",
      "Epoch 139/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3130 - accuracy: 0.9968 - val_loss: 0.3319 - val_accuracy: 0.9762\n",
      "Epoch 140/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.9968 - val_loss: 0.3309 - val_accuracy: 0.9762\n",
      "Epoch 141/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.9968 - val_loss: 0.3301 - val_accuracy: 0.9762\n",
      "Epoch 142/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.9968 - val_loss: 0.3292 - val_accuracy: 0.9762\n",
      "Epoch 143/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.9968 - val_loss: 0.3284 - val_accuracy: 0.9762\n",
      "Epoch 144/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3081 - accuracy: 0.9968 - val_loss: 0.3276 - val_accuracy: 0.9762\n",
      "Epoch 145/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.9968 - val_loss: 0.3267 - val_accuracy: 0.9762\n",
      "Epoch 146/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.9968 - val_loss: 0.3260 - val_accuracy: 0.9762\n",
      "Epoch 147/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.9968 - val_loss: 0.3252 - val_accuracy: 0.9762\n",
      "Epoch 148/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.9968 - val_loss: 0.3243 - val_accuracy: 0.9762\n",
      "Epoch 149/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.9968 - val_loss: 0.3236 - val_accuracy: 0.9762\n",
      "Epoch 150/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3025 - accuracy: 0.9968 - val_loss: 0.3228 - val_accuracy: 0.9762\n",
      "Epoch 151/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.9968 - val_loss: 0.3220 - val_accuracy: 0.9762\n",
      "Epoch 152/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.9968 - val_loss: 0.3211 - val_accuracy: 0.9762\n",
      "Epoch 153/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.9968 - val_loss: 0.3205 - val_accuracy: 0.9762\n",
      "Epoch 154/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.9968 - val_loss: 0.3197 - val_accuracy: 0.9762\n",
      "Epoch 155/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.9968 - val_loss: 0.3190 - val_accuracy: 0.9762\n",
      "Epoch 156/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.9968 - val_loss: 0.3182 - val_accuracy: 0.9762\n",
      "Epoch 157/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.9968 - val_loss: 0.3174 - val_accuracy: 0.9762\n",
      "Epoch 158/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.9968 - val_loss: 0.3167 - val_accuracy: 0.9762\n",
      "Epoch 159/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2943 - accuracy: 0.9968 - val_loss: 0.3160 - val_accuracy: 0.9762\n",
      "Epoch 160/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.9968 - val_loss: 0.3152 - val_accuracy: 0.9762\n",
      "Epoch 161/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2925 - accuracy: 0.9968 - val_loss: 0.3145 - val_accuracy: 0.9762\n",
      "Epoch 162/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.9968 - val_loss: 0.3137 - val_accuracy: 0.9762\n",
      "Epoch 163/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.2907 - accuracy: 0.9968 - val_loss: 0.3129 - val_accuracy: 0.9762\n",
      "Epoch 164/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2898 - accuracy: 0.9968 - val_loss: 0.3122 - val_accuracy: 0.9762\n",
      "Epoch 165/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.9968 - val_loss: 0.3115 - val_accuracy: 0.9762\n",
      "Epoch 166/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.9968 - val_loss: 0.3106 - val_accuracy: 0.9762\n",
      "Epoch 167/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.9968 - val_loss: 0.3100 - val_accuracy: 0.9762\n",
      "Epoch 168/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2863 - accuracy: 0.9968 - val_loss: 0.3093 - val_accuracy: 0.9702\n",
      "Epoch 169/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2854 - accuracy: 0.9968 - val_loss: 0.3086 - val_accuracy: 0.9702\n",
      "Epoch 170/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.9968 - val_loss: 0.3079 - val_accuracy: 0.9702\n",
      "Epoch 171/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.9968 - val_loss: 0.3072 - val_accuracy: 0.9702\n",
      "Epoch 172/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2828 - accuracy: 0.9968 - val_loss: 0.3064 - val_accuracy: 0.9702\n",
      "Epoch 173/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2819 - accuracy: 0.9968 - val_loss: 0.3062 - val_accuracy: 0.9702\n",
      "Epoch 174/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2810 - accuracy: 0.9968 - val_loss: 0.3054 - val_accuracy: 0.9702\n",
      "Epoch 175/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.9968 - val_loss: 0.3046 - val_accuracy: 0.9702\n",
      "Epoch 176/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2793 - accuracy: 0.9968 - val_loss: 0.3038 - val_accuracy: 0.9702\n",
      "Epoch 177/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2785 - accuracy: 0.9968 - val_loss: 0.3031 - val_accuracy: 0.9702\n",
      "Epoch 178/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.9968 - val_loss: 0.3024 - val_accuracy: 0.9702\n",
      "Epoch 179/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.9968 - val_loss: 0.3017 - val_accuracy: 0.9702\n",
      "Epoch 180/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2759 - accuracy: 0.9968 - val_loss: 0.3009 - val_accuracy: 0.9702\n",
      "Epoch 181/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2751 - accuracy: 0.9968 - val_loss: 0.3003 - val_accuracy: 0.9702\n",
      "Epoch 182/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2742 - accuracy: 0.9968 - val_loss: 0.2996 - val_accuracy: 0.9702\n",
      "Epoch 183/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.9968 - val_loss: 0.2989 - val_accuracy: 0.9702\n",
      "Epoch 184/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9968 - val_loss: 0.2982 - val_accuracy: 0.9702\n",
      "Epoch 185/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2717 - accuracy: 0.9968 - val_loss: 0.2975 - val_accuracy: 0.9702\n",
      "Epoch 186/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2709 - accuracy: 0.9968 - val_loss: 0.2968 - val_accuracy: 0.9702\n",
      "Epoch 187/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.9968 - val_loss: 0.2962 - val_accuracy: 0.9702\n",
      "Epoch 188/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.9968 - val_loss: 0.2955 - val_accuracy: 0.9702\n",
      "Epoch 189/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2684 - accuracy: 0.9968 - val_loss: 0.2949 - val_accuracy: 0.9702\n",
      "Epoch 190/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.9968 - val_loss: 0.2942 - val_accuracy: 0.9702\n",
      "Epoch 191/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.9968 - val_loss: 0.2936 - val_accuracy: 0.9702\n",
      "Epoch 192/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.9968 - val_loss: 0.2929 - val_accuracy: 0.9702\n",
      "Epoch 193/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2652 - accuracy: 0.9968 - val_loss: 0.2922 - val_accuracy: 0.9702\n",
      "Epoch 194/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2644 - accuracy: 0.9968 - val_loss: 0.2917 - val_accuracy: 0.9702\n",
      "Epoch 195/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2635 - accuracy: 0.9968 - val_loss: 0.2909 - val_accuracy: 0.9702\n",
      "Epoch 196/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2627 - accuracy: 0.9968 - val_loss: 0.2903 - val_accuracy: 0.9702\n",
      "Epoch 197/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2619 - accuracy: 0.9968 - val_loss: 0.2897 - val_accuracy: 0.9702\n",
      "Epoch 198/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9968 - val_loss: 0.2890 - val_accuracy: 0.9702\n",
      "Epoch 199/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2604 - accuracy: 0.9968 - val_loss: 0.2884 - val_accuracy: 0.9702\n",
      "Epoch 200/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2596 - accuracy: 0.9968 - val_loss: 0.2878 - val_accuracy: 0.9702\n",
      "Epoch 201/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.9968 - val_loss: 0.2872 - val_accuracy: 0.9702\n",
      "Epoch 202/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.9968 - val_loss: 0.2865 - val_accuracy: 0.9702\n",
      "Epoch 203/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2572 - accuracy: 0.9968 - val_loss: 0.2859 - val_accuracy: 0.9702\n",
      "Epoch 204/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2565 - accuracy: 0.9968 - val_loss: 0.2853 - val_accuracy: 0.9702\n",
      "Epoch 205/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2557 - accuracy: 0.9968 - val_loss: 0.2847 - val_accuracy: 0.9702\n",
      "Epoch 206/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2549 - accuracy: 0.9968 - val_loss: 0.2841 - val_accuracy: 0.9702\n",
      "Epoch 207/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2541 - accuracy: 0.9968 - val_loss: 0.2835 - val_accuracy: 0.9702\n",
      "Epoch 208/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.9968 - val_loss: 0.2829 - val_accuracy: 0.9702\n",
      "Epoch 209/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2526 - accuracy: 0.9968 - val_loss: 0.2822 - val_accuracy: 0.9702\n",
      "Epoch 210/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2519 - accuracy: 0.9968 - val_loss: 0.2817 - val_accuracy: 0.9702\n",
      "Epoch 211/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2512 - accuracy: 0.9968 - val_loss: 0.2811 - val_accuracy: 0.9702\n",
      "Epoch 212/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.9968 - val_loss: 0.2806 - val_accuracy: 0.9702\n",
      "Epoch 213/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.9968 - val_loss: 0.2800 - val_accuracy: 0.9702\n",
      "Epoch 214/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2490 - accuracy: 0.9968 - val_loss: 0.2794 - val_accuracy: 0.9702\n",
      "Epoch 215/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2482 - accuracy: 0.9968 - val_loss: 0.2788 - val_accuracy: 0.9702\n",
      "Epoch 216/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2475 - accuracy: 0.9968 - val_loss: 0.2783 - val_accuracy: 0.9702\n",
      "Epoch 217/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2468 - accuracy: 0.9968 - val_loss: 0.2778 - val_accuracy: 0.9702\n",
      "Epoch 218/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2461 - accuracy: 0.9968 - val_loss: 0.2771 - val_accuracy: 0.9702\n",
      "Epoch 219/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2454 - accuracy: 0.9968 - val_loss: 0.2767 - val_accuracy: 0.9702\n",
      "Epoch 220/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.2446 - accuracy: 0.9968 - val_loss: 0.2760 - val_accuracy: 0.9702\n",
      "Epoch 221/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2439 - accuracy: 0.9968 - val_loss: 0.2755 - val_accuracy: 0.9702\n",
      "Epoch 222/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.2432 - accuracy: 0.9968 - val_loss: 0.2749 - val_accuracy: 0.9702\n",
      "Epoch 223/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2425 - accuracy: 0.9968 - val_loss: 0.2744 - val_accuracy: 0.9702\n",
      "Epoch 224/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2418 - accuracy: 0.9968 - val_loss: 0.2739 - val_accuracy: 0.9702\n",
      "Epoch 225/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2411 - accuracy: 0.9968 - val_loss: 0.2733 - val_accuracy: 0.9702\n",
      "Epoch 226/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2404 - accuracy: 0.9968 - val_loss: 0.2727 - val_accuracy: 0.9702\n",
      "Epoch 227/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.2397 - accuracy: 0.9968 - val_loss: 0.2722 - val_accuracy: 0.9702\n",
      "Epoch 228/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2390 - accuracy: 0.9968 - val_loss: 0.2714 - val_accuracy: 0.9702\n",
      "Epoch 229/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.9968 - val_loss: 0.2709 - val_accuracy: 0.9702\n",
      "Epoch 230/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.2376 - accuracy: 0.9968 - val_loss: 0.2704 - val_accuracy: 0.9702\n",
      "Epoch 231/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2369 - accuracy: 0.9968 - val_loss: 0.2699 - val_accuracy: 0.9702\n",
      "Epoch 232/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9968 - val_loss: 0.2693 - val_accuracy: 0.9702\n",
      "Epoch 233/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2355 - accuracy: 0.9968 - val_loss: 0.2686 - val_accuracy: 0.9702\n",
      "Epoch 234/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2348 - accuracy: 0.9968 - val_loss: 0.2682 - val_accuracy: 0.9702\n",
      "Epoch 235/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2341 - accuracy: 0.9968 - val_loss: 0.2677 - val_accuracy: 0.9702\n",
      "Epoch 236/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.9968 - val_loss: 0.2670 - val_accuracy: 0.9702\n",
      "Epoch 237/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2327 - accuracy: 0.9968 - val_loss: 0.2663 - val_accuracy: 0.9702\n",
      "Epoch 238/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.9968 - val_loss: 0.2661 - val_accuracy: 0.9702\n",
      "Epoch 239/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2313 - accuracy: 0.9968 - val_loss: 0.2655 - val_accuracy: 0.9702\n",
      "Epoch 240/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9968 - val_loss: 0.2650 - val_accuracy: 0.9702\n",
      "Epoch 241/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2300 - accuracy: 0.9968 - val_loss: 0.2645 - val_accuracy: 0.9702\n",
      "Epoch 242/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2293 - accuracy: 0.9968 - val_loss: 0.2639 - val_accuracy: 0.9702\n",
      "Epoch 243/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2286 - accuracy: 0.9968 - val_loss: 0.2634 - val_accuracy: 0.9702\n",
      "Epoch 244/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2280 - accuracy: 0.9968 - val_loss: 0.2627 - val_accuracy: 0.9702\n",
      "Epoch 245/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9968 - val_loss: 0.2623 - val_accuracy: 0.9702\n",
      "Epoch 246/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9968 - val_loss: 0.2618 - val_accuracy: 0.9702\n",
      "Epoch 247/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2259 - accuracy: 0.9968 - val_loss: 0.2612 - val_accuracy: 0.9702\n",
      "Epoch 248/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2253 - accuracy: 0.9968 - val_loss: 0.2608 - val_accuracy: 0.9702\n",
      "Epoch 249/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9968 - val_loss: 0.2602 - val_accuracy: 0.9702\n",
      "Epoch 250/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2240 - accuracy: 0.9968 - val_loss: 0.2597 - val_accuracy: 0.9702\n",
      "Epoch 251/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2233 - accuracy: 0.9968 - val_loss: 0.2591 - val_accuracy: 0.9702\n",
      "Epoch 252/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2227 - accuracy: 0.9968 - val_loss: 0.2586 - val_accuracy: 0.9702\n",
      "Epoch 253/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9968 - val_loss: 0.2581 - val_accuracy: 0.9702\n",
      "Epoch 254/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2214 - accuracy: 0.9968 - val_loss: 0.2575 - val_accuracy: 0.9702\n",
      "Epoch 255/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2207 - accuracy: 0.9968 - val_loss: 0.2571 - val_accuracy: 0.9702\n",
      "Epoch 256/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2201 - accuracy: 0.9968 - val_loss: 0.2566 - val_accuracy: 0.9702\n",
      "Epoch 257/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2194 - accuracy: 0.9968 - val_loss: 0.2559 - val_accuracy: 0.9702\n",
      "Epoch 258/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2188 - accuracy: 0.9968 - val_loss: 0.2555 - val_accuracy: 0.9702\n",
      "Epoch 259/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9968 - val_loss: 0.2550 - val_accuracy: 0.9702\n",
      "Epoch 260/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2175 - accuracy: 0.9968 - val_loss: 0.2545 - val_accuracy: 0.9702\n",
      "Epoch 261/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2169 - accuracy: 0.9968 - val_loss: 0.2539 - val_accuracy: 0.9702\n",
      "Epoch 262/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2163 - accuracy: 0.9968 - val_loss: 0.2535 - val_accuracy: 0.9702\n",
      "Epoch 263/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2156 - accuracy: 0.9968 - val_loss: 0.2530 - val_accuracy: 0.9702\n",
      "Epoch 264/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2150 - accuracy: 0.9968 - val_loss: 0.2524 - val_accuracy: 0.9702\n",
      "Epoch 265/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2144 - accuracy: 0.9968 - val_loss: 0.2519 - val_accuracy: 0.9702\n",
      "Epoch 266/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2138 - accuracy: 0.9968 - val_loss: 0.2515 - val_accuracy: 0.9702\n",
      "Epoch 267/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2131 - accuracy: 0.9968 - val_loss: 0.2509 - val_accuracy: 0.9702\n",
      "Epoch 268/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2125 - accuracy: 0.9968 - val_loss: 0.2503 - val_accuracy: 0.9702\n",
      "Epoch 269/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2119 - accuracy: 0.9968 - val_loss: 0.2499 - val_accuracy: 0.9702\n",
      "Epoch 270/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2113 - accuracy: 0.9968 - val_loss: 0.2493 - val_accuracy: 0.9702\n",
      "Epoch 271/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9968 - val_loss: 0.2489 - val_accuracy: 0.9702\n",
      "Epoch 272/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2101 - accuracy: 0.9968 - val_loss: 0.2483 - val_accuracy: 0.9702\n",
      "Epoch 273/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2095 - accuracy: 0.9968 - val_loss: 0.2479 - val_accuracy: 0.9702\n",
      "Epoch 274/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2089 - accuracy: 0.9968 - val_loss: 0.2473 - val_accuracy: 0.9702\n",
      "Epoch 275/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2083 - accuracy: 0.9968 - val_loss: 0.2470 - val_accuracy: 0.9702\n",
      "Epoch 276/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.2077 - accuracy: 0.9968 - val_loss: 0.2464 - val_accuracy: 0.9702\n",
      "Epoch 277/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2071 - accuracy: 0.9968 - val_loss: 0.2458 - val_accuracy: 0.9702\n",
      "Epoch 278/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2065 - accuracy: 0.9968 - val_loss: 0.2454 - val_accuracy: 0.9702\n",
      "Epoch 279/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.2059 - accuracy: 0.9968 - val_loss: 0.2449 - val_accuracy: 0.9702\n",
      "Epoch 280/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9968 - val_loss: 0.2444 - val_accuracy: 0.9702\n",
      "Epoch 281/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2047 - accuracy: 0.9968 - val_loss: 0.2439 - val_accuracy: 0.9702\n",
      "Epoch 282/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2041 - accuracy: 0.9968 - val_loss: 0.2434 - val_accuracy: 0.9702\n",
      "Epoch 283/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2035 - accuracy: 0.9968 - val_loss: 0.2429 - val_accuracy: 0.9702\n",
      "Epoch 284/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2029 - accuracy: 0.9968 - val_loss: 0.2424 - val_accuracy: 0.9702\n",
      "Epoch 285/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2023 - accuracy: 0.9968 - val_loss: 0.2419 - val_accuracy: 0.9702\n",
      "Epoch 286/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9968 - val_loss: 0.2415 - val_accuracy: 0.9702\n",
      "Epoch 287/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2012 - accuracy: 0.9968 - val_loss: 0.2410 - val_accuracy: 0.9702\n",
      "Epoch 288/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.2006 - accuracy: 0.9968 - val_loss: 0.2405 - val_accuracy: 0.9702\n",
      "Epoch 289/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.2000 - accuracy: 0.9968 - val_loss: 0.2399 - val_accuracy: 0.9702\n",
      "Epoch 290/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1994 - accuracy: 0.9968 - val_loss: 0.2395 - val_accuracy: 0.9702\n",
      "Epoch 291/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1988 - accuracy: 0.9968 - val_loss: 0.2389 - val_accuracy: 0.9702\n",
      "Epoch 292/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1983 - accuracy: 0.9968 - val_loss: 0.2386 - val_accuracy: 0.9702\n",
      "Epoch 293/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1977 - accuracy: 0.9968 - val_loss: 0.2381 - val_accuracy: 0.9702\n",
      "Epoch 294/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1971 - accuracy: 0.9968 - val_loss: 0.2375 - val_accuracy: 0.9702\n",
      "Epoch 295/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9968 - val_loss: 0.2371 - val_accuracy: 0.9702\n",
      "Epoch 296/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1960 - accuracy: 0.9968 - val_loss: 0.2366 - val_accuracy: 0.9702\n",
      "Epoch 297/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1954 - accuracy: 0.9968 - val_loss: 0.2361 - val_accuracy: 0.9702\n",
      "Epoch 298/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1949 - accuracy: 0.9968 - val_loss: 0.2357 - val_accuracy: 0.9702\n",
      "Epoch 299/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1943 - accuracy: 0.9968 - val_loss: 0.2352 - val_accuracy: 0.9702\n",
      "Epoch 300/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.9968 - val_loss: 0.2347 - val_accuracy: 0.9702\n",
      "Epoch 301/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9968 - val_loss: 0.2341 - val_accuracy: 0.9702\n",
      "Epoch 302/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1926 - accuracy: 0.9968 - val_loss: 0.2338 - val_accuracy: 0.9702\n",
      "Epoch 303/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1921 - accuracy: 0.9968 - val_loss: 0.2333 - val_accuracy: 0.9702\n",
      "Epoch 304/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9968 - val_loss: 0.2328 - val_accuracy: 0.9702\n",
      "Epoch 305/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1910 - accuracy: 0.9968 - val_loss: 0.2323 - val_accuracy: 0.9702\n",
      "Epoch 306/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1904 - accuracy: 0.9968 - val_loss: 0.2319 - val_accuracy: 0.9702\n",
      "Epoch 307/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1899 - accuracy: 0.9968 - val_loss: 0.2313 - val_accuracy: 0.9702\n",
      "Epoch 308/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1893 - accuracy: 0.9968 - val_loss: 0.2309 - val_accuracy: 0.9702\n",
      "Epoch 309/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1888 - accuracy: 0.9968 - val_loss: 0.2305 - val_accuracy: 0.9702\n",
      "Epoch 310/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1883 - accuracy: 0.9968 - val_loss: 0.2301 - val_accuracy: 0.9702\n",
      "Epoch 311/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.9968 - val_loss: 0.2296 - val_accuracy: 0.9702\n",
      "Epoch 312/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9968 - val_loss: 0.2291 - val_accuracy: 0.9702\n",
      "Epoch 313/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1867 - accuracy: 0.9968 - val_loss: 0.2287 - val_accuracy: 0.9702\n",
      "Epoch 314/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1861 - accuracy: 0.9968 - val_loss: 0.2281 - val_accuracy: 0.9702\n",
      "Epoch 315/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.1856 - accuracy: 0.9968 - val_loss: 0.2277 - val_accuracy: 0.9702\n",
      "Epoch 316/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1851 - accuracy: 0.9968 - val_loss: 0.2278 - val_accuracy: 0.9702\n",
      "Epoch 317/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9968 - val_loss: 0.2272 - val_accuracy: 0.9702\n",
      "Epoch 318/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.9968 - val_loss: 0.2266 - val_accuracy: 0.9702\n",
      "Epoch 319/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1835 - accuracy: 0.9968 - val_loss: 0.2261 - val_accuracy: 0.9702\n",
      "Epoch 320/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1830 - accuracy: 0.9968 - val_loss: 0.2255 - val_accuracy: 0.9702\n",
      "Epoch 321/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1824 - accuracy: 0.9968 - val_loss: 0.2252 - val_accuracy: 0.9702\n",
      "Epoch 322/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1819 - accuracy: 0.9968 - val_loss: 0.2247 - val_accuracy: 0.9702\n",
      "Epoch 323/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.1814 - accuracy: 0.9968 - val_loss: 0.2243 - val_accuracy: 0.9702\n",
      "Epoch 324/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.1809 - accuracy: 0.9968 - val_loss: 0.2238 - val_accuracy: 0.9702\n",
      "Epoch 325/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9968 - val_loss: 0.2240 - val_accuracy: 0.9702\n",
      "Epoch 326/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1799 - accuracy: 0.9968 - val_loss: 0.2234 - val_accuracy: 0.9702\n",
      "Epoch 327/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1793 - accuracy: 0.9968 - val_loss: 0.2227 - val_accuracy: 0.9702\n",
      "Epoch 328/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1788 - accuracy: 0.9968 - val_loss: 0.2223 - val_accuracy: 0.9702\n",
      "Epoch 329/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1783 - accuracy: 0.9968 - val_loss: 0.2218 - val_accuracy: 0.9702\n",
      "Epoch 330/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9968 - val_loss: 0.2213 - val_accuracy: 0.9702\n",
      "Epoch 331/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.9968 - val_loss: 0.2208 - val_accuracy: 0.9702\n",
      "Epoch 332/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1768 - accuracy: 0.9968 - val_loss: 0.2203 - val_accuracy: 0.9702\n",
      "Epoch 333/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1763 - accuracy: 0.9968 - val_loss: 0.2199 - val_accuracy: 0.9702\n",
      "Epoch 334/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1758 - accuracy: 0.9968 - val_loss: 0.2195 - val_accuracy: 0.9702\n",
      "Epoch 335/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.9968 - val_loss: 0.2191 - val_accuracy: 0.9702\n",
      "Epoch 336/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1748 - accuracy: 0.9968 - val_loss: 0.2186 - val_accuracy: 0.9702\n",
      "Epoch 337/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1743 - accuracy: 0.9968 - val_loss: 0.2181 - val_accuracy: 0.9702\n",
      "Epoch 338/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1738 - accuracy: 0.9968 - val_loss: 0.2177 - val_accuracy: 0.9702\n",
      "Epoch 339/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1734 - accuracy: 0.9968 - val_loss: 0.2172 - val_accuracy: 0.9702\n",
      "Epoch 340/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9968 - val_loss: 0.2168 - val_accuracy: 0.9702\n",
      "Epoch 341/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.9968 - val_loss: 0.2164 - val_accuracy: 0.9702\n",
      "Epoch 342/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1719 - accuracy: 0.9968 - val_loss: 0.2160 - val_accuracy: 0.9702\n",
      "Epoch 343/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1714 - accuracy: 0.9968 - val_loss: 0.2156 - val_accuracy: 0.9702\n",
      "Epoch 344/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1709 - accuracy: 0.9968 - val_loss: 0.2152 - val_accuracy: 0.9702\n",
      "Epoch 345/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.9968 - val_loss: 0.2148 - val_accuracy: 0.9702\n",
      "Epoch 346/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9968 - val_loss: 0.2144 - val_accuracy: 0.9702\n",
      "Epoch 347/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9968 - val_loss: 0.2140 - val_accuracy: 0.9702\n",
      "Epoch 348/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1690 - accuracy: 0.9968 - val_loss: 0.2137 - val_accuracy: 0.9702\n",
      "Epoch 349/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1686 - accuracy: 0.9968 - val_loss: 0.2130 - val_accuracy: 0.9702\n",
      "Epoch 350/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9968 - val_loss: 0.2128 - val_accuracy: 0.9702\n",
      "Epoch 351/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1676 - accuracy: 0.9968 - val_loss: 0.2123 - val_accuracy: 0.9702\n",
      "Epoch 352/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1672 - accuracy: 0.9968 - val_loss: 0.2119 - val_accuracy: 0.9702\n",
      "Epoch 353/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1667 - accuracy: 0.9968 - val_loss: 0.2117 - val_accuracy: 0.9702\n",
      "Epoch 354/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.9968 - val_loss: 0.2113 - val_accuracy: 0.9702\n",
      "Epoch 355/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.9968 - val_loss: 0.2108 - val_accuracy: 0.9702\n",
      "Epoch 356/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.9968 - val_loss: 0.2105 - val_accuracy: 0.9702\n",
      "Epoch 357/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1649 - accuracy: 0.9968 - val_loss: 0.2100 - val_accuracy: 0.9702\n",
      "Epoch 358/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1644 - accuracy: 0.9968 - val_loss: 0.2096 - val_accuracy: 0.9702\n",
      "Epoch 359/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.9968 - val_loss: 0.2093 - val_accuracy: 0.9702\n",
      "Epoch 360/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1635 - accuracy: 0.9968 - val_loss: 0.2088 - val_accuracy: 0.9702\n",
      "Epoch 361/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9968 - val_loss: 0.2083 - val_accuracy: 0.9702\n",
      "Epoch 362/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1626 - accuracy: 0.9968 - val_loss: 0.2081 - val_accuracy: 0.9702\n",
      "Epoch 363/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1621 - accuracy: 0.9968 - val_loss: 0.2078 - val_accuracy: 0.9702\n",
      "Epoch 364/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1617 - accuracy: 0.9968 - val_loss: 0.2074 - val_accuracy: 0.9702\n",
      "Epoch 365/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9968 - val_loss: 0.2070 - val_accuracy: 0.9702\n",
      "Epoch 366/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1608 - accuracy: 0.9968 - val_loss: 0.2066 - val_accuracy: 0.9702\n",
      "Epoch 367/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1604 - accuracy: 0.9968 - val_loss: 0.2062 - val_accuracy: 0.9702\n",
      "Epoch 368/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.9968 - val_loss: 0.2057 - val_accuracy: 0.9702\n",
      "Epoch 369/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.9968 - val_loss: 0.2055 - val_accuracy: 0.9702\n",
      "Epoch 370/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1590 - accuracy: 0.9968 - val_loss: 0.2051 - val_accuracy: 0.9702\n",
      "Epoch 371/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1586 - accuracy: 0.9968 - val_loss: 0.2045 - val_accuracy: 0.9702\n",
      "Epoch 372/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1581 - accuracy: 0.9968 - val_loss: 0.2043 - val_accuracy: 0.9702\n",
      "Epoch 373/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9968 - val_loss: 0.2040 - val_accuracy: 0.9702\n",
      "Epoch 374/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1573 - accuracy: 0.9968 - val_loss: 0.2036 - val_accuracy: 0.9702\n",
      "Epoch 375/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1568 - accuracy: 0.9968 - val_loss: 0.2032 - val_accuracy: 0.9702\n",
      "Epoch 376/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9968 - val_loss: 0.2029 - val_accuracy: 0.9702\n",
      "Epoch 377/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.9968 - val_loss: 0.2024 - val_accuracy: 0.9702\n",
      "Epoch 378/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1555 - accuracy: 0.9968 - val_loss: 0.2020 - val_accuracy: 0.9702\n",
      "Epoch 379/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1551 - accuracy: 0.9968 - val_loss: 0.2017 - val_accuracy: 0.9702\n",
      "Epoch 380/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9968 - val_loss: 0.2014 - val_accuracy: 0.9702\n",
      "Epoch 381/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9968 - val_loss: 0.2011 - val_accuracy: 0.9702\n",
      "Epoch 382/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1538 - accuracy: 0.9968 - val_loss: 0.2007 - val_accuracy: 0.9702\n",
      "Epoch 383/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1534 - accuracy: 0.9968 - val_loss: 0.2004 - val_accuracy: 0.9702\n",
      "Epoch 384/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.9968 - val_loss: 0.1999 - val_accuracy: 0.9702\n",
      "Epoch 385/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1526 - accuracy: 0.9968 - val_loss: 0.1996 - val_accuracy: 0.9702\n",
      "Epoch 386/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1522 - accuracy: 0.9968 - val_loss: 0.1991 - val_accuracy: 0.9702\n",
      "Epoch 387/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9968 - val_loss: 0.1989 - val_accuracy: 0.9702\n",
      "Epoch 388/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1513 - accuracy: 0.9968 - val_loss: 0.1986 - val_accuracy: 0.9702\n",
      "Epoch 389/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9968 - val_loss: 0.1980 - val_accuracy: 0.9702\n",
      "Epoch 390/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1505 - accuracy: 0.9968 - val_loss: 0.1977 - val_accuracy: 0.9702\n",
      "Epoch 391/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1501 - accuracy: 0.9968 - val_loss: 0.1974 - val_accuracy: 0.9702\n",
      "Epoch 392/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9968 - val_loss: 0.1970 - val_accuracy: 0.9702\n",
      "Epoch 393/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1493 - accuracy: 0.9968 - val_loss: 0.1968 - val_accuracy: 0.9702\n",
      "Epoch 394/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1489 - accuracy: 0.9968 - val_loss: 0.1964 - val_accuracy: 0.9702\n",
      "Epoch 395/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9968 - val_loss: 0.1962 - val_accuracy: 0.9702\n",
      "Epoch 396/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9968 - val_loss: 0.1958 - val_accuracy: 0.9702\n",
      "Epoch 397/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1477 - accuracy: 0.9968 - val_loss: 0.1954 - val_accuracy: 0.9702\n",
      "Epoch 398/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9968 - val_loss: 0.1951 - val_accuracy: 0.9702\n",
      "Epoch 399/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1469 - accuracy: 0.9968 - val_loss: 0.1947 - val_accuracy: 0.9702\n",
      "Epoch 400/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1465 - accuracy: 0.9968 - val_loss: 0.1946 - val_accuracy: 0.9702\n",
      "Epoch 401/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1461 - accuracy: 0.9968 - val_loss: 0.1941 - val_accuracy: 0.9702\n",
      "Epoch 402/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1457 - accuracy: 0.9968 - val_loss: 0.1938 - val_accuracy: 0.9702\n",
      "Epoch 403/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1453 - accuracy: 0.9968 - val_loss: 0.1934 - val_accuracy: 0.9702\n",
      "Epoch 404/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9968 - val_loss: 0.1931 - val_accuracy: 0.9702\n",
      "Epoch 405/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1445 - accuracy: 0.9968 - val_loss: 0.1926 - val_accuracy: 0.9702\n",
      "Epoch 406/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1441 - accuracy: 0.9968 - val_loss: 0.1925 - val_accuracy: 0.9702\n",
      "Epoch 407/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.9968 - val_loss: 0.1923 - val_accuracy: 0.9702\n",
      "Epoch 408/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1434 - accuracy: 0.9968 - val_loss: 0.1919 - val_accuracy: 0.9702\n",
      "Epoch 409/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1430 - accuracy: 0.9968 - val_loss: 0.1915 - val_accuracy: 0.9702\n",
      "Epoch 410/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9968 - val_loss: 0.1913 - val_accuracy: 0.9702\n",
      "Epoch 411/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1422 - accuracy: 0.9968 - val_loss: 0.1910 - val_accuracy: 0.9702\n",
      "Epoch 412/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1418 - accuracy: 0.9968 - val_loss: 0.1905 - val_accuracy: 0.9702\n",
      "Epoch 413/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1415 - accuracy: 0.9968 - val_loss: 0.1902 - val_accuracy: 0.9702\n",
      "Epoch 414/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9968 - val_loss: 0.1898 - val_accuracy: 0.9702\n",
      "Epoch 415/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1407 - accuracy: 0.9968 - val_loss: 0.1895 - val_accuracy: 0.9702\n",
      "Epoch 416/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1404 - accuracy: 0.9968 - val_loss: 0.1890 - val_accuracy: 0.9702\n",
      "Epoch 417/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1400 - accuracy: 0.9968 - val_loss: 0.1887 - val_accuracy: 0.9702\n",
      "Epoch 418/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1397 - accuracy: 0.9968 - val_loss: 0.1887 - val_accuracy: 0.9702\n",
      "Epoch 419/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1394 - accuracy: 0.9968 - val_loss: 0.1886 - val_accuracy: 0.9702\n",
      "Epoch 420/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.9968 - val_loss: 0.1883 - val_accuracy: 0.9702\n",
      "Epoch 421/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.9968 - val_loss: 0.1879 - val_accuracy: 0.9702\n",
      "Epoch 422/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1384 - accuracy: 0.9968 - val_loss: 0.1876 - val_accuracy: 0.9702\n",
      "Epoch 423/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.9968 - val_loss: 0.1872 - val_accuracy: 0.9702\n",
      "Epoch 424/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1377 - accuracy: 0.9968 - val_loss: 0.1868 - val_accuracy: 0.9702\n",
      "Epoch 425/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1374 - accuracy: 0.9968 - val_loss: 0.1867 - val_accuracy: 0.9702\n",
      "Epoch 426/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1371 - accuracy: 0.9968 - val_loss: 0.1864 - val_accuracy: 0.9702\n",
      "Epoch 427/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1367 - accuracy: 0.9968 - val_loss: 0.1861 - val_accuracy: 0.9702\n",
      "Epoch 428/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1364 - accuracy: 0.9968 - val_loss: 0.1857 - val_accuracy: 0.9702\n",
      "Epoch 429/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1361 - accuracy: 0.9968 - val_loss: 0.1857 - val_accuracy: 0.9702\n",
      "Epoch 430/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1357 - accuracy: 0.9968 - val_loss: 0.1852 - val_accuracy: 0.9702\n",
      "Epoch 431/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1354 - accuracy: 0.9968 - val_loss: 0.1851 - val_accuracy: 0.9702\n",
      "Epoch 432/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1351 - accuracy: 0.9968 - val_loss: 0.1848 - val_accuracy: 0.9702\n",
      "Epoch 433/800\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.1347 - accuracy: 0.9968 - val_loss: 0.1843 - val_accuracy: 0.9702\n",
      "Epoch 434/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1344 - accuracy: 0.9968 - val_loss: 0.1843 - val_accuracy: 0.9702\n",
      "Epoch 435/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1340 - accuracy: 0.9968 - val_loss: 0.1838 - val_accuracy: 0.9702\n",
      "Epoch 436/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1337 - accuracy: 0.9968 - val_loss: 0.1834 - val_accuracy: 0.9702\n",
      "Epoch 437/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1334 - accuracy: 0.9968 - val_loss: 0.1831 - val_accuracy: 0.9702\n",
      "Epoch 438/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1330 - accuracy: 0.9968 - val_loss: 0.1829 - val_accuracy: 0.9702\n",
      "Epoch 439/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1327 - accuracy: 0.9968 - val_loss: 0.1826 - val_accuracy: 0.9702\n",
      "Epoch 440/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.1324 - accuracy: 0.9968 - val_loss: 0.1823 - val_accuracy: 0.9702\n",
      "Epoch 441/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1320 - accuracy: 0.9968 - val_loss: 0.1821 - val_accuracy: 0.9702\n",
      "Epoch 442/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1317 - accuracy: 0.9968 - val_loss: 0.1819 - val_accuracy: 0.9702\n",
      "Epoch 443/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1314 - accuracy: 0.9968 - val_loss: 0.1817 - val_accuracy: 0.9702\n",
      "Epoch 444/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.1310 - accuracy: 0.9968 - val_loss: 0.1814 - val_accuracy: 0.9702\n",
      "Epoch 445/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9968 - val_loss: 0.1812 - val_accuracy: 0.9702\n",
      "Epoch 446/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1304 - accuracy: 0.9968 - val_loss: 0.1808 - val_accuracy: 0.9702\n",
      "Epoch 447/800\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.1300 - accuracy: 0.9968 - val_loss: 0.1805 - val_accuracy: 0.9702\n",
      "Epoch 448/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1297 - accuracy: 0.9968 - val_loss: 0.1804 - val_accuracy: 0.9702\n",
      "Epoch 449/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1294 - accuracy: 0.9968 - val_loss: 0.1800 - val_accuracy: 0.9702\n",
      "Epoch 450/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1290 - accuracy: 0.9968 - val_loss: 0.1796 - val_accuracy: 0.9702\n",
      "Epoch 451/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1287 - accuracy: 0.9968 - val_loss: 0.1798 - val_accuracy: 0.9702\n",
      "Epoch 452/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1284 - accuracy: 0.9968 - val_loss: 0.1793 - val_accuracy: 0.9702\n",
      "Epoch 453/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9968 - val_loss: 0.1793 - val_accuracy: 0.9702\n",
      "Epoch 454/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9968 - val_loss: 0.1790 - val_accuracy: 0.9702\n",
      "Epoch 455/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1274 - accuracy: 0.9968 - val_loss: 0.1788 - val_accuracy: 0.9702\n",
      "Epoch 456/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.9968 - val_loss: 0.1784 - val_accuracy: 0.9702\n",
      "Epoch 457/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1267 - accuracy: 0.9968 - val_loss: 0.1780 - val_accuracy: 0.9702\n",
      "Epoch 458/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1264 - accuracy: 0.9968 - val_loss: 0.1778 - val_accuracy: 0.9702\n",
      "Epoch 459/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1261 - accuracy: 0.9968 - val_loss: 0.1773 - val_accuracy: 0.9702\n",
      "Epoch 460/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1258 - accuracy: 0.9968 - val_loss: 0.1773 - val_accuracy: 0.9702\n",
      "Epoch 461/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.9968 - val_loss: 0.1771 - val_accuracy: 0.9702\n",
      "Epoch 462/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9968 - val_loss: 0.1770 - val_accuracy: 0.9702\n",
      "Epoch 463/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1248 - accuracy: 0.9968 - val_loss: 0.1763 - val_accuracy: 0.9702\n",
      "Epoch 464/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.9968 - val_loss: 0.1763 - val_accuracy: 0.9702\n",
      "Epoch 465/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9968 - val_loss: 0.1760 - val_accuracy: 0.9702\n",
      "Epoch 466/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9968 - val_loss: 0.1759 - val_accuracy: 0.9702\n",
      "Epoch 467/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9968 - val_loss: 0.1757 - val_accuracy: 0.9702\n",
      "Epoch 468/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.9968 - val_loss: 0.1754 - val_accuracy: 0.9702\n",
      "Epoch 469/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.9968 - val_loss: 0.1750 - val_accuracy: 0.9702\n",
      "Epoch 470/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9968 - val_loss: 0.1749 - val_accuracy: 0.9702\n",
      "Epoch 471/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9968 - val_loss: 0.1748 - val_accuracy: 0.9702\n",
      "Epoch 472/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9968 - val_loss: 0.1747 - val_accuracy: 0.9702\n",
      "Epoch 473/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 0.9968 - val_loss: 0.1744 - val_accuracy: 0.9702\n",
      "Epoch 474/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9968 - val_loss: 0.1742 - val_accuracy: 0.9702\n",
      "Epoch 475/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1211 - accuracy: 0.9968 - val_loss: 0.1739 - val_accuracy: 0.9702\n",
      "Epoch 476/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.9968 - val_loss: 0.1735 - val_accuracy: 0.9702\n",
      "Epoch 477/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.9968 - val_loss: 0.1733 - val_accuracy: 0.9702\n",
      "Epoch 478/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.9968 - val_loss: 0.1727 - val_accuracy: 0.9702\n",
      "Epoch 479/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9968 - val_loss: 0.1727 - val_accuracy: 0.9702\n",
      "Epoch 480/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9968 - val_loss: 0.1724 - val_accuracy: 0.9702\n",
      "Epoch 481/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.9968 - val_loss: 0.1722 - val_accuracy: 0.9702\n",
      "Epoch 482/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1189 - accuracy: 0.9968 - val_loss: 0.1717 - val_accuracy: 0.9702\n",
      "Epoch 483/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9968 - val_loss: 0.1720 - val_accuracy: 0.9702\n",
      "Epoch 484/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9968 - val_loss: 0.1715 - val_accuracy: 0.9702\n",
      "Epoch 485/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9968 - val_loss: 0.1712 - val_accuracy: 0.9702\n",
      "Epoch 486/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9968 - val_loss: 0.1710 - val_accuracy: 0.9702\n",
      "Epoch 487/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9968 - val_loss: 0.1709 - val_accuracy: 0.9702\n",
      "Epoch 488/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.9968 - val_loss: 0.1706 - val_accuracy: 0.9702\n",
      "Epoch 489/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9968 - val_loss: 0.1701 - val_accuracy: 0.9702\n",
      "Epoch 490/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9968 - val_loss: 0.1701 - val_accuracy: 0.9702\n",
      "Epoch 491/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.9968 - val_loss: 0.1697 - val_accuracy: 0.9702\n",
      "Epoch 492/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.9968 - val_loss: 0.1695 - val_accuracy: 0.9702\n",
      "Epoch 493/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9968 - val_loss: 0.1692 - val_accuracy: 0.9702\n",
      "Epoch 494/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9968 - val_loss: 0.1689 - val_accuracy: 0.9702\n",
      "Epoch 495/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.9968 - val_loss: 0.1690 - val_accuracy: 0.9702\n",
      "Epoch 496/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.9968 - val_loss: 0.1685 - val_accuracy: 0.9702\n",
      "Epoch 497/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1146 - accuracy: 0.9968 - val_loss: 0.1685 - val_accuracy: 0.9702\n",
      "Epoch 498/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.9968 - val_loss: 0.1682 - val_accuracy: 0.9702\n",
      "Epoch 499/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9968 - val_loss: 0.1681 - val_accuracy: 0.9702\n",
      "Epoch 500/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9968 - val_loss: 0.1677 - val_accuracy: 0.9702\n",
      "Epoch 501/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9968 - val_loss: 0.1675 - val_accuracy: 0.9702\n",
      "Epoch 502/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9968 - val_loss: 0.1673 - val_accuracy: 0.9702\n",
      "Epoch 503/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9968 - val_loss: 0.1672 - val_accuracy: 0.9702\n",
      "Epoch 504/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9968 - val_loss: 0.1670 - val_accuracy: 0.9702\n",
      "Epoch 505/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9968 - val_loss: 0.1668 - val_accuracy: 0.9702\n",
      "Epoch 506/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1120 - accuracy: 0.9968 - val_loss: 0.1666 - val_accuracy: 0.9702\n",
      "Epoch 507/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1118 - accuracy: 0.9968 - val_loss: 0.1666 - val_accuracy: 0.9702\n",
      "Epoch 508/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1115 - accuracy: 0.9968 - val_loss: 0.1663 - val_accuracy: 0.9702\n",
      "Epoch 509/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1112 - accuracy: 0.9968 - val_loss: 0.1658 - val_accuracy: 0.9702\n",
      "Epoch 510/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9968 - val_loss: 0.1656 - val_accuracy: 0.9702\n",
      "Epoch 511/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9968 - val_loss: 0.1656 - val_accuracy: 0.9702\n",
      "Epoch 512/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1104 - accuracy: 0.9968 - val_loss: 0.1654 - val_accuracy: 0.9702\n",
      "Epoch 513/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1101 - accuracy: 0.9968 - val_loss: 0.1649 - val_accuracy: 0.9702\n",
      "Epoch 514/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1099 - accuracy: 0.9968 - val_loss: 0.1650 - val_accuracy: 0.9702\n",
      "Epoch 515/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9968 - val_loss: 0.1648 - val_accuracy: 0.9702\n",
      "Epoch 516/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9968 - val_loss: 0.1647 - val_accuracy: 0.9702\n",
      "Epoch 517/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9968 - val_loss: 0.1646 - val_accuracy: 0.9702\n",
      "Epoch 518/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9968 - val_loss: 0.1642 - val_accuracy: 0.9702\n",
      "Epoch 519/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9968 - val_loss: 0.1640 - val_accuracy: 0.9702\n",
      "Epoch 520/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9968 - val_loss: 0.1639 - val_accuracy: 0.9702\n",
      "Epoch 521/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1080 - accuracy: 0.9968 - val_loss: 0.1638 - val_accuracy: 0.9702\n",
      "Epoch 522/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9968 - val_loss: 0.1636 - val_accuracy: 0.9702\n",
      "Epoch 523/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9968 - val_loss: 0.1634 - val_accuracy: 0.9702\n",
      "Epoch 524/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9968 - val_loss: 0.1629 - val_accuracy: 0.9702\n",
      "Epoch 525/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1070 - accuracy: 0.9968 - val_loss: 0.1628 - val_accuracy: 0.9702\n",
      "Epoch 526/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9968 - val_loss: 0.1625 - val_accuracy: 0.9702\n",
      "Epoch 527/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.9968 - val_loss: 0.1624 - val_accuracy: 0.9702\n",
      "Epoch 528/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1063 - accuracy: 0.9968 - val_loss: 0.1623 - val_accuracy: 0.9702\n",
      "Epoch 529/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1060 - accuracy: 0.9968 - val_loss: 0.1622 - val_accuracy: 0.9702\n",
      "Epoch 530/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9968 - val_loss: 0.1621 - val_accuracy: 0.9702\n",
      "Epoch 531/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9968 - val_loss: 0.1621 - val_accuracy: 0.9702\n",
      "Epoch 532/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9968 - val_loss: 0.1617 - val_accuracy: 0.9702\n",
      "Epoch 533/800\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.1051 - accuracy: 0.9968 - val_loss: 0.1616 - val_accuracy: 0.9702\n",
      "Epoch 534/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9968 - val_loss: 0.1615 - val_accuracy: 0.9702\n",
      "Epoch 535/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9968 - val_loss: 0.1613 - val_accuracy: 0.9702\n",
      "Epoch 536/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9968 - val_loss: 0.1609 - val_accuracy: 0.9702\n",
      "Epoch 537/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9968 - val_loss: 0.1608 - val_accuracy: 0.9702\n",
      "Epoch 538/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1040 - accuracy: 0.9968 - val_loss: 0.1605 - val_accuracy: 0.9702\n",
      "Epoch 539/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9968 - val_loss: 0.1604 - val_accuracy: 0.9702\n",
      "Epoch 540/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1035 - accuracy: 0.9968 - val_loss: 0.1602 - val_accuracy: 0.9702\n",
      "Epoch 541/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9968 - val_loss: 0.1600 - val_accuracy: 0.9702\n",
      "Epoch 542/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9968 - val_loss: 0.1598 - val_accuracy: 0.9702\n",
      "Epoch 543/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9968 - val_loss: 0.1596 - val_accuracy: 0.9702\n",
      "Epoch 544/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.9968 - val_loss: 0.1595 - val_accuracy: 0.9702\n",
      "Epoch 545/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9968 - val_loss: 0.1592 - val_accuracy: 0.9702\n",
      "Epoch 546/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9968 - val_loss: 0.1592 - val_accuracy: 0.9702\n",
      "Epoch 547/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9968 - val_loss: 0.1591 - val_accuracy: 0.9702\n",
      "Epoch 548/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.9968 - val_loss: 0.1589 - val_accuracy: 0.9702\n",
      "Epoch 549/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9968 - val_loss: 0.1588 - val_accuracy: 0.9702\n",
      "Epoch 550/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.1011 - accuracy: 0.9968 - val_loss: 0.1586 - val_accuracy: 0.9702\n",
      "Epoch 551/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1009 - accuracy: 0.9968 - val_loss: 0.1585 - val_accuracy: 0.9702\n",
      "Epoch 552/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1007 - accuracy: 0.9968 - val_loss: 0.1581 - val_accuracy: 0.9702\n",
      "Epoch 553/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9968 - val_loss: 0.1581 - val_accuracy: 0.9702\n",
      "Epoch 554/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.9968 - val_loss: 0.1580 - val_accuracy: 0.9702\n",
      "Epoch 555/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.9968 - val_loss: 0.1578 - val_accuracy: 0.9702\n",
      "Epoch 556/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9968 - val_loss: 0.1576 - val_accuracy: 0.9702\n",
      "Epoch 557/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9968 - val_loss: 0.1575 - val_accuracy: 0.9702\n",
      "Epoch 558/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9968 - val_loss: 0.1574 - val_accuracy: 0.9702\n",
      "Epoch 559/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9968 - val_loss: 0.1571 - val_accuracy: 0.9702\n",
      "Epoch 560/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9968 - val_loss: 0.1569 - val_accuracy: 0.9702\n",
      "Epoch 561/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9968 - val_loss: 0.1569 - val_accuracy: 0.9702\n",
      "Epoch 562/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9968 - val_loss: 0.1569 - val_accuracy: 0.9702\n",
      "Epoch 563/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0981 - accuracy: 0.9968 - val_loss: 0.1567 - val_accuracy: 0.9702\n",
      "Epoch 564/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0979 - accuracy: 0.9968 - val_loss: 0.1563 - val_accuracy: 0.9702\n",
      "Epoch 565/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0977 - accuracy: 0.9968 - val_loss: 0.1560 - val_accuracy: 0.9702\n",
      "Epoch 566/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0975 - accuracy: 0.9968 - val_loss: 0.1560 - val_accuracy: 0.9702\n",
      "Epoch 567/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9968 - val_loss: 0.1560 - val_accuracy: 0.9702\n",
      "Epoch 568/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9968 - val_loss: 0.1557 - val_accuracy: 0.9702\n",
      "Epoch 569/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9968 - val_loss: 0.1557 - val_accuracy: 0.9702\n",
      "Epoch 570/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0966 - accuracy: 0.9968 - val_loss: 0.1556 - val_accuracy: 0.9702\n",
      "Epoch 571/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9968 - val_loss: 0.1555 - val_accuracy: 0.9702\n",
      "Epoch 572/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9968 - val_loss: 0.1553 - val_accuracy: 0.9702\n",
      "Epoch 573/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9968 - val_loss: 0.1553 - val_accuracy: 0.9702\n",
      "Epoch 574/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0957 - accuracy: 0.9968 - val_loss: 0.1551 - val_accuracy: 0.9702\n",
      "Epoch 575/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9968 - val_loss: 0.1549 - val_accuracy: 0.9702\n",
      "Epoch 576/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9968 - val_loss: 0.1547 - val_accuracy: 0.9702\n",
      "Epoch 577/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0950 - accuracy: 0.9968 - val_loss: 0.1547 - val_accuracy: 0.9702\n",
      "Epoch 578/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9968 - val_loss: 0.1544 - val_accuracy: 0.9702\n",
      "Epoch 579/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9968 - val_loss: 0.1543 - val_accuracy: 0.9702\n",
      "Epoch 580/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9968 - val_loss: 0.1541 - val_accuracy: 0.9702\n",
      "Epoch 581/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0942 - accuracy: 0.9968 - val_loss: 0.1539 - val_accuracy: 0.9702\n",
      "Epoch 582/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9968 - val_loss: 0.1537 - val_accuracy: 0.9702\n",
      "Epoch 583/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9968 - val_loss: 0.1536 - val_accuracy: 0.9702\n",
      "Epoch 584/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0936 - accuracy: 0.9968 - val_loss: 0.1535 - val_accuracy: 0.9702\n",
      "Epoch 585/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0933 - accuracy: 0.9968 - val_loss: 0.1534 - val_accuracy: 0.9702\n",
      "Epoch 586/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9968 - val_loss: 0.1531 - val_accuracy: 0.9702\n",
      "Epoch 587/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9968 - val_loss: 0.1531 - val_accuracy: 0.9702\n",
      "Epoch 588/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9968 - val_loss: 0.1530 - val_accuracy: 0.9702\n",
      "Epoch 589/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9968 - val_loss: 0.1527 - val_accuracy: 0.9702\n",
      "Epoch 590/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9968 - val_loss: 0.1526 - val_accuracy: 0.9702\n",
      "Epoch 591/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0921 - accuracy: 0.9968 - val_loss: 0.1523 - val_accuracy: 0.9702\n",
      "Epoch 592/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9968 - val_loss: 0.1521 - val_accuracy: 0.9702\n",
      "Epoch 593/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9968 - val_loss: 0.1520 - val_accuracy: 0.9702\n",
      "Epoch 594/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9968 - val_loss: 0.1518 - val_accuracy: 0.9702\n",
      "Epoch 595/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0913 - accuracy: 0.9968 - val_loss: 0.1519 - val_accuracy: 0.9702\n",
      "Epoch 596/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9968 - val_loss: 0.1518 - val_accuracy: 0.9702\n",
      "Epoch 597/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9968 - val_loss: 0.1517 - val_accuracy: 0.9702\n",
      "Epoch 598/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0907 - accuracy: 0.9968 - val_loss: 0.1517 - val_accuracy: 0.9702\n",
      "Epoch 599/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9968 - val_loss: 0.1516 - val_accuracy: 0.9702\n",
      "Epoch 600/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9968 - val_loss: 0.1514 - val_accuracy: 0.9702\n",
      "Epoch 601/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0901 - accuracy: 0.9968 - val_loss: 0.1514 - val_accuracy: 0.9702\n",
      "Epoch 602/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0899 - accuracy: 0.9968 - val_loss: 0.1511 - val_accuracy: 0.9702\n",
      "Epoch 603/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0897 - accuracy: 0.9968 - val_loss: 0.1511 - val_accuracy: 0.9702\n",
      "Epoch 604/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0895 - accuracy: 0.9968 - val_loss: 0.1510 - val_accuracy: 0.9702\n",
      "Epoch 605/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0893 - accuracy: 0.9968 - val_loss: 0.1508 - val_accuracy: 0.9702\n",
      "Epoch 606/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9968 - val_loss: 0.1506 - val_accuracy: 0.9702\n",
      "Epoch 607/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9968 - val_loss: 0.1507 - val_accuracy: 0.9702\n",
      "Epoch 608/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9968 - val_loss: 0.1504 - val_accuracy: 0.9702\n",
      "Epoch 609/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0885 - accuracy: 0.9968 - val_loss: 0.1502 - val_accuracy: 0.9702\n",
      "Epoch 610/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0883 - accuracy: 0.9968 - val_loss: 0.1499 - val_accuracy: 0.9702\n",
      "Epoch 611/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9968 - val_loss: 0.1498 - val_accuracy: 0.9702\n",
      "Epoch 612/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9968 - val_loss: 0.1497 - val_accuracy: 0.9702\n",
      "Epoch 613/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9968 - val_loss: 0.1496 - val_accuracy: 0.9702\n",
      "Epoch 614/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9968 - val_loss: 0.1494 - val_accuracy: 0.9702\n",
      "Epoch 615/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0874 - accuracy: 0.9968 - val_loss: 0.1491 - val_accuracy: 0.9702\n",
      "Epoch 616/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9968 - val_loss: 0.1491 - val_accuracy: 0.9702\n",
      "Epoch 617/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9968 - val_loss: 0.1491 - val_accuracy: 0.9702\n",
      "Epoch 618/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0868 - accuracy: 0.9968 - val_loss: 0.1488 - val_accuracy: 0.9702\n",
      "Epoch 619/800\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0866 - accuracy: 0.9968 - val_loss: 0.1485 - val_accuracy: 0.9702\n",
      "Epoch 620/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0864 - accuracy: 0.9968 - val_loss: 0.1485 - val_accuracy: 0.9702\n",
      "Epoch 621/800\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.0863 - accuracy: 0.9968 - val_loss: 0.1482 - val_accuracy: 0.9702\n",
      "Epoch 622/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0861 - accuracy: 0.9968 - val_loss: 0.1482 - val_accuracy: 0.9702\n",
      "Epoch 623/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0859 - accuracy: 0.9968 - val_loss: 0.1481 - val_accuracy: 0.9702\n",
      "Epoch 624/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0857 - accuracy: 0.9968 - val_loss: 0.1479 - val_accuracy: 0.9702\n",
      "Epoch 625/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9968 - val_loss: 0.1479 - val_accuracy: 0.9702\n",
      "Epoch 626/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0853 - accuracy: 0.9968 - val_loss: 0.1476 - val_accuracy: 0.9702\n",
      "Epoch 627/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0852 - accuracy: 0.9968 - val_loss: 0.1477 - val_accuracy: 0.9702\n",
      "Epoch 628/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0850 - accuracy: 0.9968 - val_loss: 0.1476 - val_accuracy: 0.9702\n",
      "Epoch 629/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0848 - accuracy: 0.9968 - val_loss: 0.1473 - val_accuracy: 0.9702\n",
      "Epoch 630/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0846 - accuracy: 0.9968 - val_loss: 0.1470 - val_accuracy: 0.9702\n",
      "Epoch 631/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0845 - accuracy: 0.9968 - val_loss: 0.1467 - val_accuracy: 0.9702\n",
      "Epoch 632/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9968 - val_loss: 0.1465 - val_accuracy: 0.9702\n",
      "Epoch 633/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0841 - accuracy: 0.9968 - val_loss: 0.1464 - val_accuracy: 0.9702\n",
      "Epoch 634/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0839 - accuracy: 0.9968 - val_loss: 0.1465 - val_accuracy: 0.9702\n",
      "Epoch 635/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0837 - accuracy: 0.9968 - val_loss: 0.1464 - val_accuracy: 0.9702\n",
      "Epoch 636/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0836 - accuracy: 0.9968 - val_loss: 0.1463 - val_accuracy: 0.9702\n",
      "Epoch 637/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0834 - accuracy: 0.9968 - val_loss: 0.1462 - val_accuracy: 0.9702\n",
      "Epoch 638/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9968 - val_loss: 0.1461 - val_accuracy: 0.9702\n",
      "Epoch 639/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0831 - accuracy: 0.9968 - val_loss: 0.1461 - val_accuracy: 0.9702\n",
      "Epoch 640/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0829 - accuracy: 0.9968 - val_loss: 0.1459 - val_accuracy: 0.9702\n",
      "Epoch 641/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0827 - accuracy: 0.9968 - val_loss: 0.1456 - val_accuracy: 0.9702\n",
      "Epoch 642/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0825 - accuracy: 0.9968 - val_loss: 0.1455 - val_accuracy: 0.9702\n",
      "Epoch 643/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0824 - accuracy: 0.9968 - val_loss: 0.1457 - val_accuracy: 0.9702\n",
      "Epoch 644/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0822 - accuracy: 0.9968 - val_loss: 0.1455 - val_accuracy: 0.9702\n",
      "Epoch 645/800\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.0820 - accuracy: 0.9968 - val_loss: 0.1453 - val_accuracy: 0.9702\n",
      "Epoch 646/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0819 - accuracy: 0.9968 - val_loss: 0.1452 - val_accuracy: 0.9702\n",
      "Epoch 647/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0817 - accuracy: 0.9968 - val_loss: 0.1452 - val_accuracy: 0.9702\n",
      "Epoch 648/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9968 - val_loss: 0.1451 - val_accuracy: 0.9702\n",
      "Epoch 649/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9968 - val_loss: 0.1450 - val_accuracy: 0.9702\n",
      "Epoch 650/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9968 - val_loss: 0.1449 - val_accuracy: 0.9702\n",
      "Epoch 651/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9968 - val_loss: 0.1447 - val_accuracy: 0.9702\n",
      "Epoch 652/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9968 - val_loss: 0.1445 - val_accuracy: 0.9702\n",
      "Epoch 653/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9968 - val_loss: 0.1446 - val_accuracy: 0.9702\n",
      "Epoch 654/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9968 - val_loss: 0.1444 - val_accuracy: 0.9702\n",
      "Epoch 655/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0804 - accuracy: 0.9968 - val_loss: 0.1444 - val_accuracy: 0.9702\n",
      "Epoch 656/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9968 - val_loss: 0.1445 - val_accuracy: 0.9702\n",
      "Epoch 657/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9968 - val_loss: 0.1444 - val_accuracy: 0.9702\n",
      "Epoch 658/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9968 - val_loss: 0.1444 - val_accuracy: 0.9702\n",
      "Epoch 659/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9968 - val_loss: 0.1441 - val_accuracy: 0.9702\n",
      "Epoch 660/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9968 - val_loss: 0.1440 - val_accuracy: 0.9702\n",
      "Epoch 661/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9968 - val_loss: 0.1437 - val_accuracy: 0.9702\n",
      "Epoch 662/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0793 - accuracy: 0.9968 - val_loss: 0.1438 - val_accuracy: 0.9702\n",
      "Epoch 663/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0791 - accuracy: 0.9968 - val_loss: 0.1439 - val_accuracy: 0.9702\n",
      "Epoch 664/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0789 - accuracy: 0.9968 - val_loss: 0.1437 - val_accuracy: 0.9702\n",
      "Epoch 665/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0788 - accuracy: 0.9968 - val_loss: 0.1434 - val_accuracy: 0.9702\n",
      "Epoch 666/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9968 - val_loss: 0.1435 - val_accuracy: 0.9702\n",
      "Epoch 667/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9968 - val_loss: 0.1435 - val_accuracy: 0.9702\n",
      "Epoch 668/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9968 - val_loss: 0.1434 - val_accuracy: 0.9702\n",
      "Epoch 669/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9968 - val_loss: 0.1432 - val_accuracy: 0.9702\n",
      "Epoch 670/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0780 - accuracy: 0.9968 - val_loss: 0.1433 - val_accuracy: 0.9702\n",
      "Epoch 671/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9968 - val_loss: 0.1431 - val_accuracy: 0.9702\n",
      "Epoch 672/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9968 - val_loss: 0.1429 - val_accuracy: 0.9702\n",
      "Epoch 673/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9968 - val_loss: 0.1427 - val_accuracy: 0.9702\n",
      "Epoch 674/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0774 - accuracy: 0.9968 - val_loss: 0.1427 - val_accuracy: 0.9702\n",
      "Epoch 675/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0772 - accuracy: 0.9968 - val_loss: 0.1427 - val_accuracy: 0.9702\n",
      "Epoch 676/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0771 - accuracy: 0.9968 - val_loss: 0.1427 - val_accuracy: 0.9702\n",
      "Epoch 677/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0769 - accuracy: 0.9968 - val_loss: 0.1424 - val_accuracy: 0.9702\n",
      "Epoch 678/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9968 - val_loss: 0.1422 - val_accuracy: 0.9702\n",
      "Epoch 679/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0766 - accuracy: 0.9968 - val_loss: 0.1422 - val_accuracy: 0.9702\n",
      "Epoch 680/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9968 - val_loss: 0.1423 - val_accuracy: 0.9702\n",
      "Epoch 681/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9968 - val_loss: 0.1422 - val_accuracy: 0.9702\n",
      "Epoch 682/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9968 - val_loss: 0.1422 - val_accuracy: 0.9702\n",
      "Epoch 683/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9968 - val_loss: 0.1422 - val_accuracy: 0.9702\n",
      "Epoch 684/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9968 - val_loss: 0.1421 - val_accuracy: 0.9702\n",
      "Epoch 685/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9968 - val_loss: 0.1417 - val_accuracy: 0.9702\n",
      "Epoch 686/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9968 - val_loss: 0.1418 - val_accuracy: 0.9702\n",
      "Epoch 687/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9968 - val_loss: 0.1419 - val_accuracy: 0.9702\n",
      "Epoch 688/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0753 - accuracy: 0.9968 - val_loss: 0.1419 - val_accuracy: 0.9702\n",
      "Epoch 689/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0752 - accuracy: 0.9968 - val_loss: 0.1417 - val_accuracy: 0.9702\n",
      "Epoch 690/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9968 - val_loss: 0.1416 - val_accuracy: 0.9702\n",
      "Epoch 691/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9968 - val_loss: 0.1417 - val_accuracy: 0.9702\n",
      "Epoch 692/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0747 - accuracy: 0.9968 - val_loss: 0.1417 - val_accuracy: 0.9702\n",
      "Epoch 693/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9968 - val_loss: 0.1414 - val_accuracy: 0.9702\n",
      "Epoch 694/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0744 - accuracy: 0.9968 - val_loss: 0.1414 - val_accuracy: 0.9702\n",
      "Epoch 695/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0743 - accuracy: 0.9968 - val_loss: 0.1414 - val_accuracy: 0.9702\n",
      "Epoch 696/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0742 - accuracy: 0.9968 - val_loss: 0.1413 - val_accuracy: 0.9702\n",
      "Epoch 697/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0740 - accuracy: 0.9968 - val_loss: 0.1411 - val_accuracy: 0.9702\n",
      "Epoch 698/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0739 - accuracy: 0.9968 - val_loss: 0.1410 - val_accuracy: 0.9702\n",
      "Epoch 699/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9968 - val_loss: 0.1407 - val_accuracy: 0.9702\n",
      "Epoch 700/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9968 - val_loss: 0.1409 - val_accuracy: 0.9702\n",
      "Epoch 701/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0735 - accuracy: 0.9968 - val_loss: 0.1409 - val_accuracy: 0.9702\n",
      "Epoch 702/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9968 - val_loss: 0.1409 - val_accuracy: 0.9702\n",
      "Epoch 703/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9968 - val_loss: 0.1409 - val_accuracy: 0.9702\n",
      "Epoch 704/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9968 - val_loss: 0.1406 - val_accuracy: 0.9702\n",
      "Epoch 705/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0729 - accuracy: 0.9968 - val_loss: 0.1407 - val_accuracy: 0.9702\n",
      "Epoch 706/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9968 - val_loss: 0.1405 - val_accuracy: 0.9702\n",
      "Epoch 707/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9968 - val_loss: 0.1403 - val_accuracy: 0.9702\n",
      "Epoch 708/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9968 - val_loss: 0.1403 - val_accuracy: 0.9702\n",
      "Epoch 709/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9968 - val_loss: 0.1402 - val_accuracy: 0.9702\n",
      "Epoch 710/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9968 - val_loss: 0.1400 - val_accuracy: 0.9702\n",
      "Epoch 711/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.9968 - val_loss: 0.1400 - val_accuracy: 0.9702\n",
      "Epoch 712/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9968 - val_loss: 0.1399 - val_accuracy: 0.9702\n",
      "Epoch 713/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0718 - accuracy: 0.9968 - val_loss: 0.1398 - val_accuracy: 0.9702\n",
      "Epoch 714/800\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0717 - accuracy: 0.9968 - val_loss: 0.1397 - val_accuracy: 0.9702\n",
      "Epoch 715/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0716 - accuracy: 0.9968 - val_loss: 0.1399 - val_accuracy: 0.9702\n",
      "Epoch 716/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9968 - val_loss: 0.1397 - val_accuracy: 0.9702\n",
      "Epoch 717/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0713 - accuracy: 0.9968 - val_loss: 0.1396 - val_accuracy: 0.9702\n",
      "Epoch 718/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9968 - val_loss: 0.1394 - val_accuracy: 0.9702\n",
      "Epoch 719/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9968 - val_loss: 0.1395 - val_accuracy: 0.9702\n",
      "Epoch 720/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0709 - accuracy: 0.9968 - val_loss: 0.1393 - val_accuracy: 0.9702\n",
      "Epoch 721/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0708 - accuracy: 0.9968 - val_loss: 0.1393 - val_accuracy: 0.9702\n",
      "Epoch 722/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0706 - accuracy: 0.9968 - val_loss: 0.1390 - val_accuracy: 0.9702\n",
      "Epoch 723/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9968 - val_loss: 0.1389 - val_accuracy: 0.9702\n",
      "Epoch 724/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0704 - accuracy: 0.9968 - val_loss: 0.1389 - val_accuracy: 0.9702\n",
      "Epoch 725/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9968 - val_loss: 0.1390 - val_accuracy: 0.9702\n",
      "Epoch 726/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0701 - accuracy: 0.9968 - val_loss: 0.1390 - val_accuracy: 0.9702\n",
      "Epoch 727/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0700 - accuracy: 0.9968 - val_loss: 0.1390 - val_accuracy: 0.9702\n",
      "Epoch 728/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0699 - accuracy: 0.9968 - val_loss: 0.1389 - val_accuracy: 0.9702\n",
      "Epoch 729/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0697 - accuracy: 0.9968 - val_loss: 0.1390 - val_accuracy: 0.9702\n",
      "Epoch 730/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0696 - accuracy: 0.9968 - val_loss: 0.1389 - val_accuracy: 0.9702\n",
      "Epoch 731/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9968 - val_loss: 0.1387 - val_accuracy: 0.9702\n",
      "Epoch 732/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0694 - accuracy: 0.9968 - val_loss: 0.1385 - val_accuracy: 0.9702\n",
      "Epoch 733/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.9968 - val_loss: 0.1384 - val_accuracy: 0.9702\n",
      "Epoch 734/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0691 - accuracy: 0.9968 - val_loss: 0.1383 - val_accuracy: 0.9702\n",
      "Epoch 735/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9968 - val_loss: 0.1382 - val_accuracy: 0.9702\n",
      "Epoch 736/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9968 - val_loss: 0.1383 - val_accuracy: 0.9702\n",
      "Epoch 737/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0687 - accuracy: 0.9968 - val_loss: 0.1383 - val_accuracy: 0.9702\n",
      "Epoch 738/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0686 - accuracy: 0.9968 - val_loss: 0.1380 - val_accuracy: 0.9702\n",
      "Epoch 739/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9968 - val_loss: 0.1379 - val_accuracy: 0.9702\n",
      "Epoch 740/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0684 - accuracy: 0.9968 - val_loss: 0.1378 - val_accuracy: 0.9702\n",
      "Epoch 741/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0682 - accuracy: 0.9968 - val_loss: 0.1378 - val_accuracy: 0.9702\n",
      "Epoch 742/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9968 - val_loss: 0.1376 - val_accuracy: 0.9702\n",
      "Epoch 743/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9968 - val_loss: 0.1374 - val_accuracy: 0.9702\n",
      "Epoch 744/800\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0679 - accuracy: 0.9968 - val_loss: 0.1375 - val_accuracy: 0.9702\n",
      "Epoch 745/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9968 - val_loss: 0.1375 - val_accuracy: 0.9702\n",
      "Epoch 746/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0676 - accuracy: 0.9968 - val_loss: 0.1374 - val_accuracy: 0.9702\n",
      "Epoch 747/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9968 - val_loss: 0.1374 - val_accuracy: 0.9702\n",
      "Epoch 748/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9968 - val_loss: 0.1373 - val_accuracy: 0.9702\n",
      "Epoch 749/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9968 - val_loss: 0.1372 - val_accuracy: 0.9702\n",
      "Epoch 750/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0671 - accuracy: 0.9968 - val_loss: 0.1370 - val_accuracy: 0.9702\n",
      "Epoch 751/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9968 - val_loss: 0.1371 - val_accuracy: 0.9702\n",
      "Epoch 752/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9968 - val_loss: 0.1371 - val_accuracy: 0.9702\n",
      "Epoch 753/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.9968 - val_loss: 0.1370 - val_accuracy: 0.9702\n",
      "Epoch 754/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.9968 - val_loss: 0.1371 - val_accuracy: 0.9702\n",
      "Epoch 755/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.9968 - val_loss: 0.1371 - val_accuracy: 0.9702\n",
      "Epoch 756/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0664 - accuracy: 0.9968 - val_loss: 0.1368 - val_accuracy: 0.9702\n",
      "Epoch 757/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9968 - val_loss: 0.1370 - val_accuracy: 0.9702\n",
      "Epoch 758/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 0.9968 - val_loss: 0.1370 - val_accuracy: 0.9702\n",
      "Epoch 759/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9968 - val_loss: 0.1369 - val_accuracy: 0.9702\n",
      "Epoch 760/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0660 - accuracy: 0.9968 - val_loss: 0.1368 - val_accuracy: 0.9702\n",
      "Epoch 761/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9968 - val_loss: 0.1367 - val_accuracy: 0.9702\n",
      "Epoch 762/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0657 - accuracy: 0.9968 - val_loss: 0.1365 - val_accuracy: 0.9702\n",
      "Epoch 763/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9968 - val_loss: 0.1364 - val_accuracy: 0.9702\n",
      "Epoch 764/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9968 - val_loss: 0.1363 - val_accuracy: 0.9702\n",
      "Epoch 765/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9968 - val_loss: 0.1362 - val_accuracy: 0.9702\n",
      "Epoch 766/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0653 - accuracy: 0.9968 - val_loss: 0.1360 - val_accuracy: 0.9702\n",
      "Epoch 767/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.9968 - val_loss: 0.1360 - val_accuracy: 0.9702\n",
      "Epoch 768/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9968 - val_loss: 0.1358 - val_accuracy: 0.9702\n",
      "Epoch 769/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0650 - accuracy: 0.9968 - val_loss: 0.1358 - val_accuracy: 0.9702\n",
      "Epoch 770/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9968 - val_loss: 0.1357 - val_accuracy: 0.9702\n",
      "Epoch 771/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9968 - val_loss: 0.1357 - val_accuracy: 0.9702\n",
      "Epoch 772/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0646 - accuracy: 0.9968 - val_loss: 0.1356 - val_accuracy: 0.9702\n",
      "Epoch 773/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.9968 - val_loss: 0.1356 - val_accuracy: 0.9702\n",
      "Epoch 774/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0644 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 775/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 776/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0642 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 777/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 778/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0640 - accuracy: 0.9968 - val_loss: 0.1356 - val_accuracy: 0.9702\n",
      "Epoch 779/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 780/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 781/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9968 - val_loss: 0.1356 - val_accuracy: 0.9702\n",
      "Epoch 782/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0636 - accuracy: 0.9968 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 783/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9968 - val_loss: 0.1353 - val_accuracy: 0.9702\n",
      "Epoch 784/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9968 - val_loss: 0.1353 - val_accuracy: 0.9702\n",
      "Epoch 785/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0632 - accuracy: 0.9968 - val_loss: 0.1352 - val_accuracy: 0.9702\n",
      "Epoch 786/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9968 - val_loss: 0.1351 - val_accuracy: 0.9702\n",
      "Epoch 787/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9968 - val_loss: 0.1350 - val_accuracy: 0.9702\n",
      "Epoch 788/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0629 - accuracy: 0.9968 - val_loss: 0.1351 - val_accuracy: 0.9702\n",
      "Epoch 789/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9968 - val_loss: 0.1350 - val_accuracy: 0.9702\n",
      "Epoch 790/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0627 - accuracy: 0.9968 - val_loss: 0.1349 - val_accuracy: 0.9702\n",
      "Epoch 791/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0626 - accuracy: 0.9968 - val_loss: 0.1348 - val_accuracy: 0.9702\n",
      "Epoch 792/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9968 - val_loss: 0.1347 - val_accuracy: 0.9702\n",
      "Epoch 793/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9968 - val_loss: 0.1347 - val_accuracy: 0.9702\n",
      "Epoch 794/800\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0623 - accuracy: 0.9968 - val_loss: 0.1346 - val_accuracy: 0.9702\n",
      "Epoch 795/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9968 - val_loss: 0.1345 - val_accuracy: 0.9702\n",
      "Epoch 796/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.9968 - val_loss: 0.1345 - val_accuracy: 0.9702\n",
      "Epoch 797/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9968 - val_loss: 0.1343 - val_accuracy: 0.9702\n",
      "Epoch 798/800\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9968 - val_loss: 0.1343 - val_accuracy: 0.9702\n",
      "Epoch 799/800\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9968 - val_loss: 0.1343 - val_accuracy: 0.9702\n",
      "Epoch 800/800\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.0617 - accuracy: 0.9968 - val_loss: 0.1343 - val_accuracy: 0.9702\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, None, 32)          15232     \n",
      "                                                                 \n",
      " gru_15 (GRU)                (None, 32)                6336      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,603\n",
      "Trainable params: 21,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,input_shape=(None, x_train.shape[-1])))\n",
    "model.add(GRU(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)  \n",
    "# Definisco l'ottimizzatore con il learning rate iniziale\n",
    "#initial_learning_rate = 0.001\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate)\n",
    "\n",
    "# Definisco il learning rate schedule con decay lineare\n",
    "#decay_steps = 1000  # Numero di passi di addestramento dopo i quali applicare il decay\n",
    "#decay_rate = 0.1  # Tasso di decay\n",
    "#lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, decay_rate, staircase=True)\n",
    "\n",
    "# Aggiunta dello strato di output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Addestramento del modello con il learning rate modificato\n",
    "history = model.fit(x_train, y_train, epochs=800, batch_size=4, validation_data=(x_val, y_val))\n",
    "                    # callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule)])\n",
    "\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(train_loss))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, None, 32)          15232     \n",
      "                                                                 \n",
      " gru_15 (GRU)                (None, 32)                6336      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,603\n",
      "Trainable params: 21,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.1343 - accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# Valutazione del modello\n",
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
