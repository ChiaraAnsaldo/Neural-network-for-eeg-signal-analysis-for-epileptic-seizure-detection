{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.DatasetManage import read_and_store_data\n",
    "from ipynb.fs.full.FeatureExtraction import feature_extraction\n",
    "from ipynb.fs.full.ClassificationPerformanceIndexes import classificationPerformanceIndexes, printClassificationPerformanceIndexes\n",
    "from ipynb.fs.full.ClassificationMethods import CompleteLSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfInd = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'MCC', 'Kappa', 'Time']\n",
    "channels = ['FP1-F7', 'F7-T7','T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'seizure']\n",
    "\n",
    "dataset = 'CHB_MIT'\n",
    "csvImportFile = 'CHB.csv'\n",
    "csvExportFile = 'CHB.csv'\n",
    "sample_rate = 256\n",
    "time_window = 2\n",
    "step = time_window * sample_rate\n",
    "\n",
    "test_ratio = 0.3\n",
    "\n",
    "pca_tolerance = 0.9\n",
    "\n",
    "undersampling_rate = 0.2\n",
    "\n",
    "oversampling_neighbors = 11\n",
    "\n",
    "k_fold = 5\n",
    "\n",
    "csvAverageFile = 'Features.csv'\n",
    "\n",
    "batch = 10\n",
    "epochs = 100\n",
    "dropout_percentage = 0.2\n",
    "loss_function = 'mean_squared_error'\n",
    "metric = 'accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestData (features, test_ratio, k_fold, perfInd):\n",
    "    x = features.loc[:, features.columns != 'seizure']\n",
    "    y = features['seizure']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_ratio, shuffle = True)\n",
    "    results = pd.DataFrame(columns = perfInd)\n",
    "    kf = KFold(n_splits = k_fold, shuffle = True)\n",
    "    return x_train, x_test, y_train, y_test, results, kf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from CHB.csv\n"
     ]
    }
   ],
   "source": [
    "print('Reading data from', csvImportFile)\n",
    "df = pd.read_csv(csvImportFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft = feature_extraction(df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv(csvAverageFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, results, kf = trainTestData (ft, test_ratio, k_fold, perfInd)\n",
    "\n",
    "x_train = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "y_train = y_train.values.astype(int)\n",
    "x_test = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_test = y_test.values.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainTestData_2 (features, perfInd):\n",
    "    x = features.loc[:, features.columns != 'seizure']\n",
    "    y = features['seizure']\n",
    "    x_1, x_test, y_1, y_test = train_test_split(x, y, test_size = 0.3, random_state=42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_1, y_1, test_size=0.2, random_state=42)\n",
    "    results = pd.DataFrame(columns = perfInd)\n",
    "    return x_train, x_test, y_train, y_test, x_val, y_val, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 1, 86)\n",
      "(313,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, x_val, y_val, results = trainTestData_2 (ft, perfInd)\n",
    "\n",
    "x_train = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "y_train = y_train.values.astype(int)\n",
    "x_val = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_val = y_test.values.astype(int)\n",
    "x_test = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_test = y_test.values.astype(int)\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "40/40 [==============================] - 4s 21ms/step - loss: 0.7409 - accuracy: 0.4856 - val_loss: 0.7240 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7397 - accuracy: 0.4856 - val_loss: 0.7228 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7383 - accuracy: 0.4856 - val_loss: 0.7218 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7371 - accuracy: 0.4856 - val_loss: 0.7209 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7360 - accuracy: 0.4856 - val_loss: 0.7199 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7349 - accuracy: 0.4856 - val_loss: 0.7189 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7336 - accuracy: 0.4856 - val_loss: 0.7178 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7323 - accuracy: 0.4856 - val_loss: 0.7168 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7312 - accuracy: 0.4856 - val_loss: 0.7160 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7301 - accuracy: 0.4856 - val_loss: 0.7150 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7290 - accuracy: 0.4856 - val_loss: 0.7141 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7279 - accuracy: 0.4856 - val_loss: 0.7133 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7269 - accuracy: 0.4856 - val_loss: 0.7125 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7258 - accuracy: 0.4856 - val_loss: 0.7117 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7250 - accuracy: 0.4856 - val_loss: 0.7110 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7241 - accuracy: 0.4856 - val_loss: 0.7102 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7231 - accuracy: 0.4856 - val_loss: 0.7095 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7222 - accuracy: 0.4856 - val_loss: 0.7088 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.4856 - val_loss: 0.7082 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7206 - accuracy: 0.4856 - val_loss: 0.7076 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7198 - accuracy: 0.4856 - val_loss: 0.7068 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7190 - accuracy: 0.4856 - val_loss: 0.7063 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7182 - accuracy: 0.4856 - val_loss: 0.7056 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7173 - accuracy: 0.4856 - val_loss: 0.7050 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7166 - accuracy: 0.4856 - val_loss: 0.7043 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7158 - accuracy: 0.4856 - val_loss: 0.7037 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7150 - accuracy: 0.4856 - val_loss: 0.7031 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7142 - accuracy: 0.4856 - val_loss: 0.7026 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7136 - accuracy: 0.4856 - val_loss: 0.7020 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.7129 - accuracy: 0.4856 - val_loss: 0.7015 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7123 - accuracy: 0.4856 - val_loss: 0.7011 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.4856 - val_loss: 0.7005 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7110 - accuracy: 0.4856 - val_loss: 0.7000 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7103 - accuracy: 0.4856 - val_loss: 0.6995 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7096 - accuracy: 0.4856 - val_loss: 0.6990 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7089 - accuracy: 0.4856 - val_loss: 0.6986 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7084 - accuracy: 0.4856 - val_loss: 0.6981 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7078 - accuracy: 0.4856 - val_loss: 0.6976 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.4856 - val_loss: 0.6972 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7066 - accuracy: 0.4856 - val_loss: 0.6967 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7060 - accuracy: 0.4856 - val_loss: 0.6964 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7056 - accuracy: 0.4856 - val_loss: 0.6960 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7050 - accuracy: 0.4856 - val_loss: 0.6956 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.7046 - accuracy: 0.4856 - val_loss: 0.6952 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7040 - accuracy: 0.4856 - val_loss: 0.6948 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.4856 - val_loss: 0.6945 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7031 - accuracy: 0.4856 - val_loss: 0.6942 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7026 - accuracy: 0.4856 - val_loss: 0.6938 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.4856 - val_loss: 0.6935 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.4856 - val_loss: 0.6932 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.7013 - accuracy: 0.4856 - val_loss: 0.6929 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.4856 - val_loss: 0.6926 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7005 - accuracy: 0.4856 - val_loss: 0.6923 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.7000 - accuracy: 0.4856 - val_loss: 0.6920 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6996 - accuracy: 0.4856 - val_loss: 0.6917 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.4856 - val_loss: 0.6915 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6989 - accuracy: 0.4856 - val_loss: 0.6912 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6986 - accuracy: 0.4856 - val_loss: 0.6909 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6982 - accuracy: 0.4856 - val_loss: 0.6907 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6979 - accuracy: 0.4856 - val_loss: 0.6905 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.4856 - val_loss: 0.6902 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6972 - accuracy: 0.4856 - val_loss: 0.6900 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.4856 - val_loss: 0.6898 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.4856 - val_loss: 0.6895 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.4856 - val_loss: 0.6893 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6960 - accuracy: 0.4856 - val_loss: 0.6891 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.4856 - val_loss: 0.6889 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6953 - accuracy: 0.4856 - val_loss: 0.6886 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.4856 - val_loss: 0.6884 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6947 - accuracy: 0.4856 - val_loss: 0.6882 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.4856 - val_loss: 0.6881 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.4856 - val_loss: 0.6878 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.4856 - val_loss: 0.6877 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.4856 - val_loss: 0.6875 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.4856 - val_loss: 0.6873 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.4856 - val_loss: 0.6871 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6928 - accuracy: 0.4856 - val_loss: 0.6869 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.4856 - val_loss: 0.6867 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.4856 - val_loss: 0.6866 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.4856 - val_loss: 0.6864 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.4856 - val_loss: 0.6863 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6915 - accuracy: 0.4856 - val_loss: 0.6861 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.4856 - val_loss: 0.6860 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.4856 - val_loss: 0.6858 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.4856 - val_loss: 0.6857 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.4856 - val_loss: 0.6855 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.4856 - val_loss: 0.6854 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6902 - accuracy: 0.4856 - val_loss: 0.6853 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.4856 - val_loss: 0.6851 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.4856 - val_loss: 0.6850 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.4856 - val_loss: 0.6848 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6894 - accuracy: 0.4856 - val_loss: 0.6847 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6892 - accuracy: 0.4856 - val_loss: 0.6846 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.4856 - val_loss: 0.6844 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.4856 - val_loss: 0.6843 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.4856 - val_loss: 0.6842 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.6884 - accuracy: 0.4856 - val_loss: 0.6841 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6883 - accuracy: 0.4856 - val_loss: 0.6839 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.4856 - val_loss: 0.6838 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.4856 - val_loss: 0.6837 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.4856 - val_loss: 0.6836 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.4856 - val_loss: 0.6835 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6874 - accuracy: 0.4856 - val_loss: 0.6834 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6873 - accuracy: 0.4856 - val_loss: 0.6833 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.4856 - val_loss: 0.6831 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.4856 - val_loss: 0.6830 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6867 - accuracy: 0.4888 - val_loss: 0.6829 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6866 - accuracy: 0.4888 - val_loss: 0.6828 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.4888 - val_loss: 0.6827 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.4888 - val_loss: 0.6826 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6861 - accuracy: 0.4888 - val_loss: 0.6825 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6860 - accuracy: 0.4888 - val_loss: 0.6824 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6858 - accuracy: 0.4888 - val_loss: 0.6823 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6856 - accuracy: 0.4920 - val_loss: 0.6822 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6855 - accuracy: 0.4920 - val_loss: 0.6821 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6854 - accuracy: 0.4952 - val_loss: 0.6820 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6852 - accuracy: 0.4952 - val_loss: 0.6819 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6851 - accuracy: 0.4984 - val_loss: 0.6818 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6849 - accuracy: 0.4984 - val_loss: 0.6817 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6848 - accuracy: 0.4984 - val_loss: 0.6816 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.4984 - val_loss: 0.6815 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6846 - accuracy: 0.4984 - val_loss: 0.6814 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6845 - accuracy: 0.4984 - val_loss: 0.6813 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6843 - accuracy: 0.4984 - val_loss: 0.6812 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6842 - accuracy: 0.5016 - val_loss: 0.6811 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6840 - accuracy: 0.5016 - val_loss: 0.6810 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.5048 - val_loss: 0.6809 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.5048 - val_loss: 0.6808 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6836 - accuracy: 0.5112 - val_loss: 0.6807 - val_accuracy: 0.5357 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.5176 - val_loss: 0.6806 - val_accuracy: 0.5476 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6833 - accuracy: 0.5176 - val_loss: 0.6805 - val_accuracy: 0.5476 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6832 - accuracy: 0.5176 - val_loss: 0.6804 - val_accuracy: 0.5476 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.5208 - val_loss: 0.6803 - val_accuracy: 0.5595 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5367 - val_loss: 0.6802 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6828 - accuracy: 0.5367 - val_loss: 0.6801 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6827 - accuracy: 0.5463 - val_loss: 0.6800 - val_accuracy: 0.6012 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.5559 - val_loss: 0.6799 - val_accuracy: 0.6012 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6824 - accuracy: 0.5559 - val_loss: 0.6798 - val_accuracy: 0.6012 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5655 - val_loss: 0.6797 - val_accuracy: 0.6131 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6822 - accuracy: 0.5815 - val_loss: 0.6796 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6821 - accuracy: 0.5847 - val_loss: 0.6795 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.5911 - val_loss: 0.6795 - val_accuracy: 0.6369 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5942 - val_loss: 0.6794 - val_accuracy: 0.6429 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.6006 - val_loss: 0.6793 - val_accuracy: 0.6488 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.6230 - val_loss: 0.6792 - val_accuracy: 0.6548 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6815 - accuracy: 0.6262 - val_loss: 0.6791 - val_accuracy: 0.6726 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6813 - accuracy: 0.6358 - val_loss: 0.6790 - val_accuracy: 0.6786 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.6454 - val_loss: 0.6789 - val_accuracy: 0.6905 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.6613 - val_loss: 0.6788 - val_accuracy: 0.7083 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6810 - accuracy: 0.6677 - val_loss: 0.6787 - val_accuracy: 0.7143 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6808 - accuracy: 0.6709 - val_loss: 0.6786 - val_accuracy: 0.7202 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6807 - accuracy: 0.6741 - val_loss: 0.6785 - val_accuracy: 0.7202 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.6741 - val_loss: 0.6784 - val_accuracy: 0.7202 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6805 - accuracy: 0.7220 - val_loss: 0.6784 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.7316 - val_loss: 0.6783 - val_accuracy: 0.7321 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.7348 - val_loss: 0.6782 - val_accuracy: 0.7381 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.7348 - val_loss: 0.6781 - val_accuracy: 0.7381 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6800 - accuracy: 0.7412 - val_loss: 0.6780 - val_accuracy: 0.7381 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6799 - accuracy: 0.7412 - val_loss: 0.6779 - val_accuracy: 0.7381 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.7508 - val_loss: 0.6778 - val_accuracy: 0.7560 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.7508 - val_loss: 0.6777 - val_accuracy: 0.7619 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.7476 - val_loss: 0.6776 - val_accuracy: 0.7619 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.7508 - val_loss: 0.6775 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.7540 - val_loss: 0.6774 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6792 - accuracy: 0.7540 - val_loss: 0.6773 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.7540 - val_loss: 0.6772 - val_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.7508 - val_loss: 0.6771 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.7604 - val_loss: 0.6770 - val_accuracy: 0.7976 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.7604 - val_loss: 0.6769 - val_accuracy: 0.7976 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6786 - accuracy: 0.7636 - val_loss: 0.6768 - val_accuracy: 0.8095 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.7668 - val_loss: 0.6767 - val_accuracy: 0.8095 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6784 - accuracy: 0.7668 - val_loss: 0.6766 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6783 - accuracy: 0.7668 - val_loss: 0.6765 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.7636 - val_loss: 0.6764 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6780 - accuracy: 0.7636 - val_loss: 0.6764 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6779 - accuracy: 0.7668 - val_loss: 0.6763 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6778 - accuracy: 0.7604 - val_loss: 0.6762 - val_accuracy: 0.8214 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.7732 - val_loss: 0.6761 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6776 - accuracy: 0.7764 - val_loss: 0.6760 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6775 - accuracy: 0.7764 - val_loss: 0.6758 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.7764 - val_loss: 0.6758 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6772 - accuracy: 0.7796 - val_loss: 0.6756 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.7732 - val_loss: 0.6755 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.7732 - val_loss: 0.6754 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6769 - accuracy: 0.7764 - val_loss: 0.6753 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6768 - accuracy: 0.7796 - val_loss: 0.6752 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6767 - accuracy: 0.7859 - val_loss: 0.6751 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6765 - accuracy: 0.7923 - val_loss: 0.6750 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.7891 - val_loss: 0.6749 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6763 - accuracy: 0.8019 - val_loss: 0.6748 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 191/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.8051 - val_loss: 0.6747 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 192/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.8019 - val_loss: 0.6746 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 193/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.6760 - accuracy: 0.8051 - val_loss: 0.6745 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 194/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6758 - accuracy: 0.8083 - val_loss: 0.6744 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 195/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6757 - accuracy: 0.8083 - val_loss: 0.6743 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 196/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6756 - accuracy: 0.8083 - val_loss: 0.6742 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 197/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.8115 - val_loss: 0.6741 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 198/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6754 - accuracy: 0.8115 - val_loss: 0.6740 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 199/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6753 - accuracy: 0.8179 - val_loss: 0.6738 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 200/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6751 - accuracy: 0.8179 - val_loss: 0.6737 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 201/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6750 - accuracy: 0.8179 - val_loss: 0.6736 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 202/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6749 - accuracy: 0.8211 - val_loss: 0.6735 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 203/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6748 - accuracy: 0.8211 - val_loss: 0.6734 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 204/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6747 - accuracy: 0.8179 - val_loss: 0.6733 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 205/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6745 - accuracy: 0.8211 - val_loss: 0.6732 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 206/1000\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 0.6744 - accuracy: 0.8179 - val_loss: 0.6731 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 207/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6743 - accuracy: 0.8179 - val_loss: 0.6730 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 208/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6742 - accuracy: 0.8211 - val_loss: 0.6729 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 209/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6740 - accuracy: 0.8307 - val_loss: 0.6728 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 210/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6739 - accuracy: 0.8371 - val_loss: 0.6727 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 211/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.8371 - val_loss: 0.6725 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 212/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6737 - accuracy: 0.8307 - val_loss: 0.6724 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 213/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6735 - accuracy: 0.8307 - val_loss: 0.6723 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 214/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6734 - accuracy: 0.8339 - val_loss: 0.6722 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 215/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.8339 - val_loss: 0.6721 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 216/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6732 - accuracy: 0.8339 - val_loss: 0.6719 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 217/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6730 - accuracy: 0.8339 - val_loss: 0.6718 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 218/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6729 - accuracy: 0.8339 - val_loss: 0.6717 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 219/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.8466 - val_loss: 0.6716 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 220/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.8339 - val_loss: 0.6715 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 221/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6725 - accuracy: 0.8466 - val_loss: 0.6714 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 222/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6724 - accuracy: 0.8466 - val_loss: 0.6712 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 223/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.8435 - val_loss: 0.6711 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 224/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.8435 - val_loss: 0.6710 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 225/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6720 - accuracy: 0.8435 - val_loss: 0.6709 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 226/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6719 - accuracy: 0.8435 - val_loss: 0.6708 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 227/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6718 - accuracy: 0.8403 - val_loss: 0.6706 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 228/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6716 - accuracy: 0.8403 - val_loss: 0.6705 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 229/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6715 - accuracy: 0.8466 - val_loss: 0.6703 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 230/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6714 - accuracy: 0.8466 - val_loss: 0.6702 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 231/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6712 - accuracy: 0.8466 - val_loss: 0.6701 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 232/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.8435 - val_loss: 0.6700 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 233/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6710 - accuracy: 0.8466 - val_loss: 0.6698 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 234/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.6708 - accuracy: 0.8435 - val_loss: 0.6697 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 235/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 0.8466 - val_loss: 0.6696 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 236/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6706 - accuracy: 0.8466 - val_loss: 0.6694 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 237/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6704 - accuracy: 0.8498 - val_loss: 0.6693 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 238/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6703 - accuracy: 0.8466 - val_loss: 0.6692 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 239/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6702 - accuracy: 0.8466 - val_loss: 0.6690 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 240/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6700 - accuracy: 0.8466 - val_loss: 0.6689 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 241/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6699 - accuracy: 0.8530 - val_loss: 0.6688 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 242/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6698 - accuracy: 0.8466 - val_loss: 0.6686 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 243/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6696 - accuracy: 0.8498 - val_loss: 0.6685 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 244/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6695 - accuracy: 0.8498 - val_loss: 0.6684 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 245/1000\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.8498 - val_loss: 0.6682 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 246/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6692 - accuracy: 0.8498 - val_loss: 0.6681 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 247/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6691 - accuracy: 0.8498 - val_loss: 0.6680 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 248/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6689 - accuracy: 0.8498 - val_loss: 0.6678 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 249/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6688 - accuracy: 0.8498 - val_loss: 0.6677 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 250/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6686 - accuracy: 0.8530 - val_loss: 0.6675 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 251/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6685 - accuracy: 0.8498 - val_loss: 0.6674 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 252/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6684 - accuracy: 0.8498 - val_loss: 0.6673 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 253/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6682 - accuracy: 0.8498 - val_loss: 0.6671 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 254/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6681 - accuracy: 0.8498 - val_loss: 0.6670 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 255/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6679 - accuracy: 0.8498 - val_loss: 0.6668 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 256/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6678 - accuracy: 0.8498 - val_loss: 0.6666 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 257/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6676 - accuracy: 0.8498 - val_loss: 0.6665 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 258/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6675 - accuracy: 0.8530 - val_loss: 0.6664 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 259/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6673 - accuracy: 0.8498 - val_loss: 0.6662 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 260/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6672 - accuracy: 0.8498 - val_loss: 0.6660 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 261/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6671 - accuracy: 0.8498 - val_loss: 0.6659 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 262/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6669 - accuracy: 0.8562 - val_loss: 0.6657 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 263/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6668 - accuracy: 0.8498 - val_loss: 0.6656 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 264/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6666 - accuracy: 0.8498 - val_loss: 0.6654 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 265/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6665 - accuracy: 0.8562 - val_loss: 0.6653 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 266/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6663 - accuracy: 0.8530 - val_loss: 0.6651 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 267/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6662 - accuracy: 0.8498 - val_loss: 0.6650 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 268/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6660 - accuracy: 0.8562 - val_loss: 0.6648 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 269/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6658 - accuracy: 0.8530 - val_loss: 0.6647 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 270/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6657 - accuracy: 0.8530 - val_loss: 0.6645 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 271/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6655 - accuracy: 0.8562 - val_loss: 0.6644 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 272/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6654 - accuracy: 0.8594 - val_loss: 0.6642 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 273/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6652 - accuracy: 0.8562 - val_loss: 0.6641 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 274/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.8530 - val_loss: 0.6639 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 275/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6649 - accuracy: 0.8530 - val_loss: 0.6637 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 276/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6647 - accuracy: 0.8562 - val_loss: 0.6636 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 277/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6646 - accuracy: 0.8562 - val_loss: 0.6634 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 278/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6644 - accuracy: 0.8562 - val_loss: 0.6633 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 279/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.8594 - val_loss: 0.6631 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 280/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6641 - accuracy: 0.8562 - val_loss: 0.6629 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 281/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6639 - accuracy: 0.8562 - val_loss: 0.6627 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 282/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6638 - accuracy: 0.8562 - val_loss: 0.6626 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 283/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.8594 - val_loss: 0.6624 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 284/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6634 - accuracy: 0.8594 - val_loss: 0.6622 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 285/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6632 - accuracy: 0.8594 - val_loss: 0.6620 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 286/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.8594 - val_loss: 0.6618 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 287/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6629 - accuracy: 0.8626 - val_loss: 0.6617 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 288/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6627 - accuracy: 0.8626 - val_loss: 0.6615 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 289/1000\n",
      " 1/40 [..............................] - ETA: 0s - loss: 0.6570 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Aggiunta dello strato GRU\n",
    "model.add(GRU(32, input_shape=(None,  x_train.shape[-1]), return_sequences=True))\n",
    "\n",
    "# Aggiunta dello strato LSTM\n",
    "model.add(LSTM(64))\n",
    "\n",
    "\n",
    "# Aggiunta dello strato di output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Definisco l'ottimizzatore con il learning rate iniziale\n",
    "initial_learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate)\n",
    "\n",
    "# Definisco il learning rate schedule con decay lineare\n",
    "decay_steps = 1000  # Numero di passi di addestramento dopo i quali applicare il decay\n",
    "decay_rate = 0.1  # Tasso di decay\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, decay_rate, staircase=True)\n",
    "\n",
    "# Aggiunta dello strato di output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Addestramento del modello con il learning rate modificato\n",
    "history = model.fit(x_train, y_train, epochs=1000, batch_size=8, validation_data=(x_val, y_val), callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule)])\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(train_loss))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 layer (optimizer SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 3s 10ms/step - loss: 0.6339 - accuracy: 0.7572 - val_loss: 0.5846 - val_accuracy: 0.8333\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.8051 - val_loss: 0.5453 - val_accuracy: 0.8571\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.8339 - val_loss: 0.5132 - val_accuracy: 0.8750\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8530 - val_loss: 0.4863 - val_accuracy: 0.8869\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.8658 - val_loss: 0.4635 - val_accuracy: 0.8988\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8690 - val_loss: 0.4441 - val_accuracy: 0.9048\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8850 - val_loss: 0.4273 - val_accuracy: 0.9048\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8818 - val_loss: 0.4125 - val_accuracy: 0.9048\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8850 - val_loss: 0.3994 - val_accuracy: 0.9048\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8850 - val_loss: 0.3877 - val_accuracy: 0.9048\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8946 - val_loss: 0.3770 - val_accuracy: 0.9048\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8946 - val_loss: 0.3673 - val_accuracy: 0.9048\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8978 - val_loss: 0.3584 - val_accuracy: 0.9048\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8978 - val_loss: 0.3502 - val_accuracy: 0.9048\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8978 - val_loss: 0.3427 - val_accuracy: 0.9048\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3519 - accuracy: 0.8978 - val_loss: 0.3357 - val_accuracy: 0.9048\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8978 - val_loss: 0.3292 - val_accuracy: 0.9048\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8978 - val_loss: 0.3230 - val_accuracy: 0.9107\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8978 - val_loss: 0.3173 - val_accuracy: 0.9107\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.9042 - val_loss: 0.3119 - val_accuracy: 0.9107\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.9073 - val_loss: 0.3069 - val_accuracy: 0.9107\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.9137 - val_loss: 0.3021 - val_accuracy: 0.9107\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.9137 - val_loss: 0.2976 - val_accuracy: 0.9167\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.9169 - val_loss: 0.2933 - val_accuracy: 0.9167\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.9169 - val_loss: 0.2892 - val_accuracy: 0.9167\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.9169 - val_loss: 0.2854 - val_accuracy: 0.9167\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.9201 - val_loss: 0.2817 - val_accuracy: 0.9167\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.9201 - val_loss: 0.2782 - val_accuracy: 0.9167\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9201 - val_loss: 0.2749 - val_accuracy: 0.9167\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.9201 - val_loss: 0.2717 - val_accuracy: 0.9167\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.9201 - val_loss: 0.2687 - val_accuracy: 0.9167\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.9201 - val_loss: 0.2658 - val_accuracy: 0.9167\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.9201 - val_loss: 0.2630 - val_accuracy: 0.9167\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.9201 - val_loss: 0.2604 - val_accuracy: 0.9167\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.9201 - val_loss: 0.2578 - val_accuracy: 0.9167\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.9201 - val_loss: 0.2554 - val_accuracy: 0.9167\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2633 - accuracy: 0.9201 - val_loss: 0.2530 - val_accuracy: 0.9167\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2608 - accuracy: 0.9201 - val_loss: 0.2507 - val_accuracy: 0.9226\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.9201 - val_loss: 0.2486 - val_accuracy: 0.9226\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.9201 - val_loss: 0.2465 - val_accuracy: 0.9226\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9233 - val_loss: 0.2444 - val_accuracy: 0.9226\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9233 - val_loss: 0.2425 - val_accuracy: 0.9226\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.9233 - val_loss: 0.2406 - val_accuracy: 0.9226\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9233 - val_loss: 0.2388 - val_accuracy: 0.9226\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2451 - accuracy: 0.9233 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9233 - val_loss: 0.2353 - val_accuracy: 0.9286\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9233 - val_loss: 0.2337 - val_accuracy: 0.9286\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2394 - accuracy: 0.9233 - val_loss: 0.2321 - val_accuracy: 0.9286\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2376 - accuracy: 0.9233 - val_loss: 0.2306 - val_accuracy: 0.9286\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2358 - accuracy: 0.9233 - val_loss: 0.2291 - val_accuracy: 0.9286\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2341 - accuracy: 0.9233 - val_loss: 0.2276 - val_accuracy: 0.9286\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9233 - val_loss: 0.2262 - val_accuracy: 0.9286\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.9233 - val_loss: 0.2248 - val_accuracy: 0.9345\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.9233 - val_loss: 0.2234 - val_accuracy: 0.9345\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.9233 - val_loss: 0.2221 - val_accuracy: 0.9345\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9233 - val_loss: 0.2208 - val_accuracy: 0.9345\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2248 - accuracy: 0.9233 - val_loss: 0.2196 - val_accuracy: 0.9345\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2233 - accuracy: 0.9265 - val_loss: 0.2184 - val_accuracy: 0.9345\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9265 - val_loss: 0.2172 - val_accuracy: 0.9345\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2206 - accuracy: 0.9297 - val_loss: 0.2160 - val_accuracy: 0.9345\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9297 - val_loss: 0.2149 - val_accuracy: 0.9345\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2179 - accuracy: 0.9297 - val_loss: 0.2138 - val_accuracy: 0.9345\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2166 - accuracy: 0.9297 - val_loss: 0.2127 - val_accuracy: 0.9345\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2154 - accuracy: 0.9297 - val_loss: 0.2117 - val_accuracy: 0.9345\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2142 - accuracy: 0.9297 - val_loss: 0.2107 - val_accuracy: 0.9345\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2130 - accuracy: 0.9297 - val_loss: 0.2097 - val_accuracy: 0.9345\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2118 - accuracy: 0.9297 - val_loss: 0.2087 - val_accuracy: 0.9345\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.9297 - val_loss: 0.2078 - val_accuracy: 0.9345\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2095 - accuracy: 0.9297 - val_loss: 0.2069 - val_accuracy: 0.9345\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9297 - val_loss: 0.2060 - val_accuracy: 0.9405\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9297 - val_loss: 0.2051 - val_accuracy: 0.9464\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9297 - val_loss: 0.2042 - val_accuracy: 0.9464\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2053 - accuracy: 0.9297 - val_loss: 0.2034 - val_accuracy: 0.9464\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.9329 - val_loss: 0.2025 - val_accuracy: 0.9464\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9361 - val_loss: 0.2017 - val_accuracy: 0.9464\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.9361 - val_loss: 0.2009 - val_accuracy: 0.9464\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.9361 - val_loss: 0.2001 - val_accuracy: 0.9464\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2003 - accuracy: 0.9361 - val_loss: 0.1993 - val_accuracy: 0.9464\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9361 - val_loss: 0.1986 - val_accuracy: 0.9464\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9361 - val_loss: 0.1978 - val_accuracy: 0.9464\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9361 - val_loss: 0.1971 - val_accuracy: 0.9464\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1966 - accuracy: 0.9361 - val_loss: 0.1964 - val_accuracy: 0.9464\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9361 - val_loss: 0.1957 - val_accuracy: 0.9464\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.9361 - val_loss: 0.1950 - val_accuracy: 0.9464\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1940 - accuracy: 0.9361 - val_loss: 0.1943 - val_accuracy: 0.9464\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9361 - val_loss: 0.1936 - val_accuracy: 0.9464\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1923 - accuracy: 0.9361 - val_loss: 0.1930 - val_accuracy: 0.9464\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1915 - accuracy: 0.9361 - val_loss: 0.1923 - val_accuracy: 0.9464\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1906 - accuracy: 0.9361 - val_loss: 0.1917 - val_accuracy: 0.9524\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9361 - val_loss: 0.1910 - val_accuracy: 0.9524\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1890 - accuracy: 0.9361 - val_loss: 0.1904 - val_accuracy: 0.9524\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1883 - accuracy: 0.9361 - val_loss: 0.1898 - val_accuracy: 0.9524\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.9361 - val_loss: 0.1892 - val_accuracy: 0.9524\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9361 - val_loss: 0.1886 - val_accuracy: 0.9524\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9361 - val_loss: 0.1880 - val_accuracy: 0.9524\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1853 - accuracy: 0.9361 - val_loss: 0.1875 - val_accuracy: 0.9524\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9393 - val_loss: 0.1869 - val_accuracy: 0.9524\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9393 - val_loss: 0.1864 - val_accuracy: 0.9524\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9393 - val_loss: 0.1858 - val_accuracy: 0.9524\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9393 - val_loss: 0.1853 - val_accuracy: 0.9524\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9393 - val_loss: 0.1847 - val_accuracy: 0.9524\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.9393 - val_loss: 0.1842 - val_accuracy: 0.9524\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 0.9393 - val_loss: 0.1837 - val_accuracy: 0.9524\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9393 - val_loss: 0.1832 - val_accuracy: 0.9524\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1790 - accuracy: 0.9393 - val_loss: 0.1827 - val_accuracy: 0.9524\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9393 - val_loss: 0.1822 - val_accuracy: 0.9524\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9393 - val_loss: 0.1817 - val_accuracy: 0.9524\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9393 - val_loss: 0.1812 - val_accuracy: 0.9524\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9393 - val_loss: 0.1808 - val_accuracy: 0.9524\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9393 - val_loss: 0.1803 - val_accuracy: 0.9524\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9393 - val_loss: 0.1798 - val_accuracy: 0.9524\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9393 - val_loss: 0.1794 - val_accuracy: 0.9524\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1740 - accuracy: 0.9393 - val_loss: 0.1789 - val_accuracy: 0.9524\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9393 - val_loss: 0.1785 - val_accuracy: 0.9524\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9393 - val_loss: 0.1780 - val_accuracy: 0.9524\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9393 - val_loss: 0.1776 - val_accuracy: 0.9524\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9393 - val_loss: 0.1772 - val_accuracy: 0.9524\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9393 - val_loss: 0.1768 - val_accuracy: 0.9524\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9393 - val_loss: 0.1763 - val_accuracy: 0.9524\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1700 - accuracy: 0.9393 - val_loss: 0.1759 - val_accuracy: 0.9524\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1695 - accuracy: 0.9393 - val_loss: 0.1755 - val_accuracy: 0.9524\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9393 - val_loss: 0.1751 - val_accuracy: 0.9524\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1684 - accuracy: 0.9393 - val_loss: 0.1747 - val_accuracy: 0.9524\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9393 - val_loss: 0.1743 - val_accuracy: 0.9524\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9457 - val_loss: 0.1739 - val_accuracy: 0.9524\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9457 - val_loss: 0.1735 - val_accuracy: 0.9524\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9457 - val_loss: 0.1732 - val_accuracy: 0.9524\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.9457 - val_loss: 0.1728 - val_accuracy: 0.9524\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9457 - val_loss: 0.1724 - val_accuracy: 0.9524\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9457 - val_loss: 0.1720 - val_accuracy: 0.9524\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9457 - val_loss: 0.1717 - val_accuracy: 0.9524\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9457 - val_loss: 0.1713 - val_accuracy: 0.9524\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9457 - val_loss: 0.1710 - val_accuracy: 0.9524\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9457 - val_loss: 0.1706 - val_accuracy: 0.9524\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1624 - accuracy: 0.9457 - val_loss: 0.1703 - val_accuracy: 0.9524\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9457 - val_loss: 0.1699 - val_accuracy: 0.9524\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9457 - val_loss: 0.1696 - val_accuracy: 0.9524\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9457 - val_loss: 0.1692 - val_accuracy: 0.9524\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9457 - val_loss: 0.1689 - val_accuracy: 0.9524\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9489 - val_loss: 0.1686 - val_accuracy: 0.9524\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9489 - val_loss: 0.1682 - val_accuracy: 0.9524\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.9489 - val_loss: 0.1679 - val_accuracy: 0.9524\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9489 - val_loss: 0.1676 - val_accuracy: 0.9524\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9489 - val_loss: 0.1673 - val_accuracy: 0.9524\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9489 - val_loss: 0.1670 - val_accuracy: 0.9524\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9489 - val_loss: 0.1666 - val_accuracy: 0.9524\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9489 - val_loss: 0.1663 - val_accuracy: 0.9524\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9489 - val_loss: 0.1660 - val_accuracy: 0.9524\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9489 - val_loss: 0.1657 - val_accuracy: 0.9524\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9489 - val_loss: 0.1654 - val_accuracy: 0.9524\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9489 - val_loss: 0.1651 - val_accuracy: 0.9524\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9489 - val_loss: 0.1648 - val_accuracy: 0.9524\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9521 - val_loss: 0.1646 - val_accuracy: 0.9524\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9521 - val_loss: 0.1643 - val_accuracy: 0.9524\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9521 - val_loss: 0.1640 - val_accuracy: 0.9524\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1532 - accuracy: 0.9521 - val_loss: 0.1637 - val_accuracy: 0.9524\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9521 - val_loss: 0.1634 - val_accuracy: 0.9524\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9553 - val_loss: 0.1631 - val_accuracy: 0.9524\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1520 - accuracy: 0.9553 - val_loss: 0.1629 - val_accuracy: 0.9524\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9553 - val_loss: 0.1626 - val_accuracy: 0.9524\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1513 - accuracy: 0.9553 - val_loss: 0.1623 - val_accuracy: 0.9524\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9553 - val_loss: 0.1621 - val_accuracy: 0.9524\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9553 - val_loss: 0.1618 - val_accuracy: 0.9524\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9553 - val_loss: 0.1615 - val_accuracy: 0.9524\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9553 - val_loss: 0.1613 - val_accuracy: 0.9524\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1494 - accuracy: 0.9553 - val_loss: 0.1610 - val_accuracy: 0.9524\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9553 - val_loss: 0.1608 - val_accuracy: 0.9524\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9553 - val_loss: 0.1605 - val_accuracy: 0.9524\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9553 - val_loss: 0.1603 - val_accuracy: 0.9524\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9553 - val_loss: 0.1600 - val_accuracy: 0.9524\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9553 - val_loss: 0.1598 - val_accuracy: 0.9524\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9553 - val_loss: 0.1595 - val_accuracy: 0.9524\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9553 - val_loss: 0.1593 - val_accuracy: 0.9524\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9553 - val_loss: 0.1591 - val_accuracy: 0.9524\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9553 - val_loss: 0.1588 - val_accuracy: 0.9524\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9553 - val_loss: 0.1586 - val_accuracy: 0.9524\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 0.1583 - val_accuracy: 0.9524\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9553 - val_loss: 0.1581 - val_accuracy: 0.9524\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9553 - val_loss: 0.1579 - val_accuracy: 0.9524\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9553 - val_loss: 0.1576 - val_accuracy: 0.9524\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9553 - val_loss: 0.1574 - val_accuracy: 0.9524\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9553 - val_loss: 0.1572 - val_accuracy: 0.9524\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9553 - val_loss: 0.1570 - val_accuracy: 0.9524\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9553 - val_loss: 0.1567 - val_accuracy: 0.9524\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9553 - val_loss: 0.1565 - val_accuracy: 0.9524\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9553 - val_loss: 0.1563 - val_accuracy: 0.9524\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9553 - val_loss: 0.1561 - val_accuracy: 0.9524\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9553 - val_loss: 0.1559 - val_accuracy: 0.9524\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1414 - accuracy: 0.9553 - val_loss: 0.1557 - val_accuracy: 0.9524\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9553 - val_loss: 0.1554 - val_accuracy: 0.9524\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9553 - val_loss: 0.1552 - val_accuracy: 0.9524\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9553 - val_loss: 0.1550 - val_accuracy: 0.9524\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9553 - val_loss: 0.1548 - val_accuracy: 0.9524\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9553 - val_loss: 0.1546 - val_accuracy: 0.9524\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9553 - val_loss: 0.1544 - val_accuracy: 0.9524\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9553 - val_loss: 0.1542 - val_accuracy: 0.9524\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9553 - val_loss: 0.1540 - val_accuracy: 0.9524\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9553 - val_loss: 0.1538 - val_accuracy: 0.9524\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9553 - val_loss: 0.1536 - val_accuracy: 0.9524\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9553 - val_loss: 0.1534 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9524\n",
      "Test Loss: 0.15338361263275146\n",
      "Test Accuracy: 0.9523809552192688\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, x_train.shape[-1])))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Definisco l'ottimizzatore con il learning rate iniziale\n",
    "initial_learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate)\n",
    "\n",
    "# Definisco il learning rate schedule con decay lineare\n",
    "decay_steps = 1000  # Numero di passi di addestramento dopo i quali applicare il decay\n",
    "decay_rate = 0.1  # Tasso di decay\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, decay_rate, staircase=True)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Utilizzo della binary cross-entropy per un problema di classificazione binaria\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=200, validation_data=(x_val, y_val))\n",
    "\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Valutazione del modello\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 32)                11520     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,553\n",
      "Trainable params: 11,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
