{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization, TimeDistributed, Bidirectional, GRU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from random import shuffle\n",
    "import math\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "PathSpectogramFolder='out'\n",
    "OutputPath='model/3/path'\n",
    "OutputPathModels='model/3/'\n",
    "interictalSpectograms=[]\n",
    "preictalSpectograms=[]  #This array contains syntetic data, it's created to have a balance dataset and it's used for training\n",
    "preictalRealSpectograms=[]  #This array containt the real preictal data, it's used for testing\n",
    "#patients = [\"01\"]\n",
    "patients = [\"01\",\"02\",\"03\",\"05\",\"09\"]\n",
    "nSeizure=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSpectogramData(indexPat):\n",
    "    global interictalSpectograms\n",
    "    global preictalSpectograms\n",
    "    global preictalRealSpectograms\n",
    "    global nSeizure\n",
    "    nFileForSeizure=0\n",
    "    \n",
    "    interictalSpectograms=[]\n",
    "    preictalSpectograms=[]\n",
    "    preictalRealSpectograms=[]\n",
    "    \n",
    "    f = open(PathSpectogramFolder+'/paz'+patients[indexPat]+'/legendAllData.txt', 'r')\n",
    "    line=f.readline()\n",
    "    while(not \"SEIZURE\" in line):\n",
    "        line=f.readline()\n",
    "    nSeizure=int(line.split(\":\")[1].strip())\n",
    "    line=f.readline()\n",
    "    line=f.readline()#legge il numero di spectogrammi. non lo salvo dato che non mi serve\n",
    "    nSpectograms=int(line.strip())\n",
    "    nFileForSeizure=math.ceil(math.ceil(nSpectograms/50)/nSeizure)\n",
    "    line=f.readline()#leggo il percorso del primo file\n",
    "    \n",
    "    #Lettura path files Interictal\n",
    "    cont=-1\n",
    "    indFilePathRead=0\n",
    "    while(\"npy\" in line and indFilePathRead<nSeizure*nFileForSeizure):\n",
    "        if(indFilePathRead%nFileForSeizure==0):\n",
    "            interictalSpectograms.append([])\n",
    "            cont=cont+1\n",
    "            interictalSpectograms[cont].append(line.split(' ')[2].rstrip())#.rstrip() remove \\n\n",
    "            indFilePathRead=indFilePathRead+1\n",
    "        else:\n",
    "            if(len(line.split(' '))>=3):\n",
    "                interictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "            indFilePathRead=indFilePathRead+1\n",
    "            \n",
    "        line=f.readline()\n",
    "    line=f.readline()#leggo PREICTAL\n",
    "    line=f.readline()#leggo n° spectogram\n",
    "    line=f.readline()#leggo n°seizure(SEIZURE X)\n",
    "\n",
    "    #Lettura path files Preictal\n",
    "    cont=-1\n",
    "    indFilePathRead=0   \n",
    "    #while(line and indFilePathRead<nSeizure*nFileForSeizure):    \n",
    "    while(line.strip()!=\"\"):\n",
    "        if(\"SEIZURE\" in line):\n",
    "            line=f.readline()#ho letto n°seizure(SEIZURE X) perciò scorro in avanti\n",
    "            if(len(line.split(' '))>=3):\n",
    "                preictalSpectograms.append([])\n",
    "                cont=cont+1\n",
    "                preictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "                indFilePathRead=indFilePathRead+1\n",
    "        else:\n",
    "            if(len(line.split(' '))>=3):\n",
    "                preictalSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "            indFilePathRead=indFilePathRead+1\n",
    "            \n",
    "        line=f.readline()\n",
    "        \n",
    "    line=f.readline()#leggo REAL_PREICTAL\n",
    "    line=f.readline()#leggo n° spectogram\n",
    "    line=f.readline()#leggo n°seizure(SEIZURE X)\n",
    "\n",
    "    #Lettura path files Real Preictal\n",
    "    cont=-1\n",
    "    while(line):\n",
    "        if(\"SEIZURE\" in line):\n",
    "            line=f.readline()#ho letto n°seizure(SEIZURE X) perciò scorro in avanti\n",
    "            preictalRealSpectograms.append([])\n",
    "            cont=cont+1\n",
    "            preictalRealSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "        else:\n",
    "            preictalRealSpectograms[cont].append(line.split(' ')[2].rstrip())\n",
    "            \n",
    "        line=f.readline()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (2, 4), activation='relu', input_shape=(22, 59, 114)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    \n",
    "    sgd = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "    model.compile(metrics=['accuracy',keras.metrics.Recall(name='sen')], loss='binary_crossentropy', optimizer= sgd)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel3():\n",
    "    model = Sequential()\n",
    "\n",
    "    # C1\n",
    "    model.add(Conv2D(16, (4, 4), strides=(1, 2), padding='same', activation='relu', input_shape=(22, 59, 114)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # C2\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 2), padding='same', activation='relu', input_shape=(22, 59, 114)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # C3\n",
    "    model.add(Conv2D(64, (3, 1), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # C4\n",
    "    model.add(Conv2D(128, (3, 1), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "    model.compile(metrics=['accuracy',keras.metrics.Recall(name='sen')], loss='binary_crossentropy', optimizer= sgd)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel2():\n",
    "\n",
    "   model = Sequential()\n",
    "\n",
    "   # C1\n",
    "   model.add(Conv2D(32, (3, 3), strides=(1, 2), padding='same', activation='relu', input_shape=(22, 59, 114)))\n",
    "   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "   model.add(BatchNormalization())\n",
    "\n",
    "   # C2\n",
    "   model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "   model.add(BatchNormalization())\n",
    "\n",
    "   # C3\n",
    "   model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "   model.add(BatchNormalization())\n",
    "\n",
    "   model.add(Flatten())\n",
    "   model.add(Dropout(0.5))\n",
    "   model.add(Dense(256, activation='relu'))\n",
    "   model.add(Dropout(0.5))\n",
    "   model.add(Dense(2, activation='softmax'))\n",
    "   \n",
    "   sgd = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "   model.compile(metrics=['accuracy',keras.metrics.Recall(name='sen')], loss='binary_crossentropy', optimizer= sgd)\n",
    "   \n",
    "   return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel1():\n",
    "\n",
    "    model = Sequential()\n",
    "    #C1\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 2), padding='valid', activation='relu', input_shape=(22, 59, 114)))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    BatchNormalization()\n",
    "    \n",
    "    #C2\n",
    "    model.add(Conv2D(32, (1, 3), strides=(1,1), padding='valid', activation='relu'))#incertezza se togliere padding\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    BatchNormalization()\n",
    "\n",
    "    #C3\n",
    "    model.add(Conv2D(64, (1, 3), strides=(1,1), padding='valid', activation='relu'))#incertezza se togliere padding\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2) ))\n",
    "    BatchNormalization()\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation='sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    sgd = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "    model.compile(metrics=['accuracy',keras.metrics.Recall(name='sen')], loss='binary_crossentropy', optimizer= sgd)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesPathWithoutSeizure(indexPat, indexSeizure):\n",
    "    filesPath=[]\n",
    "    for i in range(0, nSeizure):\n",
    "        if(i!=indexSeizure):\n",
    "            filesPath.extend(interictalSpectograms[i])\n",
    "            filesPath.extend(preictalSpectograms[i])\n",
    "    shuffle(filesPath)\n",
    "    return filesPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arrays_for_training(indexPat, paths, start=0, end=100):\n",
    "    while True:\n",
    "        from_=int(len(paths)/100*start)\n",
    "        to_=int(len(paths)/100*end)\n",
    "        for i in range(from_, int(to_)):\n",
    "            f=paths[i]\n",
    "            x = np.load(PathSpectogramFolder+f)\n",
    "            x=np.array([x])\n",
    "            x=x.swapaxes(0,1)\n",
    "            x=x[0]\n",
    "            if('P' in f):\n",
    "                y = np.repeat([[0,1]], x.shape[0], axis=0)\n",
    "            else:\n",
    "                y = np.repeat([[1,0]], x.shape[0], axis=0)\n",
    "            yield(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arrays_for_predict(indexPat, paths, start=0, end=100):\n",
    "    while True:\n",
    "        from_=int(len(paths)/100*start)\n",
    "        to_=int(len(paths)/100*end)\n",
    "        for i in range(from_, int(to_)):\n",
    "            f=paths[i]\n",
    "            x = np.load(PathSpectogramFolder+f)\n",
    "            x=np.array([x])\n",
    "            x=x.swapaxes(0,1)\n",
    "            x=x[0]\n",
    "            yield(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Parameters loaded\n",
      "Patient 01\n",
      "Spectograms data loaded\n",
      "SEIZURE OUT: 1\n",
      "Training start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "45/45 - 16s - loss: nan - accuracy: 0.6000 - sen: 0.5333 - val_loss: nan - val_accuracy: 0.6000 - val_sen: 0.0000e+00 - 16s/epoch - 357ms/step\n",
      "Epoch 2/300\n",
      "45/45 - 11s - loss: nan - accuracy: 0.4667 - sen: 0.0000e+00 - val_loss: nan - val_accuracy: 0.6000 - val_sen: 0.0000e+00 - 11s/epoch - 237ms/step\n",
      "Epoch 3/300\n"
     ]
    }
   ],
   "source": [
    "print(\"START\")\n",
    "if not os.path.exists(OutputPathModels):\n",
    "    os.makedirs(OutputPathModels)\n",
    "print(\"Parameters loaded\")\n",
    "\n",
    "for indexPat in range(0, len(patients)):\n",
    "    print('Patient '+patients[indexPat])\n",
    "    if not os.path.exists(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\"):\n",
    "        os.makedirs(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\")\n",
    "    loadSpectogramData(indexPat) \n",
    "    print('Spectograms data loaded')\n",
    "    \n",
    "    result='Patient '+patients[indexPat]+'\\n'     \n",
    "    result='Out Seizure, True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR \\n'\n",
    "    for i in range(0, nSeizure):\n",
    "        print('SEIZURE OUT: '+str(i+1))\n",
    "        \n",
    "        print('Training start')  \n",
    "        model = createModel()\n",
    "        filesPath=getFilesPathWithoutSeizure(i, indexPat)\n",
    "        \n",
    "        model.fit(generate_arrays_for_training(indexPat, filesPath, end=75), #end=75),#It take the first 75%\n",
    "                            validation_data=generate_arrays_for_training(indexPat, filesPath, start=75),#start=75), #It take the last 25%\n",
    "                            #steps_per_epoch=10000, epochs=10)\n",
    "                            steps_per_epoch=int((len(filesPath)-int(len(filesPath)/100*25))),#*25), \n",
    "                            validation_steps=int((len(filesPath)-int(len(filesPath)/100*75))),#*75),\n",
    "                            verbose=2,\n",
    "                            epochs=300, max_queue_size=2, shuffle=True, callbacks=[early_stop])# 100 epochs è meglio #aggiungere criterio di stop in base accuratezza\n",
    "        print('Training end')\n",
    "        \n",
    "        print('Testing start')\n",
    "        filesPath=interictalSpectograms[i]\n",
    "        interPrediction=model.predict(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n",
    "        filesPath=preictalRealSpectograms[i]\n",
    "        preictPrediction=model.predict(generate_arrays_for_predict(indexPat, filesPath), max_queue_size=4, steps=len(filesPath))\n",
    "        print('Testing end')\n",
    "        \n",
    "\n",
    "        # Creates a HDF5 file \n",
    "        model.save(OutputPathModels+\"ModelPat\"+patients[indexPat]+\"/\"+'ModelOutSeizure'+str(i+1)+'.h5')\n",
    "        print(\"Model saved\")\n",
    "        \n",
    "        #to plot the model\n",
    "        #plot_model(model, to_file=\"CNNModel\", show_shapes=True, show_layer_names=True)\n",
    "        \n",
    "        if not os.path.exists(OutputPathModels+\"OutputTest\"+\"/\"):\n",
    "            os.makedirs(OutputPathModels+\"OutputTest\"+\"/\")\n",
    "        np.savetxt(OutputPathModels+\"OutputTest\"+\"/\"+\"Int_\"+patients[indexPat]+\"_\"+str(i+1)+\".csv\", interPrediction, delimiter=\",\")\n",
    "        np.savetxt(OutputPathModels+\"OutputTest\"+\"/\"+\"Pre_\"+patients[indexPat]+\"_\"+str(i+1)+\".csv\", preictPrediction, delimiter=\",\")\n",
    "        \n",
    "        secondsInterictalInTest=len(interictalSpectograms[i])*50*30#50 spectograms for file, 30 seconds for each spectogram\n",
    "        acc=0#accumulator\n",
    "        fp=0\n",
    "        tp=0\n",
    "        fn=0\n",
    "        lastTenResult=list()\n",
    "        \n",
    "        for el in interPrediction:\n",
    "            if(el[1]>0.5):\n",
    "                acc=acc+1\n",
    "                lastTenResult.append(1)\n",
    "            else:\n",
    "                lastTenResult.append(0)\n",
    "            if(len(lastTenResult)>10):\n",
    "                acc=acc-lastTenResult.pop(0)\n",
    "            if(acc>=8):\n",
    "                fp=fp+1\n",
    "                lastTenResult=list()\n",
    "                acc=0\n",
    "        \n",
    "        lastTenResult=list()\n",
    "        for el in preictPrediction:\n",
    "            if(el[1]>0.5):\n",
    "                acc=acc+1\n",
    "                lastTenResult.append(1)\n",
    "            else:\n",
    "                lastTenResult.append(0)\n",
    "            if(len(lastTenResult)>10):\n",
    "                acc=acc-lastTenResult.pop(0)\n",
    "            if(acc>=8):\n",
    "                tp=tp+1 \n",
    "            else:\n",
    "                if(len(lastTenResult)==10):\n",
    "                    fn=fn+1 \n",
    "                    \n",
    "        sensitivity=tp/(tp+fn)\n",
    "        FPR=fp/(secondsInterictalInTest/(60*60))\n",
    "        \n",
    "        result=result+str(i+1)+','+str(tp)+','+str(fp)+','+str(fn)+','+str(secondsInterictalInTest)+','\n",
    "        result=result+str(sensitivity)+','+str(FPR)+'\\n'\n",
    "        print('True Positive, False Positive, False negative, Second of Inter in Test, Sensitivity, FPR')\n",
    "        print(str(tp)+','+str(fp)+','+str(fn)+','+str(secondsInterictalInTest)+','+str(sensitivity)+','+str(FPR))\n",
    "    with open(OutputPath, \"a+\") as myfile:\n",
    "        myfile.write(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
