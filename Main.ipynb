{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.DatasetManage import read_and_store_data\n",
    "from ipynb.fs.full.FeatureExtraction import feature_extraction\n",
    "from ipynb.fs.full.ClassificationPerformanceIndexes import classificationPerformanceIndexes, printClassificationPerformanceIndexes\n",
    "from ipynb.fs.full.ClassificationMethods import CompleteLSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfInd = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'MCC', 'Kappa', 'Time']\n",
    "channels = ['FP1-F7', 'F7-T7','T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'seizure']\n",
    "\n",
    "dataset = 'CHB_MIT'\n",
    "csvImportFile = 'CHB.csv'\n",
    "csvExportFile = 'CHB.csv'\n",
    "sample_rate = 256\n",
    "time_window = 2\n",
    "step = time_window * sample_rate\n",
    "\n",
    "test_ratio = 0.3\n",
    "\n",
    "pca_tolerance = 0.9\n",
    "\n",
    "undersampling_rate = 0.2\n",
    "\n",
    "oversampling_neighbors = 11\n",
    "\n",
    "k_fold = 5\n",
    "\n",
    "csvAverageFile = 'Features.csv'\n",
    "\n",
    "batch = 10\n",
    "epochs = 100\n",
    "dropout_percentage = 0.2\n",
    "loss_function = 'mean_squared_error'\n",
    "metric = 'accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestData (features, test_ratio, k_fold, perfInd):\n",
    "    x = features.loc[:, features.columns != 'seizure']\n",
    "    y = features['seizure']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_ratio, shuffle = True)\n",
    "    results = pd.DataFrame(columns = perfInd)\n",
    "    kf = KFold(n_splits = k_fold, shuffle = True)\n",
    "    return x_train, x_test, y_train, y_test, results, kf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from CHB.csv\n"
     ]
    }
   ],
   "source": [
    "print('Reading data from', csvImportFile)\n",
    "df = pd.read_csv(csvImportFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft = feature_extraction(df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv(csvAverageFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, results, kf = trainTestData (ft, test_ratio, k_fold, perfInd)\n",
    "\n",
    "x_train = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "y_train = y_train.values.astype(int)\n",
    "x_test = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_test = y_test.values.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(8, 24, activation='relu', input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 12, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 6, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dell'architettura della rete neurale\n",
    "\n",
    "num_classes = 2\n",
    "input_channels = 87\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv1D(8, 24, activation='relu', input_shape=(1, input_channels)))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 12, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 6, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='mae')\n",
    "\n",
    "# Training \n",
    "\n",
    "# X_train = X_train.reshape(-1, input_length, input_channels)\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 8\n",
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluation of the model\n",
    "\n",
    "# X_test = X_test.reshape(-1, input_length, input_channels)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "# Utilizzo del modello per effettuare predizioni\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(8, 24, activation='relu', input_shape=(None, ft.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 12, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 6, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mae')\n",
    "history = model.fit(x_train,\n",
    "                    steps_per_epoch=350,\n",
    "                    epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, ft.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mae')\n",
    "history = model.fit(x_train,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 128\n",
    "dense_units = 32  \n",
    "\n",
    "CompleteLSTM(x_train, x_test, y_train, y_test, results, ft, kf, perfInd, epochs, batch, lstm_units, dense_units, dropout_percentage, loss_function, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
