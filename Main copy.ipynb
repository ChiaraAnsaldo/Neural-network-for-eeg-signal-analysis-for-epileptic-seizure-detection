{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.DatasetManage import read_and_store_data\n",
    "from ipynb.fs.full.FeatureExtraction import feature_extraction\n",
    "from ipynb.fs.full.ClassificationPerformanceIndexes import classificationPerformanceIndexes, printClassificationPerformanceIndexes\n",
    "from ipynb.fs.full.ClassificationMethods import CompleteLSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfInd = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision', 'F1 Score', 'MCC', 'Kappa', 'Time']\n",
    "channels = ['FP1-F7', 'F7-T7','T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'seizure']\n",
    "\n",
    "dataset = 'CHB_MIT'\n",
    "csvImportFile = 'CHB.csv'\n",
    "csvExportFile = 'CHB.csv'\n",
    "sample_rate = 256\n",
    "time_window = 2\n",
    "step = time_window * sample_rate\n",
    "\n",
    "test_ratio = 0.3\n",
    "\n",
    "pca_tolerance = 0.9\n",
    "\n",
    "undersampling_rate = 0.2\n",
    "\n",
    "oversampling_neighbors = 11\n",
    "\n",
    "k_fold = 5\n",
    "\n",
    "csvAverageFile = 'Features.csv'\n",
    "\n",
    "batch = 10\n",
    "epochs = 100\n",
    "dropout_percentage = 0.2\n",
    "loss_function = 'mean_squared_error'\n",
    "metric = 'accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestData (features, test_ratio, k_fold, perfInd):\n",
    "    X_train, X_test, y_train, y_test = createTrainingAndTestDatasets(features, test_ratio)\n",
    "    results = pd.DataFrame(columns = perfInd)\n",
    "    kf = KFold(n_splits = k_fold, shuffle = True)\n",
    "    return X_train, X_test, y_train, y_test, results, kf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from CHB.csv\n"
     ]
    }
   ],
   "source": [
    "print('Reading data from', csvImportFile)\n",
    "df = pd.read_csv(csvImportFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft = feature_extraction(df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createTrainingAndTestDatasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m ft \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(csvAverageFile, delimiter \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, header \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m x_train, x_test, y_train, y_test, results, kf \u001b[39m=\u001b[39m trainTestData (ft, test_ratio, k_fold, perfInd)\n\u001b[0;32m      5\u001b[0m x_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(x_train\u001b[39m.\u001b[39mvalues, (x_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m      6\u001b[0m y_train \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m, in \u001b[0;36mtrainTestData\u001b[1;34m(features, test_ratio, k_fold, perfInd)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrainTestData\u001b[39m (features, test_ratio, k_fold, perfInd):\n\u001b[1;32m----> 2\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m createTrainingAndTestDatasets(features, test_ratio)\n\u001b[0;32m      3\u001b[0m     results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns \u001b[39m=\u001b[39m perfInd)\n\u001b[0;32m      4\u001b[0m     kf \u001b[39m=\u001b[39m KFold(n_splits \u001b[39m=\u001b[39m k_fold, shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'createTrainingAndTestDatasets' is not defined"
     ]
    }
   ],
   "source": [
    "ft = pd.read_csv(csvAverageFile, delimiter = ',', header = 0)\n",
    "\n",
    "x_train, x_test, y_train, y_test, results, kf = trainTestData (ft, test_ratio, k_fold, perfInd)\n",
    "\n",
    "x_train = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "y_train = y_train.values.astype(int)\n",
    "x_test = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_test = y_test.values.astype(int)\n",
    "\n",
    "# print (ft)\n",
    "print(X_train) # 392x86\n",
    "print(X_test) # 168x86\n",
    "\n",
    "# 560 righe e 87 colonne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM GRECO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 128\n",
    "dense_units = 32  \n",
    "\n",
    "CompleteLSTM(X_train, X_test, y_train, y_test, results, ft, kf, perfInd, epochs, batch, lstm_units, dense_units, dropout_percentage, loss_function, metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv1D(8, 24, activation='relu', input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 12, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 6, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=500,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv1d_3. Consider increasing the input size. Received input shape [None, 1, 87] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m input_channels \u001b[39m=\u001b[39m \u001b[39m87\u001b[39m\n\u001b[0;32m      6\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential()\n\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39;49madd(layers\u001b[39m.\u001b[39;49mConv1D(\u001b[39m8\u001b[39;49m, \u001b[39m24\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, input_channels)))\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mMaxPooling1D(\u001b[39m2\u001b[39m))\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mConv1D(\u001b[39m8\u001b[39m, \u001b[39m12\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdue to downsampling in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincreasing the input size. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived input shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m which would produce \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moutput shape with a zero or negative value in a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdimension.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv1d_3. Consider increasing the input size. Received input shape [None, 1, 87] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "# Definizione dell'architettura della rete neurale\n",
    "\n",
    "num_classes = 2\n",
    "input_channels = 87\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv1D(8, 24, activation='relu', input_shape=(1, input_channels)))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 12, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(8, 6, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='mae')\n",
    "\n",
    "# Training \n",
    "\n",
    "# X_train = X_train.reshape(-1, input_length, input_channels)\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 8\n",
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluation of the model\n",
    "\n",
    "# X_test = X_test.reshape(-1, input_length, input_channels)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "# Utilizzo del modello per effettuare predizioni\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
