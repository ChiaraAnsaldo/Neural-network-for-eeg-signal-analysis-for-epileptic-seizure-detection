{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, LSTM\n",
    "from tensorflow.keras import optimizers\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.DatasetManage import read_and_store_data\n",
    "from ipynb.fs.full.FeatureExtraction import feature_extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['FP1-F7', 'F7-T7','T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'seizure']\n",
    "\n",
    "dataset = 'CHB_MIT'\n",
    "csvImportFile = 'CHB.csv'\n",
    "csvExportFile = 'CHB.csv'\n",
    "sample_rate = 256\n",
    "time_window = 2\n",
    "step = time_window * sample_rate\n",
    "\n",
    "test_ratio = 0.3 # ratio to split dataset into training and testing sets\n",
    "val_ratio = 0.2 # ratio to split dataset into validation and training sets\n",
    "\n",
    "pca_tolerance = 0.9 # desired percentage of variation in the data preserved\n",
    "\n",
    "undersampling_rate = 0.2 # undersampling rate for Cluster Centroids\n",
    "\n",
    "oversampling_neighbors = 11 # size of neighbourhood for K-nearest neighbours method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define a method to split the dataset into training and testing sets, also returning the train/test\n",
    "# indexes for splitting the dataset into K folds for the K-fold cross validation\n",
    "\n",
    "def trainTestData_1 (features, test_ratio, k_fold):\n",
    "    x = features.loc[:, features.columns != 'seizure']\n",
    "    y = features['seizure']\n",
    "    x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size = test_ratio, shuffle = True, random_state=42)\n",
    "    kf = KFold(n_splits = k_fold, shuffle = True)\n",
    "    x_train = np.reshape(x_tr.values, (x_tr.shape[0], 1, x_tr.shape[1]))\n",
    "    y_train = y_tr.values.astype(int)\n",
    "    x_test = np.reshape(x_ts.values, (x_ts.shape[0], 1, x_ts.shape[1]))\n",
    "    y_test = y_ts.values.astype(int)\n",
    "    return x_train, x_test, y_train, y_test, kf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define a method to split the dataset into training, validationa and testing sets\n",
    "\n",
    "def trainTestData_2 (features, test_ratio, val_ratio):\n",
    "    x = features.loc[:, features.columns != 'seizure']\n",
    "    y = features['seizure']\n",
    "    x_1, x_ts, y_1, y_ts = train_test_split(x, y, test_size = test_ratio, random_state=42)\n",
    "    x_tr, x_v, y_tr, y_v = train_test_split(x_1, y_1, test_size = val_ratio, random_state=42)\n",
    "    x_train = np.reshape(x_tr.values, (x_tr.shape[0], 1, x_tr.shape[1]))\n",
    "    y_train = y_tr.values.astype(int)\n",
    "    x_val = np.reshape(x_ts.values, (x_ts.shape[0], 1, x_ts.shape[1]))\n",
    "    y_val = y_ts.values.astype(int)\n",
    "    x_test = np.reshape(x_ts.values, (x_ts.shape[0], 1, x_ts.shape[1]))\n",
    "    y_test = y_ts.values.astype(int)\n",
    "    return x_train, x_test, y_train, y_test, x_val, y_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and store data from the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from CHB.csv\n"
     ]
    }
   ],
   "source": [
    "print('Reading data from', csvImportFile)\n",
    "df = pd.read_csv(csvImportFile, delimiter = ',', header = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7df9b78afc401d8961b8cd9fcf9810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2963 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"    bands = [0.5, 4, 8, 12, 30, 100]\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n",
      "c:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"'''\\n\",\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sampEn13'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3799\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3798\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3799\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3800\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m   3801\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sampEn13'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\Main-Mari_3 copy.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/irene/OneDrive/Documenti/GitHub/Fuzzy-Project/Main-Mari_3%20copy.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# We compute the features and save them in the Feature.csv file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/irene/OneDrive/Documenti/GitHub/Fuzzy-Project/Main-Mari_3%20copy.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ft \u001b[39m=\u001b[39m feature_extraction(df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors)\n",
      "File \u001b[1;32mc:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\FeatureExtraction.ipynb:82\u001b[0m, in \u001b[0;36mfeature_extraction\u001b[1;34m(df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors)\u001b[0m\n\u001b[0;32m      1\u001b[0m {\n\u001b[0;32m      2\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mcells\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m      3\u001b[0m   {\n\u001b[0;32m      4\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m22\u001b[39m,\n\u001b[0;32m      6\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m      7\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m      8\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimport pywt\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimport math\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimport numpy as np\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimport pandas as pd\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom pyentrp import entropy\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom tqdm.notebook import tqdm\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom scipy.signal import welch\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom scipy.integrate import simps\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom scipy.stats import skew, kurtosis, variation\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom sklearn.utils import shuffle\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m    ]\n\u001b[0;32m     20\u001b[0m   },\n\u001b[0;32m     21\u001b[0m   {\n\u001b[0;32m     22\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m23\u001b[39m,\n\u001b[0;32m     24\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     25\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     26\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom ipynb.fs.full.Preprocessing import removeNonNumericValues, dimentionalityReduction, featureNormalization, undersamplingClusterCentroids, oversamplingSMOTE\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m    ]\n\u001b[0;32m     29\u001b[0m   },\n\u001b[0;32m     30\u001b[0m   {\n\u001b[0;32m     31\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mattachments\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     32\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmarkdown\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     34\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m     35\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTIme Domain Features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m    ]\n\u001b[0;32m     37\u001b[0m   },\n\u001b[0;32m     38\u001b[0m   {\n\u001b[0;32m     39\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     40\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m24\u001b[39m,\n\u001b[0;32m     41\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     42\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     43\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m     44\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef computeTimeDomainFeatures (x):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    mean = np.mean(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    var = np.var(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    sk = skew(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    kurt = kurtosis(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     49\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    std = np.std(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    median = np.median(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    zcr = ((x[:-1] * x[1:]) < 0).sum() / len(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if x.mean() != 0:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        cv = variation(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    else:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        cv = math.nan\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if x.size > 0:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        rms = np.sqrt(x.dot(x)/x.size)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     58\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    else:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     59\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        rms = math.nan\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    p2p = x.max() - x.min()\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    sampEn = entropy.sample_entropy(x, 1)[0]\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return mean, var, sk, kurt, std, median, zcr, cv, rms, p2p, sampEn\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m    ]\n\u001b[0;32m     64\u001b[0m   },\n\u001b[0;32m     65\u001b[0m   {\n\u001b[0;32m     66\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mattachments\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     67\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmarkdown\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     69\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m     70\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSpectral Features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m    ]\n\u001b[0;32m     72\u001b[0m   },\n\u001b[0;32m     73\u001b[0m   {\n\u001b[0;32m     74\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m25\u001b[39m,\n\u001b[0;32m     76\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     77\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     78\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m     79\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCompute the average bandpower of an EEG signal\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://raphaelvallat.com/bandpower.html\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m---> 82\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     83\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     84\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef psd (x, fs, win):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    bands = [0.5, 4, 8, 12, 30, 100]\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    freqs, psd = welch(x, fs, nperseg = win)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    avg_power=[]\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    while len(bands)>1:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        idx = np.logical_and(freqs >= bands[0], freqs <= bands[1])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     90\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        power_simps = simps(psd[idx], dx=bands[1]-bands[0])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        avg_power.append(power_simps)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        bands = np.copy(bands[1:])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     93\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    for p in avg_power:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        yield p\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m    ]\n\u001b[0;32m     96\u001b[0m   },\n\u001b[0;32m     97\u001b[0m   {\n\u001b[0;32m     98\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mattachments\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     99\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmarkdown\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    100\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m    101\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCorrelation Features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m    ]\n\u001b[0;32m    104\u001b[0m   },\n\u001b[0;32m    105\u001b[0m   {\n\u001b[0;32m    106\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    107\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m26\u001b[39m,\n\u001b[0;32m    108\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m    109\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m    110\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m    111\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef compute_correlation (left, right):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    112\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return abs(np.correlate(left, right, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)).max()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m    ]\n\u001b[0;32m    114\u001b[0m   },\n\u001b[0;32m    115\u001b[0m   {\n\u001b[0;32m    116\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mattachments\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m    117\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmarkdown\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    118\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m    119\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m    120\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFeature Extraction\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m    ]\n\u001b[0;32m    122\u001b[0m   },\n\u001b[0;32m    123\u001b[0m   {\n\u001b[0;32m    124\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    125\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m27\u001b[39m,\n\u001b[0;32m    126\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m    127\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m    128\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m    129\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef feature_extraction (df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFeature Extraction\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    132\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft = pd.DataFrame()\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    c = 0\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    for i in tqdm(range (0, df.shape[0], step)):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        temp = df.iloc[i:i+step]\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        for j in range(0, df.shape[1]-1):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            s = np.array(temp.iloc[:, j])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    138\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    139\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            # Time Domain Features\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    140\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvar\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mskew\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)],ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mkurt\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmedian\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mzcr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrms\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mp2p\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)],ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msampEn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)] = computeTimeDomainFeatures(s)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    142\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            # Frequency Domain Features\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    143\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdeltaPower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mthetaPower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39malphaPower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbetaPower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)], ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mgammaPower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+str(j)] = psd(s, sample_rate, s.shape[0])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        ft.loc[c, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mseizure\u001b[39m\u001b[39m'\u001b[39m\u001b[39m] = temp[\u001b[39m\u001b[39m'\u001b[39m\u001b[39mseizure\u001b[39m\u001b[39m'\u001b[39m\u001b[39m].value_counts().idxmax()\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    146\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        c = c + 1\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    148\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    removeNonNumericValues(ft)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    150\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft = featureNormalization(ft)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    151\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNormalized features\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    152\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    153\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    removeNonNumericValues(ft)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    154\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    size = ft.shape\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    156\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReducing features dimension\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft = dimentionalityReduction(ft, pca_tolerance)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    158\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    removeNonNumericValues(ft)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    159\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDimensions reduced from\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, size, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mto\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, ft.shape)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    160\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    size = ft.seizure.value_counts()\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    161\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    162\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUndersampling the majority class using Cluster Centroid Method\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    163\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft = undersamplingClusterCentroids(ft.loc[:, ft.columns != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mseizure\u001b[39m\u001b[39m'\u001b[39m\u001b[39m], ft[\u001b[39m\u001b[39m'\u001b[39m\u001b[39mseizure\u001b[39m\u001b[39m'\u001b[39m\u001b[39m], undersampling_rate)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    164\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    removeNonNumericValues(ft)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    165\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMajority class downsampled from (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, size[0], \u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m, ft.shape[1], \u001b[39m\u001b[39m'\u001b[39m\u001b[39m) to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m, ft.shape, sep = \u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    166\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    167\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    size = ft.shape\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    168\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOversampling the minority class using SMOTE\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    169\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft = oversamplingSMOTE(ft.loc[:, ft.columns != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mseizure\u001b[39m\u001b[39m'\u001b[39m\u001b[39m], ft[\u001b[39m\u001b[39m'\u001b[39m\u001b[39mseizure\u001b[39m\u001b[39m'\u001b[39m\u001b[39m], oversampling_neighbors)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    170\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft = shuffle(ft)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft.reset_index(drop = True, inplace = True)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    172\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    removeNonNumericValues(ft)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMinority class upsampled from (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, size[0], \u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m, ft.shape[1], \u001b[39m\u001b[39m'\u001b[39m\u001b[39m) to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m, ft.shape, sep=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    174\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWriting features to a csv file\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    ft.to_csv(\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFeatures.csv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, index = False)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    177\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    178\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return ft\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m    ]\n\u001b[0;32m    180\u001b[0m   }\n\u001b[0;32m    181\u001b[0m  ],\n\u001b[0;32m    182\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    183\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mkernelspec\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    184\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mdisplay_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPython 3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    185\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    186\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m   },\n\u001b[0;32m    188\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mlanguage_info\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    189\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcodemirror_mode\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mipython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    191\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m\n\u001b[0;32m    192\u001b[0m    },\n\u001b[0;32m    193\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mfile_extension\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    194\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmimetype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext/x-python\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mnbconvert_exporter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mpygments_lexer\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mipython3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m3.10.11\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m   },\n\u001b[0;32m    200\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39morig_nbformat\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m4\u001b[39m\n\u001b[0;32m    201\u001b[0m  },\n\u001b[0;32m    202\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mnbformat\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m4\u001b[39m,\n\u001b[0;32m    203\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mnbformat_minor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m\n\u001b[0;32m    204\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1642\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1639\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key] \u001b[39m=\u001b[39m empty_value\n\u001b[0;32m   1641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1642\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj[key] \u001b[39m=\u001b[39m infer_fill_value(value)\n\u001b[0;32m   1644\u001b[0m new_indexer \u001b[39m=\u001b[39m convert_from_missing_indexer_tuple(\n\u001b[0;32m   1645\u001b[0m     indexer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39maxes\n\u001b[0;32m   1646\u001b[0m )\n\u001b[0;32m   1647\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer(new_indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3845\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3842\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   3843\u001b[0m             value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(value, (\u001b[39mlen\u001b[39m(existing_piece\u001b[39m.\u001b[39mcolumns), \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT\n\u001b[1;32m-> 3845\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_mgr(key, value)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3802\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3799\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39mget_loc(key)\n\u001b[0;32m   3800\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m   3801\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49minsert(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis), key, value)\n\u001b[0;32m   3803\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1264\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_known_consolidated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mnot\u001b[39;00m block\u001b[39m.\u001b[39mis_extension \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks) \u001b[39m>\u001b[39m \u001b[39m100\u001b[39m:\n\u001b[0;32m   1258\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1259\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataFrame is highly fragmented.  This is usually the result \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1260\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mof calling `frame.insert` many times, which has poor performance.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider joining all columns at once using pd.concat(axis=1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1262\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minstead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1263\u001b[0m         PerformanceWarning,\n\u001b[1;32m-> 1264\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1265\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\site-packages\\pandas\\util\\_exceptions.py:32\u001b[0m, in \u001b[0;36mfind_stack_level\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_stack_level\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m     28\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m    Find the first place in the stack that is not inside pandas\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    (tests notwithstanding).\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     stack \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mstack()\n\u001b[0;32m     34\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     pkg_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(pd\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\inspect.py:1554\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(context)\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack\u001b[39m(context\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1553\u001b[0m     \u001b[39m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1554\u001b[0m     \u001b[39mreturn\u001b[39;00m getouterframes(sys\u001b[39m.\u001b[39;49m_getframe(\u001b[39m1\u001b[39;49m), context)\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\inspect.py:1531\u001b[0m, in \u001b[0;36mgetouterframes\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1529\u001b[0m framelist \u001b[39m=\u001b[39m []\n\u001b[0;32m   1530\u001b[0m \u001b[39mwhile\u001b[39;00m frame:\n\u001b[1;32m-> 1531\u001b[0m     frameinfo \u001b[39m=\u001b[39m (frame,) \u001b[39m+\u001b[39m getframeinfo(frame, context)\n\u001b[0;32m   1532\u001b[0m     framelist\u001b[39m.\u001b[39mappend(FrameInfo(\u001b[39m*\u001b[39mframeinfo))\n\u001b[0;32m   1533\u001b[0m     frame \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mf_back\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\inspect.py:1501\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isframe(frame):\n\u001b[0;32m   1499\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m is not a frame or traceback object\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(frame))\n\u001b[1;32m-> 1501\u001b[0m filename \u001b[39m=\u001b[39m getsourcefile(frame) \u001b[39mor\u001b[39;00m getfile(frame)\n\u001b[0;32m   1502\u001b[0m \u001b[39mif\u001b[39;00m context \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1503\u001b[0m     start \u001b[39m=\u001b[39m lineno \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m context\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\inspect.py:706\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39many\u001b[39m(filename\u001b[39m.\u001b[39mendswith(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m\n\u001b[0;32m    704\u001b[0m              importlib\u001b[39m.\u001b[39mmachinery\u001b[39m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    705\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexists(filename):\n\u001b[0;32m    707\u001b[0m     \u001b[39mreturn\u001b[39;00m filename\n\u001b[0;32m    708\u001b[0m \u001b[39m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\irene\\anaconda3\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     20\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We compute the features and save them in the Feature.csv file\n",
    "\n",
    "ft = feature_extraction(df, sample_rate, step, pca_tolerance, undersampling_rate, oversampling_neighbors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv(\"Features.csv\", delimiter = ',', header = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset splitting without validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = 5\n",
    "x_train, x_test, y_train, y_test, kf = trainTestData_1 (ft, test_ratio, k_fold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset splitting with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, x_val, y_val = trainTestData_2 (ft, test_ratio, val_ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "save_path = os.path.join(dir_name, 'Vanilla_RNN.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_SGD (initial_learning_rate, decay_steps, decay_rate):\n",
    "    # We define the optimizer with an initial learning rate\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate)\n",
    "\n",
    "    # We define the larning rate schedule with an exponential decay, specifying the number of decay steps and the decay rate\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, decay_rate, staircase=True)\n",
    "    \n",
    "    return optimizer, lr_schedule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2 (history):\n",
    "    \n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(len(train_loss))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, label='Training loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot method for K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1 (train_loss, train_acc, val_loss, val_acc):\n",
    "    \n",
    "    avg_train_loss = np.mean(train_loss, axis=0)\n",
    "    avg_train_acc = np.mean(train_acc, axis=0)\n",
    "    avg_val_loss = np.mean(val_loss, axis=0)\n",
    "    avg_val_acc = np.mean(train_acc, axis=0)\n",
    "\n",
    "    # Plot delle curve di apprendimento mediate sulle K fold\n",
    "\n",
    "    epochs = range(1, len(train_loss[0]) + 1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, avg_train_loss, label='Training loss')\n",
    "    plt.plot(epochs, avg_val_loss, label='Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Avg_loss')\n",
    "    plt.title('Average train and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, avg_train_acc, label='Training accuracy')\n",
    "    plt.plot(epochs, avg_val_acc, label='Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Avg_accuracy')\n",
    "    plt.title('Average train and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average loss curve\n",
    "plt.figure()\n",
    "for i in range(5):\n",
    "    plt.plot(train_loss[i])\n",
    "plt.title('Training Loss - All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(5):\n",
    "    plt.plot(train_acc[i])\n",
    "plt.title('Training Accuracy - All Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU 1 layer SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "43/63 [===================>..........] - ETA: 0s - loss: 0.7200 - accuracy: 0.6186\n",
      "Epoch 1: val_loss improved from inf to 0.69626, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 3s 11ms/step - loss: 0.7307 - accuracy: 0.6006 - val_loss: 0.6963 - val_accuracy: 0.6726 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.6290\n",
      "Epoch 2: val_loss improved from 0.69626 to 0.65035, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.6262 - val_loss: 0.6504 - val_accuracy: 0.7143 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.6355 - accuracy: 0.6873\n",
      "Epoch 3: val_loss improved from 0.65035 to 0.61083, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6869 - val_loss: 0.6108 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.5972 - accuracy: 0.7556\n",
      "Epoch 4: val_loss improved from 0.61083 to 0.57649, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.7380 - val_loss: 0.5765 - val_accuracy: 0.7679 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.5679 - accuracy: 0.7571\n",
      "Epoch 5: val_loss improved from 0.57649 to 0.54773, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7604 - val_loss: 0.5477 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.5292 - accuracy: 0.7927\n",
      "Epoch 6: val_loss improved from 0.54773 to 0.52294, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.7859 - val_loss: 0.5229 - val_accuracy: 0.8214 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.5182 - accuracy: 0.7927\n",
      "Epoch 7: val_loss improved from 0.52294 to 0.50111, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.8019 - val_loss: 0.5011 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.4834 - accuracy: 0.8145\n",
      "Epoch 8: val_loss improved from 0.50111 to 0.48172, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.8147 - val_loss: 0.4817 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.4777 - accuracy: 0.8269\n",
      "Epoch 9: val_loss improved from 0.48172 to 0.46419, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.8371 - val_loss: 0.4642 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.4578 - accuracy: 0.8453\n",
      "Epoch 10: val_loss improved from 0.46419 to 0.44848, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.8466 - val_loss: 0.4485 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.4377 - accuracy: 0.8679\n",
      "Epoch 11: val_loss improved from 0.44848 to 0.43417, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.8530 - val_loss: 0.4342 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.4395 - accuracy: 0.8480\n",
      "Epoch 12: val_loss improved from 0.43417 to 0.42129, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8530 - val_loss: 0.4213 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.4244 - accuracy: 0.8490\n",
      "Epoch 13: val_loss improved from 0.42129 to 0.40980, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8626 - val_loss: 0.4098 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.3915 - accuracy: 0.8870\n",
      "Epoch 14: val_loss improved from 0.40980 to 0.39959, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8690 - val_loss: 0.3996 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3990 - accuracy: 0.8655\n",
      "Epoch 15: val_loss improved from 0.39959 to 0.39027, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8722 - val_loss: 0.3903 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.3943 - accuracy: 0.8694\n",
      "Epoch 16: val_loss improved from 0.39027 to 0.38172, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8786 - val_loss: 0.3817 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.3666 - accuracy: 0.8885\n",
      "Epoch 17: val_loss improved from 0.38172 to 0.37385, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8786 - val_loss: 0.3738 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3679 - accuracy: 0.8727\n",
      "Epoch 18: val_loss improved from 0.37385 to 0.36650, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8818 - val_loss: 0.3665 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3573 - accuracy: 0.8945\n",
      "Epoch 19: val_loss improved from 0.36650 to 0.35963, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8882 - val_loss: 0.3596 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3497 - accuracy: 0.8889\n",
      "Epoch 20: val_loss improved from 0.35963 to 0.35323, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8882 - val_loss: 0.3532 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3505 - accuracy: 0.8909\n",
      "Epoch 21: val_loss improved from 0.35323 to 0.34726, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8914 - val_loss: 0.3473 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3511 - accuracy: 0.8945\n",
      "Epoch 22: val_loss improved from 0.34726 to 0.34164, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8946 - val_loss: 0.3416 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3289 - accuracy: 0.8981\n",
      "Epoch 23: val_loss improved from 0.34164 to 0.33640, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8946 - val_loss: 0.3364 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.3346 - accuracy: 0.8917\n",
      "Epoch 24: val_loss improved from 0.33640 to 0.33150, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8946 - val_loss: 0.3315 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.3453 - accuracy: 0.8816\n",
      "Epoch 25: val_loss improved from 0.33150 to 0.32687, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8946 - val_loss: 0.3269 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3201 - accuracy: 0.9055\n",
      "Epoch 26: val_loss improved from 0.32687 to 0.32253, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3218 - accuracy: 0.8946 - val_loss: 0.3225 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3123 - accuracy: 0.9036\n",
      "Epoch 27: val_loss improved from 0.32253 to 0.31843, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8978 - val_loss: 0.3184 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3148 - accuracy: 0.8926\n",
      "Epoch 28: val_loss improved from 0.31843 to 0.31451, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3133 - accuracy: 0.8978 - val_loss: 0.3145 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.3107 - accuracy: 0.9040\n",
      "Epoch 29: val_loss improved from 0.31451 to 0.31081, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3094 - accuracy: 0.8978 - val_loss: 0.3108 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.3217 - accuracy: 0.8846\n",
      "Epoch 30: val_loss improved from 0.31081 to 0.30729, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.8978 - val_loss: 0.3073 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2871 - accuracy: 0.9055\n",
      "Epoch 31: val_loss improved from 0.30729 to 0.30400, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3021 - accuracy: 0.8978 - val_loss: 0.3040 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3038 - accuracy: 0.8852\n",
      "Epoch 32: val_loss improved from 0.30400 to 0.30078, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.8978 - val_loss: 0.3008 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3059 - accuracy: 0.8945\n",
      "Epoch 33: val_loss improved from 0.30078 to 0.29771, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.9010 - val_loss: 0.2977 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2874 - accuracy: 0.9034\n",
      "Epoch 34: val_loss improved from 0.29771 to 0.29482, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9010 - val_loss: 0.2948 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2798 - accuracy: 0.9036\n",
      "Epoch 35: val_loss improved from 0.29482 to 0.29202, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2893 - accuracy: 0.9010 - val_loss: 0.2920 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.2870 - accuracy: 0.9021\n",
      "Epoch 36: val_loss improved from 0.29202 to 0.28932, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.9010 - val_loss: 0.2893 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2921 - accuracy: 0.8981\n",
      "Epoch 37: val_loss improved from 0.28932 to 0.28675, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.9042 - val_loss: 0.2867 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2771 - accuracy: 0.9091\n",
      "Epoch 38: val_loss improved from 0.28675 to 0.28429, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2809 - accuracy: 0.9042 - val_loss: 0.2843 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2755 - accuracy: 0.9074\n",
      "Epoch 39: val_loss improved from 0.28429 to 0.28192, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9042 - val_loss: 0.2819 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.2790 - accuracy: 0.9000\n",
      "Epoch 40: val_loss improved from 0.28192 to 0.27965, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2758 - accuracy: 0.9073 - val_loss: 0.2796 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2709 - accuracy: 0.9107\n",
      "Epoch 41: val_loss improved from 0.27965 to 0.27746, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.9073 - val_loss: 0.2775 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2853 - accuracy: 0.8923\n",
      "Epoch 42: val_loss improved from 0.27746 to 0.27534, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2711 - accuracy: 0.9073 - val_loss: 0.2753 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2680 - accuracy: 0.9000\n",
      "Epoch 43: val_loss improved from 0.27534 to 0.27330, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.9073 - val_loss: 0.2733 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2733 - accuracy: 0.9000\n",
      "Epoch 44: val_loss improved from 0.27330 to 0.27134, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2666 - accuracy: 0.9073 - val_loss: 0.2713 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2596 - accuracy: 0.9111\n",
      "Epoch 45: val_loss improved from 0.27134 to 0.26943, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.9073 - val_loss: 0.2694 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2606 - accuracy: 0.9074\n",
      "Epoch 46: val_loss improved from 0.26943 to 0.26758, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9073 - val_loss: 0.2676 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2486 - accuracy: 0.9127\n",
      "Epoch 47: val_loss improved from 0.26758 to 0.26583, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2603 - accuracy: 0.9073 - val_loss: 0.2658 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2592 - accuracy: 0.9111\n",
      "Epoch 48: val_loss improved from 0.26583 to 0.26411, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2584 - accuracy: 0.9105 - val_loss: 0.2641 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2611 - accuracy: 0.9132\n",
      "Epoch 49: val_loss improved from 0.26411 to 0.26248, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.9137 - val_loss: 0.2625 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "45/63 [====================>.........] - ETA: 0s - loss: 0.2257 - accuracy: 0.9289\n",
      "Epoch 50: val_loss improved from 0.26248 to 0.26083, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2546 - accuracy: 0.9169 - val_loss: 0.2608 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2545 - accuracy: 0.9164\n",
      "Epoch 51: val_loss improved from 0.26083 to 0.25924, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9169 - val_loss: 0.2592 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2430 - accuracy: 0.9192\n",
      "Epoch 52: val_loss improved from 0.25924 to 0.25770, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.9169 - val_loss: 0.2577 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2490 - accuracy: 0.9222\n",
      "Epoch 53: val_loss improved from 0.25770 to 0.25620, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.9201 - val_loss: 0.2562 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2396 - accuracy: 0.9245\n",
      "Epoch 54: val_loss improved from 0.25620 to 0.25474, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.9201 - val_loss: 0.2547 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2476 - accuracy: 0.9273\n",
      "Epoch 55: val_loss improved from 0.25474 to 0.25332, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2460 - accuracy: 0.9233 - val_loss: 0.2533 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2491 - accuracy: 0.9228\n",
      "Epoch 56: val_loss improved from 0.25332 to 0.25193, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2444 - accuracy: 0.9233 - val_loss: 0.2519 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2600 - accuracy: 0.9132\n",
      "Epoch 57: val_loss improved from 0.25193 to 0.25058, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2428 - accuracy: 0.9233 - val_loss: 0.2506 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2459 - accuracy: 0.9200\n",
      "Epoch 58: val_loss improved from 0.25058 to 0.24927, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2413 - accuracy: 0.9233 - val_loss: 0.2493 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2382 - accuracy: 0.9250\n",
      "Epoch 59: val_loss improved from 0.24927 to 0.24799, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.9233 - val_loss: 0.2480 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2433 - accuracy: 0.9186\n",
      "Epoch 60: val_loss improved from 0.24799 to 0.24674, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2384 - accuracy: 0.9233 - val_loss: 0.2467 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.2239 - accuracy: 0.9304\n",
      "Epoch 61: val_loss improved from 0.24674 to 0.24552, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9233 - val_loss: 0.2455 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2435 - accuracy: 0.9132\n",
      "Epoch 62: val_loss improved from 0.24552 to 0.24433, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2356 - accuracy: 0.9233 - val_loss: 0.2443 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2362 - accuracy: 0.9245\n",
      "Epoch 63: val_loss improved from 0.24433 to 0.24316, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9233 - val_loss: 0.2432 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2274 - accuracy: 0.9269\n",
      "Epoch 64: val_loss improved from 0.24316 to 0.24202, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9233 - val_loss: 0.2420 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2218 - accuracy: 0.9345\n",
      "Epoch 65: val_loss improved from 0.24202 to 0.24091, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2316 - accuracy: 0.9233 - val_loss: 0.2409 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2299 - accuracy: 0.9222\n",
      "Epoch 66: val_loss improved from 0.24091 to 0.23983, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2303 - accuracy: 0.9233 - val_loss: 0.2398 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2120 - accuracy: 0.9286\n",
      "Epoch 67: val_loss improved from 0.23983 to 0.23876, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9233 - val_loss: 0.2388 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9258\n",
      "Epoch 68: val_loss improved from 0.23876 to 0.23773, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2278 - accuracy: 0.9265 - val_loss: 0.2377 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2375 - accuracy: 0.9208\n",
      "Epoch 69: val_loss improved from 0.23773 to 0.23670, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9265 - val_loss: 0.2367 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2280 - accuracy: 0.9245\n",
      "Epoch 70: val_loss improved from 0.23670 to 0.23571, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.9297 - val_loss: 0.2357 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.2095 - accuracy: 0.9333\n",
      "Epoch 71: val_loss improved from 0.23571 to 0.23475, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9297 - val_loss: 0.2347 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2429 - accuracy: 0.9231\n",
      "Epoch 72: val_loss improved from 0.23475 to 0.23381, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2230 - accuracy: 0.9297 - val_loss: 0.2338 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2259 - accuracy: 0.9296\n",
      "Epoch 73: val_loss improved from 0.23381 to 0.23288, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9297 - val_loss: 0.2329 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2250 - accuracy: 0.9294\n",
      "Epoch 74: val_loss improved from 0.23288 to 0.23196, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2208 - accuracy: 0.9297 - val_loss: 0.2320 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2249 - accuracy: 0.9288\n",
      "Epoch 75: val_loss improved from 0.23196 to 0.23109, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2197 - accuracy: 0.9297 - val_loss: 0.2311 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2072 - accuracy: 0.9333\n",
      "Epoch 76: val_loss improved from 0.23109 to 0.23020, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9297 - val_loss: 0.2302 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2272 - accuracy: 0.9192\n",
      "Epoch 77: val_loss improved from 0.23020 to 0.22932, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2176 - accuracy: 0.9297 - val_loss: 0.2293 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2094 - accuracy: 0.9280\n",
      "Epoch 78: val_loss improved from 0.22932 to 0.22850, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9297 - val_loss: 0.2285 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9297\n",
      "Epoch 79: val_loss improved from 0.22850 to 0.22767, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2156 - accuracy: 0.9297 - val_loss: 0.2277 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9279\n",
      "Epoch 80: val_loss improved from 0.22767 to 0.22686, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2146 - accuracy: 0.9297 - val_loss: 0.2269 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2195 - accuracy: 0.9241\n",
      "Epoch 81: val_loss improved from 0.22686 to 0.22606, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9297 - val_loss: 0.2261 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2080 - accuracy: 0.9294\n",
      "Epoch 82: val_loss improved from 0.22606 to 0.22528, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2126 - accuracy: 0.9297 - val_loss: 0.2253 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2162 - accuracy: 0.9306\n",
      "Epoch 83: val_loss improved from 0.22528 to 0.22451, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2117 - accuracy: 0.9297 - val_loss: 0.2245 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2156 - accuracy: 0.9236\n",
      "Epoch 84: val_loss improved from 0.22451 to 0.22375, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9297 - val_loss: 0.2237 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2143 - accuracy: 0.9280\n",
      "Epoch 85: val_loss improved from 0.22375 to 0.22301, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2098 - accuracy: 0.9297 - val_loss: 0.2230 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.2016 - accuracy: 0.9292\n",
      "Epoch 86: val_loss improved from 0.22301 to 0.22227, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2089 - accuracy: 0.9297 - val_loss: 0.2223 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2177 - accuracy: 0.9250\n",
      "Epoch 87: val_loss improved from 0.22227 to 0.22154, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2080 - accuracy: 0.9297 - val_loss: 0.2215 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1988 - accuracy: 0.9321\n",
      "Epoch 88: val_loss improved from 0.22154 to 0.22086, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2071 - accuracy: 0.9297 - val_loss: 0.2209 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2151 - accuracy: 0.9265\n",
      "Epoch 89: val_loss improved from 0.22086 to 0.22016, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9297 - val_loss: 0.2202 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2118 - accuracy: 0.9241\n",
      "Epoch 90: val_loss improved from 0.22016 to 0.21947, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2054 - accuracy: 0.9297 - val_loss: 0.2195 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.2130 - accuracy: 0.9234\n",
      "Epoch 91: val_loss improved from 0.21947 to 0.21880, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9297 - val_loss: 0.2188 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9297\n",
      "Epoch 92: val_loss improved from 0.21880 to 0.21812, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2037 - accuracy: 0.9297 - val_loss: 0.2181 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2145 - accuracy: 0.9176\n",
      "Epoch 93: val_loss improved from 0.21812 to 0.21747, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9297 - val_loss: 0.2175 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2106 - accuracy: 0.9216\n",
      "Epoch 94: val_loss improved from 0.21747 to 0.21682, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2021 - accuracy: 0.9297 - val_loss: 0.2168 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1963 - accuracy: 0.9321\n",
      "Epoch 95: val_loss improved from 0.21682 to 0.21619, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2013 - accuracy: 0.9297 - val_loss: 0.2162 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1893 - accuracy: 0.9375\n",
      "Epoch 96: val_loss improved from 0.21619 to 0.21554, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2005 - accuracy: 0.9297 - val_loss: 0.2155 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1894 - accuracy: 0.9360\n",
      "Epoch 97: val_loss improved from 0.21554 to 0.21492, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1997 - accuracy: 0.9329 - val_loss: 0.2149 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1871 - accuracy: 0.9385\n",
      "Epoch 98: val_loss improved from 0.21492 to 0.21433, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1989 - accuracy: 0.9329 - val_loss: 0.2143 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2064 - accuracy: 0.9265\n",
      "Epoch 99: val_loss improved from 0.21433 to 0.21372, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.9329 - val_loss: 0.2137 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1980 - accuracy: 0.9322\n",
      "Epoch 100: val_loss improved from 0.21372 to 0.21313, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9329 - val_loss: 0.2131 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2025 - accuracy: 0.9345\n",
      "Epoch 101: val_loss improved from 0.21313 to 0.21254, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9361 - val_loss: 0.2125 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9361\n",
      "Epoch 102: val_loss improved from 0.21254 to 0.21196, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9361 - val_loss: 0.2120 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2052 - accuracy: 0.9306\n",
      "Epoch 103: val_loss improved from 0.21196 to 0.21139, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1952 - accuracy: 0.9361 - val_loss: 0.2114 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1961 - accuracy: 0.9373\n",
      "Epoch 104: val_loss improved from 0.21139 to 0.21083, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1945 - accuracy: 0.9361 - val_loss: 0.2108 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1889 - accuracy: 0.9414\n",
      "Epoch 105: val_loss improved from 0.21083 to 0.21028, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.9361 - val_loss: 0.2103 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2003 - accuracy: 0.9333\n",
      "Epoch 106: val_loss improved from 0.21028 to 0.20973, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1931 - accuracy: 0.9361 - val_loss: 0.2097 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1870 - accuracy: 0.9458\n",
      "Epoch 107: val_loss improved from 0.20973 to 0.20919, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1923 - accuracy: 0.9361 - val_loss: 0.2092 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1809 - accuracy: 0.9424\n",
      "Epoch 108: val_loss improved from 0.20919 to 0.20866, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1917 - accuracy: 0.9361 - val_loss: 0.2087 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1920 - accuracy: 0.9355\n",
      "Epoch 109: val_loss improved from 0.20866 to 0.20814, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1910 - accuracy: 0.9361 - val_loss: 0.2081 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1911 - accuracy: 0.9388\n",
      "Epoch 110: val_loss improved from 0.20814 to 0.20764, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1903 - accuracy: 0.9361 - val_loss: 0.2076 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1909 - accuracy: 0.9333\n",
      "Epoch 111: val_loss improved from 0.20764 to 0.20712, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1896 - accuracy: 0.9361 - val_loss: 0.2071 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9361\n",
      "Epoch 112: val_loss improved from 0.20712 to 0.20661, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1890 - accuracy: 0.9361 - val_loss: 0.2066 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1952 - accuracy: 0.9333\n",
      "Epoch 113: val_loss improved from 0.20661 to 0.20611, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1883 - accuracy: 0.9361 - val_loss: 0.2061 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9355\n",
      "Epoch 114: val_loss improved from 0.20611 to 0.20561, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1877 - accuracy: 0.9361 - val_loss: 0.2056 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2016 - accuracy: 0.9283\n",
      "Epoch 115: val_loss improved from 0.20561 to 0.20512, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1870 - accuracy: 0.9361 - val_loss: 0.2051 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2026 - accuracy: 0.9306\n",
      "Epoch 116: val_loss improved from 0.20512 to 0.20463, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9393 - val_loss: 0.2046 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1836 - accuracy: 0.9396\n",
      "Epoch 117: val_loss improved from 0.20463 to 0.20415, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1858 - accuracy: 0.9393 - val_loss: 0.2041 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1779 - accuracy: 0.9462\n",
      "Epoch 118: val_loss improved from 0.20415 to 0.20369, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1852 - accuracy: 0.9393 - val_loss: 0.2037 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1999 - accuracy: 0.9320\n",
      "Epoch 119: val_loss improved from 0.20369 to 0.20322, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9393 - val_loss: 0.2032 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1852 - accuracy: 0.9404\n",
      "Epoch 120: val_loss improved from 0.20322 to 0.20275, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1839 - accuracy: 0.9393 - val_loss: 0.2028 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1774 - accuracy: 0.9429\n",
      "Epoch 121: val_loss improved from 0.20275 to 0.20230, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1833 - accuracy: 0.9393 - val_loss: 0.2023 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1781 - accuracy: 0.9439\n",
      "Epoch 122: val_loss improved from 0.20230 to 0.20187, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1828 - accuracy: 0.9393 - val_loss: 0.2019 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1874 - accuracy: 0.9367\n",
      "Epoch 123: val_loss improved from 0.20187 to 0.20142, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1822 - accuracy: 0.9393 - val_loss: 0.2014 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1823 - accuracy: 0.9379\n",
      "Epoch 124: val_loss improved from 0.20142 to 0.20097, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1816 - accuracy: 0.9393 - val_loss: 0.2010 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1846 - accuracy: 0.9429\n",
      "Epoch 125: val_loss improved from 0.20097 to 0.20052, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1810 - accuracy: 0.9393 - val_loss: 0.2005 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1913 - accuracy: 0.9333\n",
      "Epoch 126: val_loss improved from 0.20052 to 0.20008, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9393 - val_loss: 0.2001 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9443\n",
      "Epoch 127: val_loss improved from 0.20008 to 0.19965, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9393 - val_loss: 0.1996 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1783 - accuracy: 0.9423\n",
      "Epoch 128: val_loss improved from 0.19965 to 0.19922, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 0.9393 - val_loss: 0.1992 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9393\n",
      "Epoch 129: val_loss improved from 0.19922 to 0.19880, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1787 - accuracy: 0.9393 - val_loss: 0.1988 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1691 - accuracy: 0.9412\n",
      "Epoch 130: val_loss improved from 0.19880 to 0.19837, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1782 - accuracy: 0.9393 - val_loss: 0.1984 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1725 - accuracy: 0.9373\n",
      "Epoch 131: val_loss improved from 0.19837 to 0.19798, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1776 - accuracy: 0.9393 - val_loss: 0.1980 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1792 - accuracy: 0.9377\n",
      "Epoch 132: val_loss improved from 0.19798 to 0.19757, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1771 - accuracy: 0.9393 - val_loss: 0.1976 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 133/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1777 - accuracy: 0.9375\n",
      "Epoch 133: val_loss improved from 0.19757 to 0.19717, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1766 - accuracy: 0.9393 - val_loss: 0.1972 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1729 - accuracy: 0.9410\n",
      "Epoch 134: val_loss improved from 0.19717 to 0.19679, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1760 - accuracy: 0.9393 - val_loss: 0.1968 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1712 - accuracy: 0.9467\n",
      "Epoch 135: val_loss improved from 0.19679 to 0.19639, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1755 - accuracy: 0.9393 - val_loss: 0.1964 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1758 - accuracy: 0.9410\n",
      "Epoch 136: val_loss improved from 0.19639 to 0.19599, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1750 - accuracy: 0.9393 - val_loss: 0.1960 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1536 - accuracy: 0.9517\n",
      "Epoch 137: val_loss improved from 0.19599 to 0.19562, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9393 - val_loss: 0.1956 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 138/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1666 - accuracy: 0.9404\n",
      "Epoch 138: val_loss improved from 0.19562 to 0.19523, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1739 - accuracy: 0.9393 - val_loss: 0.1952 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1653 - accuracy: 0.9404\n",
      "Epoch 139: val_loss improved from 0.19523 to 0.19484, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.9393 - val_loss: 0.1948 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1615 - accuracy: 0.9393\n",
      "Epoch 140: val_loss improved from 0.19484 to 0.19446, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1729 - accuracy: 0.9393 - val_loss: 0.1945 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1601 - accuracy: 0.9439\n",
      "Epoch 141: val_loss improved from 0.19446 to 0.19408, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.9393 - val_loss: 0.1941 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9387\n",
      "Epoch 142: val_loss improved from 0.19408 to 0.19370, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1719 - accuracy: 0.9393 - val_loss: 0.1937 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9387\n",
      "Epoch 143: val_loss improved from 0.19370 to 0.19333, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1714 - accuracy: 0.9393 - val_loss: 0.1933 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1774 - accuracy: 0.9333\n",
      "Epoch 144: val_loss improved from 0.19333 to 0.19296, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.9393 - val_loss: 0.1930 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.9333\n",
      "Epoch 145: val_loss improved from 0.19296 to 0.19260, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1705 - accuracy: 0.9393 - val_loss: 0.1926 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1719 - accuracy: 0.9429\n",
      "Epoch 146: val_loss improved from 0.19260 to 0.19223, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9393 - val_loss: 0.1922 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 147/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1706 - accuracy: 0.9404\n",
      "Epoch 147: val_loss improved from 0.19223 to 0.19187, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1695 - accuracy: 0.9393 - val_loss: 0.1919 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 148/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1720 - accuracy: 0.9407\n",
      "Epoch 148: val_loss improved from 0.19187 to 0.19151, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1690 - accuracy: 0.9393 - val_loss: 0.1915 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 149/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1676 - accuracy: 0.9418\n",
      "Epoch 149: val_loss improved from 0.19151 to 0.19116, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.9393 - val_loss: 0.1912 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 150/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1627 - accuracy: 0.9429\n",
      "Epoch 150: val_loss improved from 0.19116 to 0.19082, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1681 - accuracy: 0.9393 - val_loss: 0.1908 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 151/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1685 - accuracy: 0.9387\n",
      "Epoch 151: val_loss improved from 0.19082 to 0.19047, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1676 - accuracy: 0.9393 - val_loss: 0.1905 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 152/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9419\n",
      "Epoch 152: val_loss improved from 0.19047 to 0.19013, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1672 - accuracy: 0.9425 - val_loss: 0.1901 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 153/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9443\n",
      "Epoch 153: val_loss improved from 0.19013 to 0.18978, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9393 - val_loss: 0.1898 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 154/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1537 - accuracy: 0.9464\n",
      "Epoch 154: val_loss improved from 0.18978 to 0.18944, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9425 - val_loss: 0.1894 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 155/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1761 - accuracy: 0.9404\n",
      "Epoch 155: val_loss improved from 0.18944 to 0.18911, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.9457 - val_loss: 0.1891 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 156/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1758 - accuracy: 0.9396\n",
      "Epoch 156: val_loss improved from 0.18911 to 0.18878, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9457 - val_loss: 0.1888 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 157/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1681 - accuracy: 0.9448\n",
      "Epoch 157: val_loss improved from 0.18878 to 0.18845, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1649 - accuracy: 0.9457 - val_loss: 0.1884 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 158/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9443\n",
      "Epoch 158: val_loss improved from 0.18845 to 0.18813, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9457 - val_loss: 0.1881 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 159/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1681 - accuracy: 0.9424\n",
      "Epoch 159: val_loss improved from 0.18813 to 0.18781, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9457 - val_loss: 0.1878 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 160/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1708 - accuracy: 0.9448\n",
      "Epoch 160: val_loss improved from 0.18781 to 0.18749, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9489 - val_loss: 0.1875 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 161/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1618 - accuracy: 0.9492\n",
      "Epoch 161: val_loss improved from 0.18749 to 0.18718, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9489 - val_loss: 0.1872 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 162/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1676 - accuracy: 0.9474\n",
      "Epoch 162: val_loss improved from 0.18718 to 0.18686, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9489 - val_loss: 0.1869 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 163/200\n",
      "44/63 [===================>..........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9545\n",
      "Epoch 163: val_loss improved from 0.18686 to 0.18655, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1624 - accuracy: 0.9489 - val_loss: 0.1865 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 164/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1579 - accuracy: 0.9517\n",
      "Epoch 164: val_loss improved from 0.18655 to 0.18624, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9489 - val_loss: 0.1862 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 165/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1662 - accuracy: 0.9440\n",
      "Epoch 165: val_loss improved from 0.18624 to 0.18594, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1616 - accuracy: 0.9489 - val_loss: 0.1859 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 166/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1537 - accuracy: 0.9536\n",
      "Epoch 166: val_loss improved from 0.18594 to 0.18564, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9489 - val_loss: 0.1856 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 167/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1659 - accuracy: 0.9467\n",
      "Epoch 167: val_loss improved from 0.18564 to 0.18534, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9489 - val_loss: 0.1853 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 168/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1668 - accuracy: 0.9458\n",
      "Epoch 168: val_loss improved from 0.18534 to 0.18504, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.9489 - val_loss: 0.1850 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 169/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1565 - accuracy: 0.9491\n",
      "Epoch 169: val_loss improved from 0.18504 to 0.18475, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1600 - accuracy: 0.9489 - val_loss: 0.1848 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 170/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1664 - accuracy: 0.9455\n",
      "Epoch 170: val_loss improved from 0.18475 to 0.18445, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9489 - val_loss: 0.1845 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 171/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1622 - accuracy: 0.9474\n",
      "Epoch 171: val_loss improved from 0.18445 to 0.18417, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.9489 - val_loss: 0.1842 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 172/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1577 - accuracy: 0.9492\n",
      "Epoch 172: val_loss improved from 0.18417 to 0.18388, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9489 - val_loss: 0.1839 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 173/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1613 - accuracy: 0.9509\n",
      "Epoch 173: val_loss improved from 0.18388 to 0.18360, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9489 - val_loss: 0.1836 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 174/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1611 - accuracy: 0.9481\n",
      "Epoch 174: val_loss improved from 0.18360 to 0.18332, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9521 - val_loss: 0.1833 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 175/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1568 - accuracy: 0.9586\n",
      "Epoch 175: val_loss improved from 0.18332 to 0.18302, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1577 - accuracy: 0.9553 - val_loss: 0.1830 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 176/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1525 - accuracy: 0.9527\n",
      "Epoch 176: val_loss improved from 0.18302 to 0.18277, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9553 - val_loss: 0.1828 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 177/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1476 - accuracy: 0.9586\n",
      "Epoch 177: val_loss improved from 0.18277 to 0.18252, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9553 - val_loss: 0.1825 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9553\n",
      "Epoch 178: val_loss improved from 0.18252 to 0.18224, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1566 - accuracy: 0.9553 - val_loss: 0.1822 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 179/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1606 - accuracy: 0.9559\n",
      "Epoch 179: val_loss improved from 0.18224 to 0.18196, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9553 - val_loss: 0.1820 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 180/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1630 - accuracy: 0.9517\n",
      "Epoch 180: val_loss improved from 0.18196 to 0.18170, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.9553 - val_loss: 0.1817 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 181/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1425 - accuracy: 0.9614\n",
      "Epoch 181: val_loss improved from 0.18170 to 0.18143, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9553 - val_loss: 0.1814 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 182/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1536 - accuracy: 0.9592\n",
      "Epoch 182: val_loss improved from 0.18143 to 0.18117, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1551 - accuracy: 0.9553 - val_loss: 0.1812 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 183/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1595 - accuracy: 0.9536\n",
      "Epoch 183: val_loss improved from 0.18117 to 0.18091, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9553 - val_loss: 0.1809 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 184/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1613 - accuracy: 0.9509\n",
      "Epoch 184: val_loss improved from 0.18091 to 0.18065, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9553 - val_loss: 0.1807 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 185/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1433 - accuracy: 0.9636\n",
      "Epoch 185: val_loss improved from 0.18065 to 0.18039, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9553 - val_loss: 0.1804 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 186/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1522 - accuracy: 0.9547\n",
      "Epoch 186: val_loss improved from 0.18039 to 0.18014, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9553 - val_loss: 0.1801 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 187/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1494 - accuracy: 0.9579\n",
      "Epoch 187: val_loss improved from 0.18014 to 0.17989, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1534 - accuracy: 0.9553 - val_loss: 0.1799 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 188/200\n",
      "45/63 [====================>.........] - ETA: 0s - loss: 0.1640 - accuracy: 0.9511\n",
      "Epoch 188: val_loss improved from 0.17989 to 0.17964, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1531 - accuracy: 0.9553 - val_loss: 0.1796 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 189/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1602 - accuracy: 0.9536\n",
      "Epoch 189: val_loss improved from 0.17964 to 0.17939, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9553 - val_loss: 0.1794 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 190/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1378 - accuracy: 0.9623\n",
      "Epoch 190: val_loss improved from 0.17939 to 0.17914, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1524 - accuracy: 0.9553 - val_loss: 0.1791 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 191/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9544\n",
      "Epoch 191: val_loss improved from 0.17914 to 0.17890, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9553 - val_loss: 0.1789 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 192/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1698 - accuracy: 0.9462\n",
      "Epoch 192: val_loss improved from 0.17890 to 0.17866, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9553 - val_loss: 0.1787 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 193/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1471 - accuracy: 0.9564\n",
      "Epoch 193: val_loss improved from 0.17866 to 0.17841, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9553 - val_loss: 0.1784 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 194/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1493 - accuracy: 0.9519\n",
      "Epoch 194: val_loss improved from 0.17841 to 0.17817, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9553 - val_loss: 0.1782 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 195/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1577 - accuracy: 0.9517\n",
      "Epoch 195: val_loss improved from 0.17817 to 0.17794, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9553 - val_loss: 0.1779 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 196/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.9525\n",
      "Epoch 196: val_loss improved from 0.17794 to 0.17768, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9553 - val_loss: 0.1777 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 197/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9541\n",
      "Epoch 197: val_loss improved from 0.17768 to 0.17744, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1501 - accuracy: 0.9553 - val_loss: 0.1774 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 198/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1423 - accuracy: 0.9577\n",
      "Epoch 198: val_loss improved from 0.17744 to 0.17722, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9553 - val_loss: 0.1772 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 199/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1354 - accuracy: 0.9621\n",
      "Epoch 199: val_loss improved from 0.17722 to 0.17700, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9553 - val_loss: 0.1770 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 200/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1511 - accuracy: 0.9544\n",
      "Epoch 200: val_loss improved from 0.17700 to 0.17678, saving model to model_checkpoint\\GRU_1 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9553 - val_loss: 0.1768 - val_accuracy: 0.9464 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 32)                11520     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,553\n",
      "Trainable params: 11,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9464\n",
      "Test Loss: 0.1767757534980774\n",
      "Test Accuracy: 0.9464285969734192\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'GRU_1 layer_SGD.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, x_train.shape[-1])))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a SGD optimizer with an exponential decaying learning rate\n",
    "optimizer, lr_schedule = optimizer_SGD(0.001, 1000, 0.1)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=200, validation_data=(x_val, y_val), callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule),callbacks_list])\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU 1 layer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.6981 - accuracy: 0.5542\n",
      "Epoch 1: val_loss improved from inf to 0.70889, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 3s 10ms/step - loss: 0.6830 - accuracy: 0.5815 - val_loss: 0.7089 - val_accuracy: 0.5476\n",
      "Epoch 2/200\n",
      "45/63 [====================>.........] - ETA: 0s - loss: 0.6357 - accuracy: 0.6311\n",
      "Epoch 2: val_loss improved from 0.70889 to 0.64839, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.6486 - val_loss: 0.6484 - val_accuracy: 0.6310\n",
      "Epoch 3/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.5851 - accuracy: 0.6981\n",
      "Epoch 3: val_loss improved from 0.64839 to 0.59753, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7284 - val_loss: 0.5975 - val_accuracy: 0.6845\n",
      "Epoch 4/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.5188 - accuracy: 0.7821\n",
      "Epoch 4: val_loss improved from 0.59753 to 0.55538, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7764 - val_loss: 0.5554 - val_accuracy: 0.7262\n",
      "Epoch 5/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.4764 - accuracy: 0.8068\n",
      "Epoch 5: val_loss improved from 0.55538 to 0.51824, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.8083 - val_loss: 0.5182 - val_accuracy: 0.7798\n",
      "Epoch 6/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.4444 - accuracy: 0.8444\n",
      "Epoch 6: val_loss improved from 0.51824 to 0.48603, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8371 - val_loss: 0.4860 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.4201 - accuracy: 0.8690\n",
      "Epoch 7: val_loss improved from 0.48603 to 0.45910, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8722 - val_loss: 0.4591 - val_accuracy: 0.8512\n",
      "Epoch 8/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3767 - accuracy: 0.8982\n",
      "Epoch 8: val_loss improved from 0.45910 to 0.43459, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8978 - val_loss: 0.4346 - val_accuracy: 0.8631\n",
      "Epoch 9/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.3693 - accuracy: 0.8983\n",
      "Epoch 9: val_loss improved from 0.43459 to 0.41306, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.9042 - val_loss: 0.4131 - val_accuracy: 0.8690\n",
      "Epoch 10/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.3488 - accuracy: 0.9067\n",
      "Epoch 10: val_loss improved from 0.41306 to 0.39407, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.9073 - val_loss: 0.3941 - val_accuracy: 0.8690\n",
      "Epoch 11/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3264 - accuracy: 0.9088\n",
      "Epoch 11: val_loss improved from 0.39407 to 0.37695, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.9105 - val_loss: 0.3769 - val_accuracy: 0.8690\n",
      "Epoch 12/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9283\n",
      "Epoch 12: val_loss improved from 0.37695 to 0.36161, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.9233 - val_loss: 0.3616 - val_accuracy: 0.8750\n",
      "Epoch 13/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.3002 - accuracy: 0.9207\n",
      "Epoch 13: val_loss improved from 0.36161 to 0.34796, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.9265 - val_loss: 0.3480 - val_accuracy: 0.8750\n",
      "Epoch 14/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2832 - accuracy: 0.9276\n",
      "Epoch 14: val_loss improved from 0.34796 to 0.33540, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.9265 - val_loss: 0.3354 - val_accuracy: 0.8810\n",
      "Epoch 15/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2781 - accuracy: 0.9254\n",
      "Epoch 15: val_loss improved from 0.33540 to 0.32427, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.9297 - val_loss: 0.3243 - val_accuracy: 0.8869\n",
      "Epoch 16/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2606 - accuracy: 0.9368\n",
      "Epoch 16: val_loss improved from 0.32427 to 0.31374, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9329 - val_loss: 0.3137 - val_accuracy: 0.8988\n",
      "Epoch 17/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2603 - accuracy: 0.9356\n",
      "Epoch 17: val_loss improved from 0.31374 to 0.30474, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.9393 - val_loss: 0.3047 - val_accuracy: 0.8988\n",
      "Epoch 18/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2517 - accuracy: 0.9368\n",
      "Epoch 18: val_loss improved from 0.30474 to 0.29623, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2446 - accuracy: 0.9393 - val_loss: 0.2962 - val_accuracy: 0.8988\n",
      "Epoch 19/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2388 - accuracy: 0.9434\n",
      "Epoch 19: val_loss improved from 0.29623 to 0.28835, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2368 - accuracy: 0.9393 - val_loss: 0.2883 - val_accuracy: 0.9048\n",
      "Epoch 20/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2373 - accuracy: 0.9308\n",
      "Epoch 20: val_loss improved from 0.28835 to 0.28115, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2295 - accuracy: 0.9393 - val_loss: 0.2812 - val_accuracy: 0.9048\n",
      "Epoch 21/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2297 - accuracy: 0.9390\n",
      "Epoch 21: val_loss improved from 0.28115 to 0.27439, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9425 - val_loss: 0.2744 - val_accuracy: 0.9048\n",
      "Epoch 22/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2167 - accuracy: 0.9458\n",
      "Epoch 22: val_loss improved from 0.27439 to 0.26799, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9425 - val_loss: 0.2680 - val_accuracy: 0.9048\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9425\n",
      "Epoch 23: val_loss improved from 0.26799 to 0.26240, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.2107 - accuracy: 0.9425 - val_loss: 0.2624 - val_accuracy: 0.9048\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.9457\n",
      "Epoch 24: val_loss improved from 0.26240 to 0.25684, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2053 - accuracy: 0.9457 - val_loss: 0.2568 - val_accuracy: 0.9048\n",
      "Epoch 25/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2046 - accuracy: 0.9433\n",
      "Epoch 25: val_loss improved from 0.25684 to 0.25190, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2002 - accuracy: 0.9457 - val_loss: 0.2519 - val_accuracy: 0.9107\n",
      "Epoch 26/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1948 - accuracy: 0.9418\n",
      "Epoch 26: val_loss improved from 0.25190 to 0.24704, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1954 - accuracy: 0.9457 - val_loss: 0.2470 - val_accuracy: 0.9107\n",
      "Epoch 27/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1937 - accuracy: 0.9412\n",
      "Epoch 27: val_loss improved from 0.24704 to 0.24263, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9457 - val_loss: 0.2426 - val_accuracy: 0.9107\n",
      "Epoch 28/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1877 - accuracy: 0.9396\n",
      "Epoch 28: val_loss improved from 0.24263 to 0.23867, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9457 - val_loss: 0.2387 - val_accuracy: 0.9107\n",
      "Epoch 29/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1859 - accuracy: 0.9455\n",
      "Epoch 29: val_loss improved from 0.23867 to 0.23472, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.9457 - val_loss: 0.2347 - val_accuracy: 0.9107\n",
      "Epoch 30/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1708 - accuracy: 0.9538\n",
      "Epoch 30: val_loss improved from 0.23472 to 0.23071, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1786 - accuracy: 0.9457 - val_loss: 0.2307 - val_accuracy: 0.9107\n",
      "Epoch 31/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1670 - accuracy: 0.9481\n",
      "Epoch 31: val_loss improved from 0.23071 to 0.22728, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9457 - val_loss: 0.2273 - val_accuracy: 0.9167\n",
      "Epoch 32/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1807 - accuracy: 0.9455\n",
      "Epoch 32: val_loss improved from 0.22728 to 0.22416, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1717 - accuracy: 0.9489 - val_loss: 0.2242 - val_accuracy: 0.9107\n",
      "Epoch 33/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9475\n",
      "Epoch 33: val_loss improved from 0.22416 to 0.22090, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1683 - accuracy: 0.9489 - val_loss: 0.2209 - val_accuracy: 0.9167\n",
      "Epoch 34/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1730 - accuracy: 0.9455\n",
      "Epoch 34: val_loss improved from 0.22090 to 0.21796, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.9489 - val_loss: 0.2180 - val_accuracy: 0.9107\n",
      "Epoch 35/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1707 - accuracy: 0.9439\n",
      "Epoch 35: val_loss improved from 0.21796 to 0.21495, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.9489 - val_loss: 0.2150 - val_accuracy: 0.9167\n",
      "Epoch 36/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1626 - accuracy: 0.9467\n",
      "Epoch 36: val_loss improved from 0.21495 to 0.21239, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.9489 - val_loss: 0.2124 - val_accuracy: 0.9167\n",
      "Epoch 37/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1550 - accuracy: 0.9525\n",
      "Epoch 37: val_loss improved from 0.21239 to 0.20975, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9521 - val_loss: 0.2098 - val_accuracy: 0.9167\n",
      "Epoch 38/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1508 - accuracy: 0.9536\n",
      "Epoch 38: val_loss improved from 0.20975 to 0.20726, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1538 - accuracy: 0.9521 - val_loss: 0.2073 - val_accuracy: 0.9167\n",
      "Epoch 39/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1515 - accuracy: 0.9491\n",
      "Epoch 39: val_loss improved from 0.20726 to 0.20486, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9521 - val_loss: 0.2049 - val_accuracy: 0.9167\n",
      "Epoch 40/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1371 - accuracy: 0.9600\n",
      "Epoch 40: val_loss improved from 0.20486 to 0.20262, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.9553 - val_loss: 0.2026 - val_accuracy: 0.9167\n",
      "Epoch 41/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1554 - accuracy: 0.9491\n",
      "Epoch 41: val_loss improved from 0.20262 to 0.20059, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1464 - accuracy: 0.9553 - val_loss: 0.2006 - val_accuracy: 0.9167\n",
      "Epoch 42/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1408 - accuracy: 0.9615\n",
      "Epoch 42: val_loss improved from 0.20059 to 0.19838, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.9585 - val_loss: 0.1984 - val_accuracy: 0.9286\n",
      "Epoch 43/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1290 - accuracy: 0.9673\n",
      "Epoch 43: val_loss improved from 0.19838 to 0.19620, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9585 - val_loss: 0.1962 - val_accuracy: 0.9286\n",
      "Epoch 44/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1353 - accuracy: 0.9586\n",
      "Epoch 44: val_loss improved from 0.19620 to 0.19457, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9585 - val_loss: 0.1946 - val_accuracy: 0.9345\n",
      "Epoch 45/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1392 - accuracy: 0.9586\n",
      "Epoch 45: val_loss improved from 0.19457 to 0.19271, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9585 - val_loss: 0.1927 - val_accuracy: 0.9345\n",
      "Epoch 46/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1380 - accuracy: 0.9567\n",
      "Epoch 46: val_loss improved from 0.19271 to 0.19105, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9585 - val_loss: 0.1911 - val_accuracy: 0.9345\n",
      "Epoch 47/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1341 - accuracy: 0.9593\n",
      "Epoch 47: val_loss improved from 0.19105 to 0.18935, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9585 - val_loss: 0.1893 - val_accuracy: 0.9345\n",
      "Epoch 48/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1303 - accuracy: 0.9564\n",
      "Epoch 48: val_loss improved from 0.18935 to 0.18766, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9585 - val_loss: 0.1877 - val_accuracy: 0.9345\n",
      "Epoch 49/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.9574\n",
      "Epoch 49: val_loss improved from 0.18766 to 0.18625, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9585 - val_loss: 0.1862 - val_accuracy: 0.9345\n",
      "Epoch 50/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1268 - accuracy: 0.9600\n",
      "Epoch 50: val_loss improved from 0.18625 to 0.18460, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9585 - val_loss: 0.1846 - val_accuracy: 0.9345\n",
      "Epoch 51/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1270 - accuracy: 0.9574\n",
      "Epoch 51: val_loss improved from 0.18460 to 0.18336, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9585 - val_loss: 0.1834 - val_accuracy: 0.9345\n",
      "Epoch 52/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1269 - accuracy: 0.9567\n",
      "Epoch 52: val_loss improved from 0.18336 to 0.18197, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9585 - val_loss: 0.1820 - val_accuracy: 0.9345\n",
      "Epoch 53/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1271 - accuracy: 0.9547\n",
      "Epoch 53: val_loss improved from 0.18197 to 0.18069, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9585 - val_loss: 0.1807 - val_accuracy: 0.9405\n",
      "Epoch 54/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9607\n",
      "Epoch 54: val_loss improved from 0.18069 to 0.17914, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9585 - val_loss: 0.1791 - val_accuracy: 0.9405\n",
      "Epoch 55/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9581\n",
      "Epoch 55: val_loss improved from 0.17914 to 0.17807, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9585 - val_loss: 0.1781 - val_accuracy: 0.9405\n",
      "Epoch 56/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1201 - accuracy: 0.9567\n",
      "Epoch 56: val_loss improved from 0.17807 to 0.17664, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9585 - val_loss: 0.1766 - val_accuracy: 0.9405\n",
      "Epoch 57/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1216 - accuracy: 0.9552\n",
      "Epoch 57: val_loss improved from 0.17664 to 0.17566, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9585 - val_loss: 0.1757 - val_accuracy: 0.9405\n",
      "Epoch 58/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9613\n",
      "Epoch 58: val_loss improved from 0.17566 to 0.17458, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9617 - val_loss: 0.1746 - val_accuracy: 0.9405\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9617\n",
      "Epoch 59: val_loss improved from 0.17458 to 0.17351, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9617 - val_loss: 0.1735 - val_accuracy: 0.9405\n",
      "Epoch 60/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1065 - accuracy: 0.9655\n",
      "Epoch 60: val_loss improved from 0.17351 to 0.17225, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9617 - val_loss: 0.1723 - val_accuracy: 0.9405\n",
      "Epoch 61/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1100 - accuracy: 0.9569\n",
      "Epoch 61: val_loss improved from 0.17225 to 0.17136, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 0.9617 - val_loss: 0.1714 - val_accuracy: 0.9405\n",
      "Epoch 62/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1121 - accuracy: 0.9614\n",
      "Epoch 62: val_loss improved from 0.17136 to 0.17027, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9617 - val_loss: 0.1703 - val_accuracy: 0.9405\n",
      "Epoch 63/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1104 - accuracy: 0.9621\n",
      "Epoch 63: val_loss improved from 0.17027 to 0.16936, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9617 - val_loss: 0.1694 - val_accuracy: 0.9405\n",
      "Epoch 64/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1007 - accuracy: 0.9615\n",
      "Epoch 64: val_loss improved from 0.16936 to 0.16843, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9617 - val_loss: 0.1684 - val_accuracy: 0.9405\n",
      "Epoch 65/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1070 - accuracy: 0.9627\n",
      "Epoch 65: val_loss improved from 0.16843 to 0.16741, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9649 - val_loss: 0.1674 - val_accuracy: 0.9405\n",
      "Epoch 66/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1040 - accuracy: 0.9645\n",
      "Epoch 66: val_loss improved from 0.16741 to 0.16659, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9649 - val_loss: 0.1666 - val_accuracy: 0.9405\n",
      "Epoch 67/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1039 - accuracy: 0.9633\n",
      "Epoch 67: val_loss improved from 0.16659 to 0.16575, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1018 - accuracy: 0.9649 - val_loss: 0.1658 - val_accuracy: 0.9405\n",
      "Epoch 68/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0984 - accuracy: 0.9690\n",
      "Epoch 68: val_loss improved from 0.16575 to 0.16479, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9681 - val_loss: 0.1648 - val_accuracy: 0.9405\n",
      "Epoch 69/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1020 - accuracy: 0.9667\n",
      "Epoch 69: val_loss improved from 0.16479 to 0.16413, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.9681 - val_loss: 0.1641 - val_accuracy: 0.9405\n",
      "Epoch 70/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0970 - accuracy: 0.9700\n",
      "Epoch 70: val_loss improved from 0.16413 to 0.16314, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9681 - val_loss: 0.1631 - val_accuracy: 0.9405\n",
      "Epoch 71/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1004 - accuracy: 0.9640\n",
      "Epoch 71: val_loss improved from 0.16314 to 0.16235, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9681 - val_loss: 0.1624 - val_accuracy: 0.9405\n",
      "Epoch 72/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0955 - accuracy: 0.9714\n",
      "Epoch 72: val_loss improved from 0.16235 to 0.16169, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9681 - val_loss: 0.1617 - val_accuracy: 0.9405\n",
      "Epoch 73/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0908 - accuracy: 0.9667\n",
      "Epoch 73: val_loss improved from 0.16169 to 0.16080, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9681 - val_loss: 0.1608 - val_accuracy: 0.9405\n",
      "Epoch 74/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0889 - accuracy: 0.9709\n",
      "Epoch 74: val_loss improved from 0.16080 to 0.16004, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9681 - val_loss: 0.1600 - val_accuracy: 0.9405\n",
      "Epoch 75/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0920 - accuracy: 0.9680\n",
      "Epoch 75: val_loss improved from 0.16004 to 0.15933, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.9681 - val_loss: 0.1593 - val_accuracy: 0.9405\n",
      "Epoch 76/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0961 - accuracy: 0.9667\n",
      "Epoch 76: val_loss improved from 0.15933 to 0.15859, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9681 - val_loss: 0.1586 - val_accuracy: 0.9405\n",
      "Epoch 77/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0965 - accuracy: 0.9660\n",
      "Epoch 77: val_loss improved from 0.15859 to 0.15789, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9681 - val_loss: 0.1579 - val_accuracy: 0.9405\n",
      "Epoch 78/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0895 - accuracy: 0.9667\n",
      "Epoch 78: val_loss improved from 0.15789 to 0.15688, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9681 - val_loss: 0.1569 - val_accuracy: 0.9405\n",
      "Epoch 79/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0899 - accuracy: 0.9667\n",
      "Epoch 79: val_loss improved from 0.15688 to 0.15645, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9681 - val_loss: 0.1565 - val_accuracy: 0.9405\n",
      "Epoch 80/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0835 - accuracy: 0.9698\n",
      "Epoch 80: val_loss improved from 0.15645 to 0.15570, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9681 - val_loss: 0.1557 - val_accuracy: 0.9405\n",
      "Epoch 81/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0859 - accuracy: 0.9660\n",
      "Epoch 81: val_loss improved from 0.15570 to 0.15527, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9681 - val_loss: 0.1553 - val_accuracy: 0.9405\n",
      "Epoch 82/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0848 - accuracy: 0.9695\n",
      "Epoch 82: val_loss improved from 0.15527 to 0.15431, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9681 - val_loss: 0.1543 - val_accuracy: 0.9405\n",
      "Epoch 83/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0807 - accuracy: 0.9714\n",
      "Epoch 83: val_loss improved from 0.15431 to 0.15366, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9681 - val_loss: 0.1537 - val_accuracy: 0.9405\n",
      "Epoch 84/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0746 - accuracy: 0.9709\n",
      "Epoch 84: val_loss improved from 0.15366 to 0.15290, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9681 - val_loss: 0.1529 - val_accuracy: 0.9405\n",
      "Epoch 85/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0810 - accuracy: 0.9700\n",
      "Epoch 85: val_loss improved from 0.15290 to 0.15265, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9712 - val_loss: 0.1526 - val_accuracy: 0.9405\n",
      "Epoch 86/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0837 - accuracy: 0.9709\n",
      "Epoch 86: val_loss improved from 0.15265 to 0.15160, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9712 - val_loss: 0.1516 - val_accuracy: 0.9405\n",
      "Epoch 87/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0840 - accuracy: 0.9709\n",
      "Epoch 87: val_loss improved from 0.15160 to 0.15102, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9744 - val_loss: 0.1510 - val_accuracy: 0.9405\n",
      "Epoch 88/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0837 - accuracy: 0.9745\n",
      "Epoch 88: val_loss improved from 0.15102 to 0.15058, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9776 - val_loss: 0.1506 - val_accuracy: 0.9405\n",
      "Epoch 89/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0771 - accuracy: 0.9797\n",
      "Epoch 89: val_loss improved from 0.15058 to 0.14981, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9776 - val_loss: 0.1498 - val_accuracy: 0.9405\n",
      "Epoch 90/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0817 - accuracy: 0.9750\n",
      "Epoch 90: val_loss improved from 0.14981 to 0.14932, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9776 - val_loss: 0.1493 - val_accuracy: 0.9405\n",
      "Epoch 91/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0808 - accuracy: 0.9755\n",
      "Epoch 91: val_loss improved from 0.14932 to 0.14858, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9776 - val_loss: 0.1486 - val_accuracy: 0.9405\n",
      "Epoch 92/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0758 - accuracy: 0.9793\n",
      "Epoch 92: val_loss improved from 0.14858 to 0.14803, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9776 - val_loss: 0.1480 - val_accuracy: 0.9405\n",
      "Epoch 93/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9770\n",
      "Epoch 93: val_loss improved from 0.14803 to 0.14720, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9776 - val_loss: 0.1472 - val_accuracy: 0.9405\n",
      "Epoch 94/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0718 - accuracy: 0.9767\n",
      "Epoch 94: val_loss improved from 0.14720 to 0.14662, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9776 - val_loss: 0.1466 - val_accuracy: 0.9405\n",
      "Epoch 95/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0729 - accuracy: 0.9797\n",
      "Epoch 95: val_loss improved from 0.14662 to 0.14619, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9808 - val_loss: 0.1462 - val_accuracy: 0.9405\n",
      "Epoch 96/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0630 - accuracy: 0.9796\n",
      "Epoch 96: val_loss improved from 0.14619 to 0.14547, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9808 - val_loss: 0.1455 - val_accuracy: 0.9405\n",
      "Epoch 97/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0653 - accuracy: 0.9831\n",
      "Epoch 97: val_loss improved from 0.14547 to 0.14466, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9808 - val_loss: 0.1447 - val_accuracy: 0.9405\n",
      "Epoch 98/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0776 - accuracy: 0.9804\n",
      "Epoch 98: val_loss improved from 0.14466 to 0.14420, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.9840 - val_loss: 0.1442 - val_accuracy: 0.9405\n",
      "Epoch 99/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0723 - accuracy: 0.9811\n",
      "Epoch 99: val_loss improved from 0.14420 to 0.14350, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.9840 - val_loss: 0.1435 - val_accuracy: 0.9405\n",
      "Epoch 100/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0706 - accuracy: 0.9828\n",
      "Epoch 100: val_loss improved from 0.14350 to 0.14280, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9840 - val_loss: 0.1428 - val_accuracy: 0.9405\n",
      "Epoch 101/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0541 - accuracy: 0.9900\n",
      "Epoch 101: val_loss improved from 0.14280 to 0.14261, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9840 - val_loss: 0.1426 - val_accuracy: 0.9405\n",
      "Epoch 102/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0724 - accuracy: 0.9815\n",
      "Epoch 102: val_loss improved from 0.14261 to 0.14175, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9840 - val_loss: 0.1418 - val_accuracy: 0.9405\n",
      "Epoch 103/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0609 - accuracy: 0.9867\n",
      "Epoch 103: val_loss improved from 0.14175 to 0.14088, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9840 - val_loss: 0.1409 - val_accuracy: 0.9405\n",
      "Epoch 104/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0701 - accuracy: 0.9840\n",
      "Epoch 104: val_loss improved from 0.14088 to 0.14044, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9840 - val_loss: 0.1404 - val_accuracy: 0.9405\n",
      "Epoch 105/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0663 - accuracy: 0.9828\n",
      "Epoch 105: val_loss improved from 0.14044 to 0.14008, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9840 - val_loss: 0.1401 - val_accuracy: 0.9405\n",
      "Epoch 106/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0574 - accuracy: 0.9893\n",
      "Epoch 106: val_loss improved from 0.14008 to 0.13903, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9872 - val_loss: 0.1390 - val_accuracy: 0.9405\n",
      "Epoch 107/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0641 - accuracy: 0.9864\n",
      "Epoch 107: val_loss improved from 0.13903 to 0.13879, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9872 - val_loss: 0.1388 - val_accuracy: 0.9405\n",
      "Epoch 108/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0638 - accuracy: 0.9864\n",
      "Epoch 108: val_loss improved from 0.13879 to 0.13787, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9872 - val_loss: 0.1379 - val_accuracy: 0.9405\n",
      "Epoch 109/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0575 - accuracy: 0.9898\n",
      "Epoch 109: val_loss improved from 0.13787 to 0.13704, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9872 - val_loss: 0.1370 - val_accuracy: 0.9405\n",
      "Epoch 110/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0646 - accuracy: 0.9857\n",
      "Epoch 110: val_loss improved from 0.13704 to 0.13665, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9872 - val_loss: 0.1367 - val_accuracy: 0.9405\n",
      "Epoch 111/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0561 - accuracy: 0.9895\n",
      "Epoch 111: val_loss improved from 0.13665 to 0.13579, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9872 - val_loss: 0.1358 - val_accuracy: 0.9405\n",
      "Epoch 112/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0587 - accuracy: 0.9852\n",
      "Epoch 112: val_loss improved from 0.13579 to 0.13516, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0581 - accuracy: 0.9872 - val_loss: 0.1352 - val_accuracy: 0.9405\n",
      "Epoch 113/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0595 - accuracy: 0.9867\n",
      "Epoch 113: val_loss improved from 0.13516 to 0.13459, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9872 - val_loss: 0.1346 - val_accuracy: 0.9405\n",
      "Epoch 114/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0594 - accuracy: 0.9862\n",
      "Epoch 114: val_loss improved from 0.13459 to 0.13411, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9872 - val_loss: 0.1341 - val_accuracy: 0.9405\n",
      "Epoch 115/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9869\n",
      "Epoch 115: val_loss improved from 0.13411 to 0.13362, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9872 - val_loss: 0.1336 - val_accuracy: 0.9405\n",
      "Epoch 116/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9869\n",
      "Epoch 116: val_loss improved from 0.13362 to 0.13259, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9872 - val_loss: 0.1326 - val_accuracy: 0.9405\n",
      "Epoch 117/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0547 - accuracy: 0.9862\n",
      "Epoch 117: val_loss improved from 0.13259 to 0.13168, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9872 - val_loss: 0.1317 - val_accuracy: 0.9405\n",
      "Epoch 118/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0566 - accuracy: 0.9852\n",
      "Epoch 118: val_loss improved from 0.13168 to 0.13136, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9872 - val_loss: 0.1314 - val_accuracy: 0.9405\n",
      "Epoch 119/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9902\n",
      "Epoch 119: val_loss improved from 0.13136 to 0.13049, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9872 - val_loss: 0.1305 - val_accuracy: 0.9405\n",
      "Epoch 120/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0550 - accuracy: 0.9864\n",
      "Epoch 120: val_loss improved from 0.13049 to 0.12982, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9872 - val_loss: 0.1298 - val_accuracy: 0.9405\n",
      "Epoch 121/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0528 - accuracy: 0.9864\n",
      "Epoch 121: val_loss improved from 0.12982 to 0.12958, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9872 - val_loss: 0.1296 - val_accuracy: 0.9405\n",
      "Epoch 122/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0535 - accuracy: 0.9860\n",
      "Epoch 122: val_loss improved from 0.12958 to 0.12861, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9872 - val_loss: 0.1286 - val_accuracy: 0.9405\n",
      "Epoch 123/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0537 - accuracy: 0.9862\n",
      "Epoch 123: val_loss improved from 0.12861 to 0.12813, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9872 - val_loss: 0.1281 - val_accuracy: 0.9405\n",
      "Epoch 124/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0524 - accuracy: 0.9864\n",
      "Epoch 124: val_loss improved from 0.12813 to 0.12732, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9872 - val_loss: 0.1273 - val_accuracy: 0.9405\n",
      "Epoch 125/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0476 - accuracy: 0.9887\n",
      "Epoch 125: val_loss improved from 0.12732 to 0.12670, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0497 - accuracy: 0.9872 - val_loss: 0.1267 - val_accuracy: 0.9405\n",
      "Epoch 126/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0506 - accuracy: 0.9846\n",
      "Epoch 126: val_loss improved from 0.12670 to 0.12598, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9872 - val_loss: 0.1260 - val_accuracy: 0.9405\n",
      "Epoch 127/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0298 - accuracy: 0.9962\n",
      "Epoch 127: val_loss improved from 0.12598 to 0.12530, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9872 - val_loss: 0.1253 - val_accuracy: 0.9464\n",
      "Epoch 128/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9889\n",
      "Epoch 128: val_loss improved from 0.12530 to 0.12456, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9872 - val_loss: 0.1246 - val_accuracy: 0.9464\n",
      "Epoch 129/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9893\n",
      "Epoch 129: val_loss improved from 0.12456 to 0.12392, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9872 - val_loss: 0.1239 - val_accuracy: 0.9464\n",
      "Epoch 130/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0428 - accuracy: 0.9895\n",
      "Epoch 130: val_loss improved from 0.12392 to 0.12308, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9872 - val_loss: 0.1231 - val_accuracy: 0.9524\n",
      "Epoch 131/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0431 - accuracy: 0.9891\n",
      "Epoch 131: val_loss improved from 0.12308 to 0.12279, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9872 - val_loss: 0.1228 - val_accuracy: 0.9524\n",
      "Epoch 132/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0489 - accuracy: 0.9849\n",
      "Epoch 132: val_loss improved from 0.12279 to 0.12224, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9872 - val_loss: 0.1222 - val_accuracy: 0.9524\n",
      "Epoch 133/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0497 - accuracy: 0.9837\n",
      "Epoch 133: val_loss improved from 0.12224 to 0.12160, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9872 - val_loss: 0.1216 - val_accuracy: 0.9524\n",
      "Epoch 134/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0370 - accuracy: 0.9933\n",
      "Epoch 134: val_loss improved from 0.12160 to 0.12057, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9872 - val_loss: 0.1206 - val_accuracy: 0.9524\n",
      "Epoch 135/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0484 - accuracy: 0.9849\n",
      "Epoch 135: val_loss improved from 0.12057 to 0.12056, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.1206 - val_accuracy: 0.9524\n",
      "Epoch 136/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9869\n",
      "Epoch 136: val_loss improved from 0.12056 to 0.11975, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 0.1197 - val_accuracy: 0.9524\n",
      "Epoch 137/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0429 - accuracy: 0.9882\n",
      "Epoch 137: val_loss improved from 0.11975 to 0.11905, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.1190 - val_accuracy: 0.9524\n",
      "Epoch 138/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0433 - accuracy: 0.9898\n",
      "Epoch 138: val_loss improved from 0.11905 to 0.11853, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9904 - val_loss: 0.1185 - val_accuracy: 0.9524\n",
      "Epoch 139/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0439 - accuracy: 0.9885\n",
      "Epoch 139: val_loss improved from 0.11853 to 0.11808, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9904 - val_loss: 0.1181 - val_accuracy: 0.9524\n",
      "Epoch 140/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0463 - accuracy: 0.9882\n",
      "Epoch 140: val_loss improved from 0.11808 to 0.11716, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 0.9904 - val_loss: 0.1172 - val_accuracy: 0.9524\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9904\n",
      "Epoch 141: val_loss improved from 0.11716 to 0.11633, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9904 - val_loss: 0.1163 - val_accuracy: 0.9524\n",
      "Epoch 142/200\n",
      "45/63 [====================>.........] - ETA: 0s - loss: 0.0425 - accuracy: 0.9911\n",
      "Epoch 142: val_loss improved from 0.11633 to 0.11589, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9904 - val_loss: 0.1159 - val_accuracy: 0.9524\n",
      "Epoch 143/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0411 - accuracy: 0.9882\n",
      "Epoch 143: val_loss improved from 0.11589 to 0.11547, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9904 - val_loss: 0.1155 - val_accuracy: 0.9524\n",
      "Epoch 144/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0408 - accuracy: 0.9895\n",
      "Epoch 144: val_loss improved from 0.11547 to 0.11499, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9904 - val_loss: 0.1150 - val_accuracy: 0.9524\n",
      "Epoch 145/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0306 - accuracy: 0.9931\n",
      "Epoch 145: val_loss improved from 0.11499 to 0.11464, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9904 - val_loss: 0.1146 - val_accuracy: 0.9524\n",
      "Epoch 146/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0397 - accuracy: 0.9897\n",
      "Epoch 146: val_loss improved from 0.11464 to 0.11361, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9904 - val_loss: 0.1136 - val_accuracy: 0.9524\n",
      "Epoch 147/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.0393 - accuracy: 0.9875\n",
      "Epoch 147: val_loss improved from 0.11361 to 0.11311, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9904 - val_loss: 0.1131 - val_accuracy: 0.9524\n",
      "Epoch 148/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0393 - accuracy: 0.9891\n",
      "Epoch 148: val_loss improved from 0.11311 to 0.11265, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9904 - val_loss: 0.1127 - val_accuracy: 0.9524\n",
      "Epoch 149/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0397 - accuracy: 0.9893\n",
      "Epoch 149: val_loss improved from 0.11265 to 0.11202, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9904 - val_loss: 0.1120 - val_accuracy: 0.9524\n",
      "Epoch 150/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0354 - accuracy: 0.9930\n",
      "Epoch 150: val_loss improved from 0.11202 to 0.11116, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9904 - val_loss: 0.1112 - val_accuracy: 0.9524\n",
      "Epoch 151/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0251 - accuracy: 0.9965\n",
      "Epoch 151: val_loss improved from 0.11116 to 0.11106, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.1111 - val_accuracy: 0.9524\n",
      "Epoch 152/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0364 - accuracy: 0.9897\n",
      "Epoch 152: val_loss improved from 0.11106 to 0.11027, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9904 - val_loss: 0.1103 - val_accuracy: 0.9524\n",
      "Epoch 153/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0370 - accuracy: 0.9895\n",
      "Epoch 153: val_loss improved from 0.11027 to 0.10990, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.1099 - val_accuracy: 0.9524\n",
      "Epoch 154/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0387 - accuracy: 0.9882\n",
      "Epoch 154: val_loss improved from 0.10990 to 0.10915, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 0.1092 - val_accuracy: 0.9524\n",
      "Epoch 155/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0276 - accuracy: 0.9920\n",
      "Epoch 155: val_loss improved from 0.10915 to 0.10909, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9904 - val_loss: 0.1091 - val_accuracy: 0.9524\n",
      "Epoch 156/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0363 - accuracy: 0.9887\n",
      "Epoch 156: val_loss improved from 0.10909 to 0.10822, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9904 - val_loss: 0.1082 - val_accuracy: 0.9524\n",
      "Epoch 157/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9903\n",
      "Epoch 157: val_loss improved from 0.10822 to 0.10736, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.1074 - val_accuracy: 0.9524\n",
      "Epoch 158/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0332 - accuracy: 0.9889\n",
      "Epoch 158: val_loss improved from 0.10736 to 0.10713, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.1071 - val_accuracy: 0.9524\n",
      "Epoch 159/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0303 - accuracy: 0.9927\n",
      "Epoch 159: val_loss improved from 0.10713 to 0.10637, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.1064 - val_accuracy: 0.9524\n",
      "Epoch 160/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0330 - accuracy: 0.9897\n",
      "Epoch 160: val_loss improved from 0.10637 to 0.10614, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.1061 - val_accuracy: 0.9583\n",
      "Epoch 161/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0307 - accuracy: 0.9889\n",
      "Epoch 161: val_loss improved from 0.10614 to 0.10582, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 0.1058 - val_accuracy: 0.9583\n",
      "Epoch 162/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0327 - accuracy: 0.9889\n",
      "Epoch 162: val_loss improved from 0.10582 to 0.10538, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.1054 - val_accuracy: 0.9583\n",
      "Epoch 163/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0272 - accuracy: 0.9929\n",
      "Epoch 163: val_loss improved from 0.10538 to 0.10462, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.1046 - val_accuracy: 0.9583\n",
      "Epoch 164/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0311 - accuracy: 0.9895\n",
      "Epoch 164: val_loss improved from 0.10462 to 0.10460, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.1046 - val_accuracy: 0.9583\n",
      "Epoch 165/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0300 - accuracy: 0.9933\n",
      "Epoch 165: val_loss improved from 0.10460 to 0.10422, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9936 - val_loss: 0.1042 - val_accuracy: 0.9583\n",
      "Epoch 166/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0299 - accuracy: 0.9920\n",
      "Epoch 166: val_loss improved from 0.10422 to 0.10374, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9936 - val_loss: 0.1037 - val_accuracy: 0.9583\n",
      "Epoch 167/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0294 - accuracy: 0.9932\n",
      "Epoch 167: val_loss improved from 0.10374 to 0.10318, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9936 - val_loss: 0.1032 - val_accuracy: 0.9583\n",
      "Epoch 168/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0288 - accuracy: 0.9931\n",
      "Epoch 168: val_loss improved from 0.10318 to 0.10318, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.1032 - val_accuracy: 0.9583\n",
      "Epoch 169/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0197 - accuracy: 0.9964\n",
      "Epoch 169: val_loss improved from 0.10318 to 0.10272, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9936 - val_loss: 0.1027 - val_accuracy: 0.9583\n",
      "Epoch 170/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0198 - accuracy: 0.9965\n",
      "Epoch 170: val_loss improved from 0.10272 to 0.10237, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9936 - val_loss: 0.1024 - val_accuracy: 0.9583\n",
      "Epoch 171/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0250 - accuracy: 0.9963\n",
      "Epoch 171: val_loss improved from 0.10237 to 0.10138, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9936 - val_loss: 0.1014 - val_accuracy: 0.9583\n",
      "Epoch 172/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0279 - accuracy: 0.9925\n",
      "Epoch 172: val_loss did not improve from 0.10138\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9936 - val_loss: 0.1017 - val_accuracy: 0.9583\n",
      "Epoch 173/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0241 - accuracy: 0.9931\n",
      "Epoch 173: val_loss improved from 0.10138 to 0.10103, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.1010 - val_accuracy: 0.9583\n",
      "Epoch 174/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0271 - accuracy: 0.9929\n",
      "Epoch 174: val_loss improved from 0.10103 to 0.10097, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.1010 - val_accuracy: 0.9583\n",
      "Epoch 175/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0273 - accuracy: 0.9923\n",
      "Epoch 175: val_loss improved from 0.10097 to 0.10063, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.1006 - val_accuracy: 0.9583\n",
      "Epoch 176/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9935\n",
      "Epoch 176: val_loss improved from 0.10063 to 0.10010, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.1001 - val_accuracy: 0.9583\n",
      "Epoch 177/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0267 - accuracy: 0.9926\n",
      "Epoch 177: val_loss improved from 0.10010 to 0.09984, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.0998 - val_accuracy: 0.9583\n",
      "Epoch 178/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0255 - accuracy: 0.9923\n",
      "Epoch 178: val_loss improved from 0.09984 to 0.09970, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0997 - val_accuracy: 0.9583\n",
      "Epoch 179/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0262 - accuracy: 0.9918\n",
      "Epoch 179: val_loss improved from 0.09970 to 0.09934, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0993 - val_accuracy: 0.9583\n",
      "Epoch 180/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0228 - accuracy: 0.9927\n",
      "Epoch 180: val_loss improved from 0.09934 to 0.09865, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0987 - val_accuracy: 0.9583\n",
      "Epoch 181/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0237 - accuracy: 0.9931\n",
      "Epoch 181: val_loss did not improve from 0.09865\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 0.0988 - val_accuracy: 0.9583\n",
      "Epoch 182/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0231 - accuracy: 0.9933\n",
      "Epoch 182: val_loss improved from 0.09865 to 0.09864, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0986 - val_accuracy: 0.9583\n",
      "Epoch 183/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0233 - accuracy: 0.9926\n",
      "Epoch 183: val_loss improved from 0.09864 to 0.09824, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0982 - val_accuracy: 0.9583\n",
      "Epoch 184/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0211 - accuracy: 0.9962\n",
      "Epoch 184: val_loss improved from 0.09824 to 0.09780, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0978 - val_accuracy: 0.9583\n",
      "Epoch 185/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 185: val_loss did not improve from 0.09780\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0979 - val_accuracy: 0.9583\n",
      "Epoch 186/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9934\n",
      "Epoch 186: val_loss improved from 0.09780 to 0.09754, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0975 - val_accuracy: 0.9583\n",
      "Epoch 187/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0164 - accuracy: 0.9965\n",
      "Epoch 187: val_loss improved from 0.09754 to 0.09740, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0974 - val_accuracy: 0.9583\n",
      "Epoch 188/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0224 - accuracy: 0.9925\n",
      "Epoch 188: val_loss improved from 0.09740 to 0.09688, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0969 - val_accuracy: 0.9583\n",
      "Epoch 189/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0199 - accuracy: 0.9929\n",
      "Epoch 189: val_loss improved from 0.09688 to 0.09669, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0967 - val_accuracy: 0.9583\n",
      "Epoch 190/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0195 - accuracy: 0.9931\n",
      "Epoch 190: val_loss improved from 0.09669 to 0.09648, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0965 - val_accuracy: 0.9583\n",
      "Epoch 191/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0211 - accuracy: 0.9962\n",
      "Epoch 191: val_loss did not improve from 0.09648\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 0.0965 - val_accuracy: 0.9583\n",
      "Epoch 192/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0192 - accuracy: 0.9962\n",
      "Epoch 192: val_loss improved from 0.09648 to 0.09615, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9968 - val_loss: 0.0961 - val_accuracy: 0.9583\n",
      "Epoch 193/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 193: val_loss did not improve from 0.09615\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9968 - val_loss: 0.0962 - val_accuracy: 0.9583\n",
      "Epoch 194/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 194: val_loss improved from 0.09615 to 0.09567, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.0957 - val_accuracy: 0.9643\n",
      "Epoch 195/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0196 - accuracy: 0.9960\n",
      "Epoch 195: val_loss did not improve from 0.09567\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9968 - val_loss: 0.0957 - val_accuracy: 0.9643\n",
      "Epoch 196/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0204 - accuracy: 0.9961\n",
      "Epoch 196: val_loss improved from 0.09567 to 0.09563, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9968 - val_loss: 0.0956 - val_accuracy: 0.9643\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9968\n",
      "Epoch 197: val_loss improved from 0.09563 to 0.09561, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9968 - val_loss: 0.0956 - val_accuracy: 0.9643\n",
      "Epoch 198/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0178 - accuracy: 0.9967\n",
      "Epoch 198: val_loss improved from 0.09561 to 0.09547, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.0955 - val_accuracy: 0.9643\n",
      "Epoch 199/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0180 - accuracy: 0.9966\n",
      "Epoch 199: val_loss improved from 0.09547 to 0.09526, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.0953 - val_accuracy: 0.9643\n",
      "Epoch 200/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0176 - accuracy: 0.9966\n",
      "Epoch 200: val_loss improved from 0.09526 to 0.09505, saving model to model_checkpoint\\GRU_1 layer_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9968 - val_loss: 0.0950 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 32)                11520     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,553\n",
      "Trainable params: 11,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9643\n",
      "Test Loss: 0.09504835307598114\n",
      "Test Accuracy: 0.9642857313156128\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'GRU_1 layer_Adam.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, x_train.shape[-1])))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)  \n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=200, validation_data=(x_val, y_val), callbacks=[callbacks_list])\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU 1 layer RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.7930 - accuracy: 0.3565\n",
      "Epoch 1: val_loss improved from inf to 0.72199, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 3s 13ms/step - loss: 0.7833 - accuracy: 0.3834 - val_loss: 0.7220 - val_accuracy: 0.5060\n",
      "Epoch 2/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.7248 - accuracy: 0.4691\n",
      "Epoch 2: val_loss improved from 0.72199 to 0.66277, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7133 - accuracy: 0.4856 - val_loss: 0.6628 - val_accuracy: 0.6190\n",
      "Epoch 3/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.6561 - accuracy: 0.5745\n",
      "Epoch 3: val_loss improved from 0.66277 to 0.60938, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.5974 - val_loss: 0.6094 - val_accuracy: 0.6845\n",
      "Epoch 4/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.5990 - accuracy: 0.7143\n",
      "Epoch 4: val_loss improved from 0.60938 to 0.56258, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.7252 - val_loss: 0.5626 - val_accuracy: 0.7440\n",
      "Epoch 5/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.5410 - accuracy: 0.8038\n",
      "Epoch 5: val_loss improved from 0.56258 to 0.52054, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.7891 - val_loss: 0.5205 - val_accuracy: 0.7976\n",
      "Epoch 6/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.5083 - accuracy: 0.8426\n",
      "Epoch 6: val_loss improved from 0.52054 to 0.48333, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.8211 - val_loss: 0.4833 - val_accuracy: 0.8452\n",
      "Epoch 7/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.4673 - accuracy: 0.8346\n",
      "Epoch 7: val_loss improved from 0.48333 to 0.45016, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.8275 - val_loss: 0.4502 - val_accuracy: 0.8690\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8626\n",
      "Epoch 8: val_loss improved from 0.45016 to 0.42061, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8626 - val_loss: 0.4206 - val_accuracy: 0.8690\n",
      "Epoch 9/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.4006 - accuracy: 0.8746\n",
      "Epoch 9: val_loss improved from 0.42061 to 0.39449, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8754 - val_loss: 0.3945 - val_accuracy: 0.8869\n",
      "Epoch 10/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3870 - accuracy: 0.8842\n",
      "Epoch 10: val_loss improved from 0.39449 to 0.37126, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8882 - val_loss: 0.3713 - val_accuracy: 0.8929\n",
      "Epoch 11/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3447 - accuracy: 0.9088\n",
      "Epoch 11: val_loss improved from 0.37126 to 0.35038, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8978 - val_loss: 0.3504 - val_accuracy: 0.9107\n",
      "Epoch 12/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3391 - accuracy: 0.8964\n",
      "Epoch 12: val_loss improved from 0.35038 to 0.33215, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.9042 - val_loss: 0.3322 - val_accuracy: 0.9107\n",
      "Epoch 13/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3086 - accuracy: 0.9088\n",
      "Epoch 13: val_loss improved from 0.33215 to 0.31552, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.9073 - val_loss: 0.3155 - val_accuracy: 0.9167\n",
      "Epoch 14/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2956 - accuracy: 0.9207\n",
      "Epoch 14: val_loss improved from 0.31552 to 0.30078, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2964 - accuracy: 0.9169 - val_loss: 0.3008 - val_accuracy: 0.9167\n",
      "Epoch 15/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2875 - accuracy: 0.9143\n",
      "Epoch 15: val_loss improved from 0.30078 to 0.28772, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.9233 - val_loss: 0.2877 - val_accuracy: 0.9286\n",
      "Epoch 16/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2667 - accuracy: 0.9259\n",
      "Epoch 16: val_loss improved from 0.28772 to 0.27548, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2679 - accuracy: 0.9297 - val_loss: 0.2755 - val_accuracy: 0.9286\n",
      "Epoch 17/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2587 - accuracy: 0.9298\n",
      "Epoch 17: val_loss improved from 0.27548 to 0.26509, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2556 - accuracy: 0.9329 - val_loss: 0.2651 - val_accuracy: 0.9286\n",
      "Epoch 18/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2381 - accuracy: 0.9407\n",
      "Epoch 18: val_loss improved from 0.26509 to 0.25548, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2447 - accuracy: 0.9361 - val_loss: 0.2555 - val_accuracy: 0.9286\n",
      "Epoch 19/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2353 - accuracy: 0.9346\n",
      "Epoch 19: val_loss improved from 0.25548 to 0.24662, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.9361 - val_loss: 0.2466 - val_accuracy: 0.9286\n",
      "Epoch 20/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2207 - accuracy: 0.9385\n",
      "Epoch 20: val_loss improved from 0.24662 to 0.23855, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.9329 - val_loss: 0.2385 - val_accuracy: 0.9345\n",
      "Epoch 21/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2159 - accuracy: 0.9358\n",
      "Epoch 21: val_loss improved from 0.23855 to 0.23149, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2169 - accuracy: 0.9393 - val_loss: 0.2315 - val_accuracy: 0.9405\n",
      "Epoch 22/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2061 - accuracy: 0.9474\n",
      "Epoch 22: val_loss improved from 0.23149 to 0.22489, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9425 - val_loss: 0.2249 - val_accuracy: 0.9405\n",
      "Epoch 23/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.2146 - accuracy: 0.9375\n",
      "Epoch 23: val_loss improved from 0.22489 to 0.21906, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2023 - accuracy: 0.9457 - val_loss: 0.2191 - val_accuracy: 0.9405\n",
      "Epoch 24/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9484\n",
      "Epoch 24: val_loss improved from 0.21906 to 0.21357, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9489 - val_loss: 0.2136 - val_accuracy: 0.9405\n",
      "Epoch 25/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1698 - accuracy: 0.9625\n",
      "Epoch 25: val_loss improved from 0.21357 to 0.20850, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.9489 - val_loss: 0.2085 - val_accuracy: 0.9405\n",
      "Epoch 26/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9639\n",
      "Epoch 26: val_loss improved from 0.20850 to 0.20407, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.9553 - val_loss: 0.2041 - val_accuracy: 0.9405\n",
      "Epoch 27/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1708 - accuracy: 0.9469\n",
      "Epoch 27: val_loss improved from 0.20407 to 0.19986, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1787 - accuracy: 0.9521 - val_loss: 0.1999 - val_accuracy: 0.9405\n",
      "Epoch 28/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9574\n",
      "Epoch 28: val_loss improved from 0.19986 to 0.19599, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9553 - val_loss: 0.1960 - val_accuracy: 0.9405\n",
      "Epoch 29/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9548\n",
      "Epoch 29: val_loss improved from 0.19599 to 0.19237, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9553 - val_loss: 0.1924 - val_accuracy: 0.9405\n",
      "Epoch 30/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1662 - accuracy: 0.9536\n",
      "Epoch 30: val_loss improved from 0.19237 to 0.18917, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1647 - accuracy: 0.9553 - val_loss: 0.1892 - val_accuracy: 0.9405\n",
      "Epoch 31/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1597 - accuracy: 0.9529\n",
      "Epoch 31: val_loss improved from 0.18917 to 0.18612, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.9553 - val_loss: 0.1861 - val_accuracy: 0.9405\n",
      "Epoch 32/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1624 - accuracy: 0.9517\n",
      "Epoch 32: val_loss improved from 0.18612 to 0.18328, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9553 - val_loss: 0.1833 - val_accuracy: 0.9405\n",
      "Epoch 33/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1570 - accuracy: 0.9533\n",
      "Epoch 33: val_loss improved from 0.18328 to 0.18075, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1532 - accuracy: 0.9553 - val_loss: 0.1807 - val_accuracy: 0.9464\n",
      "Epoch 34/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1572 - accuracy: 0.9542\n",
      "Epoch 34: val_loss improved from 0.18075 to 0.17833, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9553 - val_loss: 0.1783 - val_accuracy: 0.9464\n",
      "Epoch 35/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1370 - accuracy: 0.9593\n",
      "Epoch 35: val_loss improved from 0.17833 to 0.17603, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9553 - val_loss: 0.1760 - val_accuracy: 0.9464\n",
      "Epoch 36/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1443 - accuracy: 0.9547\n",
      "Epoch 36: val_loss improved from 0.17603 to 0.17404, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9553 - val_loss: 0.1740 - val_accuracy: 0.9464\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9553\n",
      "Epoch 37: val_loss improved from 0.17404 to 0.17197, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.9553 - val_loss: 0.1720 - val_accuracy: 0.9464\n",
      "Epoch 38/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1260 - accuracy: 0.9654\n",
      "Epoch 38: val_loss improved from 0.17197 to 0.17001, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9553 - val_loss: 0.1700 - val_accuracy: 0.9524\n",
      "Epoch 39/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1400 - accuracy: 0.9538\n",
      "Epoch 39: val_loss improved from 0.17001 to 0.16826, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1353 - accuracy: 0.9553 - val_loss: 0.1683 - val_accuracy: 0.9524\n",
      "Epoch 40/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1257 - accuracy: 0.9640\n",
      "Epoch 40: val_loss improved from 0.16826 to 0.16655, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9553 - val_loss: 0.1665 - val_accuracy: 0.9524\n",
      "Epoch 41/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.1330 - accuracy: 0.9522\n",
      "Epoch 41: val_loss improved from 0.16655 to 0.16499, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1302 - accuracy: 0.9553 - val_loss: 0.1650 - val_accuracy: 0.9524\n",
      "Epoch 42/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1332 - accuracy: 0.9547\n",
      "Epoch 42: val_loss improved from 0.16499 to 0.16348, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9585 - val_loss: 0.1635 - val_accuracy: 0.9524\n",
      "Epoch 43/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1191 - accuracy: 0.9680\n",
      "Epoch 43: val_loss improved from 0.16348 to 0.16200, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1258 - accuracy: 0.9585 - val_loss: 0.1620 - val_accuracy: 0.9524\n",
      "Epoch 44/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1085 - accuracy: 0.9686\n",
      "Epoch 44: val_loss improved from 0.16200 to 0.16065, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9617 - val_loss: 0.1606 - val_accuracy: 0.9524\n",
      "Epoch 45/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9607\n",
      "Epoch 45: val_loss improved from 0.16065 to 0.15941, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1218 - accuracy: 0.9617 - val_loss: 0.1594 - val_accuracy: 0.9524\n",
      "Epoch 46/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1140 - accuracy: 0.9627\n",
      "Epoch 46: val_loss improved from 0.15941 to 0.15825, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9617 - val_loss: 0.1583 - val_accuracy: 0.9524\n",
      "Epoch 47/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1085 - accuracy: 0.9647\n",
      "Epoch 47: val_loss improved from 0.15825 to 0.15714, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9617 - val_loss: 0.1571 - val_accuracy: 0.9524\n",
      "Epoch 48/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1165 - accuracy: 0.9608\n",
      "Epoch 48: val_loss improved from 0.15714 to 0.15604, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.9617 - val_loss: 0.1560 - val_accuracy: 0.9524\n",
      "Epoch 49/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9645\n",
      "Epoch 49: val_loss improved from 0.15604 to 0.15489, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9649 - val_loss: 0.1549 - val_accuracy: 0.9524\n",
      "Epoch 50/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1230 - accuracy: 0.9633\n",
      "Epoch 50: val_loss improved from 0.15489 to 0.15376, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9649 - val_loss: 0.1538 - val_accuracy: 0.9524\n",
      "Epoch 51/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1048 - accuracy: 0.9673\n",
      "Epoch 51: val_loss improved from 0.15376 to 0.15283, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9649 - val_loss: 0.1528 - val_accuracy: 0.9524\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9649\n",
      "Epoch 52: val_loss improved from 0.15283 to 0.15197, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9649 - val_loss: 0.1520 - val_accuracy: 0.9524\n",
      "Epoch 53/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1111 - accuracy: 0.9633\n",
      "Epoch 53: val_loss improved from 0.15197 to 0.15115, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9649 - val_loss: 0.1511 - val_accuracy: 0.9524\n",
      "Epoch 54/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1053 - accuracy: 0.9615\n",
      "Epoch 54: val_loss improved from 0.15115 to 0.15032, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9649 - val_loss: 0.1503 - val_accuracy: 0.9524\n",
      "Epoch 55/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.0955 - accuracy: 0.9625\n",
      "Epoch 55: val_loss improved from 0.15032 to 0.14951, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 0.9649 - val_loss: 0.1495 - val_accuracy: 0.9524\n",
      "Epoch 56/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0881 - accuracy: 0.9686\n",
      "Epoch 56: val_loss improved from 0.14951 to 0.14876, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.9649 - val_loss: 0.1488 - val_accuracy: 0.9524\n",
      "Epoch 57/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1064 - accuracy: 0.9647\n",
      "Epoch 57: val_loss improved from 0.14876 to 0.14808, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1018 - accuracy: 0.9649 - val_loss: 0.1481 - val_accuracy: 0.9524\n",
      "Epoch 58/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1055 - accuracy: 0.9636\n",
      "Epoch 58: val_loss improved from 0.14808 to 0.14737, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1003 - accuracy: 0.9649 - val_loss: 0.1474 - val_accuracy: 0.9524\n",
      "Epoch 59/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0941 - accuracy: 0.9654\n",
      "Epoch 59: val_loss improved from 0.14737 to 0.14665, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9649 - val_loss: 0.1466 - val_accuracy: 0.9524\n",
      "Epoch 60/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0984 - accuracy: 0.9615\n",
      "Epoch 60: val_loss improved from 0.14665 to 0.14608, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9649 - val_loss: 0.1461 - val_accuracy: 0.9524\n",
      "Epoch 61/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.0900 - accuracy: 0.9667\n",
      "Epoch 61: val_loss improved from 0.14608 to 0.14544, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9649 - val_loss: 0.1454 - val_accuracy: 0.9524\n",
      "Epoch 62/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0945 - accuracy: 0.9633\n",
      "Epoch 62: val_loss improved from 0.14544 to 0.14477, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9649 - val_loss: 0.1448 - val_accuracy: 0.9524\n",
      "Epoch 63/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0971 - accuracy: 0.9627\n",
      "Epoch 63: val_loss improved from 0.14477 to 0.14408, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0940 - accuracy: 0.9649 - val_loss: 0.1441 - val_accuracy: 0.9524\n",
      "Epoch 64/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0886 - accuracy: 0.9660\n",
      "Epoch 64: val_loss improved from 0.14408 to 0.14335, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0926 - accuracy: 0.9649 - val_loss: 0.1433 - val_accuracy: 0.9524\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9649\n",
      "Epoch 65: val_loss improved from 0.14335 to 0.14283, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0914 - accuracy: 0.9649 - val_loss: 0.1428 - val_accuracy: 0.9524\n",
      "Epoch 66/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0956 - accuracy: 0.9655\n",
      "Epoch 66: val_loss improved from 0.14283 to 0.14224, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9681 - val_loss: 0.1422 - val_accuracy: 0.9524\n",
      "Epoch 67/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0914 - accuracy: 0.9667\n",
      "Epoch 67: val_loss improved from 0.14224 to 0.14184, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0893 - accuracy: 0.9681 - val_loss: 0.1418 - val_accuracy: 0.9524\n",
      "Epoch 68/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0906 - accuracy: 0.9679\n",
      "Epoch 68: val_loss improved from 0.14184 to 0.14129, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9681 - val_loss: 0.1413 - val_accuracy: 0.9524\n",
      "Epoch 69/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.0984 - accuracy: 0.9617\n",
      "Epoch 69: val_loss improved from 0.14129 to 0.14094, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 0.9681 - val_loss: 0.1409 - val_accuracy: 0.9524\n",
      "Epoch 70/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0820 - accuracy: 0.9704\n",
      "Epoch 70: val_loss improved from 0.14094 to 0.14066, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9681 - val_loss: 0.1407 - val_accuracy: 0.9524\n",
      "Epoch 71/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0739 - accuracy: 0.9754\n",
      "Epoch 71: val_loss improved from 0.14066 to 0.13999, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9681 - val_loss: 0.1400 - val_accuracy: 0.9524\n",
      "Epoch 72/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0861 - accuracy: 0.9667\n",
      "Epoch 72: val_loss improved from 0.13999 to 0.13964, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 0.9681 - val_loss: 0.1396 - val_accuracy: 0.9524\n",
      "Epoch 73/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0885 - accuracy: 0.9649\n",
      "Epoch 73: val_loss improved from 0.13964 to 0.13916, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9681 - val_loss: 0.1392 - val_accuracy: 0.9524\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9681\n",
      "Epoch 74: val_loss improved from 0.13916 to 0.13862, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9681 - val_loss: 0.1386 - val_accuracy: 0.9524\n",
      "Epoch 75/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0757 - accuracy: 0.9686\n",
      "Epoch 75: val_loss improved from 0.13862 to 0.13815, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9681 - val_loss: 0.1381 - val_accuracy: 0.9524\n",
      "Epoch 76/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0807 - accuracy: 0.9725\n",
      "Epoch 76: val_loss improved from 0.13815 to 0.13771, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9681 - val_loss: 0.1377 - val_accuracy: 0.9524\n",
      "Epoch 77/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0832 - accuracy: 0.9643\n",
      "Epoch 77: val_loss improved from 0.13771 to 0.13729, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0785 - accuracy: 0.9681 - val_loss: 0.1373 - val_accuracy: 0.9524\n",
      "Epoch 78/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0829 - accuracy: 0.9643\n",
      "Epoch 78: val_loss improved from 0.13729 to 0.13690, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0778 - accuracy: 0.9681 - val_loss: 0.1369 - val_accuracy: 0.9524\n",
      "Epoch 79/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0750 - accuracy: 0.9733\n",
      "Epoch 79: val_loss improved from 0.13690 to 0.13668, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0771 - accuracy: 0.9681 - val_loss: 0.1367 - val_accuracy: 0.9524\n",
      "Epoch 80/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0616 - accuracy: 0.9846\n",
      "Epoch 80: val_loss improved from 0.13668 to 0.13626, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0761 - accuracy: 0.9712 - val_loss: 0.1363 - val_accuracy: 0.9524\n",
      "Epoch 81/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9710\n",
      "Epoch 81: val_loss improved from 0.13626 to 0.13582, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9712 - val_loss: 0.1358 - val_accuracy: 0.9524\n",
      "Epoch 82/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0721 - accuracy: 0.9729\n",
      "Epoch 82: val_loss improved from 0.13582 to 0.13548, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0741 - accuracy: 0.9712 - val_loss: 0.1355 - val_accuracy: 0.9524\n",
      "Epoch 83/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0683 - accuracy: 0.9733\n",
      "Epoch 83: val_loss improved from 0.13548 to 0.13527, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9712 - val_loss: 0.1353 - val_accuracy: 0.9524\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9712\n",
      "Epoch 84: val_loss improved from 0.13527 to 0.13502, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9712 - val_loss: 0.1350 - val_accuracy: 0.9524\n",
      "Epoch 85/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0624 - accuracy: 0.9704\n",
      "Epoch 85: val_loss improved from 0.13502 to 0.13461, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9712 - val_loss: 0.1346 - val_accuracy: 0.9524\n",
      "Epoch 86/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0713 - accuracy: 0.9719\n",
      "Epoch 86: val_loss improved from 0.13461 to 0.13425, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0706 - accuracy: 0.9712 - val_loss: 0.1342 - val_accuracy: 0.9524\n",
      "Epoch 87/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9742\n",
      "Epoch 87: val_loss improved from 0.13425 to 0.13398, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0697 - accuracy: 0.9744 - val_loss: 0.1340 - val_accuracy: 0.9524\n",
      "Epoch 88/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0701 - accuracy: 0.9725\n",
      "Epoch 88: val_loss improved from 0.13398 to 0.13372, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9744 - val_loss: 0.1337 - val_accuracy: 0.9524\n",
      "Epoch 89/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0623 - accuracy: 0.9731\n",
      "Epoch 89: val_loss improved from 0.13372 to 0.13336, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9744 - val_loss: 0.1334 - val_accuracy: 0.9524\n",
      "Epoch 90/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9774\n",
      "Epoch 90: val_loss improved from 0.13336 to 0.13319, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.9776 - val_loss: 0.1332 - val_accuracy: 0.9524\n",
      "Epoch 91/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.0685 - accuracy: 0.9833\n",
      "Epoch 91: val_loss improved from 0.13319 to 0.13284, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9776 - val_loss: 0.1328 - val_accuracy: 0.9524\n",
      "Epoch 92/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9806\n",
      "Epoch 92: val_loss improved from 0.13284 to 0.13259, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9808 - val_loss: 0.1326 - val_accuracy: 0.9524\n",
      "Epoch 93/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0655 - accuracy: 0.9828\n",
      "Epoch 93: val_loss improved from 0.13259 to 0.13233, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9808 - val_loss: 0.1323 - val_accuracy: 0.9524\n",
      "Epoch 94/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0665 - accuracy: 0.9800\n",
      "Epoch 94: val_loss improved from 0.13233 to 0.13208, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9808 - val_loss: 0.1321 - val_accuracy: 0.9524\n",
      "Epoch 95/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0692 - accuracy: 0.9796\n",
      "Epoch 95: val_loss improved from 0.13208 to 0.13176, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9808 - val_loss: 0.1318 - val_accuracy: 0.9583\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9808\n",
      "Epoch 96: val_loss improved from 0.13176 to 0.13146, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9808 - val_loss: 0.1315 - val_accuracy: 0.9583\n",
      "Epoch 97/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0480 - accuracy: 0.9885\n",
      "Epoch 97: val_loss improved from 0.13146 to 0.13118, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 0.1312 - val_accuracy: 0.9583\n",
      "Epoch 98/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0695 - accuracy: 0.9769\n",
      "Epoch 98: val_loss improved from 0.13118 to 0.13096, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9808 - val_loss: 0.1310 - val_accuracy: 0.9583\n",
      "Epoch 99/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0664 - accuracy: 0.9808\n",
      "Epoch 99: val_loss improved from 0.13096 to 0.13076, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9808 - val_loss: 0.1308 - val_accuracy: 0.9583\n",
      "Epoch 100/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0635 - accuracy: 0.9808\n",
      "Epoch 100: val_loss improved from 0.13076 to 0.13060, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9808 - val_loss: 0.1306 - val_accuracy: 0.9583\n",
      "Epoch 101/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0641 - accuracy: 0.9804\n",
      "Epoch 101: val_loss improved from 0.13060 to 0.13042, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9840 - val_loss: 0.1304 - val_accuracy: 0.9583\n",
      "Epoch 102/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0615 - accuracy: 0.9808\n",
      "Epoch 102: val_loss improved from 0.13042 to 0.13020, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.1302 - val_accuracy: 0.9583\n",
      "Epoch 103/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9871\n",
      "Epoch 103: val_loss improved from 0.13020 to 0.12996, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9872 - val_loss: 0.1300 - val_accuracy: 0.9583\n",
      "Epoch 104/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0579 - accuracy: 0.9882\n",
      "Epoch 104: val_loss did not improve from 0.12996\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9872 - val_loss: 0.1300 - val_accuracy: 0.9583\n",
      "Epoch 105/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0621 - accuracy: 0.9849\n",
      "Epoch 105: val_loss improved from 0.12996 to 0.12969, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9872 - val_loss: 0.1297 - val_accuracy: 0.9583\n",
      "Epoch 106/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0559 - accuracy: 0.9920\n",
      "Epoch 106: val_loss improved from 0.12969 to 0.12948, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9872 - val_loss: 0.1295 - val_accuracy: 0.9583\n",
      "Epoch 107/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0580 - accuracy: 0.9862\n",
      "Epoch 107: val_loss improved from 0.12948 to 0.12938, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9872 - val_loss: 0.1294 - val_accuracy: 0.9583\n",
      "Epoch 108/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0629 - accuracy: 0.9843\n",
      "Epoch 108: val_loss improved from 0.12938 to 0.12930, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9872 - val_loss: 0.1293 - val_accuracy: 0.9583\n",
      "Epoch 109/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0535 - accuracy: 0.9889\n",
      "Epoch 109: val_loss improved from 0.12930 to 0.12912, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 0.9872 - val_loss: 0.1291 - val_accuracy: 0.9583\n",
      "Epoch 110/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0621 - accuracy: 0.9837\n",
      "Epoch 110: val_loss improved from 0.12912 to 0.12891, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0539 - accuracy: 0.9872 - val_loss: 0.1289 - val_accuracy: 0.9583\n",
      "Epoch 111/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0549 - accuracy: 0.9862\n",
      "Epoch 111: val_loss improved from 0.12891 to 0.12879, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.9872 - val_loss: 0.1288 - val_accuracy: 0.9583\n",
      "Epoch 112/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0603 - accuracy: 0.9837\n",
      "Epoch 112: val_loss improved from 0.12879 to 0.12867, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9872 - val_loss: 0.1287 - val_accuracy: 0.9583\n",
      "Epoch 113/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0415 - accuracy: 0.9893\n",
      "Epoch 113: val_loss improved from 0.12867 to 0.12857, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0530 - accuracy: 0.9872 - val_loss: 0.1286 - val_accuracy: 0.9583\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9872\n",
      "Epoch 114: val_loss improved from 0.12857 to 0.12851, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9872 - val_loss: 0.1285 - val_accuracy: 0.9583\n",
      "Epoch 115/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9869\n",
      "Epoch 115: val_loss improved from 0.12851 to 0.12847, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9872 - val_loss: 0.1285 - val_accuracy: 0.9583\n",
      "Epoch 116/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0494 - accuracy: 0.9887\n",
      "Epoch 116: val_loss improved from 0.12847 to 0.12844, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9872 - val_loss: 0.1284 - val_accuracy: 0.9583\n",
      "Epoch 117/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0534 - accuracy: 0.9860\n",
      "Epoch 117: val_loss improved from 0.12844 to 0.12825, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9872 - val_loss: 0.1283 - val_accuracy: 0.9583\n",
      "Epoch 118/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0505 - accuracy: 0.9897\n",
      "Epoch 118: val_loss improved from 0.12825 to 0.12820, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9904 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 119/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0536 - accuracy: 0.9885\n",
      "Epoch 119: val_loss improved from 0.12820 to 0.12813, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.9904 - val_loss: 0.1281 - val_accuracy: 0.9583\n",
      "Epoch 120/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0524 - accuracy: 0.9880\n",
      "Epoch 120: val_loss did not improve from 0.12813\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9904 - val_loss: 0.1283 - val_accuracy: 0.9583\n",
      "Epoch 121/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0512 - accuracy: 0.9893\n",
      "Epoch 121: val_loss did not improve from 0.12813\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9904 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 122/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 0.9893\n",
      "Epoch 122: val_loss did not improve from 0.12813\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9904 - val_loss: 0.1281 - val_accuracy: 0.9583\n",
      "Epoch 123/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0493 - accuracy: 0.9898\n",
      "Epoch 123: val_loss improved from 0.12813 to 0.12808, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 0.9904 - val_loss: 0.1281 - val_accuracy: 0.9583\n",
      "Epoch 124/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0509 - accuracy: 0.9895\n",
      "Epoch 124: val_loss improved from 0.12808 to 0.12803, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0473 - accuracy: 0.9904 - val_loss: 0.1280 - val_accuracy: 0.9583\n",
      "Epoch 125/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0393 - accuracy: 0.9964\n",
      "Epoch 125: val_loss improved from 0.12803 to 0.12784, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9904 - val_loss: 0.1278 - val_accuracy: 0.9583\n",
      "Epoch 126/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0483 - accuracy: 0.9891\n",
      "Epoch 126: val_loss did not improve from 0.12784\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9904 - val_loss: 0.1279 - val_accuracy: 0.9583\n",
      "Epoch 127/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0463 - accuracy: 0.9897\n",
      "Epoch 127: val_loss did not improve from 0.12784\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9904 - val_loss: 0.1279 - val_accuracy: 0.9583\n",
      "Epoch 128/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9903\n",
      "Epoch 128: val_loss did not improve from 0.12784\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9904 - val_loss: 0.1279 - val_accuracy: 0.9583\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9904\n",
      "Epoch 129: val_loss improved from 0.12784 to 0.12783, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.1278 - val_accuracy: 0.9583\n",
      "Epoch 130/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0485 - accuracy: 0.9882\n",
      "Epoch 130: val_loss improved from 0.12783 to 0.12782, saving model to model_checkpoint\\GRU_1 layer_RMSprop.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9904 - val_loss: 0.1278 - val_accuracy: 0.9583\n",
      "Epoch 131/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0458 - accuracy: 0.9900\n",
      "Epoch 131: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9904 - val_loss: 0.1281 - val_accuracy: 0.9583\n",
      "Epoch 132/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0464 - accuracy: 0.9918\n",
      "Epoch 132: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9904 - val_loss: 0.1281 - val_accuracy: 0.9583\n",
      "Epoch 133/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0426 - accuracy: 0.9927\n",
      "Epoch 133: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9904 - val_loss: 0.1281 - val_accuracy: 0.9583\n",
      "Epoch 134/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0501 - accuracy: 0.9880\n",
      "Epoch 134: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9904 - val_loss: 0.1280 - val_accuracy: 0.9583\n",
      "Epoch 135/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0254 - accuracy: 0.9965\n",
      "Epoch 135: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9904 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 136/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 136: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9904 - val_loss: 0.1280 - val_accuracy: 0.9583\n",
      "Epoch 137/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0451 - accuracy: 0.9895\n",
      "Epoch 137: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9904 - val_loss: 0.1281 - val_accuracy: 0.9583\n",
      "Epoch 138/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0450 - accuracy: 0.9893\n",
      "Epoch 138: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9904 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 139/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0409 - accuracy: 0.9900\n",
      "Epoch 139: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9904 - val_loss: 0.1283 - val_accuracy: 0.9583\n",
      "Epoch 140/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0435 - accuracy: 0.9895\n",
      "Epoch 140: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9904 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 141/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9903\n",
      "Epoch 141: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9904 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 142/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0373 - accuracy: 0.9923\n",
      "Epoch 142: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9904 - val_loss: 0.1284 - val_accuracy: 0.9583\n",
      "Epoch 143/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0384 - accuracy: 0.9929\n",
      "Epoch 143: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9904 - val_loss: 0.1286 - val_accuracy: 0.9583\n",
      "Epoch 144/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0434 - accuracy: 0.9889\n",
      "Epoch 144: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9904 - val_loss: 0.1286 - val_accuracy: 0.9583\n",
      "Epoch 145/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0423 - accuracy: 0.9887\n",
      "Epoch 145: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9904 - val_loss: 0.1288 - val_accuracy: 0.9583\n",
      "Epoch 146/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0432 - accuracy: 0.9887\n",
      "Epoch 146: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9904 - val_loss: 0.1288 - val_accuracy: 0.9583\n",
      "Epoch 147/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0383 - accuracy: 0.9923\n",
      "Epoch 147: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9904 - val_loss: 0.1290 - val_accuracy: 0.9583\n",
      "Epoch 148/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9903\n",
      "Epoch 148: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9904 - val_loss: 0.1290 - val_accuracy: 0.9583\n",
      "Epoch 149/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0263 - accuracy: 0.9922\n",
      "Epoch 149: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 0.1290 - val_accuracy: 0.9583\n",
      "Epoch 150/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0409 - accuracy: 0.9885\n",
      "Epoch 150: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9904 - val_loss: 0.1288 - val_accuracy: 0.9583\n",
      "Epoch 151/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0425 - accuracy: 0.9882\n",
      "Epoch 151: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 0.9904 - val_loss: 0.1289 - val_accuracy: 0.9643\n",
      "Epoch 152/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0426 - accuracy: 0.9878\n",
      "Epoch 152: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9904 - val_loss: 0.1288 - val_accuracy: 0.9643\n",
      "Epoch 153/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9902\n",
      "Epoch 153: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9904 - val_loss: 0.1288 - val_accuracy: 0.9643\n",
      "Epoch 154/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0377 - accuracy: 0.9897\n",
      "Epoch 154: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9904 - val_loss: 0.1287 - val_accuracy: 0.9643\n",
      "Epoch 155/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0221 - accuracy: 0.9925\n",
      "Epoch 155: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9904 - val_loss: 0.1292 - val_accuracy: 0.9643\n",
      "Epoch 156/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0401 - accuracy: 0.9889\n",
      "Epoch 156: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9904 - val_loss: 0.1290 - val_accuracy: 0.9643\n",
      "Epoch 157/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0319 - accuracy: 0.9930\n",
      "Epoch 157: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9904 - val_loss: 0.1290 - val_accuracy: 0.9643\n",
      "Epoch 158/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0370 - accuracy: 0.9889\n",
      "Epoch 158: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.1290 - val_accuracy: 0.9643\n",
      "Epoch 159/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0305 - accuracy: 0.9960\n",
      "Epoch 159: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.1290 - val_accuracy: 0.9643\n",
      "Epoch 160/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0375 - accuracy: 0.9882\n",
      "Epoch 160: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 0.1291 - val_accuracy: 0.9643\n",
      "Epoch 161/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.0216 - accuracy: 0.9917\n",
      "Epoch 161: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9904 - val_loss: 0.1293 - val_accuracy: 0.9643\n",
      "Epoch 162/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0340 - accuracy: 0.9922\n",
      "Epoch 162: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9904 - val_loss: 0.1293 - val_accuracy: 0.9643\n",
      "Epoch 163/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9903\n",
      "Epoch 163: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9904 - val_loss: 0.1292 - val_accuracy: 0.9643\n",
      "Epoch 164/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0324 - accuracy: 0.9926\n",
      "Epoch 164: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9904 - val_loss: 0.1293 - val_accuracy: 0.9643\n",
      "Epoch 165/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0204 - accuracy: 0.9929\n",
      "Epoch 165: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.1296 - val_accuracy: 0.9643\n",
      "Epoch 166/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0300 - accuracy: 0.9959\n",
      "Epoch 166: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9904 - val_loss: 0.1294 - val_accuracy: 0.9643\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9904\n",
      "Epoch 167: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.1295 - val_accuracy: 0.9643\n",
      "Epoch 168/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0321 - accuracy: 0.9900\n",
      "Epoch 168: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9904 - val_loss: 0.1296 - val_accuracy: 0.9643\n",
      "Epoch 169/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0177 - accuracy: 0.9932\n",
      "Epoch 169: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9904 - val_loss: 0.1299 - val_accuracy: 0.9643\n",
      "Epoch 170/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0341 - accuracy: 0.9891\n",
      "Epoch 170: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 0.1299 - val_accuracy: 0.9643\n",
      "Epoch 171/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.0345 - accuracy: 0.9915\n",
      "Epoch 171: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.1300 - val_accuracy: 0.9643\n",
      "Epoch 172/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0322 - accuracy: 0.9897\n",
      "Epoch 172: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.1301 - val_accuracy: 0.9643\n",
      "Epoch 173/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0152 - accuracy: 0.9962\n",
      "Epoch 173: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 0.1307 - val_accuracy: 0.9643\n",
      "Epoch 174/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0316 - accuracy: 0.9922\n",
      "Epoch 174: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.1306 - val_accuracy: 0.9643\n",
      "Epoch 175/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0146 - accuracy: 0.9963\n",
      "Epoch 175: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.1313 - val_accuracy: 0.9643\n",
      "Epoch 176/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0322 - accuracy: 0.9889\n",
      "Epoch 176: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.1311 - val_accuracy: 0.9643\n",
      "Epoch 177/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0316 - accuracy: 0.9889\n",
      "Epoch 177: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.1312 - val_accuracy: 0.9643\n",
      "Epoch 178/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0323 - accuracy: 0.9885\n",
      "Epoch 178: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.1313 - val_accuracy: 0.9643\n",
      "Epoch 179/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0309 - accuracy: 0.9920\n",
      "Epoch 179: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9904 - val_loss: 0.1314 - val_accuracy: 0.9643\n",
      "Epoch 180/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0322 - accuracy: 0.9889\n",
      "Epoch 180: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 0.1314 - val_accuracy: 0.9643\n",
      "Epoch 181/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0321 - accuracy: 0.9920\n",
      "Epoch 181: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9936 - val_loss: 0.1314 - val_accuracy: 0.9643\n",
      "Epoch 182/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0311 - accuracy: 0.9918\n",
      "Epoch 182: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9936 - val_loss: 0.1318 - val_accuracy: 0.9643\n",
      "Epoch 183/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0160 - accuracy: 0.9922\n",
      "Epoch 183: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.1319 - val_accuracy: 0.9643\n",
      "Epoch 184/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0314 - accuracy: 0.9923\n",
      "Epoch 184: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9936 - val_loss: 0.1319 - val_accuracy: 0.9643\n",
      "Epoch 185/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0310 - accuracy: 0.9925\n",
      "Epoch 185: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.1325 - val_accuracy: 0.9643\n",
      "Epoch 186/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0161 - accuracy: 0.9959\n",
      "Epoch 186: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9936 - val_loss: 0.1329 - val_accuracy: 0.9643\n",
      "Epoch 187/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0298 - accuracy: 0.9918\n",
      "Epoch 187: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9936 - val_loss: 0.1328 - val_accuracy: 0.9643\n",
      "Epoch 188/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0316 - accuracy: 0.9918\n",
      "Epoch 188: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.1328 - val_accuracy: 0.9643\n",
      "Epoch 189/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0298 - accuracy: 0.9922\n",
      "Epoch 189: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.1330 - val_accuracy: 0.9643\n",
      "Epoch 190/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 190: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9936 - val_loss: 0.1333 - val_accuracy: 0.9643\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9936\n",
      "Epoch 191: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.1331 - val_accuracy: 0.9643\n",
      "Epoch 192/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0298 - accuracy: 0.9925\n",
      "Epoch 192: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.1331 - val_accuracy: 0.9583\n",
      "Epoch 193/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0277 - accuracy: 0.9927\n",
      "Epoch 193: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9936 - val_loss: 0.1335 - val_accuracy: 0.9583\n",
      "Epoch 194/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0293 - accuracy: 0.9922\n",
      "Epoch 194: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.1336 - val_accuracy: 0.9583\n",
      "Epoch 195/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9968\n",
      "Epoch 195: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.1338 - val_accuracy: 0.9583\n",
      "Epoch 196/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 196: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.1342 - val_accuracy: 0.9583\n",
      "Epoch 197/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0291 - accuracy: 0.9923\n",
      "Epoch 197: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.1341 - val_accuracy: 0.9583\n",
      "Epoch 198/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0255 - accuracy: 0.9959\n",
      "Epoch 198: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.1343 - val_accuracy: 0.9583\n",
      "Epoch 199/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0226 - accuracy: 0.9964\n",
      "Epoch 199: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.1344 - val_accuracy: 0.9583\n",
      "Epoch 200/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0285 - accuracy: 0.9925\n",
      "Epoch 200: val_loss did not improve from 0.12782\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.1348 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 32)                11520     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,553\n",
      "Trainable params: 11,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9583\n",
      "Test Loss: 0.13477586209774017\n",
      "Test Accuracy: 0.9583333134651184\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'GRU_1 layer_RMSprop.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, x_train.shape[-1])))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with RMSprop optimizer\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001) \n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=200, validation_data=(x_val, y_val), callbacks=[callbacks_list])\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 layer with dropout Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.7472 - accuracy: 0.4947\n",
      "Epoch 1: val_loss improved from inf to 0.68650, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 3s 12ms/step - loss: 0.7379 - accuracy: 0.5048 - val_loss: 0.6865 - val_accuracy: 0.5655\n",
      "Epoch 2/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.7081 - accuracy: 0.5741\n",
      "Epoch 2: val_loss improved from 0.68650 to 0.64916, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5942 - val_loss: 0.6492 - val_accuracy: 0.5833\n",
      "Epoch 3/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.7036 - accuracy: 0.5882\n",
      "Epoch 3: val_loss improved from 0.64916 to 0.61401, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.6038 - val_loss: 0.6140 - val_accuracy: 0.6488\n",
      "Epoch 4/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.6343 - accuracy: 0.6467\n",
      "Epoch 4: val_loss improved from 0.61401 to 0.58325, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6303 - accuracy: 0.6486 - val_loss: 0.5832 - val_accuracy: 0.7083\n",
      "Epoch 5/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.6231 - accuracy: 0.6755\n",
      "Epoch 5: val_loss improved from 0.58325 to 0.55584, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.6741 - val_loss: 0.5558 - val_accuracy: 0.7440\n",
      "Epoch 6/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.5852 - accuracy: 0.7055\n",
      "Epoch 6: val_loss improved from 0.55584 to 0.53047, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.7061 - val_loss: 0.5305 - val_accuracy: 0.7560\n",
      "Epoch 7/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.5758 - accuracy: 0.6915\n",
      "Epoch 7: val_loss improved from 0.53047 to 0.50625, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5796 - accuracy: 0.6869 - val_loss: 0.5062 - val_accuracy: 0.7560\n",
      "Epoch 8/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.5371 - accuracy: 0.7615\n",
      "Epoch 8: val_loss improved from 0.50625 to 0.48623, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7540 - val_loss: 0.4862 - val_accuracy: 0.7619\n",
      "Epoch 9/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.5477 - accuracy: 0.7127\n",
      "Epoch 9: val_loss improved from 0.48623 to 0.46637, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7188 - val_loss: 0.4664 - val_accuracy: 0.7798\n",
      "Epoch 10/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.5245 - accuracy: 0.7684\n",
      "Epoch 10: val_loss improved from 0.46637 to 0.44718, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7636 - val_loss: 0.4472 - val_accuracy: 0.8095\n",
      "Epoch 11/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.4866 - accuracy: 0.8035\n",
      "Epoch 11: val_loss improved from 0.44718 to 0.43114, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.8019 - val_loss: 0.4311 - val_accuracy: 0.8452\n",
      "Epoch 12/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.5006 - accuracy: 0.7828\n",
      "Epoch 12: val_loss improved from 0.43114 to 0.41624, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7891 - val_loss: 0.4162 - val_accuracy: 0.8512\n",
      "Epoch 13/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.4865 - accuracy: 0.7630\n",
      "Epoch 13: val_loss improved from 0.41624 to 0.40184, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7572 - val_loss: 0.4018 - val_accuracy: 0.8571\n",
      "Epoch 14/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.4618 - accuracy: 0.8169\n",
      "Epoch 14: val_loss improved from 0.40184 to 0.38913, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.8051 - val_loss: 0.3891 - val_accuracy: 0.8750\n",
      "Epoch 15/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.4315 - accuracy: 0.8267\n",
      "Epoch 15: val_loss improved from 0.38913 to 0.37681, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8307 - val_loss: 0.3768 - val_accuracy: 0.8750\n",
      "Epoch 16/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.4310 - accuracy: 0.8373\n",
      "Epoch 16: val_loss improved from 0.37681 to 0.36518, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.8307 - val_loss: 0.3652 - val_accuracy: 0.8810\n",
      "Epoch 17/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.4120 - accuracy: 0.8218\n",
      "Epoch 17: val_loss improved from 0.36518 to 0.35487, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8211 - val_loss: 0.3549 - val_accuracy: 0.8869\n",
      "Epoch 18/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.4191 - accuracy: 0.8175\n",
      "Epoch 18: val_loss improved from 0.35487 to 0.34523, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8147 - val_loss: 0.3452 - val_accuracy: 0.9048\n",
      "Epoch 19/200\n",
      "44/63 [===================>..........] - ETA: 0s - loss: 0.3898 - accuracy: 0.8500\n",
      "Epoch 19: val_loss improved from 0.34523 to 0.33579, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8530 - val_loss: 0.3358 - val_accuracy: 0.8988\n",
      "Epoch 20/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.3952 - accuracy: 0.8308\n",
      "Epoch 20: val_loss improved from 0.33579 to 0.32720, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8339 - val_loss: 0.3272 - val_accuracy: 0.9107\n",
      "Epoch 21/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.4076 - accuracy: 0.8528\n",
      "Epoch 21: val_loss improved from 0.32720 to 0.31847, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8435 - val_loss: 0.3185 - val_accuracy: 0.9107\n",
      "Epoch 22/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3789 - accuracy: 0.8667\n",
      "Epoch 22: val_loss improved from 0.31847 to 0.31004, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8690 - val_loss: 0.3100 - val_accuracy: 0.9167\n",
      "Epoch 23/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.3795 - accuracy: 0.8552\n",
      "Epoch 23: val_loss improved from 0.31004 to 0.30229, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8562 - val_loss: 0.3023 - val_accuracy: 0.9167\n",
      "Epoch 24/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3345 - accuracy: 0.8836\n",
      "Epoch 24: val_loss improved from 0.30229 to 0.29529, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8754 - val_loss: 0.2953 - val_accuracy: 0.9167\n",
      "Epoch 25/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.3573 - accuracy: 0.8767\n",
      "Epoch 25: val_loss improved from 0.29529 to 0.28852, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8786 - val_loss: 0.2885 - val_accuracy: 0.9286\n",
      "Epoch 26/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3525 - accuracy: 0.8702\n",
      "Epoch 26: val_loss improved from 0.28852 to 0.28146, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8658 - val_loss: 0.2815 - val_accuracy: 0.9345\n",
      "Epoch 27/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3532 - accuracy: 0.8836\n",
      "Epoch 27: val_loss improved from 0.28146 to 0.27507, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8850 - val_loss: 0.2751 - val_accuracy: 0.9345\n",
      "Epoch 28/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.3258 - accuracy: 0.8780\n",
      "Epoch 28: val_loss improved from 0.27507 to 0.26925, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8786 - val_loss: 0.2693 - val_accuracy: 0.9405\n",
      "Epoch 29/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.8821\n",
      "Epoch 29: val_loss improved from 0.26925 to 0.26378, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8754 - val_loss: 0.2638 - val_accuracy: 0.9345\n",
      "Epoch 30/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3496 - accuracy: 0.8691\n",
      "Epoch 30: val_loss improved from 0.26378 to 0.25863, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8722 - val_loss: 0.2586 - val_accuracy: 0.9405\n",
      "Epoch 31/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.3353 - accuracy: 0.8857\n",
      "Epoch 31: val_loss improved from 0.25863 to 0.25323, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8946 - val_loss: 0.2532 - val_accuracy: 0.9405\n",
      "Epoch 32/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2981 - accuracy: 0.8941\n",
      "Epoch 32: val_loss improved from 0.25323 to 0.24809, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2981 - accuracy: 0.8978 - val_loss: 0.2481 - val_accuracy: 0.9464\n",
      "Epoch 33/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3352 - accuracy: 0.8778\n",
      "Epoch 33: val_loss improved from 0.24809 to 0.24402, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8914 - val_loss: 0.2440 - val_accuracy: 0.9464\n",
      "Epoch 34/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3087 - accuracy: 0.9000\n",
      "Epoch 34: val_loss improved from 0.24402 to 0.23959, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3019 - accuracy: 0.9073 - val_loss: 0.2396 - val_accuracy: 0.9524\n",
      "Epoch 35/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2933 - accuracy: 0.8881\n",
      "Epoch 35: val_loss improved from 0.23959 to 0.23561, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.8882 - val_loss: 0.2356 - val_accuracy: 0.9524\n",
      "Epoch 36/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3199 - accuracy: 0.8643\n",
      "Epoch 36: val_loss improved from 0.23561 to 0.23154, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8722 - val_loss: 0.2315 - val_accuracy: 0.9524\n",
      "Epoch 37/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2990 - accuracy: 0.9036\n",
      "Epoch 37: val_loss improved from 0.23154 to 0.22724, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3044 - accuracy: 0.8978 - val_loss: 0.2272 - val_accuracy: 0.9524\n",
      "Epoch 38/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3044 - accuracy: 0.8737\n",
      "Epoch 38: val_loss improved from 0.22724 to 0.22392, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2985 - accuracy: 0.8786 - val_loss: 0.2239 - val_accuracy: 0.9524\n",
      "Epoch 39/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2906 - accuracy: 0.8967\n",
      "Epoch 39: val_loss improved from 0.22392 to 0.22002, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2924 - accuracy: 0.8914 - val_loss: 0.2200 - val_accuracy: 0.9583\n",
      "Epoch 40/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2958 - accuracy: 0.8857\n",
      "Epoch 40: val_loss improved from 0.22002 to 0.21655, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8850 - val_loss: 0.2165 - val_accuracy: 0.9583\n",
      "Epoch 41/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2928 - accuracy: 0.9071\n",
      "Epoch 41: val_loss improved from 0.21655 to 0.21370, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.9137 - val_loss: 0.2137 - val_accuracy: 0.9583\n",
      "Epoch 42/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2978 - accuracy: 0.9000\n",
      "Epoch 42: val_loss improved from 0.21370 to 0.21060, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8882 - val_loss: 0.2106 - val_accuracy: 0.9583\n",
      "Epoch 43/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2628 - accuracy: 0.9020\n",
      "Epoch 43: val_loss improved from 0.21060 to 0.20751, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.9010 - val_loss: 0.2075 - val_accuracy: 0.9583\n",
      "Epoch 44/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2727 - accuracy: 0.9020\n",
      "Epoch 44: val_loss improved from 0.20751 to 0.20432, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2705 - accuracy: 0.9042 - val_loss: 0.2043 - val_accuracy: 0.9583\n",
      "Epoch 45/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2505 - accuracy: 0.9158\n",
      "Epoch 45: val_loss improved from 0.20432 to 0.20129, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2468 - accuracy: 0.9201 - val_loss: 0.2013 - val_accuracy: 0.9583\n",
      "Epoch 46/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2596 - accuracy: 0.8982\n",
      "Epoch 46: val_loss improved from 0.20129 to 0.19894, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2614 - accuracy: 0.9010 - val_loss: 0.1989 - val_accuracy: 0.9583\n",
      "Epoch 47/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9097\n",
      "Epoch 47: val_loss improved from 0.19894 to 0.19650, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2527 - accuracy: 0.9105 - val_loss: 0.1965 - val_accuracy: 0.9583\n",
      "Epoch 48/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2537 - accuracy: 0.9308\n",
      "Epoch 48: val_loss improved from 0.19650 to 0.19377, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2637 - accuracy: 0.9233 - val_loss: 0.1938 - val_accuracy: 0.9583\n",
      "Epoch 49/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2939 - accuracy: 0.8923\n",
      "Epoch 49: val_loss improved from 0.19377 to 0.19114, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8946 - val_loss: 0.1911 - val_accuracy: 0.9583\n",
      "Epoch 50/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2462 - accuracy: 0.9385\n",
      "Epoch 50: val_loss improved from 0.19114 to 0.18894, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2520 - accuracy: 0.9233 - val_loss: 0.1889 - val_accuracy: 0.9583\n",
      "Epoch 51/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.2807 - accuracy: 0.8958\n",
      "Epoch 51: val_loss improved from 0.18894 to 0.18693, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.9042 - val_loss: 0.1869 - val_accuracy: 0.9583\n",
      "Epoch 52/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2702 - accuracy: 0.9019\n",
      "Epoch 52: val_loss improved from 0.18693 to 0.18475, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.9073 - val_loss: 0.1847 - val_accuracy: 0.9643\n",
      "Epoch 53/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2732 - accuracy: 0.9000\n",
      "Epoch 53: val_loss improved from 0.18475 to 0.18296, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.9010 - val_loss: 0.1830 - val_accuracy: 0.9702\n",
      "Epoch 54/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2591 - accuracy: 0.8939\n",
      "Epoch 54: val_loss improved from 0.18296 to 0.18125, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2418 - accuracy: 0.9073 - val_loss: 0.1812 - val_accuracy: 0.9702\n",
      "Epoch 55/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2539 - accuracy: 0.9192\n",
      "Epoch 55: val_loss improved from 0.18125 to 0.17885, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2354 - accuracy: 0.9297 - val_loss: 0.1789 - val_accuracy: 0.9702\n",
      "Epoch 56/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2238 - accuracy: 0.9368\n",
      "Epoch 56: val_loss improved from 0.17885 to 0.17681, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2310 - accuracy: 0.9297 - val_loss: 0.1768 - val_accuracy: 0.9702\n",
      "Epoch 57/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2325 - accuracy: 0.9148\n",
      "Epoch 57: val_loss improved from 0.17681 to 0.17505, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2524 - accuracy: 0.8978 - val_loss: 0.1750 - val_accuracy: 0.9643\n",
      "Epoch 58/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2149 - accuracy: 0.9255\n",
      "Epoch 58: val_loss improved from 0.17505 to 0.17357, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2113 - accuracy: 0.9265 - val_loss: 0.1736 - val_accuracy: 0.9643\n",
      "Epoch 59/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9410\n",
      "Epoch 59: val_loss improved from 0.17357 to 0.17165, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2292 - accuracy: 0.9361 - val_loss: 0.1716 - val_accuracy: 0.9643\n",
      "Epoch 60/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2191 - accuracy: 0.9357\n",
      "Epoch 60: val_loss improved from 0.17165 to 0.16972, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2211 - accuracy: 0.9361 - val_loss: 0.1697 - val_accuracy: 0.9643\n",
      "Epoch 61/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2024 - accuracy: 0.9434\n",
      "Epoch 61: val_loss improved from 0.16972 to 0.16781, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9265 - val_loss: 0.1678 - val_accuracy: 0.9643\n",
      "Epoch 62/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2289 - accuracy: 0.9176\n",
      "Epoch 62: val_loss improved from 0.16781 to 0.16627, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2229 - accuracy: 0.9233 - val_loss: 0.1663 - val_accuracy: 0.9702\n",
      "Epoch 63/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2087 - accuracy: 0.9464\n",
      "Epoch 63: val_loss improved from 0.16627 to 0.16486, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2110 - accuracy: 0.9425 - val_loss: 0.1649 - val_accuracy: 0.9702\n",
      "Epoch 64/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2353 - accuracy: 0.9222\n",
      "Epoch 64: val_loss improved from 0.16486 to 0.16348, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9265 - val_loss: 0.1635 - val_accuracy: 0.9762\n",
      "Epoch 65/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2144 - accuracy: 0.9347\n",
      "Epoch 65: val_loss improved from 0.16348 to 0.16209, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2101 - accuracy: 0.9329 - val_loss: 0.1621 - val_accuracy: 0.9762\n",
      "Epoch 66/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2187 - accuracy: 0.9259\n",
      "Epoch 66: val_loss improved from 0.16209 to 0.16067, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2124 - accuracy: 0.9329 - val_loss: 0.1607 - val_accuracy: 0.9762\n",
      "Epoch 67/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2080 - accuracy: 0.9462\n",
      "Epoch 67: val_loss improved from 0.16067 to 0.15932, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2236 - accuracy: 0.9425 - val_loss: 0.1593 - val_accuracy: 0.9762\n",
      "Epoch 68/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2102 - accuracy: 0.9467\n",
      "Epoch 68: val_loss improved from 0.15932 to 0.15792, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2129 - accuracy: 0.9457 - val_loss: 0.1579 - val_accuracy: 0.9762\n",
      "Epoch 69/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2078 - accuracy: 0.9423\n",
      "Epoch 69: val_loss improved from 0.15792 to 0.15691, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2056 - accuracy: 0.9393 - val_loss: 0.1569 - val_accuracy: 0.9762\n",
      "Epoch 70/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2151 - accuracy: 0.9296\n",
      "Epoch 70: val_loss improved from 0.15691 to 0.15554, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2207 - accuracy: 0.9265 - val_loss: 0.1555 - val_accuracy: 0.9762\n",
      "Epoch 71/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2049 - accuracy: 0.9273\n",
      "Epoch 71: val_loss improved from 0.15554 to 0.15406, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9297 - val_loss: 0.1541 - val_accuracy: 0.9762\n",
      "Epoch 72/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2220 - accuracy: 0.9333\n",
      "Epoch 72: val_loss improved from 0.15406 to 0.15300, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2126 - accuracy: 0.9329 - val_loss: 0.1530 - val_accuracy: 0.9762\n",
      "Epoch 73/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1903 - accuracy: 0.9455\n",
      "Epoch 73: val_loss improved from 0.15300 to 0.15137, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1939 - accuracy: 0.9393 - val_loss: 0.1514 - val_accuracy: 0.9762\n",
      "Epoch 74/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2070 - accuracy: 0.9222\n",
      "Epoch 74: val_loss improved from 0.15137 to 0.15024, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9201 - val_loss: 0.1502 - val_accuracy: 0.9762\n",
      "Epoch 75/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2303 - accuracy: 0.9120\n",
      "Epoch 75: val_loss improved from 0.15024 to 0.14911, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9265 - val_loss: 0.1491 - val_accuracy: 0.9762\n",
      "Epoch 76/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.1857 - accuracy: 0.9435\n",
      "Epoch 76: val_loss improved from 0.14911 to 0.14796, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1896 - accuracy: 0.9393 - val_loss: 0.1480 - val_accuracy: 0.9762\n",
      "Epoch 77/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2053 - accuracy: 0.9214\n",
      "Epoch 77: val_loss improved from 0.14796 to 0.14700, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.9265 - val_loss: 0.1470 - val_accuracy: 0.9762\n",
      "Epoch 78/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1967 - accuracy: 0.9347\n",
      "Epoch 78: val_loss improved from 0.14700 to 0.14566, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9361 - val_loss: 0.1457 - val_accuracy: 0.9762\n",
      "Epoch 79/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2099 - accuracy: 0.9158\n",
      "Epoch 79: val_loss improved from 0.14566 to 0.14468, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9233 - val_loss: 0.1447 - val_accuracy: 0.9762\n",
      "Epoch 80/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2263 - accuracy: 0.9123\n",
      "Epoch 80: val_loss improved from 0.14468 to 0.14413, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.9201 - val_loss: 0.1441 - val_accuracy: 0.9762\n",
      "Epoch 81/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9311\n",
      "Epoch 81: val_loss improved from 0.14413 to 0.14350, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9329 - val_loss: 0.1435 - val_accuracy: 0.9762\n",
      "Epoch 82/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1722 - accuracy: 0.9467\n",
      "Epoch 82: val_loss improved from 0.14350 to 0.14279, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.9393 - val_loss: 0.1428 - val_accuracy: 0.9762\n",
      "Epoch 83/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1722 - accuracy: 0.9387\n",
      "Epoch 83: val_loss improved from 0.14279 to 0.14189, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1709 - accuracy: 0.9393 - val_loss: 0.1419 - val_accuracy: 0.9762\n",
      "Epoch 84/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1943 - accuracy: 0.9407\n",
      "Epoch 84: val_loss improved from 0.14189 to 0.14116, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9361 - val_loss: 0.1412 - val_accuracy: 0.9762\n",
      "Epoch 85/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1726 - accuracy: 0.9464\n",
      "Epoch 85: val_loss improved from 0.14116 to 0.14008, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1713 - accuracy: 0.9489 - val_loss: 0.1401 - val_accuracy: 0.9762\n",
      "Epoch 86/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1840 - accuracy: 0.9417\n",
      "Epoch 86: val_loss improved from 0.14008 to 0.13946, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1722 - accuracy: 0.9457 - val_loss: 0.1395 - val_accuracy: 0.9762\n",
      "Epoch 87/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1780 - accuracy: 0.9414\n",
      "Epoch 87: val_loss improved from 0.13946 to 0.13891, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9393 - val_loss: 0.1389 - val_accuracy: 0.9762\n",
      "Epoch 88/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1654 - accuracy: 0.9311\n",
      "Epoch 88: val_loss improved from 0.13891 to 0.13802, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9297 - val_loss: 0.1380 - val_accuracy: 0.9762\n",
      "Epoch 89/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1844 - accuracy: 0.9200\n",
      "Epoch 89: val_loss improved from 0.13802 to 0.13761, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9201 - val_loss: 0.1376 - val_accuracy: 0.9762\n",
      "Epoch 90/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1915 - accuracy: 0.9300\n",
      "Epoch 90: val_loss improved from 0.13761 to 0.13697, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9233 - val_loss: 0.1370 - val_accuracy: 0.9762\n",
      "Epoch 91/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1831 - accuracy: 0.9385\n",
      "Epoch 91: val_loss improved from 0.13697 to 0.13620, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9457 - val_loss: 0.1362 - val_accuracy: 0.9762\n",
      "Epoch 92/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1990 - accuracy: 0.9424\n",
      "Epoch 92: val_loss improved from 0.13620 to 0.13526, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9457 - val_loss: 0.1353 - val_accuracy: 0.9762\n",
      "Epoch 93/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1732 - accuracy: 0.9544\n",
      "Epoch 93: val_loss improved from 0.13526 to 0.13466, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9457 - val_loss: 0.1347 - val_accuracy: 0.9762\n",
      "Epoch 94/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9443\n",
      "Epoch 94: val_loss improved from 0.13466 to 0.13408, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9457 - val_loss: 0.1341 - val_accuracy: 0.9762\n",
      "Epoch 95/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1625 - accuracy: 0.9433\n",
      "Epoch 95: val_loss improved from 0.13408 to 0.13304, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9457 - val_loss: 0.1330 - val_accuracy: 0.9762\n",
      "Epoch 96/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1652 - accuracy: 0.9525\n",
      "Epoch 96: val_loss improved from 0.13304 to 0.13228, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1661 - accuracy: 0.9521 - val_loss: 0.1323 - val_accuracy: 0.9762\n",
      "Epoch 97/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9475\n",
      "Epoch 97: val_loss improved from 0.13228 to 0.13181, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9489 - val_loss: 0.1318 - val_accuracy: 0.9762\n",
      "Epoch 98/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1465 - accuracy: 0.9481\n",
      "Epoch 98: val_loss improved from 0.13181 to 0.13095, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9425 - val_loss: 0.1309 - val_accuracy: 0.9762\n",
      "Epoch 99/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1651 - accuracy: 0.9429\n",
      "Epoch 99: val_loss improved from 0.13095 to 0.13020, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1660 - accuracy: 0.9425 - val_loss: 0.1302 - val_accuracy: 0.9762\n",
      "Epoch 100/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1678 - accuracy: 0.9474\n",
      "Epoch 100: val_loss improved from 0.13020 to 0.12976, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9457 - val_loss: 0.1298 - val_accuracy: 0.9762\n",
      "Epoch 101/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1737 - accuracy: 0.9424\n",
      "Epoch 101: val_loss improved from 0.12976 to 0.12916, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9457 - val_loss: 0.1292 - val_accuracy: 0.9762\n",
      "Epoch 102/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1578 - accuracy: 0.9571\n",
      "Epoch 102: val_loss improved from 0.12916 to 0.12849, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.9553 - val_loss: 0.1285 - val_accuracy: 0.9762\n",
      "Epoch 103/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1646 - accuracy: 0.9464\n",
      "Epoch 103: val_loss improved from 0.12849 to 0.12807, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1599 - accuracy: 0.9489 - val_loss: 0.1281 - val_accuracy: 0.9762\n",
      "Epoch 104/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1740 - accuracy: 0.9483\n",
      "Epoch 104: val_loss improved from 0.12807 to 0.12747, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9489 - val_loss: 0.1275 - val_accuracy: 0.9762\n",
      "Epoch 105/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1739 - accuracy: 0.9283\n",
      "Epoch 105: val_loss improved from 0.12747 to 0.12688, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.9393 - val_loss: 0.1269 - val_accuracy: 0.9762\n",
      "Epoch 106/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1550 - accuracy: 0.9567\n",
      "Epoch 106: val_loss improved from 0.12688 to 0.12634, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9553 - val_loss: 0.1263 - val_accuracy: 0.9762\n",
      "Epoch 107/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1412 - accuracy: 0.9536\n",
      "Epoch 107: val_loss improved from 0.12634 to 0.12572, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1533 - accuracy: 0.9489 - val_loss: 0.1257 - val_accuracy: 0.9762\n",
      "Epoch 108/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1373 - accuracy: 0.9673\n",
      "Epoch 108: val_loss improved from 0.12572 to 0.12520, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9553 - val_loss: 0.1252 - val_accuracy: 0.9762\n",
      "Epoch 109/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1626 - accuracy: 0.9382\n",
      "Epoch 109: val_loss improved from 0.12520 to 0.12498, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1562 - accuracy: 0.9425 - val_loss: 0.1250 - val_accuracy: 0.9762\n",
      "Epoch 110/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1457 - accuracy: 0.9516\n",
      "Epoch 110: val_loss improved from 0.12498 to 0.12479, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.9489 - val_loss: 0.1248 - val_accuracy: 0.9762\n",
      "Epoch 111/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9645\n",
      "Epoch 111: val_loss improved from 0.12479 to 0.12436, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9649 - val_loss: 0.1244 - val_accuracy: 0.9762\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.9457\n",
      "Epoch 112: val_loss improved from 0.12436 to 0.12333, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1531 - accuracy: 0.9457 - val_loss: 0.1233 - val_accuracy: 0.9762\n",
      "Epoch 113/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1445 - accuracy: 0.9527\n",
      "Epoch 113: val_loss improved from 0.12333 to 0.12286, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9585 - val_loss: 0.1229 - val_accuracy: 0.9762\n",
      "Epoch 114/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9443\n",
      "Epoch 114: val_loss improved from 0.12286 to 0.12235, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1531 - accuracy: 0.9425 - val_loss: 0.1223 - val_accuracy: 0.9762\n",
      "Epoch 115/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9574\n",
      "Epoch 115: val_loss improved from 0.12235 to 0.12200, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9585 - val_loss: 0.1220 - val_accuracy: 0.9762\n",
      "Epoch 116/200\n",
      "42/63 [===================>..........] - ETA: 0s - loss: 0.1488 - accuracy: 0.9619\n",
      "Epoch 116: val_loss improved from 0.12200 to 0.12140, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9585 - val_loss: 0.1214 - val_accuracy: 0.9762\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9457\n",
      "Epoch 117: val_loss improved from 0.12140 to 0.12078, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1647 - accuracy: 0.9457 - val_loss: 0.1208 - val_accuracy: 0.9762\n",
      "Epoch 118/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9581\n",
      "Epoch 118: val_loss improved from 0.12078 to 0.12021, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9585 - val_loss: 0.1202 - val_accuracy: 0.9762\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9425\n",
      "Epoch 119: val_loss improved from 0.12021 to 0.12011, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.9425 - val_loss: 0.1201 - val_accuracy: 0.9702\n",
      "Epoch 120/200\n",
      "43/63 [===================>..........] - ETA: 0s - loss: 0.1112 - accuracy: 0.9628\n",
      "Epoch 120: val_loss improved from 0.12011 to 0.11949, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9457 - val_loss: 0.1195 - val_accuracy: 0.9762\n",
      "Epoch 121/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1418 - accuracy: 0.9585\n",
      "Epoch 121: val_loss improved from 0.11949 to 0.11926, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1590 - accuracy: 0.9521 - val_loss: 0.1193 - val_accuracy: 0.9762\n",
      "Epoch 122/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.9645\n",
      "Epoch 122: val_loss improved from 0.11926 to 0.11901, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9617 - val_loss: 0.1190 - val_accuracy: 0.9762\n",
      "Epoch 123/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1493 - accuracy: 0.9615\n",
      "Epoch 123: val_loss improved from 0.11901 to 0.11825, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9553 - val_loss: 0.1183 - val_accuracy: 0.9762\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9553\n",
      "Epoch 124: val_loss improved from 0.11825 to 0.11800, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9553 - val_loss: 0.1180 - val_accuracy: 0.9762\n",
      "Epoch 125/200\n",
      "43/63 [===================>..........] - ETA: 0s - loss: 0.1294 - accuracy: 0.9581\n",
      "Epoch 125: val_loss improved from 0.11800 to 0.11737, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9585 - val_loss: 0.1174 - val_accuracy: 0.9762\n",
      "Epoch 126/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 0.9574\n",
      "Epoch 126: val_loss improved from 0.11737 to 0.11690, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9585 - val_loss: 0.1169 - val_accuracy: 0.9762\n",
      "Epoch 127/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1315 - accuracy: 0.9593\n",
      "Epoch 127: val_loss improved from 0.11690 to 0.11638, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.9649 - val_loss: 0.1164 - val_accuracy: 0.9762\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9585\n",
      "Epoch 128: val_loss improved from 0.11638 to 0.11609, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9585 - val_loss: 0.1161 - val_accuracy: 0.9762\n",
      "Epoch 129/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1504 - accuracy: 0.9533\n",
      "Epoch 129: val_loss improved from 0.11609 to 0.11599, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1486 - accuracy: 0.9553 - val_loss: 0.1160 - val_accuracy: 0.9762\n",
      "Epoch 130/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1316 - accuracy: 0.9547\n",
      "Epoch 130: val_loss improved from 0.11599 to 0.11569, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1333 - accuracy: 0.9553 - val_loss: 0.1157 - val_accuracy: 0.9762\n",
      "Epoch 131/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1260 - accuracy: 0.9672\n",
      "Epoch 131: val_loss improved from 0.11569 to 0.11549, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.9649 - val_loss: 0.1155 - val_accuracy: 0.9762\n",
      "Epoch 132/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1241 - accuracy: 0.9679\n",
      "Epoch 132: val_loss improved from 0.11549 to 0.11525, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9712 - val_loss: 0.1152 - val_accuracy: 0.9762\n",
      "Epoch 133/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1329 - accuracy: 0.9667\n",
      "Epoch 133: val_loss improved from 0.11525 to 0.11505, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9617 - val_loss: 0.1151 - val_accuracy: 0.9762\n",
      "Epoch 134/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1463 - accuracy: 0.9418\n",
      "Epoch 134: val_loss improved from 0.11505 to 0.11503, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9489 - val_loss: 0.1150 - val_accuracy: 0.9762\n",
      "Epoch 135/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9633\n",
      "Epoch 135: val_loss improved from 0.11503 to 0.11455, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1295 - accuracy: 0.9617 - val_loss: 0.1146 - val_accuracy: 0.9762\n",
      "Epoch 136/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1372 - accuracy: 0.9593\n",
      "Epoch 136: val_loss improved from 0.11455 to 0.11429, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9617 - val_loss: 0.1143 - val_accuracy: 0.9762\n",
      "Epoch 137/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9541\n",
      "Epoch 137: val_loss improved from 0.11429 to 0.11408, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9553 - val_loss: 0.1141 - val_accuracy: 0.9762\n",
      "Epoch 138/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1484 - accuracy: 0.9483\n",
      "Epoch 138: val_loss improved from 0.11408 to 0.11388, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.9521 - val_loss: 0.1139 - val_accuracy: 0.9762\n",
      "Epoch 139/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9714\n",
      "Epoch 139: val_loss improved from 0.11388 to 0.11374, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1184 - accuracy: 0.9681 - val_loss: 0.1137 - val_accuracy: 0.9762\n",
      "Epoch 140/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1230 - accuracy: 0.9571\n",
      "Epoch 140: val_loss did not improve from 0.11374\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9521 - val_loss: 0.1138 - val_accuracy: 0.9762\n",
      "Epoch 141/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1188 - accuracy: 0.9741\n",
      "Epoch 141: val_loss improved from 0.11374 to 0.11310, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1301 - accuracy: 0.9681 - val_loss: 0.1131 - val_accuracy: 0.9762\n",
      "Epoch 142/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1344 - accuracy: 0.9672\n",
      "Epoch 142: val_loss improved from 0.11310 to 0.11261, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9681 - val_loss: 0.1126 - val_accuracy: 0.9762\n",
      "Epoch 143/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.0941 - accuracy: 0.9792\n",
      "Epoch 143: val_loss improved from 0.11261 to 0.11241, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1273 - accuracy: 0.9649 - val_loss: 0.1124 - val_accuracy: 0.9762\n",
      "Epoch 144/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1151 - accuracy: 0.9765\n",
      "Epoch 144: val_loss did not improve from 0.11241\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9744 - val_loss: 0.1125 - val_accuracy: 0.9762\n",
      "Epoch 145/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1150 - accuracy: 0.9627\n",
      "Epoch 145: val_loss improved from 0.11241 to 0.11227, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.9617 - val_loss: 0.1123 - val_accuracy: 0.9762\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9585\n",
      "Epoch 146: val_loss improved from 0.11227 to 0.11165, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1243 - accuracy: 0.9585 - val_loss: 0.1116 - val_accuracy: 0.9762\n",
      "Epoch 147/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1064 - accuracy: 0.9741\n",
      "Epoch 147: val_loss improved from 0.11165 to 0.11123, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.9712 - val_loss: 0.1112 - val_accuracy: 0.9762\n",
      "Epoch 148/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1345 - accuracy: 0.9571\n",
      "Epoch 148: val_loss improved from 0.11123 to 0.11107, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.9553 - val_loss: 0.1111 - val_accuracy: 0.9762\n",
      "Epoch 149/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1086 - accuracy: 0.9692\n",
      "Epoch 149: val_loss improved from 0.11107 to 0.11035, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1088 - accuracy: 0.9681 - val_loss: 0.1103 - val_accuracy: 0.9762\n",
      "Epoch 150/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1226 - accuracy: 0.9692\n",
      "Epoch 150: val_loss improved from 0.11035 to 0.10987, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.9681 - val_loss: 0.1099 - val_accuracy: 0.9762\n",
      "Epoch 151/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1156 - accuracy: 0.9640\n",
      "Epoch 151: val_loss improved from 0.10987 to 0.10966, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9681 - val_loss: 0.1097 - val_accuracy: 0.9762\n",
      "Epoch 152/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1329 - accuracy: 0.9542\n",
      "Epoch 152: val_loss did not improve from 0.10966\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.9585 - val_loss: 0.1097 - val_accuracy: 0.9762\n",
      "Epoch 153/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1193 - accuracy: 0.9649\n",
      "Epoch 153: val_loss improved from 0.10966 to 0.10957, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1161 - accuracy: 0.9681 - val_loss: 0.1096 - val_accuracy: 0.9762\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9617\n",
      "Epoch 154: val_loss did not improve from 0.10957\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9617 - val_loss: 0.1097 - val_accuracy: 0.9762\n",
      "Epoch 155/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9607\n",
      "Epoch 155: val_loss did not improve from 0.10957\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9585 - val_loss: 0.1097 - val_accuracy: 0.9762\n",
      "Epoch 156/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1260 - accuracy: 0.9448\n",
      "Epoch 156: val_loss did not improve from 0.10957\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9457 - val_loss: 0.1096 - val_accuracy: 0.9762\n",
      "Epoch 157/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1234 - accuracy: 0.9643\n",
      "Epoch 157: val_loss improved from 0.10957 to 0.10932, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9681 - val_loss: 0.1093 - val_accuracy: 0.9762\n",
      "Epoch 158/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.0756 - accuracy: 0.9875\n",
      "Epoch 158: val_loss improved from 0.10932 to 0.10890, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9808 - val_loss: 0.1089 - val_accuracy: 0.9762\n",
      "Epoch 159/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1268 - accuracy: 0.9544\n",
      "Epoch 159: val_loss improved from 0.10890 to 0.10877, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 0.9553 - val_loss: 0.1088 - val_accuracy: 0.9762\n",
      "Epoch 160/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0917 - accuracy: 0.9714\n",
      "Epoch 160: val_loss improved from 0.10877 to 0.10863, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.9649 - val_loss: 0.1086 - val_accuracy: 0.9762\n",
      "Epoch 161/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1176 - accuracy: 0.9655\n",
      "Epoch 161: val_loss improved from 0.10863 to 0.10860, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9617 - val_loss: 0.1086 - val_accuracy: 0.9762\n",
      "Epoch 162/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1143 - accuracy: 0.9552\n",
      "Epoch 162: val_loss did not improve from 0.10860\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9553 - val_loss: 0.1088 - val_accuracy: 0.9762\n",
      "Epoch 163/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1102 - accuracy: 0.9679\n",
      "Epoch 163: val_loss improved from 0.10860 to 0.10824, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9681 - val_loss: 0.1082 - val_accuracy: 0.9762\n",
      "Epoch 164/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.9672\n",
      "Epoch 164: val_loss improved from 0.10824 to 0.10787, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9681 - val_loss: 0.1079 - val_accuracy: 0.9762\n",
      "Epoch 165/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0790 - accuracy: 0.9849\n",
      "Epoch 165: val_loss improved from 0.10787 to 0.10723, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9744 - val_loss: 0.1072 - val_accuracy: 0.9762\n",
      "Epoch 166/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9639\n",
      "Epoch 166: val_loss improved from 0.10723 to 0.10678, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1225 - accuracy: 0.9649 - val_loss: 0.1068 - val_accuracy: 0.9762\n",
      "Epoch 167/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1196 - accuracy: 0.9679\n",
      "Epoch 167: val_loss did not improve from 0.10678\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9681 - val_loss: 0.1070 - val_accuracy: 0.9762\n",
      "Epoch 168/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1109 - accuracy: 0.9593\n",
      "Epoch 168: val_loss improved from 0.10678 to 0.10673, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9617 - val_loss: 0.1067 - val_accuracy: 0.9762\n",
      "Epoch 169/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1086 - accuracy: 0.9600\n",
      "Epoch 169: val_loss did not improve from 0.10673\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9617 - val_loss: 0.1068 - val_accuracy: 0.9762\n",
      "Epoch 170/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1103 - accuracy: 0.9621\n",
      "Epoch 170: val_loss improved from 0.10673 to 0.10633, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9585 - val_loss: 0.1063 - val_accuracy: 0.9762\n",
      "Epoch 171/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1025 - accuracy: 0.9698\n",
      "Epoch 171: val_loss improved from 0.10633 to 0.10587, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9744 - val_loss: 0.1059 - val_accuracy: 0.9762\n",
      "Epoch 172/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9661\n",
      "Epoch 172: val_loss improved from 0.10587 to 0.10565, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9681 - val_loss: 0.1057 - val_accuracy: 0.9762\n",
      "Epoch 173/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9581\n",
      "Epoch 173: val_loss did not improve from 0.10565\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1132 - accuracy: 0.9585 - val_loss: 0.1058 - val_accuracy: 0.9762\n",
      "Epoch 174/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1030 - accuracy: 0.9719\n",
      "Epoch 174: val_loss did not improve from 0.10565\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9712 - val_loss: 0.1058 - val_accuracy: 0.9762\n",
      "Epoch 175/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0979 - accuracy: 0.9686\n",
      "Epoch 175: val_loss improved from 0.10565 to 0.10554, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9681 - val_loss: 0.1055 - val_accuracy: 0.9762\n",
      "Epoch 176/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1108 - accuracy: 0.9709\n",
      "Epoch 176: val_loss improved from 0.10554 to 0.10547, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9744 - val_loss: 0.1055 - val_accuracy: 0.9762\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9649\n",
      "Epoch 177: val_loss did not improve from 0.10547\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9649 - val_loss: 0.1055 - val_accuracy: 0.9762\n",
      "Epoch 178/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1068 - accuracy: 0.9714\n",
      "Epoch 178: val_loss did not improve from 0.10547\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9744 - val_loss: 0.1056 - val_accuracy: 0.9762\n",
      "Epoch 179/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1145 - accuracy: 0.9736\n",
      "Epoch 179: val_loss improved from 0.10547 to 0.10517, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1021 - accuracy: 0.9776 - val_loss: 0.1052 - val_accuracy: 0.9762\n",
      "Epoch 180/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1169 - accuracy: 0.9585\n",
      "Epoch 180: val_loss improved from 0.10517 to 0.10503, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9649 - val_loss: 0.1050 - val_accuracy: 0.9762\n",
      "Epoch 181/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0976 - accuracy: 0.9733\n",
      "Epoch 181: val_loss improved from 0.10503 to 0.10458, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9712 - val_loss: 0.1046 - val_accuracy: 0.9762\n",
      "Epoch 182/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1261 - accuracy: 0.9640\n",
      "Epoch 182: val_loss did not improve from 0.10458\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9681 - val_loss: 0.1047 - val_accuracy: 0.9762\n",
      "Epoch 183/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1171 - accuracy: 0.9579\n",
      "Epoch 183: val_loss improved from 0.10458 to 0.10441, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.9617 - val_loss: 0.1044 - val_accuracy: 0.9762\n",
      "Epoch 184/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0927 - accuracy: 0.9763\n",
      "Epoch 184: val_loss improved from 0.10441 to 0.10421, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9744 - val_loss: 0.1042 - val_accuracy: 0.9762\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9617\n",
      "Epoch 185: val_loss improved from 0.10421 to 0.10412, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1163 - accuracy: 0.9617 - val_loss: 0.1041 - val_accuracy: 0.9762\n",
      "Epoch 186/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1134 - accuracy: 0.9667\n",
      "Epoch 186: val_loss improved from 0.10412 to 0.10404, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9617 - val_loss: 0.1040 - val_accuracy: 0.9762\n",
      "Epoch 187/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1141 - accuracy: 0.9627\n",
      "Epoch 187: val_loss did not improve from 0.10404\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.9649 - val_loss: 0.1041 - val_accuracy: 0.9762\n",
      "Epoch 188/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0945 - accuracy: 0.9686\n",
      "Epoch 188: val_loss did not improve from 0.10404\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9681 - val_loss: 0.1040 - val_accuracy: 0.9762\n",
      "Epoch 189/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1046 - accuracy: 0.9673\n",
      "Epoch 189: val_loss improved from 0.10404 to 0.10362, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.9712 - val_loss: 0.1036 - val_accuracy: 0.9762\n",
      "Epoch 190/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0877 - accuracy: 0.9729\n",
      "Epoch 190: val_loss improved from 0.10362 to 0.10332, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9744 - val_loss: 0.1033 - val_accuracy: 0.9762\n",
      "Epoch 191/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1031 - accuracy: 0.9765\n",
      "Epoch 191: val_loss improved from 0.10332 to 0.10300, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.9776 - val_loss: 0.1030 - val_accuracy: 0.9762\n",
      "Epoch 192/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9639\n",
      "Epoch 192: val_loss did not improve from 0.10300\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9649 - val_loss: 0.1032 - val_accuracy: 0.9762\n",
      "Epoch 193/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1247 - accuracy: 0.9520\n",
      "Epoch 193: val_loss did not improve from 0.10300\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1181 - accuracy: 0.9585 - val_loss: 0.1031 - val_accuracy: 0.9762\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9681\n",
      "Epoch 194: val_loss did not improve from 0.10300\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0871 - accuracy: 0.9681 - val_loss: 0.1033 - val_accuracy: 0.9762\n",
      "Epoch 195/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0759 - accuracy: 0.9769\n",
      "Epoch 195: val_loss improved from 0.10300 to 0.10283, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9744 - val_loss: 0.1028 - val_accuracy: 0.9762\n",
      "Epoch 196/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0863 - accuracy: 0.9709\n",
      "Epoch 196: val_loss improved from 0.10283 to 0.10228, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9712 - val_loss: 0.1023 - val_accuracy: 0.9762\n",
      "Epoch 197/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.0940 - accuracy: 0.9714\n",
      "Epoch 197: val_loss improved from 0.10228 to 0.10203, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9712 - val_loss: 0.1020 - val_accuracy: 0.9762\n",
      "Epoch 198/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1026 - accuracy: 0.9667\n",
      "Epoch 198: val_loss did not improve from 0.10203\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9712 - val_loss: 0.1020 - val_accuracy: 0.9762\n",
      "Epoch 199/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1004 - accuracy: 0.9633\n",
      "Epoch 199: val_loss did not improve from 0.10203\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9649 - val_loss: 0.1022 - val_accuracy: 0.9762\n",
      "Epoch 200/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0864 - accuracy: 0.9698\n",
      "Epoch 200: val_loss did not improve from 0.10203\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9712 - val_loss: 0.1026 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 32)                11520     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,553\n",
      "Trainable params: 11,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9762\n",
      "Test Loss: 0.1026051715016365\n",
      "Test Accuracy: 0.976190447807312\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'GRU_1 layer with dropout_Adam.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, \n",
    "                     dropout=0.3,\n",
    "                     recurrent_dropout=0.3,\n",
    "                     input_shape=(None, x_train.shape[-1])))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)  \n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=200, validation_data=(x_val, y_val), callbacks=[callbacks_list])\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 layer with dropout RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.7912 - accuracy: 0.4230\n",
      "Epoch 1: val_loss improved from inf to 0.73954, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 4s 11ms/step - loss: 0.7933 - accuracy: 0.4217 - val_loss: 0.7395 - val_accuracy: 0.4940\n",
      "Epoch 2/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.7521 - accuracy: 0.4912\n",
      "Epoch 2: val_loss improved from 0.73954 to 0.68323, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7504 - accuracy: 0.4952 - val_loss: 0.6832 - val_accuracy: 0.6131\n",
      "Epoch 3/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.7239 - accuracy: 0.5796\n",
      "Epoch 3: val_loss improved from 0.68323 to 0.63364, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7106 - accuracy: 0.5847 - val_loss: 0.6336 - val_accuracy: 0.7202\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.6422\n",
      "Epoch 4: val_loss improved from 0.63364 to 0.58684, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.6422 - val_loss: 0.5868 - val_accuracy: 0.7500\n",
      "Epoch 5/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.6563 - accuracy: 0.6852\n",
      "Epoch 5: val_loss improved from 0.58684 to 0.54777, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.6933 - val_loss: 0.5478 - val_accuracy: 0.7738\n",
      "Epoch 6/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.6071 - accuracy: 0.6714\n",
      "Epoch 6: val_loss improved from 0.54777 to 0.51259, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6055 - accuracy: 0.6709 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
      "Epoch 7/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.5495 - accuracy: 0.7585\n",
      "Epoch 7: val_loss improved from 0.51259 to 0.48109, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7636 - val_loss: 0.4811 - val_accuracy: 0.8214\n",
      "Epoch 8/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.5379 - accuracy: 0.7615\n",
      "Epoch 8: val_loss improved from 0.48109 to 0.45189, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7636 - val_loss: 0.4519 - val_accuracy: 0.8393\n",
      "Epoch 9/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.5208 - accuracy: 0.7614\n",
      "Epoch 9: val_loss improved from 0.45189 to 0.42472, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.7700 - val_loss: 0.4247 - val_accuracy: 0.8571\n",
      "Epoch 10/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.5008 - accuracy: 0.7544\n",
      "Epoch 10: val_loss improved from 0.42472 to 0.40126, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7700 - val_loss: 0.4013 - val_accuracy: 0.8750\n",
      "Epoch 11/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.4899 - accuracy: 0.7889\n",
      "Epoch 11: val_loss improved from 0.40126 to 0.37958, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.8019 - val_loss: 0.3796 - val_accuracy: 0.8869\n",
      "Epoch 12/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.4609 - accuracy: 0.8000\n",
      "Epoch 12: val_loss improved from 0.37958 to 0.36030, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.8051 - val_loss: 0.3603 - val_accuracy: 0.8929\n",
      "Epoch 13/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.4337 - accuracy: 0.8296\n",
      "Epoch 13: val_loss improved from 0.36030 to 0.34379, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.8307 - val_loss: 0.3438 - val_accuracy: 0.9048\n",
      "Epoch 14/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.4410 - accuracy: 0.7927\n",
      "Epoch 14: val_loss improved from 0.34379 to 0.32849, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8115 - val_loss: 0.3285 - val_accuracy: 0.9107\n",
      "Epoch 15/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3936 - accuracy: 0.8519\n",
      "Epoch 15: val_loss improved from 0.32849 to 0.31498, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8466 - val_loss: 0.3150 - val_accuracy: 0.9226\n",
      "Epoch 16/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3859 - accuracy: 0.8691\n",
      "Epoch 16: val_loss improved from 0.31498 to 0.30159, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8754 - val_loss: 0.3016 - val_accuracy: 0.9345\n",
      "Epoch 17/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3777 - accuracy: 0.8500\n",
      "Epoch 17: val_loss improved from 0.30159 to 0.28977, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8466 - val_loss: 0.2898 - val_accuracy: 0.9405\n",
      "Epoch 18/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3591 - accuracy: 0.8830\n",
      "Epoch 18: val_loss improved from 0.28977 to 0.27879, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8786 - val_loss: 0.2788 - val_accuracy: 0.9345\n",
      "Epoch 19/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3404 - accuracy: 0.9000\n",
      "Epoch 19: val_loss improved from 0.27879 to 0.26845, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.9042 - val_loss: 0.2684 - val_accuracy: 0.9405\n",
      "Epoch 20/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.3211 - accuracy: 0.9038\n",
      "Epoch 20: val_loss improved from 0.26845 to 0.25930, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.9010 - val_loss: 0.2593 - val_accuracy: 0.9405\n",
      "Epoch 21/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.3336 - accuracy: 0.8745\n",
      "Epoch 21: val_loss improved from 0.25930 to 0.25159, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8754 - val_loss: 0.2516 - val_accuracy: 0.9464\n",
      "Epoch 22/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.3308 - accuracy: 0.8746\n",
      "Epoch 22: val_loss improved from 0.25159 to 0.24451, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3246 - accuracy: 0.8818 - val_loss: 0.2445 - val_accuracy: 0.9464\n",
      "Epoch 23/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3084 - accuracy: 0.8982\n",
      "Epoch 23: val_loss improved from 0.24451 to 0.23763, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3072 - accuracy: 0.9010 - val_loss: 0.2376 - val_accuracy: 0.9464\n",
      "Epoch 24/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2943 - accuracy: 0.8926\n",
      "Epoch 24: val_loss improved from 0.23763 to 0.23089, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.8914 - val_loss: 0.2309 - val_accuracy: 0.9405\n",
      "Epoch 25/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.3109 - accuracy: 0.8840\n",
      "Epoch 25: val_loss improved from 0.23089 to 0.22508, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8818 - val_loss: 0.2251 - val_accuracy: 0.9405\n",
      "Epoch 26/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3049 - accuracy: 0.8964\n",
      "Epoch 26: val_loss improved from 0.22508 to 0.21959, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2973 - accuracy: 0.8978 - val_loss: 0.2196 - val_accuracy: 0.9405\n",
      "Epoch 27/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2824 - accuracy: 0.8964\n",
      "Epoch 27: val_loss improved from 0.21959 to 0.21462, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.8946 - val_loss: 0.2146 - val_accuracy: 0.9405\n",
      "Epoch 28/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3228 - accuracy: 0.8679\n",
      "Epoch 28: val_loss improved from 0.21462 to 0.21060, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8722 - val_loss: 0.2106 - val_accuracy: 0.9405\n",
      "Epoch 29/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2811 - accuracy: 0.8923\n",
      "Epoch 29: val_loss improved from 0.21060 to 0.20635, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.8882 - val_loss: 0.2064 - val_accuracy: 0.9464\n",
      "Epoch 30/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2990 - accuracy: 0.8846\n",
      "Epoch 30: val_loss improved from 0.20635 to 0.20246, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.8850 - val_loss: 0.2025 - val_accuracy: 0.9524\n",
      "Epoch 31/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2778 - accuracy: 0.9036\n",
      "Epoch 31: val_loss improved from 0.20246 to 0.19834, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.9042 - val_loss: 0.1983 - val_accuracy: 0.9524\n",
      "Epoch 32/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2706 - accuracy: 0.9000\n",
      "Epoch 32: val_loss improved from 0.19834 to 0.19515, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2692 - accuracy: 0.9010 - val_loss: 0.1951 - val_accuracy: 0.9524\n",
      "Epoch 33/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2769 - accuracy: 0.9057\n",
      "Epoch 33: val_loss improved from 0.19515 to 0.19197, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.9042 - val_loss: 0.1920 - val_accuracy: 0.9524\n",
      "Epoch 34/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2781 - accuracy: 0.8877\n",
      "Epoch 34: val_loss improved from 0.19197 to 0.18841, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2756 - accuracy: 0.8882 - val_loss: 0.1884 - val_accuracy: 0.9524\n",
      "Epoch 35/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2586 - accuracy: 0.9018\n",
      "Epoch 35: val_loss improved from 0.18841 to 0.18543, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.8978 - val_loss: 0.1854 - val_accuracy: 0.9524\n",
      "Epoch 36/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2685 - accuracy: 0.8926\n",
      "Epoch 36: val_loss improved from 0.18543 to 0.18277, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8978 - val_loss: 0.1828 - val_accuracy: 0.9524\n",
      "Epoch 37/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2789 - accuracy: 0.8967\n",
      "Epoch 37: val_loss improved from 0.18277 to 0.18029, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8946 - val_loss: 0.1803 - val_accuracy: 0.9524\n",
      "Epoch 38/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2645 - accuracy: 0.9091\n",
      "Epoch 38: val_loss improved from 0.18029 to 0.17768, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2656 - accuracy: 0.9073 - val_loss: 0.1777 - val_accuracy: 0.9524\n",
      "Epoch 39/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2438 - accuracy: 0.9185\n",
      "Epoch 39: val_loss improved from 0.17768 to 0.17553, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9169 - val_loss: 0.1755 - val_accuracy: 0.9524\n",
      "Epoch 40/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2341 - accuracy: 0.9267\n",
      "Epoch 40: val_loss improved from 0.17553 to 0.17288, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2287 - accuracy: 0.9297 - val_loss: 0.1729 - val_accuracy: 0.9524\n",
      "Epoch 41/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2530 - accuracy: 0.9033\n",
      "Epoch 41: val_loss improved from 0.17288 to 0.17041, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.9073 - val_loss: 0.1704 - val_accuracy: 0.9524\n",
      "Epoch 42/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2328 - accuracy: 0.9138\n",
      "Epoch 42: val_loss improved from 0.17041 to 0.16851, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2256 - accuracy: 0.9169 - val_loss: 0.1685 - val_accuracy: 0.9524\n",
      "Epoch 43/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2442 - accuracy: 0.9085\n",
      "Epoch 43: val_loss improved from 0.16851 to 0.16637, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2388 - accuracy: 0.9137 - val_loss: 0.1664 - val_accuracy: 0.9524\n",
      "Epoch 44/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2268 - accuracy: 0.9167\n",
      "Epoch 44: val_loss improved from 0.16637 to 0.16439, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.9169 - val_loss: 0.1644 - val_accuracy: 0.9524\n",
      "Epoch 45/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2308 - accuracy: 0.9220\n",
      "Epoch 45: val_loss improved from 0.16439 to 0.16258, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9233 - val_loss: 0.1626 - val_accuracy: 0.9524\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9233\n",
      "Epoch 46: val_loss improved from 0.16258 to 0.16111, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2336 - accuracy: 0.9233 - val_loss: 0.1611 - val_accuracy: 0.9524\n",
      "Epoch 47/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2271 - accuracy: 0.9267\n",
      "Epoch 47: val_loss improved from 0.16111 to 0.15928, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9297 - val_loss: 0.1593 - val_accuracy: 0.9524\n",
      "Epoch 48/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9246\n",
      "Epoch 48: val_loss improved from 0.15928 to 0.15742, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2204 - accuracy: 0.9233 - val_loss: 0.1574 - val_accuracy: 0.9524\n",
      "Epoch 49/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9279\n",
      "Epoch 49: val_loss improved from 0.15742 to 0.15609, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2186 - accuracy: 0.9265 - val_loss: 0.1561 - val_accuracy: 0.9524\n",
      "Epoch 50/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2292 - accuracy: 0.9143\n",
      "Epoch 50: val_loss improved from 0.15609 to 0.15467, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2227 - accuracy: 0.9201 - val_loss: 0.1547 - val_accuracy: 0.9583\n",
      "Epoch 51/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2159 - accuracy: 0.9347\n",
      "Epoch 51: val_loss improved from 0.15467 to 0.15343, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2304 - accuracy: 0.9265 - val_loss: 0.1534 - val_accuracy: 0.9583\n",
      "Epoch 52/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2113 - accuracy: 0.9193\n",
      "Epoch 52: val_loss improved from 0.15343 to 0.15220, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2102 - accuracy: 0.9169 - val_loss: 0.1522 - val_accuracy: 0.9583\n",
      "Epoch 53/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2269 - accuracy: 0.9071\n",
      "Epoch 53: val_loss improved from 0.15220 to 0.15108, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2169 - accuracy: 0.9169 - val_loss: 0.1511 - val_accuracy: 0.9583\n",
      "Epoch 54/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2336 - accuracy: 0.9137\n",
      "Epoch 54: val_loss improved from 0.15108 to 0.14962, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.9233 - val_loss: 0.1496 - val_accuracy: 0.9583\n",
      "Epoch 55/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2251 - accuracy: 0.9255\n",
      "Epoch 55: val_loss improved from 0.14962 to 0.14841, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.9233 - val_loss: 0.1484 - val_accuracy: 0.9583\n",
      "Epoch 56/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2283 - accuracy: 0.9193\n",
      "Epoch 56: val_loss improved from 0.14841 to 0.14739, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2291 - accuracy: 0.9169 - val_loss: 0.1474 - val_accuracy: 0.9583\n",
      "Epoch 57/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1958 - accuracy: 0.9288\n",
      "Epoch 57: val_loss improved from 0.14739 to 0.14585, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9265 - val_loss: 0.1458 - val_accuracy: 0.9583\n",
      "Epoch 58/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2049 - accuracy: 0.9241\n",
      "Epoch 58: val_loss improved from 0.14585 to 0.14473, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9201 - val_loss: 0.1447 - val_accuracy: 0.9583\n",
      "Epoch 59/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2131 - accuracy: 0.9194\n",
      "Epoch 59: val_loss improved from 0.14473 to 0.14392, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9201 - val_loss: 0.1439 - val_accuracy: 0.9583\n",
      "Epoch 60/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.9148\n",
      "Epoch 60: val_loss improved from 0.14392 to 0.14298, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.9169 - val_loss: 0.1430 - val_accuracy: 0.9583\n",
      "Epoch 61/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1864 - accuracy: 0.9358\n",
      "Epoch 61: val_loss improved from 0.14298 to 0.14190, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9329 - val_loss: 0.1419 - val_accuracy: 0.9583\n",
      "Epoch 62/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2070 - accuracy: 0.9276\n",
      "Epoch 62: val_loss improved from 0.14190 to 0.14077, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.9297 - val_loss: 0.1408 - val_accuracy: 0.9583\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.9329\n",
      "Epoch 63: val_loss improved from 0.14077 to 0.13964, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9329 - val_loss: 0.1396 - val_accuracy: 0.9583\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9201\n",
      "Epoch 64: val_loss improved from 0.13964 to 0.13844, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.9201 - val_loss: 0.1384 - val_accuracy: 0.9583\n",
      "Epoch 65/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1855 - accuracy: 0.9346\n",
      "Epoch 65: val_loss improved from 0.13844 to 0.13756, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1880 - accuracy: 0.9297 - val_loss: 0.1376 - val_accuracy: 0.9583\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.9265\n",
      "Epoch 66: val_loss improved from 0.13756 to 0.13681, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.9265 - val_loss: 0.1368 - val_accuracy: 0.9583\n",
      "Epoch 67/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2086 - accuracy: 0.9311\n",
      "Epoch 67: val_loss improved from 0.13681 to 0.13611, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2067 - accuracy: 0.9329 - val_loss: 0.1361 - val_accuracy: 0.9583\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.9233\n",
      "Epoch 68: val_loss improved from 0.13611 to 0.13529, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9233 - val_loss: 0.1353 - val_accuracy: 0.9583\n",
      "Epoch 69/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1834 - accuracy: 0.9458\n",
      "Epoch 69: val_loss improved from 0.13529 to 0.13428, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1676 - accuracy: 0.9489 - val_loss: 0.1343 - val_accuracy: 0.9583\n",
      "Epoch 70/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1876 - accuracy: 0.9267\n",
      "Epoch 70: val_loss improved from 0.13428 to 0.13335, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1838 - accuracy: 0.9297 - val_loss: 0.1334 - val_accuracy: 0.9583\n",
      "Epoch 71/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1725 - accuracy: 0.9434\n",
      "Epoch 71: val_loss improved from 0.13335 to 0.13237, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1902 - accuracy: 0.9361 - val_loss: 0.1324 - val_accuracy: 0.9583\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.9361\n",
      "Epoch 72: val_loss improved from 0.13237 to 0.13172, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1843 - accuracy: 0.9361 - val_loss: 0.1317 - val_accuracy: 0.9583\n",
      "Epoch 73/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1797 - accuracy: 0.9346\n",
      "Epoch 73: val_loss improved from 0.13172 to 0.13095, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9393 - val_loss: 0.1309 - val_accuracy: 0.9583\n",
      "Epoch 74/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.2162 - accuracy: 0.9043\n",
      "Epoch 74: val_loss improved from 0.13095 to 0.13039, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2110 - accuracy: 0.9105 - val_loss: 0.1304 - val_accuracy: 0.9583\n",
      "Epoch 75/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1577 - accuracy: 0.9492\n",
      "Epoch 75: val_loss improved from 0.13039 to 0.12921, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.9489 - val_loss: 0.1292 - val_accuracy: 0.9643\n",
      "Epoch 76/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1574 - accuracy: 0.9346\n",
      "Epoch 76: val_loss improved from 0.12921 to 0.12833, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9329 - val_loss: 0.1283 - val_accuracy: 0.9643\n",
      "Epoch 77/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1769 - accuracy: 0.9333\n",
      "Epoch 77: val_loss improved from 0.12833 to 0.12732, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1810 - accuracy: 0.9361 - val_loss: 0.1273 - val_accuracy: 0.9643\n",
      "Epoch 78/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1450 - accuracy: 0.9500\n",
      "Epoch 78: val_loss improved from 0.12732 to 0.12681, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9425 - val_loss: 0.1268 - val_accuracy: 0.9643\n",
      "Epoch 79/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.9368\n",
      "Epoch 79: val_loss improved from 0.12681 to 0.12613, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1795 - accuracy: 0.9393 - val_loss: 0.1261 - val_accuracy: 0.9643\n",
      "Epoch 80/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1924 - accuracy: 0.9233\n",
      "Epoch 80: val_loss improved from 0.12613 to 0.12574, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.9265 - val_loss: 0.1257 - val_accuracy: 0.9643\n",
      "Epoch 81/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1806 - accuracy: 0.9418\n",
      "Epoch 81: val_loss improved from 0.12574 to 0.12511, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9489 - val_loss: 0.1251 - val_accuracy: 0.9643\n",
      "Epoch 82/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9419\n",
      "Epoch 82: val_loss improved from 0.12511 to 0.12430, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1691 - accuracy: 0.9425 - val_loss: 0.1243 - val_accuracy: 0.9643\n",
      "Epoch 83/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1710 - accuracy: 0.9483\n",
      "Epoch 83: val_loss improved from 0.12430 to 0.12367, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9521 - val_loss: 0.1237 - val_accuracy: 0.9643\n",
      "Epoch 84/200\n",
      "45/63 [====================>.........] - ETA: 0s - loss: 0.1641 - accuracy: 0.9422\n",
      "Epoch 84: val_loss improved from 0.12367 to 0.12306, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9297 - val_loss: 0.1231 - val_accuracy: 0.9643\n",
      "Epoch 85/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9452\n",
      "Epoch 85: val_loss improved from 0.12306 to 0.12262, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.9457 - val_loss: 0.1226 - val_accuracy: 0.9643\n",
      "Epoch 86/200\n",
      "44/63 [===================>..........] - ETA: 0s - loss: 0.1847 - accuracy: 0.9318\n",
      "Epoch 86: val_loss improved from 0.12262 to 0.12185, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9489 - val_loss: 0.1218 - val_accuracy: 0.9643\n",
      "Epoch 87/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.1615 - accuracy: 0.9404\n",
      "Epoch 87: val_loss improved from 0.12185 to 0.12134, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1500 - accuracy: 0.9489 - val_loss: 0.1213 - val_accuracy: 0.9643\n",
      "Epoch 88/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1925 - accuracy: 0.9259\n",
      "Epoch 88: val_loss improved from 0.12134 to 0.12084, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9329 - val_loss: 0.1208 - val_accuracy: 0.9643\n",
      "Epoch 89/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1471 - accuracy: 0.9356\n",
      "Epoch 89: val_loss improved from 0.12084 to 0.12025, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9329 - val_loss: 0.1202 - val_accuracy: 0.9643\n",
      "Epoch 90/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1563 - accuracy: 0.9483\n",
      "Epoch 90: val_loss improved from 0.12025 to 0.11977, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9457 - val_loss: 0.1198 - val_accuracy: 0.9643\n",
      "Epoch 91/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1500 - accuracy: 0.9615\n",
      "Epoch 91: val_loss improved from 0.11977 to 0.11950, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.9617 - val_loss: 0.1195 - val_accuracy: 0.9643\n",
      "Epoch 92/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1580 - accuracy: 0.9400\n",
      "Epoch 92: val_loss improved from 0.11950 to 0.11877, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 0.9457 - val_loss: 0.1188 - val_accuracy: 0.9643\n",
      "Epoch 93/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1553 - accuracy: 0.9538\n",
      "Epoch 93: val_loss improved from 0.11877 to 0.11807, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1502 - accuracy: 0.9489 - val_loss: 0.1181 - val_accuracy: 0.9643\n",
      "Epoch 94/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1575 - accuracy: 0.9552\n",
      "Epoch 94: val_loss improved from 0.11807 to 0.11758, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9585 - val_loss: 0.1176 - val_accuracy: 0.9643\n",
      "Epoch 95/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1499 - accuracy: 0.9472\n",
      "Epoch 95: val_loss improved from 0.11758 to 0.11693, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1383 - accuracy: 0.9553 - val_loss: 0.1169 - val_accuracy: 0.9643\n",
      "Epoch 96/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1525 - accuracy: 0.9433\n",
      "Epoch 96: val_loss improved from 0.11693 to 0.11653, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1471 - accuracy: 0.9457 - val_loss: 0.1165 - val_accuracy: 0.9643\n",
      "Epoch 97/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9323\n",
      "Epoch 97: val_loss improved from 0.11653 to 0.11618, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.9329 - val_loss: 0.1162 - val_accuracy: 0.9643\n",
      "Epoch 98/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1547 - accuracy: 0.9481\n",
      "Epoch 98: val_loss improved from 0.11618 to 0.11558, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9553 - val_loss: 0.1156 - val_accuracy: 0.9643\n",
      "Epoch 99/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1445 - accuracy: 0.9577\n",
      "Epoch 99: val_loss improved from 0.11558 to 0.11481, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9457 - val_loss: 0.1148 - val_accuracy: 0.9643\n",
      "Epoch 100/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1356 - accuracy: 0.9520\n",
      "Epoch 100: val_loss improved from 0.11481 to 0.11460, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1565 - accuracy: 0.9425 - val_loss: 0.1146 - val_accuracy: 0.9643\n",
      "Epoch 101/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1585 - accuracy: 0.9396\n",
      "Epoch 101: val_loss improved from 0.11460 to 0.11421, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1466 - accuracy: 0.9457 - val_loss: 0.1142 - val_accuracy: 0.9643\n",
      "Epoch 102/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1712 - accuracy: 0.9382\n",
      "Epoch 102: val_loss improved from 0.11421 to 0.11374, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1648 - accuracy: 0.9393 - val_loss: 0.1137 - val_accuracy: 0.9643\n",
      "Epoch 103/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1527 - accuracy: 0.9615\n",
      "Epoch 103: val_loss improved from 0.11374 to 0.11328, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9553 - val_loss: 0.1133 - val_accuracy: 0.9643\n",
      "Epoch 104/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1446 - accuracy: 0.9538\n",
      "Epoch 104: val_loss improved from 0.11328 to 0.11290, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1416 - accuracy: 0.9553 - val_loss: 0.1129 - val_accuracy: 0.9643\n",
      "Epoch 105/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1445 - accuracy: 0.9600\n",
      "Epoch 105: val_loss improved from 0.11290 to 0.11253, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1540 - accuracy: 0.9553 - val_loss: 0.1125 - val_accuracy: 0.9643\n",
      "Epoch 106/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1607 - accuracy: 0.9519\n",
      "Epoch 106: val_loss improved from 0.11253 to 0.11215, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1545 - accuracy: 0.9521 - val_loss: 0.1121 - val_accuracy: 0.9643\n",
      "Epoch 107/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1487 - accuracy: 0.9491\n",
      "Epoch 107: val_loss improved from 0.11215 to 0.11175, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1403 - accuracy: 0.9553 - val_loss: 0.1118 - val_accuracy: 0.9643\n",
      "Epoch 108/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1668 - accuracy: 0.9368\n",
      "Epoch 108: val_loss improved from 0.11175 to 0.11139, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.9393 - val_loss: 0.1114 - val_accuracy: 0.9643\n",
      "Epoch 109/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1328 - accuracy: 0.9500\n",
      "Epoch 109: val_loss improved from 0.11139 to 0.11094, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.9489 - val_loss: 0.1109 - val_accuracy: 0.9702\n",
      "Epoch 110/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1331 - accuracy: 0.9434\n",
      "Epoch 110: val_loss improved from 0.11094 to 0.11073, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1302 - accuracy: 0.9457 - val_loss: 0.1107 - val_accuracy: 0.9702\n",
      "Epoch 111/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1662 - accuracy: 0.9400\n",
      "Epoch 111: val_loss improved from 0.11073 to 0.11045, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9425 - val_loss: 0.1105 - val_accuracy: 0.9702\n",
      "Epoch 112/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1265 - accuracy: 0.9649\n",
      "Epoch 112: val_loss improved from 0.11045 to 0.10992, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9617 - val_loss: 0.1099 - val_accuracy: 0.9702\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9393\n",
      "Epoch 113: val_loss improved from 0.10992 to 0.10952, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9393 - val_loss: 0.1095 - val_accuracy: 0.9702\n",
      "Epoch 114/200\n",
      "44/63 [===================>..........] - ETA: 0s - loss: 0.1383 - accuracy: 0.9409\n",
      "Epoch 114: val_loss improved from 0.10952 to 0.10941, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9457 - val_loss: 0.1094 - val_accuracy: 0.9702\n",
      "Epoch 115/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1239 - accuracy: 0.9636\n",
      "Epoch 115: val_loss improved from 0.10941 to 0.10906, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9681 - val_loss: 0.1091 - val_accuracy: 0.9762\n",
      "Epoch 116/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9508\n",
      "Epoch 116: val_loss improved from 0.10906 to 0.10881, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9521 - val_loss: 0.1088 - val_accuracy: 0.9702\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9585\n",
      "Epoch 117: val_loss improved from 0.10881 to 0.10865, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9585 - val_loss: 0.1086 - val_accuracy: 0.9762\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9489\n",
      "Epoch 118: val_loss improved from 0.10865 to 0.10812, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9489 - val_loss: 0.1081 - val_accuracy: 0.9762\n",
      "Epoch 119/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1246 - accuracy: 0.9509\n",
      "Epoch 119: val_loss improved from 0.10812 to 0.10756, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1416 - accuracy: 0.9489 - val_loss: 0.1076 - val_accuracy: 0.9762\n",
      "Epoch 120/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9443\n",
      "Epoch 120: val_loss improved from 0.10756 to 0.10745, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9425 - val_loss: 0.1074 - val_accuracy: 0.9762\n",
      "Epoch 121/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1523 - accuracy: 0.9529\n",
      "Epoch 121: val_loss improved from 0.10745 to 0.10730, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9585 - val_loss: 0.1073 - val_accuracy: 0.9762\n",
      "Epoch 122/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1340 - accuracy: 0.9491\n",
      "Epoch 122: val_loss improved from 0.10730 to 0.10656, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.9489 - val_loss: 0.1066 - val_accuracy: 0.9762\n",
      "Epoch 123/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1311 - accuracy: 0.9600\n",
      "Epoch 123: val_loss improved from 0.10656 to 0.10650, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9617 - val_loss: 0.1065 - val_accuracy: 0.9762\n",
      "Epoch 124/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1290 - accuracy: 0.9552\n",
      "Epoch 124: val_loss improved from 0.10650 to 0.10629, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1382 - accuracy: 0.9521 - val_loss: 0.1063 - val_accuracy: 0.9762\n",
      "Epoch 125/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1348 - accuracy: 0.9520\n",
      "Epoch 125: val_loss improved from 0.10629 to 0.10608, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.1061 - val_accuracy: 0.9702\n",
      "Epoch 126/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9710\n",
      "Epoch 126: val_loss improved from 0.10608 to 0.10573, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.9712 - val_loss: 0.1057 - val_accuracy: 0.9702\n",
      "Epoch 127/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1390 - accuracy: 0.9490\n",
      "Epoch 127: val_loss improved from 0.10573 to 0.10524, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.9585 - val_loss: 0.1052 - val_accuracy: 0.9702\n",
      "Epoch 128/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1416 - accuracy: 0.9527\n",
      "Epoch 128: val_loss improved from 0.10524 to 0.10489, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9553 - val_loss: 0.1049 - val_accuracy: 0.9702\n",
      "Epoch 129/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1523 - accuracy: 0.9388\n",
      "Epoch 129: val_loss improved from 0.10489 to 0.10430, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9425 - val_loss: 0.1043 - val_accuracy: 0.9762\n",
      "Epoch 130/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1278 - accuracy: 0.9412\n",
      "Epoch 130: val_loss improved from 0.10430 to 0.10427, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1349 - accuracy: 0.9425 - val_loss: 0.1043 - val_accuracy: 0.9702\n",
      "Epoch 131/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1398 - accuracy: 0.9536\n",
      "Epoch 131: val_loss improved from 0.10427 to 0.10416, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1380 - accuracy: 0.9553 - val_loss: 0.1042 - val_accuracy: 0.9702\n",
      "Epoch 132/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1173 - accuracy: 0.9586\n",
      "Epoch 132: val_loss improved from 0.10416 to 0.10380, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1267 - accuracy: 0.9521 - val_loss: 0.1038 - val_accuracy: 0.9702\n",
      "Epoch 133/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1331 - accuracy: 0.9544\n",
      "Epoch 133: val_loss improved from 0.10380 to 0.10369, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9521 - val_loss: 0.1037 - val_accuracy: 0.9702\n",
      "Epoch 134/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1134 - accuracy: 0.9654\n",
      "Epoch 134: val_loss improved from 0.10369 to 0.10364, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9553 - val_loss: 0.1036 - val_accuracy: 0.9702\n",
      "Epoch 135/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1039 - accuracy: 0.9684\n",
      "Epoch 135: val_loss improved from 0.10364 to 0.10352, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9617 - val_loss: 0.1035 - val_accuracy: 0.9702\n",
      "Epoch 136/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1338 - accuracy: 0.9483\n",
      "Epoch 136: val_loss improved from 0.10352 to 0.10317, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.9457 - val_loss: 0.1032 - val_accuracy: 0.9702\n",
      "Epoch 137/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1252 - accuracy: 0.9455\n",
      "Epoch 137: val_loss improved from 0.10317 to 0.10248, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.9489 - val_loss: 0.1025 - val_accuracy: 0.9762\n",
      "Epoch 138/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1288 - accuracy: 0.9636\n",
      "Epoch 138: val_loss improved from 0.10248 to 0.10223, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9649 - val_loss: 0.1022 - val_accuracy: 0.9762\n",
      "Epoch 139/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.1294 - accuracy: 0.9574\n",
      "Epoch 139: val_loss improved from 0.10223 to 0.10222, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.9649 - val_loss: 0.1022 - val_accuracy: 0.9702\n",
      "Epoch 140/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0755 - accuracy: 0.9797\n",
      "Epoch 140: val_loss improved from 0.10222 to 0.10182, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9744 - val_loss: 0.1018 - val_accuracy: 0.9702\n",
      "Epoch 141/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1385 - accuracy: 0.9472\n",
      "Epoch 141: val_loss improved from 0.10182 to 0.10140, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9489 - val_loss: 0.1014 - val_accuracy: 0.9821\n",
      "Epoch 142/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1291 - accuracy: 0.9556\n",
      "Epoch 142: val_loss improved from 0.10140 to 0.10116, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9521 - val_loss: 0.1012 - val_accuracy: 0.9821\n",
      "Epoch 143/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9452\n",
      "Epoch 143: val_loss improved from 0.10116 to 0.10085, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9457 - val_loss: 0.1008 - val_accuracy: 0.9821\n",
      "Epoch 144/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1128 - accuracy: 0.9607\n",
      "Epoch 144: val_loss did not improve from 0.10085\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9585 - val_loss: 0.1009 - val_accuracy: 0.9762\n",
      "Epoch 145/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.1092 - accuracy: 0.9609\n",
      "Epoch 145: val_loss improved from 0.10085 to 0.10046, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9617 - val_loss: 0.1005 - val_accuracy: 0.9762\n",
      "Epoch 146/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1097 - accuracy: 0.9533\n",
      "Epoch 146: val_loss improved from 0.10046 to 0.10032, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9553 - val_loss: 0.1003 - val_accuracy: 0.9762\n",
      "Epoch 147/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9672\n",
      "Epoch 147: val_loss improved from 0.10032 to 0.10005, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9649 - val_loss: 0.1001 - val_accuracy: 0.9762\n",
      "Epoch 148/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1255 - accuracy: 0.9593\n",
      "Epoch 148: val_loss did not improve from 0.10005\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9649 - val_loss: 0.1001 - val_accuracy: 0.9762\n",
      "Epoch 149/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1148 - accuracy: 0.9698\n",
      "Epoch 149: val_loss improved from 0.10005 to 0.09980, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9712 - val_loss: 0.0998 - val_accuracy: 0.9821\n",
      "Epoch 150/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1523 - accuracy: 0.9492\n",
      "Epoch 150: val_loss improved from 0.09980 to 0.09976, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9489 - val_loss: 0.0998 - val_accuracy: 0.9821\n",
      "Epoch 151/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1364 - accuracy: 0.9491\n",
      "Epoch 151: val_loss did not improve from 0.09976\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.9553 - val_loss: 0.0998 - val_accuracy: 0.9762\n",
      "Epoch 152/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9639\n",
      "Epoch 152: val_loss did not improve from 0.09976\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9649 - val_loss: 0.1000 - val_accuracy: 0.9762\n",
      "Epoch 153/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1034 - accuracy: 0.9709\n",
      "Epoch 153: val_loss improved from 0.09976 to 0.09973, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.9712 - val_loss: 0.0997 - val_accuracy: 0.9762\n",
      "Epoch 154/200\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.1083 - accuracy: 0.9652\n",
      "Epoch 154: val_loss improved from 0.09973 to 0.09937, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9649 - val_loss: 0.0994 - val_accuracy: 0.9762\n",
      "Epoch 155/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1097 - accuracy: 0.9704\n",
      "Epoch 155: val_loss improved from 0.09937 to 0.09927, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1129 - accuracy: 0.9681 - val_loss: 0.0993 - val_accuracy: 0.9762\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9585\n",
      "Epoch 156: val_loss improved from 0.09927 to 0.09892, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9585 - val_loss: 0.0989 - val_accuracy: 0.9762\n",
      "Epoch 157/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1166 - accuracy: 0.9667\n",
      "Epoch 157: val_loss improved from 0.09892 to 0.09885, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1147 - accuracy: 0.9681 - val_loss: 0.0989 - val_accuracy: 0.9762\n",
      "Epoch 158/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9581\n",
      "Epoch 158: val_loss improved from 0.09885 to 0.09879, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1214 - accuracy: 0.9585 - val_loss: 0.0988 - val_accuracy: 0.9762\n",
      "Epoch 159/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.9593\n",
      "Epoch 159: val_loss did not improve from 0.09879\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1182 - accuracy: 0.9521 - val_loss: 0.0990 - val_accuracy: 0.9762\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9649\n",
      "Epoch 160: val_loss did not improve from 0.09879\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1276 - accuracy: 0.9649 - val_loss: 0.0990 - val_accuracy: 0.9762\n",
      "Epoch 161/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1285 - accuracy: 0.9556\n",
      "Epoch 161: val_loss did not improve from 0.09879\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9585 - val_loss: 0.0990 - val_accuracy: 0.9762\n",
      "Epoch 162/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0984 - accuracy: 0.9655\n",
      "Epoch 162: val_loss improved from 0.09879 to 0.09875, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9649 - val_loss: 0.0987 - val_accuracy: 0.9762\n",
      "Epoch 163/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1148 - accuracy: 0.9714\n",
      "Epoch 163: val_loss improved from 0.09875 to 0.09862, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.9712 - val_loss: 0.0986 - val_accuracy: 0.9762\n",
      "Epoch 164/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1270 - accuracy: 0.9608\n",
      "Epoch 164: val_loss improved from 0.09862 to 0.09830, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9649 - val_loss: 0.0983 - val_accuracy: 0.9762\n",
      "Epoch 165/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1072 - accuracy: 0.9729\n",
      "Epoch 165: val_loss improved from 0.09830 to 0.09782, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.9712 - val_loss: 0.0978 - val_accuracy: 0.9762\n",
      "Epoch 166/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1145 - accuracy: 0.9608\n",
      "Epoch 166: val_loss did not improve from 0.09782\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1040 - accuracy: 0.9681 - val_loss: 0.0979 - val_accuracy: 0.9762\n",
      "Epoch 167/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9516\n",
      "Epoch 167: val_loss improved from 0.09782 to 0.09778, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1211 - accuracy: 0.9521 - val_loss: 0.0978 - val_accuracy: 0.9762\n",
      "Epoch 168/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1102 - accuracy: 0.9661\n",
      "Epoch 168: val_loss improved from 0.09778 to 0.09778, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9681 - val_loss: 0.0978 - val_accuracy: 0.9762\n",
      "Epoch 169/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0795 - accuracy: 0.9725\n",
      "Epoch 169: val_loss improved from 0.09778 to 0.09763, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9649 - val_loss: 0.0976 - val_accuracy: 0.9762\n",
      "Epoch 170/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1048 - accuracy: 0.9708\n",
      "Epoch 170: val_loss did not improve from 0.09763\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9744 - val_loss: 0.0977 - val_accuracy: 0.9762\n",
      "Epoch 171/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1052 - accuracy: 0.9673\n",
      "Epoch 171: val_loss improved from 0.09763 to 0.09724, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9617 - val_loss: 0.0972 - val_accuracy: 0.9762\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9617\n",
      "Epoch 172: val_loss improved from 0.09724 to 0.09692, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9617 - val_loss: 0.0969 - val_accuracy: 0.9762\n",
      "Epoch 173/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9742\n",
      "Epoch 173: val_loss improved from 0.09692 to 0.09679, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0927 - accuracy: 0.9744 - val_loss: 0.0968 - val_accuracy: 0.9762\n",
      "Epoch 174/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1109 - accuracy: 0.9569\n",
      "Epoch 174: val_loss improved from 0.09679 to 0.09661, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.9585 - val_loss: 0.0966 - val_accuracy: 0.9762\n",
      "Epoch 175/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1095 - accuracy: 0.9519\n",
      "Epoch 175: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9553 - val_loss: 0.0969 - val_accuracy: 0.9762\n",
      "Epoch 176/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1274 - accuracy: 0.9633\n",
      "Epoch 176: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9617 - val_loss: 0.0970 - val_accuracy: 0.9762\n",
      "Epoch 177/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1082 - accuracy: 0.9564\n",
      "Epoch 177: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9617 - val_loss: 0.0971 - val_accuracy: 0.9762\n",
      "Epoch 178/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0911 - accuracy: 0.9607\n",
      "Epoch 178: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0880 - accuracy: 0.9649 - val_loss: 0.0970 - val_accuracy: 0.9762\n",
      "Epoch 179/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.9581\n",
      "Epoch 179: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0920 - accuracy: 0.9585 - val_loss: 0.0968 - val_accuracy: 0.9762\n",
      "Epoch 180/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0839 - accuracy: 0.9782\n",
      "Epoch 180: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9808 - val_loss: 0.0973 - val_accuracy: 0.9762\n",
      "Epoch 181/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0932 - accuracy: 0.9607\n",
      "Epoch 181: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9649 - val_loss: 0.0971 - val_accuracy: 0.9762\n",
      "Epoch 182/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0899 - accuracy: 0.9793\n",
      "Epoch 182: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9776 - val_loss: 0.0970 - val_accuracy: 0.9762\n",
      "Epoch 183/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1028 - accuracy: 0.9636\n",
      "Epoch 183: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9681 - val_loss: 0.0968 - val_accuracy: 0.9762\n",
      "Epoch 184/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0969 - accuracy: 0.9686\n",
      "Epoch 184: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9712 - val_loss: 0.0968 - val_accuracy: 0.9762\n",
      "Epoch 185/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.0963 - accuracy: 0.9640\n",
      "Epoch 185: val_loss did not improve from 0.09661\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9649 - val_loss: 0.0968 - val_accuracy: 0.9762\n",
      "Epoch 186/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9508\n",
      "Epoch 186: val_loss improved from 0.09661 to 0.09640, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9521 - val_loss: 0.0964 - val_accuracy: 0.9762\n",
      "Epoch 187/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9705\n",
      "Epoch 187: val_loss did not improve from 0.09640\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.9712 - val_loss: 0.0964 - val_accuracy: 0.9762\n",
      "Epoch 188/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1223 - accuracy: 0.9593\n",
      "Epoch 188: val_loss did not improve from 0.09640\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9585 - val_loss: 0.0965 - val_accuracy: 0.9762\n",
      "Epoch 189/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9639\n",
      "Epoch 189: val_loss did not improve from 0.09640\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9617 - val_loss: 0.0966 - val_accuracy: 0.9762\n",
      "Epoch 190/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1044 - accuracy: 0.9661\n",
      "Epoch 190: val_loss did not improve from 0.09640\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9681 - val_loss: 0.0966 - val_accuracy: 0.9762\n",
      "Epoch 191/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9581\n",
      "Epoch 191: val_loss improved from 0.09640 to 0.09594, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.9585 - val_loss: 0.0959 - val_accuracy: 0.9762\n",
      "Epoch 192/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0850 - accuracy: 0.9714\n",
      "Epoch 192: val_loss did not improve from 0.09594\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9712 - val_loss: 0.0962 - val_accuracy: 0.9762\n",
      "Epoch 193/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1038 - accuracy: 0.9673\n",
      "Epoch 193: val_loss improved from 0.09594 to 0.09579, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.9712 - val_loss: 0.0958 - val_accuracy: 0.9762\n",
      "Epoch 194/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1051 - accuracy: 0.9615\n",
      "Epoch 194: val_loss did not improve from 0.09579\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.9617 - val_loss: 0.0959 - val_accuracy: 0.9762\n",
      "Epoch 195/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0853 - accuracy: 0.9736\n",
      "Epoch 195: val_loss improved from 0.09579 to 0.09564, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9712 - val_loss: 0.0956 - val_accuracy: 0.9762\n",
      "Epoch 196/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9613\n",
      "Epoch 196: val_loss improved from 0.09564 to 0.09558, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.9617 - val_loss: 0.0956 - val_accuracy: 0.9762\n",
      "Epoch 197/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0816 - accuracy: 0.9729\n",
      "Epoch 197: val_loss improved from 0.09558 to 0.09518, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9744 - val_loss: 0.0952 - val_accuracy: 0.9762\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9617\n",
      "Epoch 198: val_loss improved from 0.09518 to 0.09480, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9617 - val_loss: 0.0948 - val_accuracy: 0.9762\n",
      "Epoch 199/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1028 - accuracy: 0.9600\n",
      "Epoch 199: val_loss did not improve from 0.09480\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.9585 - val_loss: 0.0950 - val_accuracy: 0.9762\n",
      "Epoch 200/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0947 - accuracy: 0.9633\n",
      "Epoch 200: val_loss did not improve from 0.09480\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9617 - val_loss: 0.0948 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABLsElEQVR4nO3deXxU1fn48c8zk31fSUL2sO8BQlgUxB3csC4VpCpStVqXfuve2la+bW1t9devK1Vcq1WpdUFUXEFkVfZ9DSGBsIQsZN+T8/vjDiEJWQbInuf9es1rZu49c+8zd5Jnzpx77jlijEEppVTXZ+voAJRSSrUOTehKKdVNaEJXSqluQhO6Ukp1E5rQlVKqm9CErpRS3YQmdNUoEflCRG5p7bIdSUTSROSiNtiuEZG+jscvicjvnSl7BvuZKSJfn2mczWx3sohktPZ2Vftz6egAVOsRkaI6T72AcqDa8fwXxph3nN2WMWZqW5Tt7owxd7bGdkQkDtgPuBpjqhzbfgdw+jNUPY8m9G7EGONz4rGIpAG3GWO+bVhORFxOJAmlVPehTS49wImf1CLyiIgcBd4QkUAR+UxEskTkuONxVJ3XLBWR2xyPZ4nIChF52lF2v4hMPcOy8SKyTEQKReRbEXlRRP7dRNzOxPgnEVnp2N7XIhJSZ/1NIpIuIjki8lgzx2eciBwVEXudZT8RkS2Ox8kislpE8kTkiIi8ICJuTWzrTRH5c53nDzlec1hEZjcoe7mIbBSRAhE5KCJz6qxe5rjPE5EiERl/4tjWef0EEVkrIvmO+wnOHpvmiMggx+vzRGS7iFxVZ91lIrLDsc1DIvKgY3mI4/PJE5FcEVkuIppf2pke8J4jHAgCYoE7sD77NxzPY4BS4IVmXj8W2A2EAH8HXhMROYOy7wJrgGBgDnBTM/t0JsYbgVuBXoAbcCLBDAb+6dh+b8f+omiEMeYHoBi4oMF233U8rgZ+7Xg/44ELgV82EzeOGKY44rkY6Ac0bL8vBm4GAoDLgbtE5GrHukmO+wBjjI8xZnWDbQcBnwPPOd7bP4DPRSS4wXs45di0ELMr8CnwteN19wLviMgAR5HXsJrvfIGhwBLH8geADCAUCAN+C+i4Iu1ME3rPUQM8bowpN8aUGmNyjDEfGmNKjDGFwBPAec28Pt0Y84oxphr4FxCB9Y/rdFkRiQHGAH8wxlQYY1YAC5vaoZMxvmGM2WOMKQXeBxIdy68DPjPGLDPGlAO/dxyDprwHzAAQEV/gMscyjDHrjTE/GGOqjDFpwMuNxNGYnzri22aMKcb6Aqv7/pYaY7YaY2qMMVsc+3Nmu2B9Aew1xrztiOs9YBdwZZ0yTR2b5owDfIAnHZ/REuAzHMcGqAQGi4ifMea4MWZDneURQKwxptIYs9zoQFHtThN6z5FljCk78UREvETkZUeTRAHWT/yAus0ODRw98cAYU+J46HOaZXsDuXWWARxsKmAnYzxa53FJnZh61922I6HmNLUvrNr4NSLiDlwDbDDGpDvi6O9oTjjqiOMvWLX1ltSLAUhv8P7Gish3jialfOBOJ7d7YtvpDZalA5F1njd1bFqM2RhT98uv7navxfqySxeR70VkvGP5U0AK8LWIpIrIo869DdWaNKH3HA1rSw8AA4Cxxhg/Tv7Eb6oZpTUcAYJExKvOsuhmyp9NjEfqbtuxz+CmChtjdmAlrqnUb24Bq+lmF9DPEcdvzyQGrGajut7F+oUSbYzxB16qs92WareHsZqi6ooBDjkRV0vbjW7Q/l27XWPMWmPMNKzmmAVYNX+MMYXGmAeMMQlYvxLuF5ELzzIWdZo0ofdcvlht0nmO9tjH23qHjhrvOmCOiLg5andXNvOSs4nxA+AKETnXcQLzj7T89/4ucB/WF8d/G8RRABSJyEDgLidjeB+YJSKDHV8oDeP3xfrFUiYiyVhfJCdkYTURJTSx7UVAfxG5UURcROQGYDBW88jZ+BGrbf9hEXEVkclYn9F8x2c2U0T8jTGVWMekGkBErhCRvo5zJSeWVze6B9VmNKH3XM8AnkA28APwZTvtdybWicUc4M/Af7D6yzfmGc4wRmPMduBurCR9BDiOddKuOe8Bk4ElxpjsOssfxEq2hcArjpidieELx3tYgtUcsaRBkV8CfxSRQuAPOGq7jteWYJ0zWOnoOTKuwbZzgCuwfsXkAA8DVzSI+7QZYyqAq7B+qWQDc4GbjTG7HEVuAtIcTU93Aj9zLO8HfAsUAauBucaYpWcTizp9ouctVEcSkf8Au4wxbf4LQanuTmvoql2JyBgR6SMiNke3vmlYbbFKqbOkV4qq9hYOfIR1gjIDuMsYs7FjQ1Kqe9AmF6WU6ia0yUUppbqJDmtyCQkJMXFxcR21e6WU6pLWr1+fbYwJbWxdhyX0uLg41q1b11G7V0qpLklEGl4hXEubXJRSqpvQhK6UUt2EJnSllOomnGpDd1wA8ixgB141xjzZYL0/8G+sQXxcgKeNMW+0cqxKqbNUWVlJRkYGZWVlLRdWHcrDw4OoqChcXV2dfk2LCd0xVOmLWIP0ZwBrRWShY3S6E+4GdhhjrhSRUGC3iLzjGBdCKdVJZGRk4OvrS1xcHE3PT6I6mjGGnJwcMjIyiI+Pd/p1zjS5JAMpxphUR4Kej3W5dr39A76OkdZ8gFxA56xUqpMpKysjODhYk3knJyIEBwef9i8pZxJ6JPUH6c+g/iD6YE0LNghrLOWtwK8aDJB/Isg7RGSdiKzLyso6rUCVUq1Dk3nXcCafkzMJvbGtNhwv4FJgE9ZsJ4nACyLid8qLjJlnjEkyxiSFhjbaL75Fu44W8Pcvd5FfWnlGr1dKqe7KmYSeQf1ZV6KwauJ13Qp8ZCwpwH5gYOuEWN+BnBLmLt1HWnZxW2xeKdWGcnJySExMJDExkfDwcCIjI2ufV1Q0f8pt3bp13HfffS3uY8KECa0S69KlS7niiitaZVvtxZleLmuBfiISjzUN1XTqz6wCcABrJvTlIhKGNW1YamsGekJMsDV7WXpuCSOiA9piF0qpNhIcHMymTZsAmDNnDj4+Pjz44IO166uqqnBxaTwtJSUlkZSU1OI+Vq1a1SqxdkUt1tCNMVXAPcBXwE7gfWPMdhG5U0TudBT7EzBBRLYCi4FHznbmlKbEBFkJ/WBuSQsllVJdwaxZs7j//vs5//zzeeSRR1izZg0TJkxg5MiRTJgwgd27dwP1a8xz5sxh9uzZTJ48mYSEBJ577rna7fn4+NSWnzx5Mtdddx0DBw5k5syZnBhddtGiRQwcOJBzzz2X++67r8WaeG5uLldffTXDhw9n3LhxbNmyBYDvv/++9hfGyJEjKSws5MiRI0yaNInExESGDh3K8uXLW/2YNcWpfujGmEVYcxjWXfZSnceHgUtaN7TGebm5EOLjzoEcTehKnY3//XQ7Ow4XtOo2B/f24/Erh5z26/bs2cO3336L3W6noKCAZcuW4eLiwrfffstvf/tbPvzww1Nes2vXLr777jsKCwsZMGAAd9111yl9tjdu3Mj27dvp3bs355xzDitXriQpKYlf/OIXLFu2jPj4eGbMmNFifI8//jgjR45kwYIFLFmyhJtvvplNmzbx9NNP8+KLL3LOOedQVFSEh4cH8+bN49JLL+Wxxx6jurqakpL2y1VdcoKLmCBPDmgNXalu4/rrr8dutwOQn5/PLbfcwt69exERKisb7wBx+eWX4+7ujru7O7169SIzM5OoqKh6ZZKTk2uXJSYmkpaWho+PDwkJCbX9u2fMmMG8efOajW/FihW1XyoXXHABOTk55Ofnc84553D//fczc+ZMrrnmGqKiohgzZgyzZ8+msrKSq6++msTExLM5NKelSyb02GBv1uzP7egwlOrSzqQm3Va8vb1rH//+97/n/PPP5+OPPyYtLY3Jkyc3+hp3d/fax3a7naqqUy99aazMmUzq09hrRIRHH32Uyy+/nEWLFjFu3Di+/fZbJk2axLJly/j888+56aabeOihh7j55ptPe59nokuO5RId5MXh/FIqqk7p6q6U6uLy8/OJjLQudXnzzTdbffsDBw4kNTWVtLQ0AP7zn/+0+JpJkybxzjvvAFbbfEhICH5+fuzbt49hw4bxyCOPkJSUxK5du0hPT6dXr17cfvvt/PznP2fDhg2t/h6a0iVr6DFBXhgDh/JKiQ/xbvkFSqku4+GHH+aWW27hH//4BxdccEGrb9/T05O5c+cyZcoUQkJCSE5ObvE1c+bM4dZbb2X48OF4eXnxr3/9C4BnnnmG7777DrvdzuDBg5k6dSrz58/nqaeewtXVFR8fH956661Wfw9N6bA5RZOSksyZTnCxZn8uP315Nf+ancx5/c/sAiWleqKdO3cyaNCgjg6jwxUVFeHj44Mxhrvvvpt+/frx61//uqPDOkVjn5eIrDfGNNp/s0s2ucQ6+qIfyNGLi5RSp++VV14hMTGRIUOGkJ+fzy9+8YuODqlVdMkml1Afd9xdbNrTRSl1Rn796193yhr52eqSNXSbTYgO8tKErpRSdXTJhA7WidEDuaUdHYZSSnUaXTuh5xSfUZ9SpZTqjrpeQj/wA8yfyQDvEoorqskt1kmRlFIKumJCLz0Ouz6jj9txAG1HV6oLmTx5Ml999VW9Zc888wy//OUvm33NiS7Ol112GXl5eaeUmTNnDk8//XSz+16wYAE7dpycOfMPf/gD33777WlE37jONMxu10vovuEARLlagwppQleq65gxYwbz58+vt2z+/PlODZAF1iiJAQEBZ7Tvhgn9j3/8IxdddNEZbauz6noJ3cdK6CHkAeioi0p1Iddddx2fffYZ5eXlAKSlpXH48GHOPfdc7rrrLpKSkhgyZAiPP/54o6+Pi4sjO9samfuJJ55gwIABXHTRRbVD7ILVx3zMmDGMGDGCa6+9lpKSElatWsXChQt56KGHSExMZN++fcyaNYsPPvgAgMWLFzNy5EiGDRvG7Nmza+OLi4vj8ccfZ9SoUQwbNoxdu3Y1+/46epjdrtcP3TsUENxKMunlG6c1dKXO1BePwtGtrbvN8GEw9ckmVwcHB5OcnMyXX37JtGnTmD9/PjfccAMiwhNPPEFQUBDV1dVceOGFbNmyheHDhze6nfXr1zN//nw2btxIVVUVo0aNYvTo0QBcc8013H777QD87ne/47XXXuPee+/lqquu4oorruC6666rt62ysjJmzZrF4sWL6d+/PzfffDP//Oc/+Z//+R8AQkJC2LBhA3PnzuXpp5/m1VdfbfL9dfQwu12vhm53sZJ60VFH10VN6Ep1JXWbXeo2t7z//vuMGjWKkSNHsn379nrNIw0tX76cn/zkJ3h5eeHn58dVV11Vu27btm1MnDiRYcOG8c4777B9+/Zm49m9ezfx8fH0798fgFtuuYVly5bVrr/mmmsAGD16dO2AXk1ZsWIFN910E9D4MLvPPfcceXl5uLi4MGbMGN544w3mzJnD1q1b8fX1bXbbzuh6NXQA3zAozCQm2IvV+3I6OhqluqZmatJt6eqrr+b+++9nw4YNlJaWMmrUKPbv38/TTz/N2rVrCQwMZNasWZSVlTW7HZHG5q+3ZkBasGABI0aM4M0332Tp0qXNbqelrs8nhuBtaojelrbVnsPsdr0aOoBvRG0N/WhBGWWV1R0dkVLKST4+PkyePJnZs2fX1s4LCgrw9vbG39+fzMxMvvjii2a3MWnSJD7++GNKS0spLCzk008/rV1XWFhIREQElZWVtUPeAvj6+lJYWHjKtgYOHEhaWhopKSkAvP3225x33nln9N46epjdrllD9wmDI5trh9HNOF5K314+HR2VUspJM2bM4JprrqltehkxYgQjR45kyJAhJCQkcM455zT7+lGjRnHDDTeQmJhIbGwsEydOrF33pz/9ibFjxxIbG8uwYcNqk/j06dO5/fbbee6552pPhgJ4eHjwxhtvcP3111NVVcWYMWO48847T9mnMzp6mF2nhs8VkSnAs4AdeNUY82SD9Q8BMx1PXYBBQKgxpslphc5m+FyW/BmW/z823rKXn7z0I/NuGs0lQ8LPbFtK9SA6fG7X0urD54qIHXgRmAoMBmaIyOC6ZYwxTxljEo0xicBvgO+bS+ZnzScMTA39fa02tj2Zp/6MUkqpnsaZNvRkIMUYk2qMqQDmA9OaKT8DeK81gmuS4+Ii7/JsogI92XVUE7pSSjmT0COBg3WeZziWnUJEvIApwIdNrL9DRNaJyLqsrKzTjfUk3wjrviiTgeG+WkNX6jTogHZdw5l8Ts4k9Mb6BjW1pyuBlU01txhj5hljkowxSaGhZzF1nE+YdV94hP5hvqRmFeuE0Uo5wcPDg5ycHE3qnZwxhpycHDw8PE7rdc70cskAous8jwION1F2Om3d3AJ1EnomA8J9qaoxpGYXMTDcr813rVRXFhUVRUZGBmf1C1m1Cw8PD6Kiok7rNc4k9LVAPxGJBw5hJe0bGxYSEX/gPOBnpxXBmXBxA88gKDrKgIHW1VW7jxZqQleqBa6ursTHx3d0GKqNtJjQjTFVInIP8BVWt8XXjTHbReROx/qXHEV/AnxtjGmfmZt9I6DwKAkhPrjYhN16YlQp1cM5dWGRMWYRsKjBspcaPH8TeLO1AmuRX28oOISbi42EUG9N6EqpHq9rXvoP4B8J+RkA9O3lw76sog4OSCmlOlYXTuhRUJIDlaUkhPhw8Hip9nRRSvVoXTeh+znO/hYcJiHUm+oao0PpKqV6tK6b0P0dCT3/IAmh1sBcqdrsopTqwbpwQndcrJp/iPgQbwBSs9ung41SSnVGXTeh+51I6Bn4e7oS4uPG/ixN6EqpnqvrJnQXd/DuBQVWT5eEEB9Ss7XJRSnVc3XdhA6OrouHAEgI9SZVa+hKqR6sayd0v5N90RNCvckpriC/pLKDg1JKqY7RtRO6fzQUHAJjiA9x9HTRZhelVA/VxRN6JFQUQVk+CaGOni7a7KKU6qG6eEI/0Rc9g5ggL1xsojV0pVSP1bUTeu3VoodwtduICfLSGrpSqsfq2gm99uIia4a8+BBv9uvFRUqpHqprJ3SfMLC51Ou6uD+7mJoanV5LKdXzdO2EbrODrzUuOkBCqA/lVTUcyivt4MCUUqr9de2EDtaJ0RN90XVMF6VUD9YNEvrJi4viHV0X9+uoi0qpHsiphC4iU0Rkt4ikiMijTZSZLCKbRGS7iHzfumE2wy8SCg5DTQ2hPu74urtoDV0p1SO1OKeoiNiBF4GLgQxgrYgsNMbsqFMmAJgLTDHGHBCRXm0U76n8o6CmEoqPIb7hOqaLUqrHcqaGngykGGNSjTEVwHxgWoMyNwIfGWMOABhjjrVumM2ovbjIOjEaHeSlJ0WVUj2SMwk9EjhY53mGY1ld/YFAEVkqIutF5ObWCrBFfvX7oof4uJNdWN5uu1dKqc6ixSYXQBpZ1rCjtwswGrgQ8ARWi8gPxpg99TYkcgdwB0BMTMzpR9sY/5NXiwKE+rpTWF5FWWU1Hq721tmHUkp1Ac7U0DOA6DrPo4DDjZT50hhTbIzJBpYBIxpuyBgzzxiTZIxJCg0NPdOY6/MMBFev2iaXUB93ALK0lq6U6mGcSehrgX4iEi8ibsB0YGGDMp8AE0XERUS8gLHAztYNtQkijr7ojiYXXzcAsos0oSulepYWm1yMMVUicg/wFWAHXjfGbBeROx3rXzLG7BSRL4EtQA3wqjFmW1sGXo9/FOQdAKw2dIDsoop2271SSnUGzrShY4xZBCxqsOylBs+fAp5qvdBOQ1ACZKwHYwj11SYXpVTP1PWvFAUI6gPl+VCSS7D3iRq6JnSlVM/STRJ6gnWfm4qbiw1/T1dN6EqpHqfbJXSAEB83TehKqR6neyT0wFgQG+TuA6y+6NqGrpTqabpHQndxt3q61NbQ3bWXi1Kqx+keCR2sZpe6CV1r6EqpHqZbJvS6l/8rpVRP0b0SeulxKMnVy/+VUj1SN0rofaz73FS9/F8p1SN1n4Qe7EjoOSm1l/8f0xq6UqoH6T4JPSgBbC6QvYc+oT54utpZujuro6NSSql2030Sut0VAuMhew/e7i5MGRrOZ1sO64lRpVSP0X0SOkBIf8jeC8C1o6IoLKvi252ZHRyUUkq1j26W0PtBzj6ormJ8n2DC/Tz4cH1GR0ellFLtonsl9NABUFMJx9Ow24RrR0fy/Z4sMo6XdHRkSinV5rpXQg/pb91nW1OZzki25i19b82BjopIKaXaTfdK6MF9rfvs3QBEBXpxwcBe/GftQSqqajowMKWUanvdK6F7BoBPWO2JUYCfjYslu6hCT44qpbq97pXQwWp2ydpd+3Riv1B83F1YtS+7A4NSSqm251RCF5EpIrJbRFJE5NFG1k8WkXwR2eS4/aH1Q3VSr8FwbCfUWE0sdpswMiaAdWnHOywkpZRqDy0mdBGxAy8CU4HBwAwRGdxI0eXGmETH7Y+tHKfzwoZAZTEc31+7aHRsILszCykoq+ywsJRSqq05U0NPBlKMManGmApgPjCtbcM6C+FDrfvM7bWLkmKDMAY2HsjrmJiUUqodOJPQI4GDdZ5nOJY1NF5ENovIFyIypLENicgdIrJORNZlZbXROCuhg6zp6DK31S5KjAnAJrA+Lbdt9qmUUp2AMwldGllmGjzfAMQaY0YAzwMLGtuQMWaeMSbJGJMUGhp6WoE6zc3LGkr36MmE7uPuwqAIP9alazu6Uqr7ciahZwDRdZ5HAYfrFjDGFBhjihyPFwGuIhLSalGervCh9WroAGPigliffpzjxTrXqFKqe3Imoa8F+olIvIi4AdOBhXULiEi4iIjjcbJjuzmtHazTwoZCXjqUFdQumpEcQ3lVDe/qVaNKqW6qxYRujKkC7gG+AnYC7xtjtovInSJyp6PYdcA2EdkMPAdMN8Y0bJZpP2GnnhgdEO7LxH4hvLkqjfIqHVJXKdX9ONUP3RizyBjT3xjTxxjzhGPZS8aYlxyPXzDGDDHGjDDGjDPGrGrLoFtU29OlfrPL7RMTyCos54utRzsgKKWUalvd70pRAL9I8Ag4JaFP7BdCiI8by/fqVaNKqe6neyZ0EQgfVq+ni7VYGBUTyPp07b6olOp+umdCB+uK0WM7aocAOGF0bCBpOSVkF+kE0kqp7qUbJ/ShUFlSbwgAgKS4QADWa590pVQ3030T+okTo0e31ls8pLc/bnYbGzShK6W6me6b0EMHOoYA2F5vsYernWFR/nrVqFKq2+m+Cd3VE4L7ndLTBSApNpCtGfnkl+roi0qp7qP7JnSwml0aNLkAXDG8NxXVNXyy6VAHBKWUUm2jeyf0iETIPwjF9fudD4vyZ2ikH+/+eICOvKBVKaVaU/dO6L1HWveHN56yavqYGHYdLWRzRn47B6WUUm2jeyf0iBGANJrQpyX2xtPVznwdrEsp1U1074Tu4Qch/RpN6L4erlwxPIKFmw9TVF7VAcEppVTr6t4JHaxml0YSOsD05BhKKqr5dPPhRtcrpVRX0jMSeuERKDhyyqpRMQEMCPPVZhelVLfQMxI6NFpLFxGuGx3F5ox8juSXtnNgSinVurp/Qg8fDjYXyFjT6Oox8UEAbDqQ145BKaVU6+v+Cd3Ny+qPfuCHRlcPivDFzW5j08G8dg1LKaVaW/dP6ACx4+HQeqgsO2WVu4udwb392KgJXSnVxfWMhB4zHqormuztkhgdwNaMfKqqaxpdr5RSXYFTCV1EpojIbhFJEZFHmyk3RkSqReS61guxFUSPs+4PrG50dWJ0AKWV1ezJLGrHoJRSqnW1mNBFxA68CEwFBgMzRGRwE+X+BnzV2kGeNe9gCBnQbEIHtB1dKdWlOVNDTwZSjDGpxpgKYD4wrZFy9wIfAsdaMb7WEzMODvwINdWnrIoN9iLQy5VNB3WMdKVU1+VMQo8EDtZ5nuFYVktEIoGfAC81tyERuUNE1onIuqysrNON9ezETYTyfDi6pbG4GBEdoDV0pVSX5kxCl0aWNRxz9hngEWPMqdXfui8yZp4xJskYkxQaGupkiK0kfqJ1v39Zo6sTowPYe6yIwjKd9EIp1TU5k9AzgOg6z6OAhoOfJAHzRSQNuA6YKyJXt0aArcY3HEL6w/7lja5OjA7AGNiqw+kqpbooZxL6WqCfiMSLiBswHVhYt4AxJt4YE2eMiQM+AH5pjFnQ2sGetbiJkL4Kqk+thZ84Mar90ZVSXVWLCd0YUwXcg9V7ZSfwvjFmu4jcKSJ3tnWArSp+ElQWN9ofPcDLjfgQbzYfzGPxzkxSjhV2QIBKKXXmXJwpZIxZBCxqsKzRE6DGmFlnH1YbiXO0o6cuhejkU1YnRgewcPNhvt6Rybl9Q/j3bWPbNz6llDoLPeNK0RO8g63RF1O+bXT12PggqmsMvf09WJuWS1lls+d4lVKqU+lZCR2g78WQsRZKck9Z9dOkaL76n0n86eqhlFfVsOGA9ktXSnUdPS+h97sETA3sW3LKKptNGBDuS3J8EHabsColpwMCVEqpM9PzEnrkKPAMgr3fNFnE18OVEVH+rNyX3Y6BKaXU2el5Cd1mh74XWu3ojQwDcMI5fUPYkpFPgV5opJTqInpeQgcYeDmUZEPaiiaLjE8IprrGsCFd29GVUl1Dz0zo/aeAmw9s+6DJIiOiA7AJbNCp6ZRSXUTPTOiunlYtfccnUFXeaBFvdxcGRfhpDV0p1WX0zIQOMPQ6KMuHlMVNFhkdG8jGA8eprmk4FplSSnU+PTeh9znf6u3STLPLqJhAiiuq2X1UhwFQSnV+PTeh211hyNWw+wuoKG60yOjYQIDaC4yW783ix1Ttm66U6px6bkIHq9mlssRK6o2ICvQk1Nedt1enM2fhdm56bQ13vbNBhwRQSnVKPTuhx4wHv0jY2nizi4jwhysGk1dawZur0hgbH0RucQULNzUcDl4ppTqeU6Mtdls2Gwz5Cfz4MhRng3fIKUWuHNGbKUPD2X20kCG9/Zj67HJeX7mf65OiEGlsMiellOoYPbuGDjDyJqiphI1vN1nE1W5jaKQ/IsLsc+PZdbSQtWnanVEp1bloQu81EGLPhXVvQE1Ni8WvGB6Bu4uNRVuPtENwSinlPE3oAGN+DnnpsK/pPukneLm5MKl/KF9vP4oxVv/0kooqcosr6pWrrK6pXa+UUu1BEzrAwCvAuxesfdWp4pcOCedwfhlbD1kTSj/+yXaufH4FNY4LkIrKqxj7l8W8v+5gm4WslFINOZXQRWSKiOwWkRQRebSR9dNEZIuIbBKRdSJybuuH2oZc3GDUzbDnKzie3mLxiwb1wm4Tvtx2lJoaw+JdxziUV1rbX331vhxyiytYvPNYW0eulFK1WkzoImIHXgSmAoOBGSIyuEGxxcAIY0wiMBtwrqrbmYyeBSKw/s0WiwZ4uTEuIYjPthxhy6H82uaWL7cdBWDZniwA1qUf12YXpVS7caaGngykGGNSjTEVwHxgWt0CxpgiczJzeQNdL4sFRFujMG58u8kBu+qaPiaGA7klPPH5DsAanfGLbVa7+rK9WbjZbeQWV5Ca3fhVqEop1dqcSeiRQN3G4AzHsnpE5Ccisgv4HKuW3vUk3wHFWbDp3RaLThkaTrifB2vTjjM4wo+ZY2M4lFfKf9dnkJ5TwvTkaADWpZ06d6lSSrUFZxJ6Y1fPnFIDN8Z8bIwZCFwN/KnRDYnc4WhjX5eVlXVagbaLhMkQORpW/AOqm5+pyNVu46bxsQBM6h/KJYPDCPRy5eEPtgAwa0IcgV6u2l9dKdVunEnoGUB0nedRQJPXvhtjlgF9ROSUyy6NMfOMMUnGmKTQ0NDTDrbNicCkhyDvQJPDAdQ1c2wMFwzsxXWjIwnwcuOrX0/ip0lRTB0aTnyIN0lxQazel8OxgrJ2CF4p1dNJSyftRMQF2ANcCBwC1gI3GmO21ynTF9hnjDEiMgr4FIgyzWw8KSnJrFu3rhXeQiszBl6aCFVlcPeP1hykZ+iLrUe4572N2G3Cb6cOZNY58a0YqFKqJxKR9caYpMbWtVhDN8ZUAfcAXwE7gfeNMdtF5E4RudNR7Fpgm4hswuoRc0NzybxTE4FJD0LOXmtGo7MwdVgESx44j4l9Q5jz6Q5e+n5fKwWplFKnarGG3lY6bQ0drCEA5o4DmwvcucIaxOssVFXX8Kv/bOLzLUf45teT6Bfm20qBKqV6mrOqofdINptVSz+2HXaeXS0dwMVu449XDcHNbuPtH6wLl2pqDF9sPcLezJOzIe08UsDkp74j5ZjOkKSUOn2a0Jsy9FroNRgW/6nFHi/OCPZx54rhEXy4PoPv92Qx7cWV3PXOBv7wSe2pCN5YuZ+0nBJeWJJy1vtTSvU8mtCbYrPDhX+A3H2w4a1W2eTNE+IorqjmltfXkFVYzjl9g1mblktBWSUFZZV8uvkInq52Pt1yhIO5Ja2yT6VUz6EJvTn9p0DMBPjuCSg5+wuEEqMDmDUhjnsv6MviB87jvgv6UVVjWLE3m082Haa0sppnpydiF+HlZXoCVSl1ejShN0cELvs7lB6HJY1eK3Xa5lw1hAcuGYC3uwujYwPx83BhwcZDzFu2jyG9/bh4cBjTEnvz0YZDFJVXtco+lVI9gyb0loQPg+RfWBNgpK9q1U272G3W2Oo7MjmaX8b/XjUEEWHG2BhKKqr5dLPOXaqUcp4mdGdc8BgExcMHP4finFbd9MWDwwD489VDSYoLAmBkdAADw315b82BVt2XUqp704TuDHdfuP5NKMmGj3/h1FR1zrpyeG8WP3AeN4yJqV0mIkwfE82WjHx2HC6gpsbw3poDFGsTjFKqGZrQnRUxAqb8FVK+gVXPttpmbTahT6jPKcsvGx4BwPK9WaxJy+U3H23lg/UZrbZfpVT3own9dCT9HAZfbfVNT1vRprvq5etBQog3a/bnsmqf1cxzYkYkpZRqjCb00yECVz0HQQnw/i3WqIxtKDk+iDVpuaxKyQZgfbqV0Ldk5FFR1XrNPkqp7kET+uny8IcZ70F1Bcy/ESra7gKg5PggCsuqWJd+HH9PVzKOl7J09zGuemElzy/Z22b7VUp1TZrQz0RIP7j2NTi6DT652xpytw0kxwfVPp41IQ6Axz7eBsDbP6RTUmGdJP1oQwY/f3MtldVaa1eqJ9OEfqb6XwIXzYHtH8E3f2iTpB4V6EVkgCcuNuHWc+Jws9s4lFfKiCh/8koqeX/tQVKOFfGbj7ayeNcxvnBMUl1XWWU1015YwVNf7Wp0H4Vllfxl0U7ySipaPX6lVPvShH42zvmVdaJ01XPW8ABt4JpRkVw1ojcBXm4MifQD4K/XDGd0bCB/+3I30+f9gJebnahAT15fsf+U1/910U42Z+SzYONhGhsq+YXvUpi3LJVvdx5rk/iVUu3HpaMD6NJE4LKnoaYSlj0FNleY/Eir7uKBSwbUPv7Z2FiGRfozuLcfT18/gpe/30fKsSJ+eX4fDuaW8vjC7by1Oo1RMYEMjvDj7R/S+dfqdGKDvUjPKWF/djEJdbpIZhwv4Y2VaQDsPlrQqnErpdqfJvSzZbPBFc9CTTUs/Yt1svSC31nJvpVdOzqKa0dHARAf4s2T1w6vXVdcXsXL3++rHY7Xz8OFgrIqzh8Qym8vG8TF/7eMFSnZeLm5YBPw83Tl9wus9vjIAE92HdUx2JXq6jShtwabDa563hpyd/nTUHgELv9/4OrZbiF4u7vwzf3nkZ5Tws4jBXy3+xijYgKZNSEOm02IDfbiow2HeObbvRSWVRId6EVqdjF/nDaEzQfzWbY3q3ZbxhhqDNhtrf+lpJRqO9qG3lpsdrjyOTjvUdj0DrxyIWTtbtcQvN1dGNzbj2tHR/HCjaOYfW48NkdSntgvhE0H86iqruHaUVEUllfx/IyR3Dw+jkERvmQVlpNTVE51jeHudzdw8T++J7uovNVjXJmSzedbjrT6dpVSTiZ0EZkiIrtFJEVEHm1k/UwR2eK4rRKREa0fahcgAuf/BmZ+CEWZ8PJ51uQYnWC+7ClDInBzsfHCjaN48trhrH3sIq4c0RuAAeHWHKe7jxby9y93sWjrUdJzS/jF2+spq6xucdslFVV8tuUw1TUtv89nF+/lb1823uNGKXV2WkzoImIHXgSmAoOBGSIyuEGx/cB5xpjhwJ+Aea0daJfS7yK4ayVEj4GF98KHP4eyjj3peG6/ELbNuZRJ/UNPWTcw3Oo9M3fpPl5elspN42J5fsZI1qcf581VaQDsyypqMrnPW5bKPe9u5IH3N1HVQl/4fceKOFZY1miPG6XU2XGmhp4MpBhjUo0xFcB8YFrdAsaYVcaYEwON/ABEtW6YXZBvONy0wDpBun0BvDwRDq3v0JDcXBr/uEN93Qn2dmNFSjZDI/34/RWDuWxYBMlxQcxfc4A9mYVc8n/LmPudNdfpNzsyOZRXWvv6L7cdtSbq2HSYZxc3fQXr8eIKcoorKKusoaBMR45UqrU5k9AjgYN1nmc4ljXl58AXja0QkTtEZJ2IrMvKymqsSPdis8Okh+DWRVBdBa9eDJ/dD8XZHR3ZKQZF+OHmYuP/fppYm/inJ0eTllPCnf9eT3WN4aONh0g5VsTtb63jtx9tBSA9p5hdRwu578J+JMUGsnpf0+PFp2QV1T7OKixr2zekVA/kTEJvrKtDo7+XReR8rITeaGdsY8w8Y0ySMSYpNPTUn/7dVsw4uGsFjPk5rH8TnhsJK5+FqtY/6Ximfn/FYN6enUy/MN/aZVOHRuDr4UJqVjGDI/zIOF7KA//dDMD3e7LYmpHPV9utq1MvHRLOgHBf9h4rarI5JeXYyYSeWdB53rtS3YUzCT0DiK7zPAo4ZW40ERkOvApMM8a07rQ+3YFnIFz2FPxyNcSMt4YLeGEMbP+4U5w0HRDuy9iE4HrLPN3sTB8TTaivO2/cOgYPVxubD+YxZUg4vh4u/PGz7by35iBDevsRHeRFv14+5JdWkuXoHbNmfy5XPr+CdWnWBNt1E/qxZmroK1Oy+c1HW7WdXanT5ExCXwv0E5F4EXEDpgML6xYQkRjgI+AmY8ye1g+zGwkdADPfh5s+Bjcf+O8seP1SyOjY9vWmPDp1EEsfnEyYnwcXDbKmy7v3wr7MPieetWnHyS2u4O7z+wLQ31G7T8ksYl+W1TSz9VA+t765lh2HC9iXVURcsBfQdA29vKqaRz/awntrDujFTkqdphYvLDLGVInIPcBXgB143RizXUTudKx/CfgDEAzMFesKySpjTFLbhd0N9LkA7lwOG/8NS/4Mr14Ag66CCfdCdHJHR1fLbhO83a0/k4cvHcj5A3oxpLc/A8J8uXpkJLFBXrV93fuGWcMK7Mks5G9f7cbFJrx3+zjuf38Tt7+1jqqaGsbGB5NVWE5mwcka+sYDxxkU4YeHq513fzzAwVzrhOvinZkMivBzKs6yymo8XO2t+daV6nKc6odujFlkjOlvjOljjHnCsewlRzLHGHObMSbQGJPouGkyd4bNDqNvgfs2wKSHYf/38NrF8OpFVs+Y6s7VEyQm2Kt26AEXu434EO/aZA4Q6uOOv6crX+/IZPPBPO6a3IfxfYJ5ceYojuSXkllQTp9QH8L8PDhWaNXQ16Xl8pO5q3jnxwNUVNXw/JIUzukbzPAofxbvcm7AsK0Z+Qyb8xXbDuW3/ptWqgvRK0U7A3dfuOAx+PUOmPqU1Qvmv7fA8yNh9dwO78PuLBGhXy8fVu3LQQSuGG5duDQqJpBfTj7RLONDqK87xxw19BPdHH9IzWHTwTxyiyu4aVwcFw4MY9PBvHpXq246mMfd72wgv6Sy3n5/3J9DZbXhk02H2uNtKtVpaULvTNx9YOwdcO96uOHf4BcJX/0G/m8IfPUYHNvZ0RG2qJ+j2WVMbBDh/h61y391UT+enZ7IhYPCCPPzILOgnPXpx1m+NxtfdxfWpeWyal82IjAuIYgLB/XCGHjxuxRyiyuoqKrhwf9u5vOtR3jq6/pXmu44Yn3hfbn96GmdSK2sriGnDYY3UKqjaELvjGx2GHQlzP4SblsCfS+CH/4Jc8fBi2Nh6ZNwrHNePt+vl3Vi9MoREfWWu9ptTEuMxM3FRpifO8cKy3j5+30EebvxwCX9Oe6YsGNQuJ819ntvPyYPCOWNlWmM/+tibn79R1KOFTE6NpB3fjzAxjoTZu88UoiLTTiYW8r2w87/mpm3LJXzn15KeVXLwxso1RVoQu/sokbD9W/A/Tutsde9QqyEPncsvDgOlv4NsjpPx6LzB/ZiUv/Q2uaWxvTy9aCssoZvd2ZyfVIU5w3oBcDh/DLG97G6TooIb96azBe/msgVw3uzZn8uFw8O481bx9DL152Zr/7IGyv3U1FVQ8qxQq4ZFYlN4IP1GfWGHyitaDpZL919jIKyKvYcLWp0/e8WbOXNladOGlLX19uP8u6P9ScLP15coV0uVYfQhN5V+IZB8u1w6+fwwC6rrd0zEJb+FV4cA3MnwPdPQXZKh4YZH+LNW7OTCfR2a7JMLz93AGoM3JAUTVywFyE+1rLxDfrCD4rw4//9dASrf3Mhz88Yia+HKx/cOYHk+CD+99MdvL5yP5XVhnP6hnDBwDDeXJXGuL8uIeVYIalZRYz449d8tuWUyyYoq6xm80HrJOq2w6eeTM0qLOedHw/wj2/21M7d2phnF+/lic931M7nmltcwfgnF7Nw86n7VKqtaULvinzDrbb22V/A/Ttgyt/Aww+++zO8MNqquX/+AGz9APIOtry9dtbL12pbT44PIiHUBxEhOT4Qm0ByQlCjrwnz86jtlhgd5MW8m5II9XXn2W+tk6qDIvx44caRzJ05ipKKKl7+PpV3HT1nnlu8l5oaw/K9WbUDjG04cJwKRxLeeiifVSnZXPn8Cu5+dwNbM/JZsisTY6CgrIqPN9Y/2VpdYzDGUFRexc4jBRRXVLP5YB4AO48UUFZZw5aMlnvcVNeYehdbKXW2dIKLrs6vN4y707rlH4KdC2HPV7B5Pqx91VEm0hp+IHqcdR82xGqn7yAJod642oVbxsfVLrvvwn5cNCgMPw9Xp7bh5mLjZ2Nj+b9v9+DmYiMhxBsXu43LhkWwMiWbD9Zn4OlmJ8THnT2ZRfzstR9ZtS+HX1/Un19d1I8fUnOxCQzu7cf2Q/lk5pexP7uYg8dL2HYon7hgbyIDPAn0duXNlWncmBxDanYxt7+1jrTsYi4aFMZN42M5MWLw8r3ZJMUF1V4MlZZdDFjNOonRAQR4nfqL5f11B/ntx1v5/N6JDO7tXH/79lBdY3hj5X6uHx2Nv5dzn4fqHLSG3p34R8K4u+DmBfBIOvximdU0Ez0W0lfDFw9Zoz4+GQtvXW21v6d8C0XtO0F0mJ8HG35/MZcPP3nidGC4H9eMOr1BOm8cG4OrXegf5oOL/eSf8s3j4yivqiGvpJK/XzeMqEBPVu3Lwd3FVjv2zI+pOQzp7c/4hGB2Hilk2d4sbhwbw7PTR5KeU8L3e7K4eHAYsybEs/dYEd/syGTud/s4ml/GxH6hfL0jk483HMIm0LeXDytTrAHX9jgS+v7sYrKLypn1xtraaQEb+n53FsbAu2vST+t9t7W1abn8+fOdLGykqaqhnUcK+P2CbU6Nha/antbQuyu7C0SMsG5j77DGi8k/CAd+hAOr4eCPVvv7iXHWQgdC3LnQa7B1CxsMHv5tFp6vkzXx5oT6uvP4lUMIbFD7HRDuy4Q+wWQcL2Vy/148fb0L2w8XUF1Tw18W7WLTwTw2Hszj5nGxDI30r216uWpEb4ZG+nNe/1C+35PFRYPCGJsQxNzvUnhi0U4O55Uyc2wsd0xK4Ny/LeGjjYcYHGH1xnl5WSqFZZXszrQS+oHcEjYdyAPg0y2Hue/CvvTtdXLgs5oaw+pUa8ijBRsPc//FA0jPKSYxOgA5jfloP9l0iG93HuPZGxLrXeR1NtanWz2IUrNabg5asPEQb/+QzvTkaIb0bru/F+UcTeg9hQgExFi34ddby0rz4OhWOLwB9n0HW96H8jrd/gJiIWI4hI+A8GHWY9+INpkA+0z9bFxso8v/OXM05dXV2GzCuIRgxiUEcyCnhL8s2sWtb6zBGMP05Jjat5IQ4s0QR7PHn68eyntrDjAuIQgXu42HLh3AXe9sQARmnxNP7wBPzusfyne7s0iKC+TcviHMXbqPlSnZ7M0sxN/TlfzSSr50/BrwdLXz3OIUnpsxkg0HjvPaiv3cOiGO/NJKfjYuhn//cIBz/7aEkopqfnf5IG6bmODUe6+pMfzjmz2k55QwbURvLhocdvYHlLoJvbjFsnscX2AbDuRpQu8ENKH3ZJ4BED/Rup3zK0ctPgOO7bAS/dGtcHQL7Pz05Gu8QyF8uCPRD4PgfhDcB9y8O+xtNMZq+63/KyAm2IuB4b6147f37eVDTY0hPsSbmeNia2vG0UFePDxlYO3rpgwNZ0KfYCL8PYlxDC52w5gYvtudRXJ8EGPig+jl687/fbOX4opqrh0VwYcbMvhq21HiQ7y5cGAvXl+5n79cM4xPNh7i8y1H2OhImvec34+9mUWUVdXg7+nKXxbtxN3VzuXDIgjydqO8qpr/rD3I1KERhPq613s/q/blkJ5TgotNeHFpCpGBnqTnlDBlaHijx6SgrBI3u63ZMW9qaszJhJ7dcg19T6ZVZkP6cW5q4stVtR9N6OokEQiItm79Lz25vKwAMrdZCf7IZjiyBVY9DzV1uvP59rYSe3Bf6xbSz7oPiLWafzqJm8fHsXDzIX45uQ8ANpvw3YOTm+03LiK8e/u4essuHWL1iZ/YLxS7TbhxbAzPOHrcTBkazocbMigsr2LywF6c2y+EV1fsZ0tGHlsd480czi8jIdSbcH8P/vOL8YA1N+uMV37k9wu28afPdvDubWPZdDCPP3++k5e/T+XVW5LqDVb23poDBHq5cvf5ffnz5zuZ+uxyAD6951z6hflY49jXOdl6/T9XM6S3H/+4IbHJ95qaXUR+aSWRAZ5kHC9tdtCzwrLK2pmrTnwJqI7Vef7TVOfl4QexE6zbCVXlkL0HclIct33W/faPoSzvZDmbCwTGWwk+KMHqcRMYa9Xu/aPbvfnmxrEx3Dg25pTlp9NufaL8ZMcFUQA3JsfwwpIUqmoM4xKC8HV3obC8imGRfiRGBwBWLXbHkQKuGRnJ8pRsLhzYq942vdxc+OiuCWzJsMas+d2CbeQUVzCktx85RRXc/tY6vn/ofBZtPcLTX+8mPaeEn58bz8/GxfL9niz69fLlww0ZPLt4LzXGsGTXMd67fRzj+wRzNL+M3ZmFHDxewl8qq/n3D+kEeLlxnWOwtfKqap79di+FjqkBrxsdxbOL95KeU1I7iXhDJ2rnY+OD+HF/LlmF5af8igBrVqv73tvI3J+NJjLA87SOszo9mtDVmXFxt5Jy+LBT1xXnQO4+yN7rSPZ7rYSfshiq64yd4uEPYcMgfKiV3H3DHbcI8AmzxrbpInr5eTAtMZJth/Lx9XAlPtSbLRn5DI30J8DLjbhgLz7ccIiyyhom9Q/lj1cPxaOROV7tNmFkTCC/u2Iwv3xnAwDPzxhJTlEFd7+7gW92ZPK/n24nwMuNBy/pz6xz4vFwtfP2z8cC4OfpUvtLwdvNzmMLtrLovomscUwyUlJRzTs/HuCvX+wiwt+Da0dFIiKsSzvO3KX7AAj0cuXCQb14dvFeUrOKmkzoex3t5zOSY/hxfy4bDhzn0iGnNvd8uvkwmzPyWbDxUO3Y+WBd3PX6yv1cOyqKMD+PU16nTp8mdNX6vIOtW8Nx3Y2BklzITbXa5o9utZpyNrwNlY2cgHPztbpiBsRYCT8g2rr3620lfd8IcO08ieCv1wyr7TETF3wyoQOMiA7gk01WN8Chkf74uDf/rzd1aDiXDQvHGBiXEExFVQ3B3m488uEW8ksreW76SCb0DTnldbdOiOffPxzgvP6hTEvszc2vr+GVZalkFpbh7WbH1cXGXxftpLrGkHG8lH1ZxfTt5UPG8RIAHrykP31CfUgItb5MU7ObPjG6O7MQT1c7U4aG4/aBjcU7MxtN6Et3W/MHf739aL2E/sqyVP7fN3tYl3ac125JOu1fSepUmtBV+xGpk+zHnFxujNVMU5gJhUegyHFfeNQ6SZt3AA6uqd+Uc4JnoKNG38uq1fv0Ap/wOo8d956Bbd684+Ziq51g+/qkKCIDPWsvlEp0JHRvNzsJIS2fQBYRXrxxVL1tX5cUxcvfpzI00q92zJuG/L1cWf7w+Xi42hARLhkcxrzlqQR6uTE6LogwX3f+uz6Dif1CWL43m6W7j9G3lw8Hc0ux24Q7z+tT26c/3M+Dfc10XdyTWUj/MB88XO3MHBfDGyvTuGhQGJfUSer5JZVsOHCcYG83NjuuwH36qz1cNKgX85anEuLjzpJdx/hmR2a912UcLyHcz6M2lvXpx3l9xX7+74aTk5g74+0f0jlWUMYDlwxw+jWNKa+qZvHOY0wdGt6pv3g0oauOJ2IlXM9A6DWw6XJlBVaCLzxy8lbg+AIoyrT61xdm1m/WOcHudmqSr/sFEBBt/RJw92uVq2gn9gtlYr+TE6GPcLSjD4n0d7q/eMPEMTM5ln+vTue+C/o1m1Q83U7G/6uL+vH1c5kUllXx06QoxiYE893uY/zvVUO44+31fL8ni9smJpBxvIQIf496F2glhHqzr4mui5sP5rE1I7+2Rv7o1IGsSzvOg//dzLL4oNorY5ftzaLGWOsf+mALt/1rHW4uNp5bUoC7i40P7xrPHW+t58kvdnHx4DBEhA0HjnP9S6u5eFAY//zZKESE11fs5/OtR/jJyEinu2dWVtfwzDd7KCqv4p4L+uLucuaf6wfrM3js4228cnMSF7dS99C2oAlddR0efuDhuOipKcZAWb519euJRF90DIqOnlyWdwAy1loTidBI7xY3H2vSEc8g60vGK9B67BVU/94z0DoP4OFnfRG4+YCt8drj4Ag/vNzsjI4NPOO3HxPsxdY5l57WBURDevtzyeAwvt6RSXJ8MGPiglj3u4sBOK9/KG//kE5pRTUZx0uJCqx/wnJ0bCDPL0lh+d6sel9Ob69O4/efbCfY243pydYJZncXO3+9ZhhXPL+CBRsPMeuceArKKlmw8RABXq5cMyqKl5elknG8hP/+YgKFZdYkJbHB3vxsfCy/X7CN/dnFhPt7cP9/NuFqF77cfpRXl+/npvGxfLfbupp54ebDTif0ZXuyyCmuAGBLRj5j4hofJ6gppRXVbD+cT1JcUG2z0X/XHXQqoVdW1/D0V7uZkRxDnBO/yFqLJnTVvYhY/es9AyC0f/NlqyutpF50FI6nQ8EhKC+0bmV51oVXJbnWyd2SXCjNrd9V85R926wvAvc6Sd7DDzz88XD3Y+UYD7w9d8C61bXL8Qi0TgR7+Fm/ImyuTX4pAGd0NejvLh9MXIg3I2MC6i0/r38or63Yz9q0XDKOl3Juv/pt8r+c3Jcvtx3l/vc388+Zo0iMDiCnuIInv9jFxH4h/PNno+udCxga6c/wKH/mrz1IXIg3d/17A6WV1dwxKQG7TZg7cxQVVTW15xVq43B8WXy/J4vMgnLSc0t497Zx/GtVGk9+uYv80kpKKqrp18uHb3ZkUlJRhZebtd/CskreX5fBT5Oi6l19bIzh442H8POwehv9sC/ntBJ6eVU1t721lpUpObw1O5lVKdm42W0s2XWM7KJyQnzcKS6vwkCj50OW7DrGy8tS8XZ34b4L+zm937PlVEIXkSnAs1iTRL9qjHmywfqBwBvAKOAxY8zTrR2oUq3O7gp+Edat98iWyxtjJfvS3JMJvqzAurq29j6//rKCQ9ZMU+UFBJYVgHFiMg3PQOvkr5u3leRdPMDFDVy9Tn5JuPvV+XXQ4AvE3c8q6/hiiAn24reXDTplNyNjAhCxpv/LLCwjOtCrfhhudp6/cSTXzl3FdS+tJtDLlTA/DyprDE9cPazRRPbTpGh+t2Abd/17A7HBXjx13QiGRVkJvH9Y471lYoK9SAjxZtHWI+w6UsjlwyIY3yeYwRF+bH52GS98l4K/pytzrhrCzFd/5JsdmUxLjATgrdXpPPXVbj5Yn8Ebs8YQ7u/Bfe9tZPneLIrLq5meHM3atOP8sD+He3E+sf72o22sTMnBy83OIx9uobiimoenDODvX+7mv+symJEczTX/XEWYrwfv3THulNe/v9Ya5bTuOYhth/LZl1VUG3tbaDGhi4gdeBG4GMgA1orIQmPMjjrFcoH7gKvbIkilOgURR83aDwLjTv/1xkBlycmkX5ZvfSkUHoGKYqiugKoKKM6yzhVUlkBVmVWuqtzqCXTiy8LUtLw/mwvY3a0upi7u1peDd4h1LYC7L76unjzll0PhOjfusNk4Ly8eNkaCq6f1heDqxUBXL1bPDmP94Qq+2pvPl7uP8asLh9ReMdvQVYm9+fPnO3BzsTHvpqQmyzU0qX8ob65KA+COSdbQB/5erjx9/QhmvvojlwwOY3xCMJEBnsxblsoVw3tjtwmfbTlCdJAnB3KKuefdDcydOYrPthymf5gv1TWGmWNjsYkwf601lHJzJ1QLyirxdnMhs6CMDzdkcPvEeHw9XPnHN3twtQs3j49j+Z5s/v7VLuavPUB6TgnpOSUUlFXWGyU0s6CstoloX1YRxhie/GIX85anYoxVo79wUNu0wztTQ08GUowxqQAiMh+YBtQmdGPMMeCYiFzeJlEq1R2IWLVuN2+r6+WZMsb6Aqj3y6AAyuv8Oqgss74Mqius+6py61Z8DLJ2W18WFcVcVVGMmym3RknY5rg14Aec77g96QYsB1a6Wknf7ur44nAFmx0/mwvrg8Bud8XjA7eTXyquntbN7lhmsztuLiB2biuqINolm1B/L4bvWgt7XMAjgHM8A/jm/CLC/LOxbdnO84PzePOHDFZ/ups+EUH0ytzFveMSELsbL6/YzT/np9OHAl65fDzRIX5ALueHlbC46gg7d2yxTk7bXKD0uHUMHb+A8iuFn762kUuHRhLq504I+dw0zBs/T1feXVrM0MgAfGoKeeWG/jz99R7+s+EIM5L78t6aA/yYas2mtTUjn3vf20BReTU1Bi4Y2IvV+3I4mFvKy8tSuXJEb3YfLeAPn2xnfJ/g2maj1iQtTZUlItcBU4wxtzme3wSMNcbc00jZOUBRU00uInIHcAdATEzM6PT0zjVsqFI9zX/XHeThDzbhQQVL7ksmwstARYmV8CtLHfeOxxXFjmWl1q+FihKoqbTOK9RUO+6rTj6vrrTWV1ee3EZ1haNstdX85ChvaqopK6/AzVaDnRrrNY2dsO5EjGcgR0psBLhU4eodwL4CAbHj5uaGq5s7dncvNmdWktA7jJWHqpg2PIyaqgoW7sjDd/BF/PTG285ovyKy3hiT1Ng6Z74iGjsLc0ZH2hgzD5gHkJSU1Lk/LaV6gFGxgRhsVNo86RUeBa00BO/pEqBeH5sTvZXK8qlNN8YAhvTsQv64YBNHjxcyIsKTv1w1EGoqWbghjU83pDNrbG/Oifd3fClYFm07yrc7jzFrfAzbD+UycVg/osJCobqCvMIinli4kYEhbhzILqSquobLhoZxTp/g2n1iauo/rq5A8jNI2ZlBTrkdn+Ji3KWEpBh/vFwMVFdSWFhAguQQcGw/P7UX473fA7G5cpN7CUV+LZywP0POJPQMILrO8yhAJ0xUqhtICPEmwMsVPw9X7B2UzBtVt7dSA7FBMO/B4Xy36xgJod7guKr14qhqssMPMHpsDDQYUGzCgAoe+dt3fLSyCojjMt9wnhs3koc/2MLnW49QXXMu39x4Hh+sP8gry/Zz72Xng3/LVyHv8tvHXxbtws1u4707xuFVp1tqaUEZl/5lMQDn9g3h37dZwzO4AafXgdJ5ziT0tUA/EYkHDgHTgRvbKB6lVDsSEaYOjaCmi804ZLfJKf3RPd3szD43vtHyAV5u/O6KQSzfm42r3cZnWw7z6or9fLTxEDckRXPj2BjiQ7y5/+IBzEiOIdyJZA5wwcAwnv56D09cPfSUawxCfd1rB2kbdRbXH5yOFtvQAUTkMuAZrG6LrxtjnhCROwGMMS+JSDiwDuv8SQ1QBAw2xhQ0sUmSkpLMunXrzv4dKKXUadh9tJBLn1kGWEMyfPzLCWd1OX9ldQ2u9sZ7z0x7cSWbD+bxr9nJnNc/tNEyp+ts29AxxiwCFjVY9lKdx0exmmKUUqpTGxDuy8iYADYeyOPhSwec9dgsTSVzgD6h3mzJyKsdQrmt6ZWiSqke57eXDWLN/txGR6xsTbdOiGdEVAD+nmc/h64zNKErpXqcMXFBpz22y5kYFuVfe6Vse3B+HEqllFKdmiZ0pZTqJjShK6VUN6EJXSmluglN6Eop1U1oQldKqW5CE7pSSnUTmtCVUqqbcGoslzbZsUgWcKYDoocA2a0YTmvqrLFpXKens8YFnTc2jev0nGlcscaYRgeG6bCEfjZEZF1Tg9N0tM4am8Z1ejprXNB5Y9O4Tk9bxKVNLkop1U1oQldKqW6iqyb0eR0dQDM6a2wa1+nprHFB541N4zo9rR5Xl2xDV0opdaquWkNXSinVgCZ0pZTqJrpcQheRKSKyW0RSROTRDowjWkS+E5GdIrJdRH7lWD5HRA6JyCbH7bIOiC1NRLY69r/OsSxIRL4Rkb2O+/aZtbZ+XAPqHJdNIlIgIv/TEcdMRF4XkWMisq3OsiaPkYj8xvE3t1tELm3nuJ4SkV0iskVEPhaRAMfyOBEprXPcXmpyw20TV5OfW3sdr2Zi+0+duNJEZJNjebscs2byQ9v+jRljuswNa5LqfUAC4AZsxpqMuiNiiQBGOR77AnuAwcAc4MEOPk5pQEiDZX8HHnU8fhT4Wyf4LI8CsR1xzIBJwChgW0vHyPG5bgbcgXjH36C9HeO6BHBxPP5bnbji6pbrgOPV6OfWnserqdgarP9/wB/a85g1kx/a9G+sq9XQk4EUY0yqMaYCmA9M64hAjDFHjDEbHI8LgZ1AZEfE4qRpwL8cj/8FXN1xoQBwIbDPGHOmVwufFWPMMiC3weKmjtE0YL4xptwYsx9IwfpbbJe4jDFfG2OqHE9/oAMmZG/ieDWl3Y5XS7GJNQP0T4H32mr/TcTUVH5o07+xrpbQI4GDdZ5n0AmSqIjEASOBHx2L7nH8PH69I5o2AAN8LSLrReQOx7IwY8wRsP7YgF4dEFdd06n/T9bRxwyaPkad6e9uNvBFnefxIrJRRL4XkYkdEE9jn1tnOl4TgUxjzN46y9r1mDXID236N9bVEro0sqxD+12KiA/wIfA/xpgC4J9AHyAROIL1c6+9nWOMGQVMBe4WkUkdEEOTRMQNuAr4r2NRZzhmzekUf3ci8hhQBbzjWHQEiDHGjATuB94VEb92DKmpz61THC+HGdSvOLTrMWskPzRZtJFlp33MulpCzwCi6zyPAg53UCyIiCvWh/WOMeYjAGNMpjGm2hhTA7xCG/7UbIox5rDj/hjwsSOGTBGJcMQdARxr77jqmApsMMZkQuc4Zg5NHaMO/7sTkVuAK4CZxtHo6vh5nuN4vB6r3bV/e8XUzOfW4ccLQERcgGuA/5xY1p7HrLH8QBv/jXW1hL4W6Cci8Y5a3nRgYUcE4mibew3YaYz5R53lEXWK/QTY1vC1bRyXt4j4nniMdUJtG9ZxusVR7Bbgk/aMq4F6taaOPmZ1NHWMFgLTRcRdROKBfsCa9gpKRKYAjwBXGWNK6iwPFRG743GCI67Udoyrqc+tQ49XHRcBu4wxGScWtNcxayo/0NZ/Y219trcNzh5fhnXGeB/wWAfGcS7WT6ItwCbH7TLgbWCrY/lCIKKd40rAOlu+Gdh+4hgBwcBiYK/jPqiDjpsXkAP411nW7scM6wvlCFCJVTv6eXPHCHjM8Te3G5jaznGlYLWvnvg7e8lR9lrHZ7wZ2ABc2c5xNfm5tdfxaio2x/I3gTsblG2XY9ZMfmjTvzG99F8ppbqJrtbkopRSqgma0JVSqpvQhK6UUt2EJnSllOomNKErpVQ3oQldKaW6CU3oSinVTfx/BUz9G/vBmGkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 32)                11520     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,553\n",
      "Trainable params: 11,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9762\n",
      "Test Loss: 0.09482745826244354\n",
      "Test Accuracy: 0.976190447807312\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'GRU_1 layer with dropout_Adam.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, \n",
    "                     dropout=0.3,\n",
    "                     recurrent_dropout=0.3,\n",
    "                     input_shape=(None, x_train.shape[-1])))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=200, validation_data=(x_val, y_val), callbacks=[callbacks_list])\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.6969 - accuracy: 0.6510\n",
      "Epoch 1: val_loss improved from inf to 0.64976, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 3s 11ms/step - loss: 0.7005 - accuracy: 0.6390 - val_loss: 0.6498 - val_accuracy: 0.7381\n",
      "Epoch 2/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.6573 - accuracy: 0.6836\n",
      "Epoch 2: val_loss improved from 0.64976 to 0.61326, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.6997 - val_loss: 0.6133 - val_accuracy: 0.8036\n",
      "Epoch 3/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.6434 - accuracy: 0.7226\n",
      "Epoch 3: val_loss improved from 0.61326 to 0.58001, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.7188 - val_loss: 0.5800 - val_accuracy: 0.8393\n",
      "Epoch 4/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.6089 - accuracy: 0.7627\n",
      "Epoch 4: val_loss improved from 0.58001 to 0.55285, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.7700 - val_loss: 0.5528 - val_accuracy: 0.8452\n",
      "Epoch 5/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.5886 - accuracy: 0.7900\n",
      "Epoch 5: val_loss improved from 0.55285 to 0.52800, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5933 - accuracy: 0.7859 - val_loss: 0.5280 - val_accuracy: 0.8452\n",
      "Epoch 6/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.7705\n",
      "Epoch 6: val_loss improved from 0.52800 to 0.50925, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.8631\n",
      "Epoch 7/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.5654 - accuracy: 0.7929\n",
      "Epoch 7: val_loss improved from 0.50925 to 0.49013, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5680 - accuracy: 0.7923 - val_loss: 0.4901 - val_accuracy: 0.8750\n",
      "Epoch 8/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.8194\n",
      "Epoch 8: val_loss improved from 0.49013 to 0.47414, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.8179 - val_loss: 0.4741 - val_accuracy: 0.8810\n",
      "Epoch 9/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.8484\n",
      "Epoch 9: val_loss improved from 0.47414 to 0.45953, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.8466 - val_loss: 0.4595 - val_accuracy: 0.8869\n",
      "Epoch 10/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.5065 - accuracy: 0.8492\n",
      "Epoch 10: val_loss improved from 0.45953 to 0.44597, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.5052 - accuracy: 0.8530 - val_loss: 0.4460 - val_accuracy: 0.8929\n",
      "Epoch 11/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.5105 - accuracy: 0.8328\n",
      "Epoch 11: val_loss improved from 0.44597 to 0.43451, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.8371 - val_loss: 0.4345 - val_accuracy: 0.8988\n",
      "Epoch 12/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.5201 - accuracy: 0.8308\n",
      "Epoch 12: val_loss improved from 0.43451 to 0.42436, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.8307 - val_loss: 0.4244 - val_accuracy: 0.8988\n",
      "Epoch 13/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.4673 - accuracy: 0.8627\n",
      "Epoch 13: val_loss improved from 0.42436 to 0.41443, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.8626 - val_loss: 0.4144 - val_accuracy: 0.8988\n",
      "Epoch 14/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.4711 - accuracy: 0.8577\n",
      "Epoch 14: val_loss improved from 0.41443 to 0.40427, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.8530 - val_loss: 0.4043 - val_accuracy: 0.9048\n",
      "Epoch 15/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.4669 - accuracy: 0.8618\n",
      "Epoch 15: val_loss improved from 0.40427 to 0.39597, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.8690 - val_loss: 0.3960 - val_accuracy: 0.9107\n",
      "Epoch 16/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.4488 - accuracy: 0.8473\n",
      "Epoch 16: val_loss improved from 0.39597 to 0.38836, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8530 - val_loss: 0.3884 - val_accuracy: 0.9107\n",
      "Epoch 17/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.4355 - accuracy: 0.8909\n",
      "Epoch 17: val_loss improved from 0.38836 to 0.38097, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.8946 - val_loss: 0.3810 - val_accuracy: 0.9107\n",
      "Epoch 18/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.4628 - accuracy: 0.8302\n",
      "Epoch 18: val_loss improved from 0.38097 to 0.37427, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8339 - val_loss: 0.3743 - val_accuracy: 0.9167\n",
      "Epoch 19/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.4283 - accuracy: 0.8778\n",
      "Epoch 19: val_loss improved from 0.37427 to 0.36696, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8882 - val_loss: 0.3670 - val_accuracy: 0.9167\n",
      "Epoch 20/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.4113 - accuracy: 0.8792\n",
      "Epoch 20: val_loss improved from 0.36696 to 0.36109, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8882 - val_loss: 0.3611 - val_accuracy: 0.9167\n",
      "Epoch 21/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.4221 - accuracy: 0.8979\n",
      "Epoch 21: val_loss improved from 0.36109 to 0.35534, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8978 - val_loss: 0.3553 - val_accuracy: 0.9167\n",
      "Epoch 22/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.4288 - accuracy: 0.8571\n",
      "Epoch 22: val_loss improved from 0.35534 to 0.35003, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8626 - val_loss: 0.3500 - val_accuracy: 0.9167\n",
      "Epoch 23/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.4078 - accuracy: 0.8784\n",
      "Epoch 23: val_loss improved from 0.35003 to 0.34521, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8722 - val_loss: 0.3452 - val_accuracy: 0.9345\n",
      "Epoch 24/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.3921 - accuracy: 0.8898\n",
      "Epoch 24: val_loss improved from 0.34521 to 0.34005, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8850 - val_loss: 0.3401 - val_accuracy: 0.9345\n",
      "Epoch 25/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.3939 - accuracy: 0.8612\n",
      "Epoch 25: val_loss improved from 0.34005 to 0.33552, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8626 - val_loss: 0.3355 - val_accuracy: 0.9345\n",
      "Epoch 26/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3813 - accuracy: 0.8926\n",
      "Epoch 26: val_loss improved from 0.33552 to 0.33009, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8946 - val_loss: 0.3301 - val_accuracy: 0.9345\n",
      "Epoch 27/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3880 - accuracy: 0.8873\n",
      "Epoch 27: val_loss improved from 0.33009 to 0.32615, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8882 - val_loss: 0.3261 - val_accuracy: 0.9345\n",
      "Epoch 28/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3617 - accuracy: 0.9185\n",
      "Epoch 28: val_loss improved from 0.32615 to 0.32200, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.9137 - val_loss: 0.3220 - val_accuracy: 0.9345\n",
      "Epoch 29/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3716 - accuracy: 0.8912\n",
      "Epoch 29: val_loss improved from 0.32200 to 0.31802, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8882 - val_loss: 0.3180 - val_accuracy: 0.9345\n",
      "Epoch 30/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3520 - accuracy: 0.9298\n",
      "Epoch 30: val_loss improved from 0.31802 to 0.31442, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.9297 - val_loss: 0.3144 - val_accuracy: 0.9345\n",
      "Epoch 31/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.3519 - accuracy: 0.8979\n",
      "Epoch 31: val_loss improved from 0.31442 to 0.31109, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8882 - val_loss: 0.3111 - val_accuracy: 0.9345\n",
      "Epoch 32/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.3844 - accuracy: 0.8863\n",
      "Epoch 32: val_loss improved from 0.31109 to 0.30790, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8882 - val_loss: 0.3079 - val_accuracy: 0.9405\n",
      "Epoch 33/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3461 - accuracy: 0.9094\n",
      "Epoch 33: val_loss improved from 0.30790 to 0.30498, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.9105 - val_loss: 0.3050 - val_accuracy: 0.9464\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.8818\n",
      "Epoch 34: val_loss improved from 0.30498 to 0.30182, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8818 - val_loss: 0.3018 - val_accuracy: 0.9464\n",
      "Epoch 35/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.3406 - accuracy: 0.9102\n",
      "Epoch 35: val_loss improved from 0.30182 to 0.29867, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.9010 - val_loss: 0.2987 - val_accuracy: 0.9464\n",
      "Epoch 36/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3224 - accuracy: 0.9309\n",
      "Epoch 36: val_loss improved from 0.29867 to 0.29586, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.9297 - val_loss: 0.2959 - val_accuracy: 0.9464\n",
      "Epoch 37/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.3446 - accuracy: 0.9098\n",
      "Epoch 37: val_loss improved from 0.29586 to 0.29316, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3456 - accuracy: 0.9073 - val_loss: 0.2932 - val_accuracy: 0.9464\n",
      "Epoch 38/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.3209 - accuracy: 0.9040\n",
      "Epoch 38: val_loss improved from 0.29316 to 0.29049, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.9042 - val_loss: 0.2905 - val_accuracy: 0.9464\n",
      "Epoch 39/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.3438 - accuracy: 0.9059\n",
      "Epoch 39: val_loss improved from 0.29049 to 0.28799, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.9010 - val_loss: 0.2880 - val_accuracy: 0.9464\n",
      "Epoch 40/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.3573 - accuracy: 0.8889\n",
      "Epoch 40: val_loss improved from 0.28799 to 0.28564, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8850 - val_loss: 0.2856 - val_accuracy: 0.9464\n",
      "Epoch 41/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3298 - accuracy: 0.9088\n",
      "Epoch 41: val_loss improved from 0.28564 to 0.28307, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.9137 - val_loss: 0.2831 - val_accuracy: 0.9464\n",
      "Epoch 42/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9143\n",
      "Epoch 42: val_loss improved from 0.28307 to 0.28044, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3251 - accuracy: 0.9137 - val_loss: 0.2804 - val_accuracy: 0.9464\n",
      "Epoch 43/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.3371 - accuracy: 0.9133\n",
      "Epoch 43: val_loss improved from 0.28044 to 0.27823, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.9073 - val_loss: 0.2782 - val_accuracy: 0.9464\n",
      "Epoch 44/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3266 - accuracy: 0.9263\n",
      "Epoch 44: val_loss improved from 0.27823 to 0.27597, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.9297 - val_loss: 0.2760 - val_accuracy: 0.9464\n",
      "Epoch 45/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.3179 - accuracy: 0.9216\n",
      "Epoch 45: val_loss improved from 0.27597 to 0.27301, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3061 - accuracy: 0.9233 - val_loss: 0.2730 - val_accuracy: 0.9464\n",
      "Epoch 46/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.3060 - accuracy: 0.9269\n",
      "Epoch 46: val_loss improved from 0.27301 to 0.27108, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.9233 - val_loss: 0.2711 - val_accuracy: 0.9464\n",
      "Epoch 47/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3040 - accuracy: 0.9321\n",
      "Epoch 47: val_loss improved from 0.27108 to 0.26938, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.9329 - val_loss: 0.2694 - val_accuracy: 0.9464\n",
      "Epoch 48/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2877 - accuracy: 0.9216\n",
      "Epoch 48: val_loss improved from 0.26938 to 0.26706, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2863 - accuracy: 0.9233 - val_loss: 0.2671 - val_accuracy: 0.9464\n",
      "Epoch 49/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3200 - accuracy: 0.8982\n",
      "Epoch 49: val_loss improved from 0.26706 to 0.26488, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.9010 - val_loss: 0.2649 - val_accuracy: 0.9464\n",
      "Epoch 50/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2925 - accuracy: 0.9143\n",
      "Epoch 50: val_loss improved from 0.26488 to 0.26224, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.9137 - val_loss: 0.2622 - val_accuracy: 0.9464\n",
      "Epoch 51/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2869 - accuracy: 0.9228\n",
      "Epoch 51: val_loss improved from 0.26224 to 0.25990, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.9233 - val_loss: 0.2599 - val_accuracy: 0.9464\n",
      "Epoch 52/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.9179\n",
      "Epoch 52: val_loss improved from 0.25990 to 0.25831, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.9233 - val_loss: 0.2583 - val_accuracy: 0.9464\n",
      "Epoch 53/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2959 - accuracy: 0.9370\n",
      "Epoch 53: val_loss improved from 0.25831 to 0.25628, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2918 - accuracy: 0.9425 - val_loss: 0.2563 - val_accuracy: 0.9464\n",
      "Epoch 54/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2880 - accuracy: 0.9296\n",
      "Epoch 54: val_loss improved from 0.25628 to 0.25477, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.9265 - val_loss: 0.2548 - val_accuracy: 0.9464\n",
      "Epoch 55/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3003 - accuracy: 0.9170\n",
      "Epoch 55: val_loss improved from 0.25477 to 0.25310, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.9201 - val_loss: 0.2531 - val_accuracy: 0.9464\n",
      "Epoch 56/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.9097\n",
      "Epoch 56: val_loss improved from 0.25310 to 0.25155, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3065 - accuracy: 0.9105 - val_loss: 0.2516 - val_accuracy: 0.9464\n",
      "Epoch 57/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.3279 - accuracy: 0.9077\n",
      "Epoch 57: val_loss improved from 0.25155 to 0.25014, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.9137 - val_loss: 0.2501 - val_accuracy: 0.9464\n",
      "Epoch 58/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2773 - accuracy: 0.9396\n",
      "Epoch 58: val_loss improved from 0.25014 to 0.24897, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2858 - accuracy: 0.9393 - val_loss: 0.2490 - val_accuracy: 0.9464\n",
      "Epoch 59/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2818 - accuracy: 0.9444\n",
      "Epoch 59: val_loss improved from 0.24897 to 0.24748, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.9457 - val_loss: 0.2475 - val_accuracy: 0.9464\n",
      "Epoch 60/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2797 - accuracy: 0.9245\n",
      "Epoch 60: val_loss improved from 0.24748 to 0.24608, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.9265 - val_loss: 0.2461 - val_accuracy: 0.9464\n",
      "Epoch 61/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3283 - accuracy: 0.8982\n",
      "Epoch 61: val_loss improved from 0.24608 to 0.24507, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.9105 - val_loss: 0.2451 - val_accuracy: 0.9464\n",
      "Epoch 62/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2922 - accuracy: 0.9228\n",
      "Epoch 62: val_loss improved from 0.24507 to 0.24307, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2834 - accuracy: 0.9297 - val_loss: 0.2431 - val_accuracy: 0.9464\n",
      "Epoch 63/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2744 - accuracy: 0.9355\n",
      "Epoch 63: val_loss improved from 0.24307 to 0.24197, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2752 - accuracy: 0.9361 - val_loss: 0.2420 - val_accuracy: 0.9464\n",
      "Epoch 64/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2637 - accuracy: 0.9322\n",
      "Epoch 64: val_loss improved from 0.24197 to 0.24034, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.9265 - val_loss: 0.2403 - val_accuracy: 0.9464\n",
      "Epoch 65/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2664 - accuracy: 0.9418\n",
      "Epoch 65: val_loss improved from 0.24034 to 0.23902, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.9361 - val_loss: 0.2390 - val_accuracy: 0.9524\n",
      "Epoch 66/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2576 - accuracy: 0.9440\n",
      "Epoch 66: val_loss improved from 0.23902 to 0.23773, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2602 - accuracy: 0.9393 - val_loss: 0.2377 - val_accuracy: 0.9524\n",
      "Epoch 67/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2771 - accuracy: 0.9345\n",
      "Epoch 67: val_loss improved from 0.23773 to 0.23641, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.9329 - val_loss: 0.2364 - val_accuracy: 0.9524\n",
      "Epoch 68/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2698 - accuracy: 0.9345\n",
      "Epoch 68: val_loss improved from 0.23641 to 0.23550, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2684 - accuracy: 0.9361 - val_loss: 0.2355 - val_accuracy: 0.9524\n",
      "Epoch 69/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.9082\n",
      "Epoch 69: val_loss improved from 0.23550 to 0.23439, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.9073 - val_loss: 0.2344 - val_accuracy: 0.9524\n",
      "Epoch 70/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2413 - accuracy: 0.9424\n",
      "Epoch 70: val_loss improved from 0.23439 to 0.23304, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.9425 - val_loss: 0.2330 - val_accuracy: 0.9524\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.9137\n",
      "Epoch 71: val_loss improved from 0.23304 to 0.23162, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.9137 - val_loss: 0.2316 - val_accuracy: 0.9524\n",
      "Epoch 72/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2219 - accuracy: 0.9608\n",
      "Epoch 72: val_loss improved from 0.23162 to 0.23044, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2469 - accuracy: 0.9489 - val_loss: 0.2304 - val_accuracy: 0.9524\n",
      "Epoch 73/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2669 - accuracy: 0.9481\n",
      "Epoch 73: val_loss improved from 0.23044 to 0.22896, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2735 - accuracy: 0.9425 - val_loss: 0.2290 - val_accuracy: 0.9524\n",
      "Epoch 74/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2660 - accuracy: 0.9382\n",
      "Epoch 74: val_loss improved from 0.22896 to 0.22798, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.9329 - val_loss: 0.2280 - val_accuracy: 0.9524\n",
      "Epoch 75/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2871 - accuracy: 0.9245\n",
      "Epoch 75: val_loss improved from 0.22798 to 0.22686, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2786 - accuracy: 0.9233 - val_loss: 0.2269 - val_accuracy: 0.9524\n",
      "Epoch 76/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2459 - accuracy: 0.9509\n",
      "Epoch 76: val_loss improved from 0.22686 to 0.22610, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.9425 - val_loss: 0.2261 - val_accuracy: 0.9524\n",
      "Epoch 77/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2592 - accuracy: 0.9475\n",
      "Epoch 77: val_loss improved from 0.22610 to 0.22494, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.9489 - val_loss: 0.2249 - val_accuracy: 0.9524\n",
      "Epoch 78/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2515 - accuracy: 0.9536\n",
      "Epoch 78: val_loss improved from 0.22494 to 0.22349, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2462 - accuracy: 0.9521 - val_loss: 0.2235 - val_accuracy: 0.9524\n",
      "Epoch 79/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2604 - accuracy: 0.9320\n",
      "Epoch 79: val_loss improved from 0.22349 to 0.22248, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.9329 - val_loss: 0.2225 - val_accuracy: 0.9583\n",
      "Epoch 80/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.2491 - accuracy: 0.9319\n",
      "Epoch 80: val_loss improved from 0.22248 to 0.22158, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2560 - accuracy: 0.9361 - val_loss: 0.2216 - val_accuracy: 0.9524\n",
      "Epoch 81/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.9452\n",
      "Epoch 81: val_loss improved from 0.22158 to 0.22041, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2601 - accuracy: 0.9457 - val_loss: 0.2204 - val_accuracy: 0.9524\n",
      "Epoch 82/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2546 - accuracy: 0.9434\n",
      "Epoch 82: val_loss improved from 0.22041 to 0.21951, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9329 - val_loss: 0.2195 - val_accuracy: 0.9583\n",
      "Epoch 83/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2518 - accuracy: 0.9448\n",
      "Epoch 83: val_loss improved from 0.21951 to 0.21848, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2463 - accuracy: 0.9457 - val_loss: 0.2185 - val_accuracy: 0.9583\n",
      "Epoch 84/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2219 - accuracy: 0.9614\n",
      "Epoch 84: val_loss improved from 0.21848 to 0.21737, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9521 - val_loss: 0.2174 - val_accuracy: 0.9583\n",
      "Epoch 85/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2524 - accuracy: 0.9347\n",
      "Epoch 85: val_loss improved from 0.21737 to 0.21652, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9425 - val_loss: 0.2165 - val_accuracy: 0.9583\n",
      "Epoch 86/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.2624 - accuracy: 0.9375\n",
      "Epoch 86: val_loss improved from 0.21652 to 0.21531, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2507 - accuracy: 0.9393 - val_loss: 0.2153 - val_accuracy: 0.9583\n",
      "Epoch 87/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2477 - accuracy: 0.9296\n",
      "Epoch 87: val_loss improved from 0.21531 to 0.21446, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.9265 - val_loss: 0.2145 - val_accuracy: 0.9583\n",
      "Epoch 88/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2482 - accuracy: 0.9333\n",
      "Epoch 88: val_loss improved from 0.21446 to 0.21362, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2414 - accuracy: 0.9361 - val_loss: 0.2136 - val_accuracy: 0.9583\n",
      "Epoch 89/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2534 - accuracy: 0.9333\n",
      "Epoch 89: val_loss improved from 0.21362 to 0.21304, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.9393 - val_loss: 0.2130 - val_accuracy: 0.9583\n",
      "Epoch 90/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2507 - accuracy: 0.9393\n",
      "Epoch 90: val_loss improved from 0.21304 to 0.21224, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2469 - accuracy: 0.9393 - val_loss: 0.2122 - val_accuracy: 0.9583\n",
      "Epoch 91/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2324 - accuracy: 0.9536\n",
      "Epoch 91: val_loss improved from 0.21224 to 0.21130, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2376 - accuracy: 0.9553 - val_loss: 0.2113 - val_accuracy: 0.9583\n",
      "Epoch 92/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2479 - accuracy: 0.9388\n",
      "Epoch 92: val_loss improved from 0.21130 to 0.21075, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2319 - accuracy: 0.9489 - val_loss: 0.2107 - val_accuracy: 0.9583\n",
      "Epoch 93/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2216 - accuracy: 0.9519\n",
      "Epoch 93: val_loss improved from 0.21075 to 0.21032, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2233 - accuracy: 0.9489 - val_loss: 0.2103 - val_accuracy: 0.9583\n",
      "Epoch 94/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2458 - accuracy: 0.9577\n",
      "Epoch 94: val_loss improved from 0.21032 to 0.20982, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.9553 - val_loss: 0.2098 - val_accuracy: 0.9583\n",
      "Epoch 95/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2461 - accuracy: 0.9404\n",
      "Epoch 95: val_loss improved from 0.20982 to 0.20888, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2401 - accuracy: 0.9457 - val_loss: 0.2089 - val_accuracy: 0.9583\n",
      "Epoch 96/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.1865 - accuracy: 0.9745\n",
      "Epoch 96: val_loss improved from 0.20888 to 0.20836, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9553 - val_loss: 0.2084 - val_accuracy: 0.9583\n",
      "Epoch 97/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2225 - accuracy: 0.9472\n",
      "Epoch 97: val_loss improved from 0.20836 to 0.20721, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2289 - accuracy: 0.9457 - val_loss: 0.2072 - val_accuracy: 0.9583\n",
      "Epoch 98/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2272 - accuracy: 0.9536\n",
      "Epoch 98: val_loss improved from 0.20721 to 0.20634, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2347 - accuracy: 0.9489 - val_loss: 0.2063 - val_accuracy: 0.9643\n",
      "Epoch 99/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2451 - accuracy: 0.9407\n",
      "Epoch 99: val_loss improved from 0.20634 to 0.20576, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2341 - accuracy: 0.9489 - val_loss: 0.2058 - val_accuracy: 0.9643\n",
      "Epoch 100/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2082 - accuracy: 0.9444\n",
      "Epoch 100: val_loss improved from 0.20576 to 0.20490, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9457 - val_loss: 0.2049 - val_accuracy: 0.9643\n",
      "Epoch 101/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2226 - accuracy: 0.9480\n",
      "Epoch 101: val_loss improved from 0.20490 to 0.20410, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9489 - val_loss: 0.2041 - val_accuracy: 0.9643\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9553\n",
      "Epoch 102: val_loss improved from 0.20410 to 0.20333, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2194 - accuracy: 0.9553 - val_loss: 0.2033 - val_accuracy: 0.9643\n",
      "Epoch 103/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2198 - accuracy: 0.9483\n",
      "Epoch 103: val_loss improved from 0.20333 to 0.20270, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2153 - accuracy: 0.9489 - val_loss: 0.2027 - val_accuracy: 0.9643\n",
      "Epoch 104/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9387\n",
      "Epoch 104: val_loss improved from 0.20270 to 0.20222, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2358 - accuracy: 0.9393 - val_loss: 0.2022 - val_accuracy: 0.9643\n",
      "Epoch 105/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2051 - accuracy: 0.9592\n",
      "Epoch 105: val_loss improved from 0.20222 to 0.20156, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2144 - accuracy: 0.9521 - val_loss: 0.2016 - val_accuracy: 0.9643\n",
      "Epoch 106/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2119 - accuracy: 0.9414\n",
      "Epoch 106: val_loss improved from 0.20156 to 0.20133, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2093 - accuracy: 0.9425 - val_loss: 0.2013 - val_accuracy: 0.9643\n",
      "Epoch 107/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9645\n",
      "Epoch 107: val_loss improved from 0.20133 to 0.20058, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2139 - accuracy: 0.9649 - val_loss: 0.2006 - val_accuracy: 0.9643\n",
      "Epoch 108/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2220 - accuracy: 0.9541\n",
      "Epoch 108: val_loss improved from 0.20058 to 0.20027, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2188 - accuracy: 0.9553 - val_loss: 0.2003 - val_accuracy: 0.9643\n",
      "Epoch 109/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2272 - accuracy: 0.9519\n",
      "Epoch 109: val_loss improved from 0.20027 to 0.19958, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9489 - val_loss: 0.1996 - val_accuracy: 0.9643\n",
      "Epoch 110/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2158 - accuracy: 0.9517\n",
      "Epoch 110: val_loss improved from 0.19958 to 0.19945, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2204 - accuracy: 0.9489 - val_loss: 0.1995 - val_accuracy: 0.9643\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.9553\n",
      "Epoch 111: val_loss improved from 0.19945 to 0.19912, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2092 - accuracy: 0.9553 - val_loss: 0.1991 - val_accuracy: 0.9643\n",
      "Epoch 112/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2264 - accuracy: 0.9525\n",
      "Epoch 112: val_loss improved from 0.19912 to 0.19864, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2277 - accuracy: 0.9457 - val_loss: 0.1986 - val_accuracy: 0.9643\n",
      "Epoch 113/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1998 - accuracy: 0.9745\n",
      "Epoch 113: val_loss improved from 0.19864 to 0.19809, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9712 - val_loss: 0.1981 - val_accuracy: 0.9643\n",
      "Epoch 114/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2230 - accuracy: 0.9490\n",
      "Epoch 114: val_loss improved from 0.19809 to 0.19743, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9553 - val_loss: 0.1974 - val_accuracy: 0.9643\n",
      "Epoch 115/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2079 - accuracy: 0.9500\n",
      "Epoch 115: val_loss improved from 0.19743 to 0.19703, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9521 - val_loss: 0.1970 - val_accuracy: 0.9643\n",
      "Epoch 116/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2023 - accuracy: 0.9698\n",
      "Epoch 116: val_loss improved from 0.19703 to 0.19625, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1967 - accuracy: 0.9712 - val_loss: 0.1963 - val_accuracy: 0.9643\n",
      "Epoch 117/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2368 - accuracy: 0.9382\n",
      "Epoch 117: val_loss improved from 0.19625 to 0.19577, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2241 - accuracy: 0.9457 - val_loss: 0.1958 - val_accuracy: 0.9643\n",
      "Epoch 118/200\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2108 - accuracy: 0.9484\n",
      "Epoch 118: val_loss improved from 0.19577 to 0.19501, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2108 - accuracy: 0.9489 - val_loss: 0.1950 - val_accuracy: 0.9643\n",
      "Epoch 119/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2108 - accuracy: 0.9527\n",
      "Epoch 119: val_loss improved from 0.19501 to 0.19403, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2058 - accuracy: 0.9521 - val_loss: 0.1940 - val_accuracy: 0.9643\n",
      "Epoch 120/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2036 - accuracy: 0.9556\n",
      "Epoch 120: val_loss improved from 0.19403 to 0.19365, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9585 - val_loss: 0.1936 - val_accuracy: 0.9643\n",
      "Epoch 121/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1879 - accuracy: 0.9623\n",
      "Epoch 121: val_loss improved from 0.19365 to 0.19352, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9617 - val_loss: 0.1935 - val_accuracy: 0.9643\n",
      "Epoch 122/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1965 - accuracy: 0.9673\n",
      "Epoch 122: val_loss improved from 0.19352 to 0.19300, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2016 - accuracy: 0.9617 - val_loss: 0.1930 - val_accuracy: 0.9643\n",
      "Epoch 123/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2168 - accuracy: 0.9429\n",
      "Epoch 123: val_loss improved from 0.19300 to 0.19232, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9457 - val_loss: 0.1923 - val_accuracy: 0.9643\n",
      "Epoch 124/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2062 - accuracy: 0.9509\n",
      "Epoch 124: val_loss improved from 0.19232 to 0.19192, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.9521 - val_loss: 0.1919 - val_accuracy: 0.9643\n",
      "Epoch 125/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2080 - accuracy: 0.9564\n",
      "Epoch 125: val_loss improved from 0.19192 to 0.19120, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2022 - accuracy: 0.9585 - val_loss: 0.1912 - val_accuracy: 0.9643\n",
      "Epoch 126/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2016 - accuracy: 0.9614\n",
      "Epoch 126: val_loss improved from 0.19120 to 0.19114, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2005 - accuracy: 0.9617 - val_loss: 0.1911 - val_accuracy: 0.9643\n",
      "Epoch 127/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.2200 - accuracy: 0.9592\n",
      "Epoch 127: val_loss improved from 0.19114 to 0.19062, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2082 - accuracy: 0.9617 - val_loss: 0.1906 - val_accuracy: 0.9702\n",
      "Epoch 128/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2010 - accuracy: 0.9633\n",
      "Epoch 128: val_loss improved from 0.19062 to 0.18997, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9649 - val_loss: 0.1900 - val_accuracy: 0.9702\n",
      "Epoch 129/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1979 - accuracy: 0.9765\n",
      "Epoch 129: val_loss improved from 0.18997 to 0.18963, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1881 - accuracy: 0.9808 - val_loss: 0.1896 - val_accuracy: 0.9702\n",
      "Epoch 130/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1931 - accuracy: 0.9614\n",
      "Epoch 130: val_loss improved from 0.18963 to 0.18905, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9649 - val_loss: 0.1890 - val_accuracy: 0.9702\n",
      "Epoch 131/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1984 - accuracy: 0.9614\n",
      "Epoch 131: val_loss improved from 0.18905 to 0.18891, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.9649 - val_loss: 0.1889 - val_accuracy: 0.9702\n",
      "Epoch 132/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2073 - accuracy: 0.9679\n",
      "Epoch 132: val_loss improved from 0.18891 to 0.18836, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2038 - accuracy: 0.9712 - val_loss: 0.1884 - val_accuracy: 0.9702\n",
      "Epoch 133/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2246 - accuracy: 0.9368\n",
      "Epoch 133: val_loss improved from 0.18836 to 0.18780, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9425 - val_loss: 0.1878 - val_accuracy: 0.9702\n",
      "Epoch 134/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1820 - accuracy: 0.9700\n",
      "Epoch 134: val_loss improved from 0.18780 to 0.18764, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9649 - val_loss: 0.1876 - val_accuracy: 0.9702\n",
      "Epoch 135/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1705 - accuracy: 0.9789\n",
      "Epoch 135: val_loss improved from 0.18764 to 0.18742, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1830 - accuracy: 0.9712 - val_loss: 0.1874 - val_accuracy: 0.9702\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.9553\n",
      "Epoch 136: val_loss improved from 0.18742 to 0.18699, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1916 - accuracy: 0.9553 - val_loss: 0.1870 - val_accuracy: 0.9702\n",
      "Epoch 137/200\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1827 - accuracy: 0.9661\n",
      "Epoch 137: val_loss improved from 0.18699 to 0.18634, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9681 - val_loss: 0.1863 - val_accuracy: 0.9702\n",
      "Epoch 138/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1945 - accuracy: 0.9698\n",
      "Epoch 138: val_loss improved from 0.18634 to 0.18544, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1967 - accuracy: 0.9649 - val_loss: 0.1854 - val_accuracy: 0.9702\n",
      "Epoch 139/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1707 - accuracy: 0.9673\n",
      "Epoch 139: val_loss improved from 0.18544 to 0.18500, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1834 - accuracy: 0.9553 - val_loss: 0.1850 - val_accuracy: 0.9702\n",
      "Epoch 140/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1759 - accuracy: 0.9741\n",
      "Epoch 140: val_loss did not improve from 0.18500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9681 - val_loss: 0.1850 - val_accuracy: 0.9702\n",
      "Epoch 141/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.2015 - accuracy: 0.9608\n",
      "Epoch 141: val_loss did not improve from 0.18500\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9617 - val_loss: 0.1850 - val_accuracy: 0.9702\n",
      "Epoch 142/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1703 - accuracy: 0.9736\n",
      "Epoch 142: val_loss improved from 0.18500 to 0.18463, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1882 - accuracy: 0.9681 - val_loss: 0.1846 - val_accuracy: 0.9702\n",
      "Epoch 143/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1940 - accuracy: 0.9556\n",
      "Epoch 143: val_loss improved from 0.18463 to 0.18369, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.9585 - val_loss: 0.1837 - val_accuracy: 0.9702\n",
      "Epoch 144/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1932 - accuracy: 0.9577\n",
      "Epoch 144: val_loss improved from 0.18369 to 0.18323, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9585 - val_loss: 0.1832 - val_accuracy: 0.9702\n",
      "Epoch 145/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2028 - accuracy: 0.9547\n",
      "Epoch 145: val_loss improved from 0.18323 to 0.18317, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9585 - val_loss: 0.1832 - val_accuracy: 0.9702\n",
      "Epoch 146/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1758 - accuracy: 0.9704\n",
      "Epoch 146: val_loss improved from 0.18317 to 0.18297, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1761 - accuracy: 0.9681 - val_loss: 0.1830 - val_accuracy: 0.9702\n",
      "Epoch 147/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2009 - accuracy: 0.9623\n",
      "Epoch 147: val_loss improved from 0.18297 to 0.18257, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2066 - accuracy: 0.9585 - val_loss: 0.1826 - val_accuracy: 0.9702\n",
      "Epoch 148/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1844 - accuracy: 0.9667\n",
      "Epoch 148: val_loss improved from 0.18257 to 0.18220, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1815 - accuracy: 0.9681 - val_loss: 0.1822 - val_accuracy: 0.9702\n",
      "Epoch 149/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9639\n",
      "Epoch 149: val_loss improved from 0.18220 to 0.18164, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1888 - accuracy: 0.9649 - val_loss: 0.1816 - val_accuracy: 0.9702\n",
      "Epoch 150/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1790 - accuracy: 0.9667\n",
      "Epoch 150: val_loss improved from 0.18164 to 0.18068, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1838 - accuracy: 0.9617 - val_loss: 0.1807 - val_accuracy: 0.9702\n",
      "Epoch 151/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2117 - accuracy: 0.9585\n",
      "Epoch 151: val_loss improved from 0.18068 to 0.17991, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9585 - val_loss: 0.1799 - val_accuracy: 0.9702\n",
      "Epoch 152/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1637 - accuracy: 0.9704\n",
      "Epoch 152: val_loss did not improve from 0.17991\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1685 - accuracy: 0.9681 - val_loss: 0.1800 - val_accuracy: 0.9702\n",
      "Epoch 153/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1748 - accuracy: 0.9733\n",
      "Epoch 153: val_loss improved from 0.17991 to 0.17983, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9712 - val_loss: 0.1798 - val_accuracy: 0.9702\n",
      "Epoch 154/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1961 - accuracy: 0.9560\n",
      "Epoch 154: val_loss improved from 0.17983 to 0.17946, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1845 - accuracy: 0.9649 - val_loss: 0.1795 - val_accuracy: 0.9702\n",
      "Epoch 155/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1690 - accuracy: 0.9667\n",
      "Epoch 155: val_loss improved from 0.17946 to 0.17907, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1715 - accuracy: 0.9649 - val_loss: 0.1791 - val_accuracy: 0.9702\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.9681\n",
      "Epoch 156: val_loss improved from 0.17907 to 0.17863, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1852 - accuracy: 0.9681 - val_loss: 0.1786 - val_accuracy: 0.9702\n",
      "Epoch 157/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1943 - accuracy: 0.9509\n",
      "Epoch 157: val_loss did not improve from 0.17863\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9489 - val_loss: 0.1787 - val_accuracy: 0.9702\n",
      "Epoch 158/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1688 - accuracy: 0.9724\n",
      "Epoch 158: val_loss improved from 0.17863 to 0.17860, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1786 - accuracy: 0.9617 - val_loss: 0.1786 - val_accuracy: 0.9702\n",
      "Epoch 159/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1601 - accuracy: 0.9750\n",
      "Epoch 159: val_loss improved from 0.17860 to 0.17797, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1867 - accuracy: 0.9649 - val_loss: 0.1780 - val_accuracy: 0.9702\n",
      "Epoch 160/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1814 - accuracy: 0.9667\n",
      "Epoch 160: val_loss improved from 0.17797 to 0.17762, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9681 - val_loss: 0.1776 - val_accuracy: 0.9702\n",
      "Epoch 161/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1722 - accuracy: 0.9579\n",
      "Epoch 161: val_loss improved from 0.17762 to 0.17735, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1679 - accuracy: 0.9617 - val_loss: 0.1774 - val_accuracy: 0.9702\n",
      "Epoch 162/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1711 - accuracy: 0.9600\n",
      "Epoch 162: val_loss improved from 0.17735 to 0.17697, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.9617 - val_loss: 0.1770 - val_accuracy: 0.9702\n",
      "Epoch 163/200\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1871 - accuracy: 0.9592\n",
      "Epoch 163: val_loss did not improve from 0.17697\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9649 - val_loss: 0.1771 - val_accuracy: 0.9702\n",
      "Epoch 164/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9731\n",
      "Epoch 164: val_loss improved from 0.17697 to 0.17665, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9712 - val_loss: 0.1766 - val_accuracy: 0.9702\n",
      "Epoch 165/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1771 - accuracy: 0.9630\n",
      "Epoch 165: val_loss improved from 0.17665 to 0.17656, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9649 - val_loss: 0.1766 - val_accuracy: 0.9702\n",
      "Epoch 166/200\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1861 - accuracy: 0.9600\n",
      "Epoch 166: val_loss improved from 0.17656 to 0.17569, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1876 - accuracy: 0.9585 - val_loss: 0.1757 - val_accuracy: 0.9702\n",
      "Epoch 167/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1624 - accuracy: 0.9709\n",
      "Epoch 167: val_loss improved from 0.17569 to 0.17555, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1636 - accuracy: 0.9712 - val_loss: 0.1755 - val_accuracy: 0.9702\n",
      "Epoch 168/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1586 - accuracy: 0.9741\n",
      "Epoch 168: val_loss improved from 0.17555 to 0.17541, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1701 - accuracy: 0.9681 - val_loss: 0.1754 - val_accuracy: 0.9702\n",
      "Epoch 169/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1790 - accuracy: 0.9623\n",
      "Epoch 169: val_loss improved from 0.17541 to 0.17528, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9681 - val_loss: 0.1753 - val_accuracy: 0.9702\n",
      "Epoch 170/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1774 - accuracy: 0.9647\n",
      "Epoch 170: val_loss improved from 0.17528 to 0.17486, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1727 - accuracy: 0.9649 - val_loss: 0.1749 - val_accuracy: 0.9702\n",
      "Epoch 171/200\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.1923 - accuracy: 0.9617\n",
      "Epoch 171: val_loss did not improve from 0.17486\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1796 - accuracy: 0.9681 - val_loss: 0.1751 - val_accuracy: 0.9702\n",
      "Epoch 172/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1632 - accuracy: 0.9745\n",
      "Epoch 172: val_loss improved from 0.17486 to 0.17448, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9776 - val_loss: 0.1745 - val_accuracy: 0.9702\n",
      "Epoch 173/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1732 - accuracy: 0.9600\n",
      "Epoch 173: val_loss did not improve from 0.17448\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9553 - val_loss: 0.1746 - val_accuracy: 0.9702\n",
      "Epoch 174/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1677 - accuracy: 0.9698\n",
      "Epoch 174: val_loss did not improve from 0.17448\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1751 - accuracy: 0.9649 - val_loss: 0.1747 - val_accuracy: 0.9702\n",
      "Epoch 175/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1637 - accuracy: 0.9733\n",
      "Epoch 175: val_loss improved from 0.17448 to 0.17423, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.9712 - val_loss: 0.1742 - val_accuracy: 0.9702\n",
      "Epoch 176/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1691 - accuracy: 0.9700\n",
      "Epoch 176: val_loss improved from 0.17423 to 0.17368, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1728 - accuracy: 0.9681 - val_loss: 0.1737 - val_accuracy: 0.9702\n",
      "Epoch 177/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1540 - accuracy: 0.9815\n",
      "Epoch 177: val_loss improved from 0.17368 to 0.17276, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1550 - accuracy: 0.9808 - val_loss: 0.1728 - val_accuracy: 0.9702\n",
      "Epoch 178/200\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1684 - accuracy: 0.9704\n",
      "Epoch 178: val_loss did not improve from 0.17276\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9681 - val_loss: 0.1728 - val_accuracy: 0.9702\n",
      "Epoch 179/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1659 - accuracy: 0.9736\n",
      "Epoch 179: val_loss did not improve from 0.17276\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9776 - val_loss: 0.1730 - val_accuracy: 0.9702\n",
      "Epoch 180/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1639 - accuracy: 0.9655\n",
      "Epoch 180: val_loss did not improve from 0.17276\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9681 - val_loss: 0.1729 - val_accuracy: 0.9702\n",
      "Epoch 181/200\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1571 - accuracy: 0.9774\n",
      "Epoch 181: val_loss improved from 0.17276 to 0.17249, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9776 - val_loss: 0.1725 - val_accuracy: 0.9702\n",
      "Epoch 182/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1768 - accuracy: 0.9672\n",
      "Epoch 182: val_loss did not improve from 0.17249\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9681 - val_loss: 0.1726 - val_accuracy: 0.9702\n",
      "Epoch 183/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1681 - accuracy: 0.9745\n",
      "Epoch 183: val_loss improved from 0.17249 to 0.17236, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9776 - val_loss: 0.1724 - val_accuracy: 0.9702\n",
      "Epoch 184/200\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9672\n",
      "Epoch 184: val_loss did not improve from 0.17236\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9681 - val_loss: 0.1725 - val_accuracy: 0.9702\n",
      "Epoch 185/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1653 - accuracy: 0.9733\n",
      "Epoch 185: val_loss did not improve from 0.17236\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1622 - accuracy: 0.9744 - val_loss: 0.1725 - val_accuracy: 0.9702\n",
      "Epoch 186/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1581 - accuracy: 0.9789\n",
      "Epoch 186: val_loss improved from 0.17236 to 0.17233, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1543 - accuracy: 0.9808 - val_loss: 0.1723 - val_accuracy: 0.9702\n",
      "Epoch 187/200\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1945 - accuracy: 0.9439\n",
      "Epoch 187: val_loss improved from 0.17233 to 0.17207, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1857 - accuracy: 0.9489 - val_loss: 0.1721 - val_accuracy: 0.9702\n",
      "Epoch 188/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1628 - accuracy: 0.9608\n",
      "Epoch 188: val_loss improved from 0.17207 to 0.17154, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9649 - val_loss: 0.1715 - val_accuracy: 0.9702\n",
      "Epoch 189/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1547 - accuracy: 0.9692\n",
      "Epoch 189: val_loss did not improve from 0.17154\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.9681 - val_loss: 0.1717 - val_accuracy: 0.9702\n",
      "Epoch 190/200\n",
      "48/63 [=====================>........] - ETA: 0s - loss: 0.1749 - accuracy: 0.9708\n",
      "Epoch 190: val_loss improved from 0.17154 to 0.17153, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1628 - accuracy: 0.9776 - val_loss: 0.1715 - val_accuracy: 0.9702\n",
      "Epoch 191/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1473 - accuracy: 0.9828\n",
      "Epoch 191: val_loss improved from 0.17153 to 0.17083, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9808 - val_loss: 0.1708 - val_accuracy: 0.9702\n",
      "Epoch 192/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1658 - accuracy: 0.9724\n",
      "Epoch 192: val_loss improved from 0.17083 to 0.17063, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9649 - val_loss: 0.1706 - val_accuracy: 0.9702\n",
      "Epoch 193/200\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1533 - accuracy: 0.9633\n",
      "Epoch 193: val_loss improved from 0.17063 to 0.17022, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.9649 - val_loss: 0.1702 - val_accuracy: 0.9702\n",
      "Epoch 194/200\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1755 - accuracy: 0.9552\n",
      "Epoch 194: val_loss improved from 0.17022 to 0.16924, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1713 - accuracy: 0.9585 - val_loss: 0.1692 - val_accuracy: 0.9702\n",
      "Epoch 195/200\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1529 - accuracy: 0.9786\n",
      "Epoch 195: val_loss improved from 0.16924 to 0.16910, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9808 - val_loss: 0.1691 - val_accuracy: 0.9702\n",
      "Epoch 196/200\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1703 - accuracy: 0.9608\n",
      "Epoch 196: val_loss improved from 0.16910 to 0.16883, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1600 - accuracy: 0.9681 - val_loss: 0.1688 - val_accuracy: 0.9702\n",
      "Epoch 197/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1658 - accuracy: 0.9692\n",
      "Epoch 197: val_loss did not improve from 0.16883\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9712 - val_loss: 0.1689 - val_accuracy: 0.9702\n",
      "Epoch 198/200\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1380 - accuracy: 0.9808\n",
      "Epoch 198: val_loss did not improve from 0.16883\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1514 - accuracy: 0.9808 - val_loss: 0.1689 - val_accuracy: 0.9702\n",
      "Epoch 199/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1667 - accuracy: 0.9709\n",
      "Epoch 199: val_loss improved from 0.16883 to 0.16797, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1598 - accuracy: 0.9744 - val_loss: 0.1680 - val_accuracy: 0.9702\n",
      "Epoch 200/200\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1539 - accuracy: 0.9745\n",
      "Epoch 200: val_loss improved from 0.16797 to 0.16790, saving model to model_checkpoint\\GRU_1 layer with dropout_Adam.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1605 - accuracy: 0.9744 - val_loss: 0.1679 - val_accuracy: 0.9702\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_22 (GRU)                (None, 32)                11520     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,553\n",
      "Trainable params: 11,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9702\n",
      "Test Loss: 0.16790375113487244\n",
      "Test Accuracy: 0.9702380895614624\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'GRU_1 layer with dropout_Adam.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, \n",
    "                     dropout=0.3,\n",
    "                     recurrent_dropout=0.3,\n",
    "                     input_shape=(None, x_train.shape[-1]),\n",
    "                     activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=200, validation_data=(x_val, y_val), callbacks=[callbacks_list])\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU 2 layers SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.7068 - accuracy: 0.4102\n",
      "Epoch 1: val_loss improved from inf to 0.70381, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 6s 19ms/step - loss: 0.7039 - accuracy: 0.4281 - val_loss: 0.7038 - val_accuracy: 0.3810 - lr: 0.0010\n",
      "Epoch 2/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.6983 - accuracy: 0.4755\n",
      "Epoch 2: val_loss improved from 0.70381 to 0.69240, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 3/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.6826 - accuracy: 0.5846\n",
      "Epoch 3: val_loss improved from 0.69240 to 0.68137, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.5847 - val_loss: 0.6814 - val_accuracy: 0.5655 - lr: 0.0010\n",
      "Epoch 4/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.6740 - accuracy: 0.6107\n",
      "Epoch 4: val_loss improved from 0.68137 to 0.67066, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6715 - accuracy: 0.6390 - val_loss: 0.6707 - val_accuracy: 0.6429 - lr: 0.0010\n",
      "Epoch 5/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.6626 - accuracy: 0.6689\n",
      "Epoch 5: val_loss improved from 0.67066 to 0.66024, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6614 - accuracy: 0.6741 - val_loss: 0.6602 - val_accuracy: 0.7321 - lr: 0.0010\n",
      "Epoch 6/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.6510 - accuracy: 0.7400\n",
      "Epoch 6: val_loss improved from 0.66024 to 0.65012, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6515 - accuracy: 0.7380 - val_loss: 0.6501 - val_accuracy: 0.7619 - lr: 0.0010\n",
      "Epoch 7/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.7859\n",
      "Epoch 7: val_loss improved from 0.65012 to 0.64019, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.6419 - accuracy: 0.7859 - val_loss: 0.6402 - val_accuracy: 0.8214 - lr: 0.0010\n",
      "Epoch 8/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.6285 - accuracy: 0.8321\n",
      "Epoch 8: val_loss improved from 0.64019 to 0.63058, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6325 - accuracy: 0.8179 - val_loss: 0.6306 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 9/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.6220 - accuracy: 0.8400\n",
      "Epoch 9: val_loss improved from 0.63058 to 0.62104, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6234 - accuracy: 0.8339 - val_loss: 0.6210 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 10/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.6154 - accuracy: 0.8500\n",
      "Epoch 10: val_loss improved from 0.62104 to 0.61166, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.8562 - val_loss: 0.6117 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 11/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.6055 - accuracy: 0.8645\n",
      "Epoch 11: val_loss improved from 0.61166 to 0.60247, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6055 - accuracy: 0.8658 - val_loss: 0.6025 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 12/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.5953 - accuracy: 0.8689\n",
      "Epoch 12: val_loss improved from 0.60247 to 0.59349, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.5967 - accuracy: 0.8658 - val_loss: 0.5935 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 13/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.5901 - accuracy: 0.8691\n",
      "Epoch 13: val_loss improved from 0.59349 to 0.58456, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5882 - accuracy: 0.8690 - val_loss: 0.5846 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 14/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.8850\n",
      "Epoch 14: val_loss improved from 0.58456 to 0.57579, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.8850 - val_loss: 0.5758 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 15/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.5736 - accuracy: 0.8814\n",
      "Epoch 15: val_loss improved from 0.57579 to 0.56720, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.8882 - val_loss: 0.5672 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 16/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.8914\n",
      "Epoch 16: val_loss improved from 0.56720 to 0.55872, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.8914 - val_loss: 0.5587 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 17/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.5547 - accuracy: 0.8903\n",
      "Epoch 17: val_loss improved from 0.55872 to 0.55041, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5550 - accuracy: 0.8914 - val_loss: 0.5504 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 18/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.5471 - accuracy: 0.8982\n",
      "Epoch 18: val_loss improved from 0.55041 to 0.54228, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5471 - accuracy: 0.8978 - val_loss: 0.5423 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 19/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.5371 - accuracy: 0.9067\n",
      "Epoch 19: val_loss improved from 0.54228 to 0.53435, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5393 - accuracy: 0.9010 - val_loss: 0.5344 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 20/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.5334 - accuracy: 0.9053\n",
      "Epoch 20: val_loss improved from 0.53435 to 0.52646, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.9042 - val_loss: 0.5265 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 21/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.5226 - accuracy: 0.9097\n",
      "Epoch 21: val_loss improved from 0.52646 to 0.51881, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.5241 - accuracy: 0.9042 - val_loss: 0.5188 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 22/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.5181 - accuracy: 0.8967\n",
      "Epoch 22: val_loss improved from 0.51881 to 0.51122, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.9010 - val_loss: 0.5112 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 23/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.5109 - accuracy: 0.9037\n",
      "Epoch 23: val_loss improved from 0.51122 to 0.50377, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.5094 - accuracy: 0.9073 - val_loss: 0.5038 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 24/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.5049 - accuracy: 0.9053\n",
      "Epoch 24: val_loss improved from 0.50377 to 0.49646, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5022 - accuracy: 0.9073 - val_loss: 0.4965 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 25/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.4934 - accuracy: 0.9082\n",
      "Epoch 25: val_loss improved from 0.49646 to 0.48928, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4952 - accuracy: 0.9073 - val_loss: 0.4893 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 26/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.4859 - accuracy: 0.9127\n",
      "Epoch 26: val_loss improved from 0.48928 to 0.48220, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.4882 - accuracy: 0.9073 - val_loss: 0.4822 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 27/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.4797 - accuracy: 0.9172\n",
      "Epoch 27: val_loss improved from 0.48220 to 0.47531, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.9105 - val_loss: 0.4753 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 28/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.4749 - accuracy: 0.9085\n",
      "Epoch 28: val_loss improved from 0.47531 to 0.46849, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.4747 - accuracy: 0.9105 - val_loss: 0.4685 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 29/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.4639 - accuracy: 0.9148\n",
      "Epoch 29: val_loss improved from 0.46849 to 0.46181, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.4681 - accuracy: 0.9105 - val_loss: 0.4618 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 30/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.4637 - accuracy: 0.9088\n",
      "Epoch 30: val_loss improved from 0.46181 to 0.45531, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.9105 - val_loss: 0.4553 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 31/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.4428 - accuracy: 0.9373\n",
      "Epoch 31: val_loss improved from 0.45531 to 0.44894, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.9105 - val_loss: 0.4489 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 32/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.4516 - accuracy: 0.9082\n",
      "Epoch 32: val_loss improved from 0.44894 to 0.44263, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.9105 - val_loss: 0.4426 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 33/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.4414 - accuracy: 0.9098\n",
      "Epoch 33: val_loss improved from 0.44263 to 0.43644, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.9105 - val_loss: 0.4364 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 34/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.4327 - accuracy: 0.9193\n",
      "Epoch 34: val_loss improved from 0.43644 to 0.43040, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.9105 - val_loss: 0.4304 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 35/600\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.4391 - accuracy: 0.9021\n",
      "Epoch 35: val_loss improved from 0.43040 to 0.42447, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.9105 - val_loss: 0.4245 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 36/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.9115\n",
      "Epoch 36: val_loss improved from 0.42447 to 0.41868, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9105 - val_loss: 0.4187 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 37/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.4246 - accuracy: 0.9034\n",
      "Epoch 37: val_loss improved from 0.41868 to 0.41299, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.9105 - val_loss: 0.4130 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 38/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.4128 - accuracy: 0.9143\n",
      "Epoch 38: val_loss improved from 0.41299 to 0.40745, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.9105 - val_loss: 0.4074 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 39/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.4092 - accuracy: 0.9115\n",
      "Epoch 39: val_loss improved from 0.40745 to 0.40200, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.9137 - val_loss: 0.4020 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 40/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.4068 - accuracy: 0.9133\n",
      "Epoch 40: val_loss improved from 0.40200 to 0.39670, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.9137 - val_loss: 0.3967 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 41/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.4027 - accuracy: 0.9100\n",
      "Epoch 41: val_loss improved from 0.39670 to 0.39152, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.9137 - val_loss: 0.3915 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 42/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.3942 - accuracy: 0.9119\n",
      "Epoch 42: val_loss improved from 0.39152 to 0.38646, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.9137 - val_loss: 0.3865 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 43/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.3924 - accuracy: 0.9098\n",
      "Epoch 43: val_loss improved from 0.38646 to 0.38151, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.9137 - val_loss: 0.3815 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 44/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.3827 - accuracy: 0.9119\n",
      "Epoch 44: val_loss improved from 0.38151 to 0.37675, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.9137 - val_loss: 0.3767 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 45/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.3747 - accuracy: 0.9172\n",
      "Epoch 45: val_loss improved from 0.37675 to 0.37206, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.9137 - val_loss: 0.3721 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 46/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.3761 - accuracy: 0.9167\n",
      "Epoch 46: val_loss improved from 0.37206 to 0.36746, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.9169 - val_loss: 0.3675 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 47/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.3743 - accuracy: 0.9119\n",
      "Epoch 47: val_loss improved from 0.36746 to 0.36297, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.9169 - val_loss: 0.3630 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 48/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3702 - accuracy: 0.9164\n",
      "Epoch 48: val_loss improved from 0.36297 to 0.35858, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.9169 - val_loss: 0.3586 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 49/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3606 - accuracy: 0.9245\n",
      "Epoch 49: val_loss improved from 0.35858 to 0.35430, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.9169 - val_loss: 0.3543 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 50/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.9246\n",
      "Epoch 50: val_loss improved from 0.35430 to 0.35014, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.9169 - val_loss: 0.3501 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 51/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.3533 - accuracy: 0.9170\n",
      "Epoch 51: val_loss improved from 0.35014 to 0.34607, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.9201 - val_loss: 0.3461 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 52/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.3545 - accuracy: 0.9172\n",
      "Epoch 52: val_loss improved from 0.34607 to 0.34212, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.9201 - val_loss: 0.3421 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 53/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.3479 - accuracy: 0.9186\n",
      "Epoch 53: val_loss improved from 0.34212 to 0.33824, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3457 - accuracy: 0.9201 - val_loss: 0.3382 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 54/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3461 - accuracy: 0.9193\n",
      "Epoch 54: val_loss improved from 0.33824 to 0.33445, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3419 - accuracy: 0.9233 - val_loss: 0.3345 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 55/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.9213\n",
      "Epoch 55: val_loss improved from 0.33445 to 0.33075, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 0.9233 - val_loss: 0.3308 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 56/600\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.3350 - accuracy: 0.9234\n",
      "Epoch 56: val_loss improved from 0.33075 to 0.32713, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.9233 - val_loss: 0.3271 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 57/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.3358 - accuracy: 0.9200\n",
      "Epoch 57: val_loss improved from 0.32713 to 0.32361, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3310 - accuracy: 0.9233 - val_loss: 0.3236 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 58/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.9233\n",
      "Epoch 58: val_loss improved from 0.32361 to 0.32017, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.9233 - val_loss: 0.3202 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 59/600\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.3195 - accuracy: 0.9277\n",
      "Epoch 59: val_loss improved from 0.32017 to 0.31682, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3242 - accuracy: 0.9233 - val_loss: 0.3168 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 60/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.3220 - accuracy: 0.9226\n",
      "Epoch 60: val_loss improved from 0.31682 to 0.31354, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3208 - accuracy: 0.9233 - val_loss: 0.3135 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 61/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3122 - accuracy: 0.9228\n",
      "Epoch 61: val_loss improved from 0.31354 to 0.31039, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.9233 - val_loss: 0.3104 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 62/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.9226\n",
      "Epoch 62: val_loss improved from 0.31039 to 0.30727, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3145 - accuracy: 0.9233 - val_loss: 0.3073 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 63/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.3084 - accuracy: 0.9267\n",
      "Epoch 63: val_loss improved from 0.30727 to 0.30423, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3114 - accuracy: 0.9233 - val_loss: 0.3042 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 64/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.3088 - accuracy: 0.9213\n",
      "Epoch 64: val_loss improved from 0.30423 to 0.30126, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3084 - accuracy: 0.9233 - val_loss: 0.3013 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 65/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.3122 - accuracy: 0.9158\n",
      "Epoch 65: val_loss improved from 0.30126 to 0.29836, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3055 - accuracy: 0.9233 - val_loss: 0.2984 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 66/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.3005 - accuracy: 0.9276\n",
      "Epoch 66: val_loss improved from 0.29836 to 0.29553, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3026 - accuracy: 0.9233 - val_loss: 0.2955 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 67/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.9226\n",
      "Epoch 67: val_loss improved from 0.29553 to 0.29278, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2998 - accuracy: 0.9233 - val_loss: 0.2928 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 68/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.3024 - accuracy: 0.9120\n",
      "Epoch 68: val_loss improved from 0.29278 to 0.29008, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2971 - accuracy: 0.9233 - val_loss: 0.2901 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 69/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2918 - accuracy: 0.9192\n",
      "Epoch 69: val_loss improved from 0.29008 to 0.28745, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2944 - accuracy: 0.9233 - val_loss: 0.2875 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 70/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2897 - accuracy: 0.9254\n",
      "Epoch 70: val_loss improved from 0.28745 to 0.28489, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2918 - accuracy: 0.9233 - val_loss: 0.2849 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 71/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2905 - accuracy: 0.9226\n",
      "Epoch 71: val_loss improved from 0.28489 to 0.28239, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2893 - accuracy: 0.9233 - val_loss: 0.2824 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 72/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2886 - accuracy: 0.9246\n",
      "Epoch 72: val_loss improved from 0.28239 to 0.27995, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2868 - accuracy: 0.9265 - val_loss: 0.2800 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 73/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2848 - accuracy: 0.9254\n",
      "Epoch 73: val_loss improved from 0.27995 to 0.27757, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2844 - accuracy: 0.9265 - val_loss: 0.2776 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 74/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2791 - accuracy: 0.9276\n",
      "Epoch 74: val_loss improved from 0.27757 to 0.27525, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2820 - accuracy: 0.9265 - val_loss: 0.2752 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 75/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2886 - accuracy: 0.9214\n",
      "Epoch 75: val_loss improved from 0.27525 to 0.27296, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2797 - accuracy: 0.9265 - val_loss: 0.2730 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 76/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2848 - accuracy: 0.9228\n",
      "Epoch 76: val_loss improved from 0.27296 to 0.27074, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2774 - accuracy: 0.9265 - val_loss: 0.2707 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 77/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2781 - accuracy: 0.9231\n",
      "Epoch 77: val_loss improved from 0.27074 to 0.26857, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2752 - accuracy: 0.9265 - val_loss: 0.2686 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 78/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2834 - accuracy: 0.9222\n",
      "Epoch 78: val_loss improved from 0.26857 to 0.26645, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2731 - accuracy: 0.9265 - val_loss: 0.2664 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 79/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2725 - accuracy: 0.9259\n",
      "Epoch 79: val_loss improved from 0.26645 to 0.26439, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2709 - accuracy: 0.9265 - val_loss: 0.2644 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 80/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2810 - accuracy: 0.9192\n",
      "Epoch 80: val_loss improved from 0.26439 to 0.26236, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2689 - accuracy: 0.9265 - val_loss: 0.2624 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 81/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2713 - accuracy: 0.9245\n",
      "Epoch 81: val_loss improved from 0.26236 to 0.26038, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2668 - accuracy: 0.9265 - val_loss: 0.2604 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 82/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2547 - accuracy: 0.9346\n",
      "Epoch 82: val_loss improved from 0.26038 to 0.25846, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2648 - accuracy: 0.9265 - val_loss: 0.2585 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 83/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2624 - accuracy: 0.9333\n",
      "Epoch 83: val_loss improved from 0.25846 to 0.25656, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2629 - accuracy: 0.9297 - val_loss: 0.2566 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 84/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2598 - accuracy: 0.9300\n",
      "Epoch 84: val_loss improved from 0.25656 to 0.25471, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.2610 - accuracy: 0.9297 - val_loss: 0.2547 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 85/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.9297\n",
      "Epoch 85: val_loss improved from 0.25471 to 0.25289, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2592 - accuracy: 0.9297 - val_loss: 0.2529 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 86/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2593 - accuracy: 0.9279\n",
      "Epoch 86: val_loss improved from 0.25289 to 0.25111, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.2573 - accuracy: 0.9297 - val_loss: 0.2511 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 87/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2593 - accuracy: 0.9298\n",
      "Epoch 87: val_loss improved from 0.25111 to 0.24937, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2555 - accuracy: 0.9329 - val_loss: 0.2494 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 88/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.9329\n",
      "Epoch 88: val_loss improved from 0.24937 to 0.24767, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2538 - accuracy: 0.9329 - val_loss: 0.2477 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 89/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2502 - accuracy: 0.9346\n",
      "Epoch 89: val_loss improved from 0.24767 to 0.24603, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2521 - accuracy: 0.9329 - val_loss: 0.2460 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 90/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2561 - accuracy: 0.9300\n",
      "Epoch 90: val_loss improved from 0.24603 to 0.24439, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2504 - accuracy: 0.9329 - val_loss: 0.2444 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 91/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2523 - accuracy: 0.9345\n",
      "Epoch 91: val_loss improved from 0.24439 to 0.24280, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.9329 - val_loss: 0.2428 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 92/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2335 - accuracy: 0.9379\n",
      "Epoch 92: val_loss improved from 0.24280 to 0.24123, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2471 - accuracy: 0.9329 - val_loss: 0.2412 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 93/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2533 - accuracy: 0.9298\n",
      "Epoch 93: val_loss improved from 0.24123 to 0.23969, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2456 - accuracy: 0.9329 - val_loss: 0.2397 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 94/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2484 - accuracy: 0.9286\n",
      "Epoch 94: val_loss improved from 0.23969 to 0.23818, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2440 - accuracy: 0.9329 - val_loss: 0.2382 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 95/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.9311\n",
      "Epoch 95: val_loss improved from 0.23818 to 0.23671, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.9329 - val_loss: 0.2367 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 96/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.2249 - accuracy: 0.9434\n",
      "Epoch 96: val_loss improved from 0.23671 to 0.23529, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2410 - accuracy: 0.9329 - val_loss: 0.2353 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 97/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2536 - accuracy: 0.9296\n",
      "Epoch 97: val_loss improved from 0.23529 to 0.23387, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2395 - accuracy: 0.9329 - val_loss: 0.2339 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 98/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2373 - accuracy: 0.9309\n",
      "Epoch 98: val_loss improved from 0.23387 to 0.23247, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2381 - accuracy: 0.9329 - val_loss: 0.2325 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 99/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2296 - accuracy: 0.9379\n",
      "Epoch 99: val_loss improved from 0.23247 to 0.23111, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2367 - accuracy: 0.9329 - val_loss: 0.2311 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 100/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2370 - accuracy: 0.9333\n",
      "Epoch 100: val_loss improved from 0.23111 to 0.22976, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2353 - accuracy: 0.9329 - val_loss: 0.2298 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 101/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9323\n",
      "Epoch 101: val_loss improved from 0.22976 to 0.22845, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2339 - accuracy: 0.9329 - val_loss: 0.2284 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 102/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2290 - accuracy: 0.9356\n",
      "Epoch 102: val_loss improved from 0.22845 to 0.22716, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2326 - accuracy: 0.9329 - val_loss: 0.2272 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 103/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2338 - accuracy: 0.9273\n",
      "Epoch 103: val_loss improved from 0.22716 to 0.22588, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2312 - accuracy: 0.9329 - val_loss: 0.2259 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 104/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9355\n",
      "Epoch 104: val_loss improved from 0.22588 to 0.22464, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2300 - accuracy: 0.9361 - val_loss: 0.2246 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 105/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2282 - accuracy: 0.9390\n",
      "Epoch 105: val_loss improved from 0.22464 to 0.22344, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2287 - accuracy: 0.9361 - val_loss: 0.2234 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 106/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2240 - accuracy: 0.9400\n",
      "Epoch 106: val_loss improved from 0.22344 to 0.22223, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2274 - accuracy: 0.9361 - val_loss: 0.2222 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 107/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2280 - accuracy: 0.9367\n",
      "Epoch 107: val_loss improved from 0.22223 to 0.22104, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2262 - accuracy: 0.9361 - val_loss: 0.2210 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 108/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2280 - accuracy: 0.9356\n",
      "Epoch 108: val_loss improved from 0.22104 to 0.21988, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2250 - accuracy: 0.9361 - val_loss: 0.2199 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 109/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2210 - accuracy: 0.9407\n",
      "Epoch 109: val_loss improved from 0.21988 to 0.21876, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9393 - val_loss: 0.2188 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 110/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2280 - accuracy: 0.9345\n",
      "Epoch 110: val_loss improved from 0.21876 to 0.21763, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2227 - accuracy: 0.9393 - val_loss: 0.2176 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 111/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2225 - accuracy: 0.9423\n",
      "Epoch 111: val_loss improved from 0.21763 to 0.21653, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.9393 - val_loss: 0.2165 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 112/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.2283 - accuracy: 0.9356\n",
      "Epoch 112: val_loss improved from 0.21653 to 0.21544, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2204 - accuracy: 0.9393 - val_loss: 0.2154 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 113/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2122 - accuracy: 0.9423\n",
      "Epoch 113: val_loss improved from 0.21544 to 0.21438, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2193 - accuracy: 0.9393 - val_loss: 0.2144 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 114/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2206 - accuracy: 0.9385\n",
      "Epoch 114: val_loss improved from 0.21438 to 0.21333, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2182 - accuracy: 0.9393 - val_loss: 0.2133 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 115/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9393\n",
      "Epoch 115: val_loss improved from 0.21333 to 0.21230, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2171 - accuracy: 0.9393 - val_loss: 0.2123 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 116/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9393\n",
      "Epoch 116: val_loss improved from 0.21230 to 0.21128, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2160 - accuracy: 0.9393 - val_loss: 0.2113 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 117/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.9393\n",
      "Epoch 117: val_loss improved from 0.21128 to 0.21028, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2150 - accuracy: 0.9393 - val_loss: 0.2103 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 118/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2104 - accuracy: 0.9414\n",
      "Epoch 118: val_loss improved from 0.21028 to 0.20929, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2140 - accuracy: 0.9393 - val_loss: 0.2093 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 119/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.2117 - accuracy: 0.9379\n",
      "Epoch 119: val_loss improved from 0.20929 to 0.20831, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2129 - accuracy: 0.9393 - val_loss: 0.2083 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 120/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2083 - accuracy: 0.9429\n",
      "Epoch 120: val_loss improved from 0.20831 to 0.20735, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2119 - accuracy: 0.9393 - val_loss: 0.2074 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 121/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2150 - accuracy: 0.9400\n",
      "Epoch 121: val_loss improved from 0.20735 to 0.20641, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2110 - accuracy: 0.9425 - val_loss: 0.2064 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 122/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9400\n",
      "Epoch 122: val_loss improved from 0.20641 to 0.20549, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2100 - accuracy: 0.9425 - val_loss: 0.2055 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 123/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2079 - accuracy: 0.9444\n",
      "Epoch 123: val_loss improved from 0.20549 to 0.20457, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2090 - accuracy: 0.9425 - val_loss: 0.2046 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 124/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2209 - accuracy: 0.9345\n",
      "Epoch 124: val_loss improved from 0.20457 to 0.20367, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.2081 - accuracy: 0.9425 - val_loss: 0.2037 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 125/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2099 - accuracy: 0.9410\n",
      "Epoch 125: val_loss improved from 0.20367 to 0.20278, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.2072 - accuracy: 0.9425 - val_loss: 0.2028 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 126/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9443\n",
      "Epoch 126: val_loss improved from 0.20278 to 0.20191, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2063 - accuracy: 0.9425 - val_loss: 0.2019 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 127/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9419\n",
      "Epoch 127: val_loss improved from 0.20191 to 0.20105, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2054 - accuracy: 0.9425 - val_loss: 0.2010 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 128/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.2125 - accuracy: 0.9382\n",
      "Epoch 128: val_loss improved from 0.20105 to 0.20020, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2045 - accuracy: 0.9425 - val_loss: 0.2002 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 129/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2043 - accuracy: 0.9360\n",
      "Epoch 129: val_loss improved from 0.20020 to 0.19936, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2036 - accuracy: 0.9425 - val_loss: 0.1994 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 130/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.9419\n",
      "Epoch 130: val_loss improved from 0.19936 to 0.19853, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2027 - accuracy: 0.9425 - val_loss: 0.1985 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 131/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.2035 - accuracy: 0.9444\n",
      "Epoch 131: val_loss improved from 0.19853 to 0.19772, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2019 - accuracy: 0.9425 - val_loss: 0.1977 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 132/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1947 - accuracy: 0.9443\n",
      "Epoch 132: val_loss improved from 0.19772 to 0.19693, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2010 - accuracy: 0.9425 - val_loss: 0.1969 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 133/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1870 - accuracy: 0.9509\n",
      "Epoch 133: val_loss improved from 0.19693 to 0.19614, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2002 - accuracy: 0.9425 - val_loss: 0.1961 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 134/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.2074 - accuracy: 0.9423\n",
      "Epoch 134: val_loss improved from 0.19614 to 0.19535, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1994 - accuracy: 0.9425 - val_loss: 0.1954 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 135/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2022 - accuracy: 0.9400\n",
      "Epoch 135: val_loss improved from 0.19535 to 0.19458, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1986 - accuracy: 0.9425 - val_loss: 0.1946 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 136/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1913 - accuracy: 0.9500\n",
      "Epoch 136: val_loss improved from 0.19458 to 0.19381, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1978 - accuracy: 0.9425 - val_loss: 0.1938 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 137/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1877 - accuracy: 0.9455\n",
      "Epoch 137: val_loss improved from 0.19381 to 0.19306, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1970 - accuracy: 0.9425 - val_loss: 0.1931 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 138/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.2012 - accuracy: 0.9400\n",
      "Epoch 138: val_loss improved from 0.19306 to 0.19231, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1963 - accuracy: 0.9425 - val_loss: 0.1923 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 139/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1905 - accuracy: 0.9451\n",
      "Epoch 139: val_loss improved from 0.19231 to 0.19157, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1955 - accuracy: 0.9425 - val_loss: 0.1916 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 140/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9419\n",
      "Epoch 140: val_loss improved from 0.19157 to 0.19084, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.9425 - val_loss: 0.1908 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 141/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1899 - accuracy: 0.9491\n",
      "Epoch 141: val_loss improved from 0.19084 to 0.19011, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1940 - accuracy: 0.9425 - val_loss: 0.1901 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 142/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.2000 - accuracy: 0.9368\n",
      "Epoch 142: val_loss improved from 0.19011 to 0.18939, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1932 - accuracy: 0.9425 - val_loss: 0.1894 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 143/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1848 - accuracy: 0.9474\n",
      "Epoch 143: val_loss improved from 0.18939 to 0.18869, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1925 - accuracy: 0.9425 - val_loss: 0.1887 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 144/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9410\n",
      "Epoch 144: val_loss improved from 0.18869 to 0.18800, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1918 - accuracy: 0.9425 - val_loss: 0.1880 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 145/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1602 - accuracy: 0.9520\n",
      "Epoch 145: val_loss improved from 0.18800 to 0.18731, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1910 - accuracy: 0.9425 - val_loss: 0.1873 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 146/600\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1888 - accuracy: 0.9469\n",
      "Epoch 146: val_loss improved from 0.18731 to 0.18665, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1903 - accuracy: 0.9425 - val_loss: 0.1866 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 147/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1733 - accuracy: 0.9500\n",
      "Epoch 147: val_loss improved from 0.18665 to 0.18598, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1897 - accuracy: 0.9425 - val_loss: 0.1860 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 148/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1764 - accuracy: 0.9490\n",
      "Epoch 148: val_loss improved from 0.18598 to 0.18532, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1890 - accuracy: 0.9425 - val_loss: 0.1853 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 149/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1902 - accuracy: 0.9424\n",
      "Epoch 149: val_loss improved from 0.18532 to 0.18466, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1883 - accuracy: 0.9425 - val_loss: 0.1847 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 150/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.9419\n",
      "Epoch 150: val_loss improved from 0.18466 to 0.18402, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1876 - accuracy: 0.9425 - val_loss: 0.1840 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 151/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1921 - accuracy: 0.9390\n",
      "Epoch 151: val_loss improved from 0.18402 to 0.18338, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1869 - accuracy: 0.9425 - val_loss: 0.1834 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 152/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1817 - accuracy: 0.9433\n",
      "Epoch 152: val_loss improved from 0.18338 to 0.18275, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1863 - accuracy: 0.9425 - val_loss: 0.1827 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 153/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1924 - accuracy: 0.9368\n",
      "Epoch 153: val_loss improved from 0.18275 to 0.18213, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1856 - accuracy: 0.9425 - val_loss: 0.1821 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 154/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1820 - accuracy: 0.9444\n",
      "Epoch 154: val_loss improved from 0.18213 to 0.18151, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1850 - accuracy: 0.9425 - val_loss: 0.1815 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 155/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.9483\n",
      "Epoch 155: val_loss improved from 0.18151 to 0.18090, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1844 - accuracy: 0.9457 - val_loss: 0.1809 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 156/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9484\n",
      "Epoch 156: val_loss improved from 0.18090 to 0.18028, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1837 - accuracy: 0.9457 - val_loss: 0.1803 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 157/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1853 - accuracy: 0.9448\n",
      "Epoch 157: val_loss improved from 0.18028 to 0.17968, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1831 - accuracy: 0.9457 - val_loss: 0.1797 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 158/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1884 - accuracy: 0.9424\n",
      "Epoch 158: val_loss improved from 0.17968 to 0.17909, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1825 - accuracy: 0.9457 - val_loss: 0.1791 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 159/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1833 - accuracy: 0.9491\n",
      "Epoch 159: val_loss improved from 0.17909 to 0.17852, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1819 - accuracy: 0.9457 - val_loss: 0.1785 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 160/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1751 - accuracy: 0.9455\n",
      "Epoch 160: val_loss improved from 0.17852 to 0.17793, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1813 - accuracy: 0.9457 - val_loss: 0.1779 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 161/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9457\n",
      "Epoch 161: val_loss improved from 0.17793 to 0.17736, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1807 - accuracy: 0.9457 - val_loss: 0.1774 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 162/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1893 - accuracy: 0.9444\n",
      "Epoch 162: val_loss improved from 0.17736 to 0.17679, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1801 - accuracy: 0.9457 - val_loss: 0.1768 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 163/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9457\n",
      "Epoch 163: val_loss improved from 0.17679 to 0.17623, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1795 - accuracy: 0.9457 - val_loss: 0.1762 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 164/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1783 - accuracy: 0.9467\n",
      "Epoch 164: val_loss improved from 0.17623 to 0.17568, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1790 - accuracy: 0.9457 - val_loss: 0.1757 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 165/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1819 - accuracy: 0.9433\n",
      "Epoch 165: val_loss improved from 0.17568 to 0.17513, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1784 - accuracy: 0.9457 - val_loss: 0.1751 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 166/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9475\n",
      "Epoch 166: val_loss improved from 0.17513 to 0.17458, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1778 - accuracy: 0.9489 - val_loss: 0.1746 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 167/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9489\n",
      "Epoch 167: val_loss improved from 0.17458 to 0.17404, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.9489 - val_loss: 0.1740 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 168/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1925 - accuracy: 0.9358\n",
      "Epoch 168: val_loss improved from 0.17404 to 0.17351, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1767 - accuracy: 0.9457 - val_loss: 0.1735 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 169/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1774 - accuracy: 0.9452\n",
      "Epoch 169: val_loss improved from 0.17351 to 0.17298, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1762 - accuracy: 0.9457 - val_loss: 0.1730 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 170/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1721 - accuracy: 0.9484\n",
      "Epoch 170: val_loss improved from 0.17298 to 0.17246, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1756 - accuracy: 0.9457 - val_loss: 0.1725 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 171/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.9457\n",
      "Epoch 171: val_loss improved from 0.17246 to 0.17194, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1751 - accuracy: 0.9457 - val_loss: 0.1719 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 172/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1830 - accuracy: 0.9429\n",
      "Epoch 172: val_loss improved from 0.17194 to 0.17143, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9457 - val_loss: 0.1714 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 173/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 0.9452\n",
      "Epoch 173: val_loss improved from 0.17143 to 0.17092, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 0.9457 - val_loss: 0.1709 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 174/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9475\n",
      "Epoch 174: val_loss improved from 0.17092 to 0.17043, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.9457 - val_loss: 0.1704 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 175/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1770 - accuracy: 0.9433\n",
      "Epoch 175: val_loss improved from 0.17043 to 0.16993, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1730 - accuracy: 0.9457 - val_loss: 0.1699 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 176/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.9457\n",
      "Epoch 176: val_loss improved from 0.16993 to 0.16943, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1725 - accuracy: 0.9457 - val_loss: 0.1694 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 177/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1727 - accuracy: 0.9434\n",
      "Epoch 177: val_loss improved from 0.16943 to 0.16895, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1720 - accuracy: 0.9457 - val_loss: 0.1689 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 178/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1816 - accuracy: 0.9407\n",
      "Epoch 178: val_loss improved from 0.16895 to 0.16846, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.9457 - val_loss: 0.1685 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 179/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1785 - accuracy: 0.9414\n",
      "Epoch 179: val_loss improved from 0.16846 to 0.16798, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1710 - accuracy: 0.9457 - val_loss: 0.1680 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 180/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9457\n",
      "Epoch 180: val_loss improved from 0.16798 to 0.16750, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1705 - accuracy: 0.9457 - val_loss: 0.1675 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 181/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1778 - accuracy: 0.9423\n",
      "Epoch 181: val_loss improved from 0.16750 to 0.16702, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9457 - val_loss: 0.1670 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 182/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1565 - accuracy: 0.9577\n",
      "Epoch 182: val_loss improved from 0.16702 to 0.16655, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1695 - accuracy: 0.9457 - val_loss: 0.1666 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 183/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1734 - accuracy: 0.9396\n",
      "Epoch 183: val_loss improved from 0.16655 to 0.16608, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1690 - accuracy: 0.9457 - val_loss: 0.1661 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 184/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9452\n",
      "Epoch 184: val_loss improved from 0.16608 to 0.16562, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.9457 - val_loss: 0.1656 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 185/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1707 - accuracy: 0.9424\n",
      "Epoch 185: val_loss improved from 0.16562 to 0.16517, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1681 - accuracy: 0.9457 - val_loss: 0.1652 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 186/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9443\n",
      "Epoch 186: val_loss improved from 0.16517 to 0.16472, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1676 - accuracy: 0.9457 - val_loss: 0.1647 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 187/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1677 - accuracy: 0.9439\n",
      "Epoch 187: val_loss improved from 0.16472 to 0.16427, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1671 - accuracy: 0.9457 - val_loss: 0.1643 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 188/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9457\n",
      "Epoch 188: val_loss improved from 0.16427 to 0.16383, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1667 - accuracy: 0.9457 - val_loss: 0.1638 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 189/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1473 - accuracy: 0.9544\n",
      "Epoch 189: val_loss improved from 0.16383 to 0.16339, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.1662 - accuracy: 0.9457 - val_loss: 0.1634 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 190/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1699 - accuracy: 0.9433\n",
      "Epoch 190: val_loss improved from 0.16339 to 0.16295, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9457 - val_loss: 0.1630 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 191/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1529 - accuracy: 0.9527\n",
      "Epoch 191: val_loss improved from 0.16295 to 0.16252, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1653 - accuracy: 0.9457 - val_loss: 0.1625 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 192/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1689 - accuracy: 0.9434\n",
      "Epoch 192: val_loss improved from 0.16252 to 0.16209, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1649 - accuracy: 0.9457 - val_loss: 0.1621 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 193/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1700 - accuracy: 0.9412\n",
      "Epoch 193: val_loss improved from 0.16209 to 0.16166, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 0.9457 - val_loss: 0.1617 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 194/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1651 - accuracy: 0.9452\n",
      "Epoch 194: val_loss improved from 0.16166 to 0.16124, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1640 - accuracy: 0.9457 - val_loss: 0.1612 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 195/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1744 - accuracy: 0.9451\n",
      "Epoch 195: val_loss improved from 0.16124 to 0.16083, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1635 - accuracy: 0.9457 - val_loss: 0.1608 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 196/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1716 - accuracy: 0.9423\n",
      "Epoch 196: val_loss improved from 0.16083 to 0.16041, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1631 - accuracy: 0.9457 - val_loss: 0.1604 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 197/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9440\n",
      "Epoch 197: val_loss improved from 0.16041 to 0.16000, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1627 - accuracy: 0.9457 - val_loss: 0.1600 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 198/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1580 - accuracy: 0.9483\n",
      "Epoch 198: val_loss improved from 0.16000 to 0.15960, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.9457 - val_loss: 0.1596 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 199/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1684 - accuracy: 0.9429\n",
      "Epoch 199: val_loss improved from 0.15960 to 0.15917, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1618 - accuracy: 0.9457 - val_loss: 0.1592 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 200/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1663 - accuracy: 0.9414\n",
      "Epoch 200: val_loss improved from 0.15917 to 0.15877, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1614 - accuracy: 0.9457 - val_loss: 0.1588 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 201/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1647 - accuracy: 0.9433\n",
      "Epoch 201: val_loss improved from 0.15877 to 0.15837, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1610 - accuracy: 0.9457 - val_loss: 0.1584 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 202/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1645 - accuracy: 0.9474\n",
      "Epoch 202: val_loss improved from 0.15837 to 0.15798, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.9457 - val_loss: 0.1580 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 203/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1675 - accuracy: 0.9393\n",
      "Epoch 203: val_loss improved from 0.15798 to 0.15759, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1602 - accuracy: 0.9457 - val_loss: 0.1576 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 204/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1669 - accuracy: 0.9418\n",
      "Epoch 204: val_loss improved from 0.15759 to 0.15720, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1598 - accuracy: 0.9457 - val_loss: 0.1572 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 205/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1594 - accuracy: 0.9457\n",
      "Epoch 205: val_loss improved from 0.15720 to 0.15682, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9457 - val_loss: 0.1568 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 206/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1511 - accuracy: 0.9527\n",
      "Epoch 206: val_loss improved from 0.15682 to 0.15644, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1590 - accuracy: 0.9457 - val_loss: 0.1564 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 207/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1557 - accuracy: 0.9439\n",
      "Epoch 207: val_loss improved from 0.15644 to 0.15606, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1586 - accuracy: 0.9457 - val_loss: 0.1561 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 208/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1513 - accuracy: 0.9500\n",
      "Epoch 208: val_loss improved from 0.15606 to 0.15569, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1582 - accuracy: 0.9457 - val_loss: 0.1557 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 209/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1611 - accuracy: 0.9439\n",
      "Epoch 209: val_loss improved from 0.15569 to 0.15531, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 0.9457 - val_loss: 0.1553 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 210/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1518 - accuracy: 0.9481\n",
      "Epoch 210: val_loss improved from 0.15531 to 0.15494, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.9457 - val_loss: 0.1549 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 211/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1639 - accuracy: 0.9424\n",
      "Epoch 211: val_loss improved from 0.15494 to 0.15458, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9457 - val_loss: 0.1546 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 212/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9452\n",
      "Epoch 212: val_loss improved from 0.15458 to 0.15421, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9457 - val_loss: 0.1542 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 213/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1641 - accuracy: 0.9462\n",
      "Epoch 213: val_loss improved from 0.15421 to 0.15385, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1563 - accuracy: 0.9457 - val_loss: 0.1538 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 214/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9448\n",
      "Epoch 214: val_loss improved from 0.15385 to 0.15348, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1559 - accuracy: 0.9457 - val_loss: 0.1535 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 215/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9448\n",
      "Epoch 215: val_loss improved from 0.15348 to 0.15312, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1555 - accuracy: 0.9457 - val_loss: 0.1531 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 216/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1414 - accuracy: 0.9525\n",
      "Epoch 216: val_loss improved from 0.15312 to 0.15277, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1551 - accuracy: 0.9457 - val_loss: 0.1528 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 217/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1503 - accuracy: 0.9474\n",
      "Epoch 217: val_loss improved from 0.15277 to 0.15242, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9457 - val_loss: 0.1524 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 218/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1524 - accuracy: 0.9458\n",
      "Epoch 218: val_loss improved from 0.15242 to 0.15207, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1544 - accuracy: 0.9457 - val_loss: 0.1521 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 219/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1482 - accuracy: 0.9474\n",
      "Epoch 219: val_loss improved from 0.15207 to 0.15172, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.9457 - val_loss: 0.1517 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 220/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1582 - accuracy: 0.9433\n",
      "Epoch 220: val_loss improved from 0.15172 to 0.15138, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1537 - accuracy: 0.9457 - val_loss: 0.1514 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 221/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1584 - accuracy: 0.9424\n",
      "Epoch 221: val_loss improved from 0.15138 to 0.15104, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1533 - accuracy: 0.9457 - val_loss: 0.1510 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 222/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1670 - accuracy: 0.9346\n",
      "Epoch 222: val_loss improved from 0.15104 to 0.15070, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.9457 - val_loss: 0.1507 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 223/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1429 - accuracy: 0.9569\n",
      "Epoch 223: val_loss improved from 0.15070 to 0.15037, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.9457 - val_loss: 0.1504 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 224/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1565 - accuracy: 0.9433\n",
      "Epoch 224: val_loss improved from 0.15037 to 0.15004, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1523 - accuracy: 0.9457 - val_loss: 0.1500 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 225/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1631 - accuracy: 0.9385\n",
      "Epoch 225: val_loss improved from 0.15004 to 0.14970, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1519 - accuracy: 0.9457 - val_loss: 0.1497 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 226/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1536 - accuracy: 0.9483\n",
      "Epoch 226: val_loss improved from 0.14970 to 0.14939, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1516 - accuracy: 0.9489 - val_loss: 0.1494 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 227/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1446 - accuracy: 0.9500\n",
      "Epoch 227: val_loss improved from 0.14939 to 0.14906, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1512 - accuracy: 0.9489 - val_loss: 0.1491 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 228/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9521\n",
      "Epoch 228: val_loss improved from 0.14906 to 0.14873, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9521 - val_loss: 0.1487 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 229/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9517\n",
      "Epoch 229: val_loss improved from 0.14873 to 0.14841, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1505 - accuracy: 0.9521 - val_loss: 0.1484 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 230/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1265 - accuracy: 0.9660\n",
      "Epoch 230: val_loss improved from 0.14841 to 0.14809, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1502 - accuracy: 0.9521 - val_loss: 0.1481 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 231/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9521\n",
      "Epoch 231: val_loss improved from 0.14809 to 0.14777, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1499 - accuracy: 0.9521 - val_loss: 0.1478 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 232/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1520 - accuracy: 0.9517\n",
      "Epoch 232: val_loss improved from 0.14777 to 0.14746, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.9521 - val_loss: 0.1475 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 233/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1617 - accuracy: 0.9444\n",
      "Epoch 233: val_loss improved from 0.14746 to 0.14714, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9521 - val_loss: 0.1471 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 234/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1606 - accuracy: 0.9455\n",
      "Epoch 234: val_loss improved from 0.14714 to 0.14683, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9521 - val_loss: 0.1468 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 235/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1447 - accuracy: 0.9567\n",
      "Epoch 235: val_loss improved from 0.14683 to 0.14651, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.9553 - val_loss: 0.1465 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 236/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1462 - accuracy: 0.9571\n",
      "Epoch 236: val_loss improved from 0.14651 to 0.14620, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1482 - accuracy: 0.9553 - val_loss: 0.1462 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 237/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1542 - accuracy: 0.9569\n",
      "Epoch 237: val_loss improved from 0.14620 to 0.14589, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1479 - accuracy: 0.9553 - val_loss: 0.1459 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 238/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1505 - accuracy: 0.9533\n",
      "Epoch 238: val_loss improved from 0.14589 to 0.14559, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.9553 - val_loss: 0.1456 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 239/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1341 - accuracy: 0.9593\n",
      "Epoch 239: val_loss improved from 0.14559 to 0.14529, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9553 - val_loss: 0.1453 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 240/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1443 - accuracy: 0.9559\n",
      "Epoch 240: val_loss improved from 0.14529 to 0.14499, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1469 - accuracy: 0.9553 - val_loss: 0.1450 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 241/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1515 - accuracy: 0.9525\n",
      "Epoch 241: val_loss improved from 0.14499 to 0.14469, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9553 - val_loss: 0.1447 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 242/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1377 - accuracy: 0.9585\n",
      "Epoch 242: val_loss improved from 0.14469 to 0.14440, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1463 - accuracy: 0.9553 - val_loss: 0.1444 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 243/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1532 - accuracy: 0.9517\n",
      "Epoch 243: val_loss improved from 0.14440 to 0.14410, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.9553 - val_loss: 0.1441 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 244/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1493 - accuracy: 0.9525\n",
      "Epoch 244: val_loss improved from 0.14410 to 0.14381, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1457 - accuracy: 0.9553 - val_loss: 0.1438 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 245/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1508 - accuracy: 0.9509\n",
      "Epoch 245: val_loss improved from 0.14381 to 0.14352, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 0.1435 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 246/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1489 - accuracy: 0.9533\n",
      "Epoch 246: val_loss improved from 0.14352 to 0.14324, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1451 - accuracy: 0.9553 - val_loss: 0.1432 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 247/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9548\n",
      "Epoch 247: val_loss improved from 0.14324 to 0.14295, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 0.1429 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 248/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1495 - accuracy: 0.9517\n",
      "Epoch 248: val_loss improved from 0.14295 to 0.14267, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.9553 - val_loss: 0.1427 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 249/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1582 - accuracy: 0.9472\n",
      "Epoch 249: val_loss improved from 0.14267 to 0.14238, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9553 - val_loss: 0.1424 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 250/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1503 - accuracy: 0.9509\n",
      "Epoch 250: val_loss improved from 0.14238 to 0.14211, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1439 - accuracy: 0.9553 - val_loss: 0.1421 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 251/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1453 - accuracy: 0.9544\n",
      "Epoch 251: val_loss improved from 0.14211 to 0.14184, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 0.9553 - val_loss: 0.1418 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 252/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9527\n",
      "Epoch 252: val_loss improved from 0.14184 to 0.14155, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1433 - accuracy: 0.9553 - val_loss: 0.1416 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 253/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1384 - accuracy: 0.9564\n",
      "Epoch 253: val_loss improved from 0.14155 to 0.14128, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1430 - accuracy: 0.9553 - val_loss: 0.1413 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 254/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1467 - accuracy: 0.9552\n",
      "Epoch 254: val_loss improved from 0.14128 to 0.14101, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9553 - val_loss: 0.1410 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 255/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1403 - accuracy: 0.9556\n",
      "Epoch 255: val_loss improved from 0.14101 to 0.14073, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1424 - accuracy: 0.9553 - val_loss: 0.1407 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 256/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1344 - accuracy: 0.9569\n",
      "Epoch 256: val_loss improved from 0.14073 to 0.14046, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1421 - accuracy: 0.9553 - val_loss: 0.1405 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 257/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1471 - accuracy: 0.9517\n",
      "Epoch 257: val_loss improved from 0.14046 to 0.14020, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1418 - accuracy: 0.9553 - val_loss: 0.1402 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 258/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1402 - accuracy: 0.9571\n",
      "Epoch 258: val_loss improved from 0.14020 to 0.13993, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9553 - val_loss: 0.1399 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 259/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9553\n",
      "Epoch 259: val_loss improved from 0.13993 to 0.13967, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1412 - accuracy: 0.9553 - val_loss: 0.1397 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 260/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1497 - accuracy: 0.9509\n",
      "Epoch 260: val_loss improved from 0.13967 to 0.13941, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9553 - val_loss: 0.1394 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 261/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1442 - accuracy: 0.9525\n",
      "Epoch 261: val_loss improved from 0.13941 to 0.13915, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1406 - accuracy: 0.9553 - val_loss: 0.1392 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 262/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1377 - accuracy: 0.9579\n",
      "Epoch 262: val_loss improved from 0.13915 to 0.13889, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1404 - accuracy: 0.9553 - val_loss: 0.1389 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 263/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1454 - accuracy: 0.9577\n",
      "Epoch 263: val_loss improved from 0.13889 to 0.13864, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1401 - accuracy: 0.9553 - val_loss: 0.1386 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 264/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1478 - accuracy: 0.9490\n",
      "Epoch 264: val_loss improved from 0.13864 to 0.13838, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9553 - val_loss: 0.1384 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 265/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1256 - accuracy: 0.9655\n",
      "Epoch 265: val_loss improved from 0.13838 to 0.13813, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1395 - accuracy: 0.9585 - val_loss: 0.1381 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 266/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1246 - accuracy: 0.9647\n",
      "Epoch 266: val_loss improved from 0.13813 to 0.13788, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1392 - accuracy: 0.9585 - val_loss: 0.1379 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 267/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1385 - accuracy: 0.9600\n",
      "Epoch 267: val_loss improved from 0.13788 to 0.13763, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1389 - accuracy: 0.9585 - val_loss: 0.1376 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 268/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9581\n",
      "Epoch 268: val_loss improved from 0.13763 to 0.13739, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1387 - accuracy: 0.9585 - val_loss: 0.1374 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 269/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1496 - accuracy: 0.9538\n",
      "Epoch 269: val_loss improved from 0.13739 to 0.13714, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9585 - val_loss: 0.1371 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 270/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1506 - accuracy: 0.9536\n",
      "Epoch 270: val_loss improved from 0.13714 to 0.13690, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.9585 - val_loss: 0.1369 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 271/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1357 - accuracy: 0.9586\n",
      "Epoch 271: val_loss improved from 0.13690 to 0.13665, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9585 - val_loss: 0.1367 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 272/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1418 - accuracy: 0.9559\n",
      "Epoch 272: val_loss improved from 0.13665 to 0.13641, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9585 - val_loss: 0.1364 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 273/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1348 - accuracy: 0.9600\n",
      "Epoch 273: val_loss improved from 0.13641 to 0.13617, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1373 - accuracy: 0.9585 - val_loss: 0.1362 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 274/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1293 - accuracy: 0.9621\n",
      "Epoch 274: val_loss improved from 0.13617 to 0.13593, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1370 - accuracy: 0.9585 - val_loss: 0.1359 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 275/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9585\n",
      "Epoch 275: val_loss improved from 0.13593 to 0.13569, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1368 - accuracy: 0.9585 - val_loss: 0.1357 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 276/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1440 - accuracy: 0.9544\n",
      "Epoch 276: val_loss improved from 0.13569 to 0.13545, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9585 - val_loss: 0.1355 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 277/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1350 - accuracy: 0.9569\n",
      "Epoch 277: val_loss improved from 0.13545 to 0.13522, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1362 - accuracy: 0.9585 - val_loss: 0.1352 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 278/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1460 - accuracy: 0.9520\n",
      "Epoch 278: val_loss improved from 0.13522 to 0.13499, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9585 - val_loss: 0.1350 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 279/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1320 - accuracy: 0.9607\n",
      "Epoch 279: val_loss improved from 0.13499 to 0.13476, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1357 - accuracy: 0.9585 - val_loss: 0.1348 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 280/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1415 - accuracy: 0.9552\n",
      "Epoch 280: val_loss improved from 0.13476 to 0.13453, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1355 - accuracy: 0.9585 - val_loss: 0.1345 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 281/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1465 - accuracy: 0.9538\n",
      "Epoch 281: val_loss improved from 0.13453 to 0.13431, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9585 - val_loss: 0.1343 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 282/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.9581\n",
      "Epoch 282: val_loss improved from 0.13431 to 0.13408, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1349 - accuracy: 0.9585 - val_loss: 0.1341 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 283/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1426 - accuracy: 0.9544\n",
      "Epoch 283: val_loss improved from 0.13408 to 0.13386, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9585 - val_loss: 0.1339 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 284/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9574\n",
      "Epoch 284: val_loss improved from 0.13386 to 0.13363, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.9585 - val_loss: 0.1336 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 285/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1081 - accuracy: 0.9698\n",
      "Epoch 285: val_loss improved from 0.13363 to 0.13341, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9585 - val_loss: 0.1334 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 286/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1357 - accuracy: 0.9556\n",
      "Epoch 286: val_loss improved from 0.13341 to 0.13319, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9585 - val_loss: 0.1332 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 287/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1339 - accuracy: 0.9615\n",
      "Epoch 287: val_loss improved from 0.13319 to 0.13296, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9585 - val_loss: 0.1330 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 288/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1347 - accuracy: 0.9586\n",
      "Epoch 288: val_loss improved from 0.13296 to 0.13274, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.9585 - val_loss: 0.1327 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 289/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1360 - accuracy: 0.9586\n",
      "Epoch 289: val_loss improved from 0.13274 to 0.13252, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1331 - accuracy: 0.9585 - val_loss: 0.1325 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 290/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1277 - accuracy: 0.9633\n",
      "Epoch 290: val_loss improved from 0.13252 to 0.13233, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1329 - accuracy: 0.9585 - val_loss: 0.1323 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 291/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1496 - accuracy: 0.9490\n",
      "Epoch 291: val_loss improved from 0.13233 to 0.13212, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9585 - val_loss: 0.1321 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 292/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1230 - accuracy: 0.9627\n",
      "Epoch 292: val_loss improved from 0.13212 to 0.13189, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9585 - val_loss: 0.1319 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 293/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1221 - accuracy: 0.9593\n",
      "Epoch 293: val_loss improved from 0.13189 to 0.13167, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1321 - accuracy: 0.9585 - val_loss: 0.1317 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 294/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1343 - accuracy: 0.9574\n",
      "Epoch 294: val_loss improved from 0.13167 to 0.13146, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.9585 - val_loss: 0.1315 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 295/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1284 - accuracy: 0.9614\n",
      "Epoch 295: val_loss improved from 0.13146 to 0.13125, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1316 - accuracy: 0.9585 - val_loss: 0.1313 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 296/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1398 - accuracy: 0.9544\n",
      "Epoch 296: val_loss improved from 0.13125 to 0.13105, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 0.9585 - val_loss: 0.1310 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 297/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1365 - accuracy: 0.9538\n",
      "Epoch 297: val_loss improved from 0.13105 to 0.13084, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.9585 - val_loss: 0.1308 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 298/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1310 - accuracy: 0.9600\n",
      "Epoch 298: val_loss improved from 0.13084 to 0.13063, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9585 - val_loss: 0.1306 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 299/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1340 - accuracy: 0.9547\n",
      "Epoch 299: val_loss improved from 0.13063 to 0.13043, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.9585 - val_loss: 0.1304 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 300/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1198 - accuracy: 0.9607\n",
      "Epoch 300: val_loss improved from 0.13043 to 0.13022, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9585 - val_loss: 0.1302 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 301/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1380 - accuracy: 0.9544\n",
      "Epoch 301: val_loss improved from 0.13022 to 0.13000, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1301 - accuracy: 0.9585 - val_loss: 0.1300 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 302/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1205 - accuracy: 0.9630\n",
      "Epoch 302: val_loss improved from 0.13000 to 0.12980, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1299 - accuracy: 0.9585 - val_loss: 0.1298 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 303/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1400 - accuracy: 0.9547\n",
      "Epoch 303: val_loss improved from 0.12980 to 0.12960, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9585 - val_loss: 0.1296 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 304/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1343 - accuracy: 0.9564\n",
      "Epoch 304: val_loss improved from 0.12960 to 0.12940, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9585 - val_loss: 0.1294 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 305/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1362 - accuracy: 0.9552\n",
      "Epoch 305: val_loss improved from 0.12940 to 0.12920, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9585 - val_loss: 0.1292 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 306/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1428 - accuracy: 0.9529\n",
      "Epoch 306: val_loss improved from 0.12920 to 0.12900, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1289 - accuracy: 0.9585 - val_loss: 0.1290 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 307/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1358 - accuracy: 0.9556\n",
      "Epoch 307: val_loss improved from 0.12900 to 0.12881, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9585 - val_loss: 0.1288 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 308/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1264 - accuracy: 0.9600\n",
      "Epoch 308: val_loss improved from 0.12881 to 0.12861, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1284 - accuracy: 0.9585 - val_loss: 0.1286 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 309/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9574\n",
      "Epoch 309: val_loss improved from 0.12861 to 0.12841, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1282 - accuracy: 0.9585 - val_loss: 0.1284 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 310/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1116 - accuracy: 0.9698\n",
      "Epoch 310: val_loss improved from 0.12841 to 0.12823, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9585 - val_loss: 0.1282 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 311/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9585\n",
      "Epoch 311: val_loss improved from 0.12823 to 0.12804, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1277 - accuracy: 0.9585 - val_loss: 0.1280 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 312/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1177 - accuracy: 0.9614\n",
      "Epoch 312: val_loss improved from 0.12804 to 0.12785, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9585 - val_loss: 0.1278 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 313/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1320 - accuracy: 0.9538\n",
      "Epoch 313: val_loss improved from 0.12785 to 0.12766, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1273 - accuracy: 0.9585 - val_loss: 0.1277 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 314/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1163 - accuracy: 0.9654\n",
      "Epoch 314: val_loss improved from 0.12766 to 0.12747, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1270 - accuracy: 0.9585 - val_loss: 0.1275 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 315/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1441 - accuracy: 0.9490\n",
      "Epoch 315: val_loss improved from 0.12747 to 0.12729, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9585 - val_loss: 0.1273 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 316/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1343 - accuracy: 0.9527\n",
      "Epoch 316: val_loss improved from 0.12729 to 0.12710, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9585 - val_loss: 0.1271 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 317/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1353 - accuracy: 0.9538\n",
      "Epoch 317: val_loss improved from 0.12710 to 0.12691, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1263 - accuracy: 0.9585 - val_loss: 0.1269 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 318/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9667\n",
      "Epoch 318: val_loss improved from 0.12691 to 0.12673, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9585 - val_loss: 0.1267 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 319/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1198 - accuracy: 0.9585\n",
      "Epoch 319: val_loss improved from 0.12673 to 0.12655, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.9585 - val_loss: 0.1265 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 320/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9581\n",
      "Epoch 320: val_loss improved from 0.12655 to 0.12636, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9585 - val_loss: 0.1264 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 321/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.9585\n",
      "Epoch 321: val_loss improved from 0.12636 to 0.12618, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1254 - accuracy: 0.9585 - val_loss: 0.1262 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 322/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1388 - accuracy: 0.9509\n",
      "Epoch 322: val_loss improved from 0.12618 to 0.12600, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9585 - val_loss: 0.1260 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 323/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1021 - accuracy: 0.9660\n",
      "Epoch 323: val_loss improved from 0.12600 to 0.12582, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1250 - accuracy: 0.9585 - val_loss: 0.1258 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 324/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1296 - accuracy: 0.9579\n",
      "Epoch 324: val_loss improved from 0.12582 to 0.12564, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1247 - accuracy: 0.9585 - val_loss: 0.1256 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 325/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1179 - accuracy: 0.9585\n",
      "Epoch 325: val_loss improved from 0.12564 to 0.12545, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.9585 - val_loss: 0.1255 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 326/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9673\n",
      "Epoch 326: val_loss improved from 0.12545 to 0.12529, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1243 - accuracy: 0.9585 - val_loss: 0.1253 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 327/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1304 - accuracy: 0.9615\n",
      "Epoch 327: val_loss improved from 0.12529 to 0.12511, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.9585 - val_loss: 0.1251 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 328/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9585\n",
      "Epoch 328: val_loss improved from 0.12511 to 0.12494, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1238 - accuracy: 0.9585 - val_loss: 0.1249 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 329/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1155 - accuracy: 0.9623\n",
      "Epoch 329: val_loss improved from 0.12494 to 0.12477, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9585 - val_loss: 0.1248 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 330/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1183 - accuracy: 0.9600\n",
      "Epoch 330: val_loss improved from 0.12477 to 0.12460, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9585 - val_loss: 0.1246 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 331/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1262 - accuracy: 0.9559\n",
      "Epoch 331: val_loss improved from 0.12460 to 0.12442, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1231 - accuracy: 0.9585 - val_loss: 0.1244 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 332/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1308 - accuracy: 0.9536\n",
      "Epoch 332: val_loss improved from 0.12442 to 0.12425, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.9585 - val_loss: 0.1242 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 333/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1164 - accuracy: 0.9630\n",
      "Epoch 333: val_loss improved from 0.12425 to 0.12408, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9585 - val_loss: 0.1241 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 334/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1092 - accuracy: 0.9600\n",
      "Epoch 334: val_loss improved from 0.12408 to 0.12391, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.9585 - val_loss: 0.1239 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 335/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1124 - accuracy: 0.9636\n",
      "Epoch 335: val_loss improved from 0.12391 to 0.12374, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9585 - val_loss: 0.1237 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 336/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1261 - accuracy: 0.9559\n",
      "Epoch 336: val_loss improved from 0.12374 to 0.12358, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9585 - val_loss: 0.1236 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 337/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1185 - accuracy: 0.9600\n",
      "Epoch 337: val_loss improved from 0.12358 to 0.12342, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1218 - accuracy: 0.9585 - val_loss: 0.1234 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 338/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1215 - accuracy: 0.9593\n",
      "Epoch 338: val_loss improved from 0.12342 to 0.12325, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9585 - val_loss: 0.1233 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 339/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1176 - accuracy: 0.9585\n",
      "Epoch 339: val_loss improved from 0.12325 to 0.12309, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.9585 - val_loss: 0.1231 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 340/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1179 - accuracy: 0.9630\n",
      "Epoch 340: val_loss improved from 0.12309 to 0.12293, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1211 - accuracy: 0.9585 - val_loss: 0.1229 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 341/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1310 - accuracy: 0.9547\n",
      "Epoch 341: val_loss improved from 0.12293 to 0.12277, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.9585 - val_loss: 0.1228 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 342/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1071 - accuracy: 0.9621\n",
      "Epoch 342: val_loss improved from 0.12277 to 0.12260, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9585 - val_loss: 0.1226 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 343/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1242 - accuracy: 0.9567\n",
      "Epoch 343: val_loss improved from 0.12260 to 0.12244, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.9585 - val_loss: 0.1224 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 344/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1202 - accuracy: 0.9586\n",
      "Epoch 344: val_loss improved from 0.12244 to 0.12229, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1203 - accuracy: 0.9585 - val_loss: 0.1223 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 345/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1081 - accuracy: 0.9667\n",
      "Epoch 345: val_loss improved from 0.12229 to 0.12212, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.9585 - val_loss: 0.1221 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 346/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1234 - accuracy: 0.9586\n",
      "Epoch 346: val_loss improved from 0.12212 to 0.12197, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.9585 - val_loss: 0.1220 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 347/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9630\n",
      "Epoch 347: val_loss improved from 0.12197 to 0.12182, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.9585 - val_loss: 0.1218 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 348/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1245 - accuracy: 0.9571\n",
      "Epoch 348: val_loss improved from 0.12182 to 0.12166, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9585 - val_loss: 0.1217 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 349/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1225 - accuracy: 0.9621\n",
      "Epoch 349: val_loss improved from 0.12166 to 0.12151, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 0.9617 - val_loss: 0.1215 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 350/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1225 - accuracy: 0.9600\n",
      "Epoch 350: val_loss improved from 0.12151 to 0.12136, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9617 - val_loss: 0.1214 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 351/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1118 - accuracy: 0.9623\n",
      "Epoch 351: val_loss improved from 0.12136 to 0.12121, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9617 - val_loss: 0.1212 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 352/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.9613\n",
      "Epoch 352: val_loss improved from 0.12121 to 0.12107, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.9617 - val_loss: 0.1211 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 353/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1169 - accuracy: 0.9615\n",
      "Epoch 353: val_loss improved from 0.12107 to 0.12092, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9617 - val_loss: 0.1209 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 354/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1225 - accuracy: 0.9586\n",
      "Epoch 354: val_loss improved from 0.12092 to 0.12078, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.9617 - val_loss: 0.1208 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 355/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1227 - accuracy: 0.9585\n",
      "Epoch 355: val_loss improved from 0.12078 to 0.12063, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9617 - val_loss: 0.1206 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 356/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1095 - accuracy: 0.9627\n",
      "Epoch 356: val_loss improved from 0.12063 to 0.12049, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9617 - val_loss: 0.1205 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 357/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1208 - accuracy: 0.9607\n",
      "Epoch 357: val_loss improved from 0.12049 to 0.12034, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.9617 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 358/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1210 - accuracy: 0.9600\n",
      "Epoch 358: val_loss improved from 0.12034 to 0.12019, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9617 - val_loss: 0.1202 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 359/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1273 - accuracy: 0.9556\n",
      "Epoch 359: val_loss improved from 0.12019 to 0.12005, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.9617 - val_loss: 0.1200 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 360/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1036 - accuracy: 0.9636\n",
      "Epoch 360: val_loss improved from 0.12005 to 0.11991, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9617 - val_loss: 0.1199 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 361/600\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9633\n",
      "Epoch 361: val_loss improved from 0.11991 to 0.11977, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9617 - val_loss: 0.1198 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 362/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1108 - accuracy: 0.9627\n",
      "Epoch 362: val_loss improved from 0.11977 to 0.11963, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9617 - val_loss: 0.1196 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 363/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9617\n",
      "Epoch 363: val_loss improved from 0.11963 to 0.11949, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.9617 - val_loss: 0.1195 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 364/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1100 - accuracy: 0.9690\n",
      "Epoch 364: val_loss improved from 0.11949 to 0.11935, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9617 - val_loss: 0.1194 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 365/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1038 - accuracy: 0.9709\n",
      "Epoch 365: val_loss improved from 0.11935 to 0.11922, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.9617 - val_loss: 0.1192 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 366/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1203 - accuracy: 0.9579\n",
      "Epoch 366: val_loss improved from 0.11922 to 0.11908, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.9617 - val_loss: 0.1191 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 367/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1220 - accuracy: 0.9586\n",
      "Epoch 367: val_loss improved from 0.11908 to 0.11895, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9617 - val_loss: 0.1190 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 368/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9607\n",
      "Epoch 368: val_loss improved from 0.11895 to 0.11882, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.9617 - val_loss: 0.1188 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 369/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9613\n",
      "Epoch 369: val_loss improved from 0.11882 to 0.11868, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9617 - val_loss: 0.1187 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 370/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0996 - accuracy: 0.9731\n",
      "Epoch 370: val_loss improved from 0.11868 to 0.11854, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.9649 - val_loss: 0.1185 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 371/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.9639\n",
      "Epoch 371: val_loss improved from 0.11854 to 0.11841, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.9617 - val_loss: 0.1184 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 372/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1175 - accuracy: 0.9623\n",
      "Epoch 372: val_loss improved from 0.11841 to 0.11828, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.9617 - val_loss: 0.1183 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 373/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1113 - accuracy: 0.9630\n",
      "Epoch 373: val_loss improved from 0.11828 to 0.11815, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9617 - val_loss: 0.1181 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 374/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1223 - accuracy: 0.9615\n",
      "Epoch 374: val_loss improved from 0.11815 to 0.11803, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9617 - val_loss: 0.1180 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 375/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9607\n",
      "Epoch 375: val_loss improved from 0.11803 to 0.11790, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1137 - accuracy: 0.9649 - val_loss: 0.1179 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 376/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1150 - accuracy: 0.9633\n",
      "Epoch 376: val_loss improved from 0.11790 to 0.11776, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1135 - accuracy: 0.9649 - val_loss: 0.1178 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 377/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1113 - accuracy: 0.9655\n",
      "Epoch 377: val_loss improved from 0.11776 to 0.11763, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.9649 - val_loss: 0.1176 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 378/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1143 - accuracy: 0.9667\n",
      "Epoch 378: val_loss improved from 0.11763 to 0.11751, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.9649 - val_loss: 0.1175 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 379/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1177 - accuracy: 0.9643\n",
      "Epoch 379: val_loss improved from 0.11751 to 0.11738, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1128 - accuracy: 0.9649 - val_loss: 0.1174 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 380/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1129 - accuracy: 0.9643\n",
      "Epoch 380: val_loss improved from 0.11738 to 0.11728, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9649 - val_loss: 0.1173 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 381/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1217 - accuracy: 0.9640\n",
      "Epoch 381: val_loss improved from 0.11728 to 0.11716, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.9649 - val_loss: 0.1172 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 382/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1131 - accuracy: 0.9698\n",
      "Epoch 382: val_loss improved from 0.11716 to 0.11703, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.9649 - val_loss: 0.1170 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 383/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9649\n",
      "Epoch 383: val_loss improved from 0.11703 to 0.11691, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1120 - accuracy: 0.9649 - val_loss: 0.1169 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 384/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1104 - accuracy: 0.9684\n",
      "Epoch 384: val_loss improved from 0.11691 to 0.11678, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9649 - val_loss: 0.1168 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 385/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1042 - accuracy: 0.9698\n",
      "Epoch 385: val_loss improved from 0.11678 to 0.11665, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.9649 - val_loss: 0.1167 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 386/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1058 - accuracy: 0.9654\n",
      "Epoch 386: val_loss improved from 0.11665 to 0.11653, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9649 - val_loss: 0.1165 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 387/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1178 - accuracy: 0.9600\n",
      "Epoch 387: val_loss improved from 0.11653 to 0.11640, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1112 - accuracy: 0.9649 - val_loss: 0.1164 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 388/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1124 - accuracy: 0.9655\n",
      "Epoch 388: val_loss improved from 0.11640 to 0.11628, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.9649 - val_loss: 0.1163 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 389/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1095 - accuracy: 0.9640\n",
      "Epoch 389: val_loss improved from 0.11628 to 0.11616, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.9649 - val_loss: 0.1162 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 390/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1105 - accuracy: 0.9621\n",
      "Epoch 390: val_loss improved from 0.11616 to 0.11604, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9649 - val_loss: 0.1160 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 391/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1141 - accuracy: 0.9636\n",
      "Epoch 391: val_loss improved from 0.11604 to 0.11592, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.9649 - val_loss: 0.1159 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 392/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9649\n",
      "Epoch 392: val_loss improved from 0.11592 to 0.11581, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.9649 - val_loss: 0.1158 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 393/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1091 - accuracy: 0.9649\n",
      "Epoch 393: val_loss improved from 0.11581 to 0.11569, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9649 - val_loss: 0.1157 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 394/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1087 - accuracy: 0.9640\n",
      "Epoch 394: val_loss improved from 0.11569 to 0.11557, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.1156 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 395/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1129 - accuracy: 0.9621\n",
      "Epoch 395: val_loss improved from 0.11557 to 0.11546, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9649 - val_loss: 0.1155 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 396/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1103 - accuracy: 0.9633\n",
      "Epoch 396: val_loss improved from 0.11546 to 0.11532, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9649 - val_loss: 0.1153 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 397/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1167 - accuracy: 0.9593\n",
      "Epoch 397: val_loss improved from 0.11532 to 0.11521, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.9649 - val_loss: 0.1152 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 398/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1061 - accuracy: 0.9643\n",
      "Epoch 398: val_loss improved from 0.11521 to 0.11508, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.9649 - val_loss: 0.1151 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 399/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.9639\n",
      "Epoch 399: val_loss improved from 0.11508 to 0.11496, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9649 - val_loss: 0.1150 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 400/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1024 - accuracy: 0.9655\n",
      "Epoch 400: val_loss improved from 0.11496 to 0.11488, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.9649 - val_loss: 0.1149 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 401/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1047 - accuracy: 0.9654\n",
      "Epoch 401: val_loss improved from 0.11488 to 0.11477, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9649 - val_loss: 0.1148 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 402/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0926 - accuracy: 0.9704\n",
      "Epoch 402: val_loss improved from 0.11477 to 0.11466, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.9649 - val_loss: 0.1147 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 403/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1037 - accuracy: 0.9690\n",
      "Epoch 403: val_loss improved from 0.11466 to 0.11455, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9649 - val_loss: 0.1146 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 404/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1078 - accuracy: 0.9660\n",
      "Epoch 404: val_loss improved from 0.11455 to 0.11444, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.9649 - val_loss: 0.1144 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 405/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1135 - accuracy: 0.9621\n",
      "Epoch 405: val_loss improved from 0.11444 to 0.11433, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9649 - val_loss: 0.1143 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 406/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9649\n",
      "Epoch 406: val_loss improved from 0.11433 to 0.11422, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.9649 - val_loss: 0.1142 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 407/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1033 - accuracy: 0.9704\n",
      "Epoch 407: val_loss improved from 0.11422 to 0.11411, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1071 - accuracy: 0.9649 - val_loss: 0.1141 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 408/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9645\n",
      "Epoch 408: val_loss improved from 0.11411 to 0.11401, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1069 - accuracy: 0.9649 - val_loss: 0.1140 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 409/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1027 - accuracy: 0.9686\n",
      "Epoch 409: val_loss improved from 0.11401 to 0.11390, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9649 - val_loss: 0.1139 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 410/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1053 - accuracy: 0.9684\n",
      "Epoch 410: val_loss improved from 0.11390 to 0.11380, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.9649 - val_loss: 0.1138 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 411/600\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1067 - accuracy: 0.9592\n",
      "Epoch 411: val_loss improved from 0.11380 to 0.11369, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.9649 - val_loss: 0.1137 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 412/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1097 - accuracy: 0.9636\n",
      "Epoch 412: val_loss improved from 0.11369 to 0.11358, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9649 - val_loss: 0.1136 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 413/600\n",
      "49/63 [======================>.......] - ETA: 0s - loss: 0.1141 - accuracy: 0.9633\n",
      "Epoch 413: val_loss improved from 0.11358 to 0.11348, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.9649 - val_loss: 0.1135 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 414/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9577\n",
      "Epoch 414: val_loss improved from 0.11348 to 0.11338, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9649 - val_loss: 0.1134 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 415/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1094 - accuracy: 0.9627\n",
      "Epoch 415: val_loss improved from 0.11338 to 0.11328, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9649 - val_loss: 0.1133 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 416/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1087 - accuracy: 0.9633\n",
      "Epoch 416: val_loss improved from 0.11328 to 0.11318, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9649 - val_loss: 0.1132 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 417/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1043 - accuracy: 0.9630\n",
      "Epoch 417: val_loss improved from 0.11318 to 0.11308, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9649 - val_loss: 0.1131 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 418/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9649\n",
      "Epoch 418: val_loss improved from 0.11308 to 0.11297, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.9649 - val_loss: 0.1130 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 419/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1148 - accuracy: 0.9585\n",
      "Epoch 419: val_loss improved from 0.11297 to 0.11286, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9649 - val_loss: 0.1129 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 420/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.1061 - accuracy: 0.9661\n",
      "Epoch 420: val_loss improved from 0.11286 to 0.11277, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9649 - val_loss: 0.1128 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 421/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1080 - accuracy: 0.9636\n",
      "Epoch 421: val_loss improved from 0.11277 to 0.11267, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9649 - val_loss: 0.1127 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 422/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1073 - accuracy: 0.9633\n",
      "Epoch 422: val_loss improved from 0.11267 to 0.11258, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9649 - val_loss: 0.1126 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 423/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1081 - accuracy: 0.9654\n",
      "Epoch 423: val_loss improved from 0.11258 to 0.11252, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9649 - val_loss: 0.1125 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 424/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1003 - accuracy: 0.9686\n",
      "Epoch 424: val_loss improved from 0.11252 to 0.11243, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9649 - val_loss: 0.1124 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 425/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1158 - accuracy: 0.9615\n",
      "Epoch 425: val_loss improved from 0.11243 to 0.11232, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9649 - val_loss: 0.1123 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 426/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0971 - accuracy: 0.9714\n",
      "Epoch 426: val_loss improved from 0.11232 to 0.11222, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9681 - val_loss: 0.1122 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 427/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1139 - accuracy: 0.9585\n",
      "Epoch 427: val_loss improved from 0.11222 to 0.11213, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.9649 - val_loss: 0.1121 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 428/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1113 - accuracy: 0.9600\n",
      "Epoch 428: val_loss improved from 0.11213 to 0.11204, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9649 - val_loss: 0.1120 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 429/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9636\n",
      "Epoch 429: val_loss improved from 0.11204 to 0.11194, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9681 - val_loss: 0.1119 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 430/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9681\n",
      "Epoch 430: val_loss improved from 0.11194 to 0.11185, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.9681 - val_loss: 0.1118 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 431/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1026 - accuracy: 0.9690\n",
      "Epoch 431: val_loss improved from 0.11185 to 0.11174, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9681 - val_loss: 0.1117 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 432/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0975 - accuracy: 0.9700\n",
      "Epoch 432: val_loss improved from 0.11174 to 0.11164, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9681 - val_loss: 0.1116 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 433/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0946 - accuracy: 0.9745\n",
      "Epoch 433: val_loss improved from 0.11164 to 0.11155, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9681 - val_loss: 0.1116 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 434/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1008 - accuracy: 0.9654\n",
      "Epoch 434: val_loss improved from 0.11155 to 0.11146, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9681 - val_loss: 0.1115 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 435/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0949 - accuracy: 0.9725\n",
      "Epoch 435: val_loss improved from 0.11146 to 0.11137, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.9681 - val_loss: 0.1114 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 436/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9681\n",
      "Epoch 436: val_loss improved from 0.11137 to 0.11127, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9681 - val_loss: 0.1113 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 437/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0965 - accuracy: 0.9704\n",
      "Epoch 437: val_loss improved from 0.11127 to 0.11119, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.9681 - val_loss: 0.1112 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 438/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0972 - accuracy: 0.9704\n",
      "Epoch 438: val_loss improved from 0.11119 to 0.11108, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9681 - val_loss: 0.1111 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 439/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0914 - accuracy: 0.9719\n",
      "Epoch 439: val_loss improved from 0.11108 to 0.11101, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1009 - accuracy: 0.9681 - val_loss: 0.1110 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 440/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0865 - accuracy: 0.9759\n",
      "Epoch 440: val_loss improved from 0.11101 to 0.11095, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9681 - val_loss: 0.1109 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 441/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0952 - accuracy: 0.9690\n",
      "Epoch 441: val_loss improved from 0.11095 to 0.11088, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1005 - accuracy: 0.9681 - val_loss: 0.1109 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 442/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1017 - accuracy: 0.9684\n",
      "Epoch 442: val_loss improved from 0.11088 to 0.11079, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1003 - accuracy: 0.9681 - val_loss: 0.1108 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 443/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9681\n",
      "Epoch 443: val_loss improved from 0.11079 to 0.11070, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9681 - val_loss: 0.1107 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 444/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1030 - accuracy: 0.9654\n",
      "Epoch 444: val_loss improved from 0.11070 to 0.11059, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9681 - val_loss: 0.1106 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 445/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0974 - accuracy: 0.9714\n",
      "Epoch 445: val_loss improved from 0.11059 to 0.11051, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9681 - val_loss: 0.1105 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 446/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1024 - accuracy: 0.9655\n",
      "Epoch 446: val_loss improved from 0.11051 to 0.11043, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9681 - val_loss: 0.1104 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 447/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1017 - accuracy: 0.9667\n",
      "Epoch 447: val_loss improved from 0.11043 to 0.11034, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9681 - val_loss: 0.1103 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 448/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9681\n",
      "Epoch 448: val_loss improved from 0.11034 to 0.11028, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9681 - val_loss: 0.1103 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 449/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.1012 - accuracy: 0.9690\n",
      "Epoch 449: val_loss improved from 0.11028 to 0.11019, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0989 - accuracy: 0.9681 - val_loss: 0.1102 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 450/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0826 - accuracy: 0.9731\n",
      "Epoch 450: val_loss improved from 0.11019 to 0.11011, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9681 - val_loss: 0.1101 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 451/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0991 - accuracy: 0.9677\n",
      "Epoch 451: val_loss improved from 0.11011 to 0.11002, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0986 - accuracy: 0.9681 - val_loss: 0.1100 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 452/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1018 - accuracy: 0.9667\n",
      "Epoch 452: val_loss improved from 0.11002 to 0.10993, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9681 - val_loss: 0.1099 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 453/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0988 - accuracy: 0.9692\n",
      "Epoch 453: val_loss improved from 0.10993 to 0.10985, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0982 - accuracy: 0.9681 - val_loss: 0.1099 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 454/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9672\n",
      "Epoch 454: val_loss improved from 0.10985 to 0.10977, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0980 - accuracy: 0.9681 - val_loss: 0.1098 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 455/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1014 - accuracy: 0.9684\n",
      "Epoch 455: val_loss improved from 0.10977 to 0.10969, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9681 - val_loss: 0.1097 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 456/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.1002 - accuracy: 0.9667\n",
      "Epoch 456: val_loss improved from 0.10969 to 0.10961, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 0.9681 - val_loss: 0.1096 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 457/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1060 - accuracy: 0.9623\n",
      "Epoch 457: val_loss improved from 0.10961 to 0.10953, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.9681 - val_loss: 0.1095 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 458/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0984 - accuracy: 0.9667\n",
      "Epoch 458: val_loss improved from 0.10953 to 0.10945, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9681 - val_loss: 0.1095 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 459/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0966 - accuracy: 0.9709\n",
      "Epoch 459: val_loss improved from 0.10945 to 0.10938, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9681 - val_loss: 0.1094 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 460/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0984 - accuracy: 0.9667\n",
      "Epoch 460: val_loss improved from 0.10938 to 0.10929, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9681 - val_loss: 0.1093 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 461/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0927 - accuracy: 0.9714\n",
      "Epoch 461: val_loss improved from 0.10929 to 0.10921, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9681 - val_loss: 0.1092 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 462/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0992 - accuracy: 0.9667\n",
      "Epoch 462: val_loss improved from 0.10921 to 0.10912, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9681 - val_loss: 0.1091 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 463/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0883 - accuracy: 0.9673\n",
      "Epoch 463: val_loss improved from 0.10912 to 0.10905, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9681 - val_loss: 0.1091 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 464/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1059 - accuracy: 0.9630\n",
      "Epoch 464: val_loss improved from 0.10905 to 0.10898, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9681 - val_loss: 0.1090 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 465/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1061 - accuracy: 0.9608\n",
      "Epoch 465: val_loss improved from 0.10898 to 0.10890, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9681 - val_loss: 0.1089 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 466/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0916 - accuracy: 0.9679\n",
      "Epoch 466: val_loss improved from 0.10890 to 0.10882, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9681 - val_loss: 0.1088 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 467/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0973 - accuracy: 0.9690\n",
      "Epoch 467: val_loss improved from 0.10882 to 0.10875, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9681 - val_loss: 0.1087 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 468/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1018 - accuracy: 0.9647\n",
      "Epoch 468: val_loss improved from 0.10875 to 0.10871, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9681 - val_loss: 0.1087 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 469/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9672\n",
      "Epoch 469: val_loss improved from 0.10871 to 0.10863, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0952 - accuracy: 0.9681 - val_loss: 0.1086 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 470/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1000 - accuracy: 0.9649\n",
      "Epoch 470: val_loss improved from 0.10863 to 0.10856, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0951 - accuracy: 0.9681 - val_loss: 0.1086 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 471/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0972 - accuracy: 0.9673\n",
      "Epoch 471: val_loss improved from 0.10856 to 0.10849, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9681 - val_loss: 0.1085 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 472/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0790 - accuracy: 0.9778\n",
      "Epoch 472: val_loss improved from 0.10849 to 0.10841, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0947 - accuracy: 0.9681 - val_loss: 0.1084 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 473/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0790 - accuracy: 0.9736\n",
      "Epoch 473: val_loss improved from 0.10841 to 0.10835, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9681 - val_loss: 0.1084 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 474/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0924 - accuracy: 0.9686\n",
      "Epoch 474: val_loss improved from 0.10835 to 0.10828, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9681 - val_loss: 0.1083 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 475/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9681\n",
      "Epoch 475: val_loss improved from 0.10828 to 0.10821, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9681 - val_loss: 0.1082 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 476/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1000 - accuracy: 0.9649\n",
      "Epoch 476: val_loss improved from 0.10821 to 0.10814, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9681 - val_loss: 0.1081 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 477/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0957 - accuracy: 0.9690\n",
      "Epoch 477: val_loss improved from 0.10814 to 0.10808, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9681 - val_loss: 0.1081 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 478/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1021 - accuracy: 0.9654\n",
      "Epoch 478: val_loss improved from 0.10808 to 0.10799, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.9681 - val_loss: 0.1080 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 479/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0928 - accuracy: 0.9684\n",
      "Epoch 479: val_loss improved from 0.10799 to 0.10792, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.9681 - val_loss: 0.1079 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 480/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1000 - accuracy: 0.9636\n",
      "Epoch 480: val_loss improved from 0.10792 to 0.10785, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0932 - accuracy: 0.9681 - val_loss: 0.1078 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 481/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0892 - accuracy: 0.9698\n",
      "Epoch 481: val_loss improved from 0.10785 to 0.10778, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9681 - val_loss: 0.1078 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 482/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0930 - accuracy: 0.9690\n",
      "Epoch 482: val_loss improved from 0.10778 to 0.10772, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9681 - val_loss: 0.1077 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 483/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0900 - accuracy: 0.9684\n",
      "Epoch 483: val_loss improved from 0.10772 to 0.10766, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9681 - val_loss: 0.1077 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 484/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0973 - accuracy: 0.9649\n",
      "Epoch 484: val_loss improved from 0.10766 to 0.10760, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9681 - val_loss: 0.1076 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 485/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0965 - accuracy: 0.9660\n",
      "Epoch 485: val_loss improved from 0.10760 to 0.10756, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9681 - val_loss: 0.1076 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 486/600\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1022 - accuracy: 0.9640\n",
      "Epoch 486: val_loss improved from 0.10756 to 0.10749, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9681 - val_loss: 0.1075 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 487/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.1012 - accuracy: 0.9615\n",
      "Epoch 487: val_loss improved from 0.10749 to 0.10742, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0920 - accuracy: 0.9681 - val_loss: 0.1074 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 488/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0916 - accuracy: 0.9673\n",
      "Epoch 488: val_loss improved from 0.10742 to 0.10736, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.1074 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 489/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0905 - accuracy: 0.9679\n",
      "Epoch 489: val_loss improved from 0.10736 to 0.10729, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9681 - val_loss: 0.1073 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 490/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0930 - accuracy: 0.9698\n",
      "Epoch 490: val_loss improved from 0.10729 to 0.10723, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9681 - val_loss: 0.1072 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 491/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0814 - accuracy: 0.9724\n",
      "Epoch 491: val_loss improved from 0.10723 to 0.10717, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9681 - val_loss: 0.1072 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 492/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0925 - accuracy: 0.9679\n",
      "Epoch 492: val_loss improved from 0.10717 to 0.10711, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9681 - val_loss: 0.1071 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 493/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9738\n",
      "Epoch 493: val_loss improved from 0.10711 to 0.10709, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0910 - accuracy: 0.9681 - val_loss: 0.1071 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 494/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0959 - accuracy: 0.9667\n",
      "Epoch 494: val_loss improved from 0.10709 to 0.10702, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9712 - val_loss: 0.1070 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 495/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9712\n",
      "Epoch 495: val_loss improved from 0.10702 to 0.10696, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9712 - val_loss: 0.1070 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 496/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0938 - accuracy: 0.9690\n",
      "Epoch 496: val_loss improved from 0.10696 to 0.10690, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9712 - val_loss: 0.1069 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 497/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0936 - accuracy: 0.9695\n",
      "Epoch 497: val_loss improved from 0.10690 to 0.10683, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9712 - val_loss: 0.1068 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 498/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0981 - accuracy: 0.9692\n",
      "Epoch 498: val_loss improved from 0.10683 to 0.10676, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9712 - val_loss: 0.1068 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 499/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9705\n",
      "Epoch 499: val_loss improved from 0.10676 to 0.10670, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0899 - accuracy: 0.9712 - val_loss: 0.1067 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 500/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0942 - accuracy: 0.9698\n",
      "Epoch 500: val_loss improved from 0.10670 to 0.10664, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0898 - accuracy: 0.9712 - val_loss: 0.1066 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 501/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0900 - accuracy: 0.9710\n",
      "Epoch 501: val_loss improved from 0.10664 to 0.10657, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9712 - val_loss: 0.1066 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 502/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1016 - accuracy: 0.9686\n",
      "Epoch 502: val_loss improved from 0.10657 to 0.10651, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9712 - val_loss: 0.1065 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 503/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0937 - accuracy: 0.9679\n",
      "Epoch 503: val_loss improved from 0.10651 to 0.10645, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9712 - val_loss: 0.1064 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 504/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9712\n",
      "Epoch 504: val_loss improved from 0.10645 to 0.10639, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.1064 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 505/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0881 - accuracy: 0.9698\n",
      "Epoch 505: val_loss improved from 0.10639 to 0.10633, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9712 - val_loss: 0.1063 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 506/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0917 - accuracy: 0.9695\n",
      "Epoch 506: val_loss improved from 0.10633 to 0.10627, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9712 - val_loss: 0.1063 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 507/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0936 - accuracy: 0.9690\n",
      "Epoch 507: val_loss improved from 0.10627 to 0.10621, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.9712 - val_loss: 0.1062 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 508/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9738\n",
      "Epoch 508: val_loss improved from 0.10621 to 0.10616, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9712 - val_loss: 0.1062 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 509/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0915 - accuracy: 0.9698\n",
      "Epoch 509: val_loss improved from 0.10616 to 0.10610, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9712 - val_loss: 0.1061 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 510/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0857 - accuracy: 0.9759\n",
      "Epoch 510: val_loss improved from 0.10610 to 0.10604, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9712 - val_loss: 0.1060 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 511/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0854 - accuracy: 0.9754\n",
      "Epoch 511: val_loss improved from 0.10604 to 0.10597, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9712 - val_loss: 0.1060 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 512/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0922 - accuracy: 0.9731\n",
      "Epoch 512: val_loss improved from 0.10597 to 0.10591, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9712 - val_loss: 0.1059 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 513/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0856 - accuracy: 0.9692\n",
      "Epoch 513: val_loss improved from 0.10591 to 0.10586, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9712 - val_loss: 0.1059 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 514/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0905 - accuracy: 0.9695\n",
      "Epoch 514: val_loss improved from 0.10586 to 0.10580, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9712 - val_loss: 0.1058 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 515/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0873 - accuracy: 0.9729\n",
      "Epoch 515: val_loss improved from 0.10580 to 0.10574, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9712 - val_loss: 0.1057 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 516/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0793 - accuracy: 0.9767\n",
      "Epoch 516: val_loss did not improve from 0.10574\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0871 - accuracy: 0.9712 - val_loss: 0.1057 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 517/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0793 - accuracy: 0.9731\n",
      "Epoch 517: val_loss improved from 0.10574 to 0.10569, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9712 - val_loss: 0.1057 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 518/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0799 - accuracy: 0.9778\n",
      "Epoch 518: val_loss improved from 0.10569 to 0.10564, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.9712 - val_loss: 0.1056 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 519/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9712\n",
      "Epoch 519: val_loss improved from 0.10564 to 0.10558, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0866 - accuracy: 0.9712 - val_loss: 0.1056 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 520/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0895 - accuracy: 0.9690\n",
      "Epoch 520: val_loss improved from 0.10558 to 0.10550, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9712 - val_loss: 0.1055 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 521/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9712\n",
      "Epoch 521: val_loss improved from 0.10550 to 0.10544, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9712 - val_loss: 0.1054 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 522/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0882 - accuracy: 0.9686\n",
      "Epoch 522: val_loss improved from 0.10544 to 0.10538, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0861 - accuracy: 0.9712 - val_loss: 0.1054 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 523/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.9705\n",
      "Epoch 523: val_loss improved from 0.10538 to 0.10533, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9712 - val_loss: 0.1053 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 524/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0926 - accuracy: 0.9660\n",
      "Epoch 524: val_loss improved from 0.10533 to 0.10527, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9712 - val_loss: 0.1053 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 525/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9742\n",
      "Epoch 525: val_loss improved from 0.10527 to 0.10519, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0857 - accuracy: 0.9712 - val_loss: 0.1052 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 526/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0934 - accuracy: 0.9692\n",
      "Epoch 526: val_loss improved from 0.10519 to 0.10513, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9744 - val_loss: 0.1051 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 527/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0749 - accuracy: 0.9804\n",
      "Epoch 527: val_loss improved from 0.10513 to 0.10509, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9744 - val_loss: 0.1051 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 528/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0785 - accuracy: 0.9804\n",
      "Epoch 528: val_loss improved from 0.10509 to 0.10503, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0851 - accuracy: 0.9744 - val_loss: 0.1050 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 529/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9742\n",
      "Epoch 529: val_loss improved from 0.10503 to 0.10497, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0850 - accuracy: 0.9744 - val_loss: 0.1050 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 530/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9744\n",
      "Epoch 530: val_loss improved from 0.10497 to 0.10492, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9744 - val_loss: 0.1049 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 531/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0853 - accuracy: 0.9754\n",
      "Epoch 531: val_loss improved from 0.10492 to 0.10487, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9744 - val_loss: 0.1049 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 532/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9770\n",
      "Epoch 532: val_loss did not improve from 0.10487\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9744 - val_loss: 0.1049 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 533/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0852 - accuracy: 0.9741\n",
      "Epoch 533: val_loss improved from 0.10487 to 0.10483, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0844 - accuracy: 0.9744 - val_loss: 0.1048 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 534/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9744\n",
      "Epoch 534: val_loss improved from 0.10483 to 0.10478, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9744 - val_loss: 0.1048 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 535/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0887 - accuracy: 0.9741\n",
      "Epoch 535: val_loss improved from 0.10478 to 0.10473, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9744 - val_loss: 0.1047 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 536/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0944 - accuracy: 0.9686\n",
      "Epoch 536: val_loss improved from 0.10473 to 0.10468, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9744 - val_loss: 0.1047 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 537/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0893 - accuracy: 0.9719\n",
      "Epoch 537: val_loss improved from 0.10468 to 0.10462, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9744 - val_loss: 0.1046 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 538/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0882 - accuracy: 0.9719\n",
      "Epoch 538: val_loss improved from 0.10462 to 0.10457, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9744 - val_loss: 0.1046 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 539/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9738\n",
      "Epoch 539: val_loss improved from 0.10457 to 0.10452, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9744 - val_loss: 0.1045 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 540/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0742 - accuracy: 0.9759\n",
      "Epoch 540: val_loss improved from 0.10452 to 0.10447, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0833 - accuracy: 0.9744 - val_loss: 0.1045 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 541/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0849 - accuracy: 0.9733\n",
      "Epoch 541: val_loss improved from 0.10447 to 0.10441, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9744 - val_loss: 0.1044 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 542/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0850 - accuracy: 0.9724\n",
      "Epoch 542: val_loss improved from 0.10441 to 0.10435, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9744 - val_loss: 0.1044 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 543/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0896 - accuracy: 0.9736\n",
      "Epoch 543: val_loss improved from 0.10435 to 0.10430, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9744 - val_loss: 0.1043 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 544/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9742\n",
      "Epoch 544: val_loss improved from 0.10430 to 0.10427, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 0.9744 - val_loss: 0.1043 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 545/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0859 - accuracy: 0.9724\n",
      "Epoch 545: val_loss improved from 0.10427 to 0.10423, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9744 - val_loss: 0.1042 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 546/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9744\n",
      "Epoch 546: val_loss improved from 0.10423 to 0.10418, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9744 - val_loss: 0.1042 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 547/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0883 - accuracy: 0.9714\n",
      "Epoch 547: val_loss improved from 0.10418 to 0.10412, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0822 - accuracy: 0.9744 - val_loss: 0.1041 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 548/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0845 - accuracy: 0.9733\n",
      "Epoch 548: val_loss improved from 0.10412 to 0.10408, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9744 - val_loss: 0.1041 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 549/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0753 - accuracy: 0.9750\n",
      "Epoch 549: val_loss improved from 0.10408 to 0.10405, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9744 - val_loss: 0.1040 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 550/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0849 - accuracy: 0.9709\n",
      "Epoch 550: val_loss improved from 0.10405 to 0.10399, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 0.1040 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 551/600\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0822 - accuracy: 0.9754\n",
      "Epoch 551: val_loss improved from 0.10399 to 0.10395, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0817 - accuracy: 0.9744 - val_loss: 0.1039 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 552/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9738\n",
      "Epoch 552: val_loss improved from 0.10395 to 0.10391, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0815 - accuracy: 0.9744 - val_loss: 0.1039 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 553/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0823 - accuracy: 0.9759\n",
      "Epoch 553: val_loss improved from 0.10391 to 0.10387, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0813 - accuracy: 0.9744 - val_loss: 0.1039 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 554/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0704 - accuracy: 0.9774\n",
      "Epoch 554: val_loss improved from 0.10387 to 0.10383, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0812 - accuracy: 0.9744 - val_loss: 0.1038 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 555/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0859 - accuracy: 0.9725\n",
      "Epoch 555: val_loss improved from 0.10383 to 0.10379, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9744 - val_loss: 0.1038 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 556/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0818 - accuracy: 0.9731\n",
      "Epoch 556: val_loss improved from 0.10379 to 0.10374, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 557/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0844 - accuracy: 0.9729\n",
      "Epoch 557: val_loss improved from 0.10374 to 0.10370, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0808 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 558/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0835 - accuracy: 0.9733\n",
      "Epoch 558: val_loss improved from 0.10370 to 0.10366, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 559/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0848 - accuracy: 0.9714\n",
      "Epoch 559: val_loss improved from 0.10366 to 0.10362, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0805 - accuracy: 0.9744 - val_loss: 0.1036 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 560/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0794 - accuracy: 0.9763\n",
      "Epoch 560: val_loss improved from 0.10362 to 0.10355, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0804 - accuracy: 0.9744 - val_loss: 0.1035 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 561/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0835 - accuracy: 0.9759\n",
      "Epoch 561: val_loss improved from 0.10355 to 0.10349, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0802 - accuracy: 0.9776 - val_loss: 0.1035 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 562/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9776\n",
      "Epoch 562: val_loss improved from 0.10349 to 0.10345, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9776 - val_loss: 0.1034 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 563/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0831 - accuracy: 0.9763\n",
      "Epoch 563: val_loss improved from 0.10345 to 0.10340, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0799 - accuracy: 0.9776 - val_loss: 0.1034 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 564/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0672 - accuracy: 0.9774\n",
      "Epoch 564: val_loss improved from 0.10340 to 0.10336, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0798 - accuracy: 0.9776 - val_loss: 0.1034 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 565/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9774\n",
      "Epoch 565: val_loss improved from 0.10336 to 0.10332, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9776 - val_loss: 0.1033 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 566/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9770\n",
      "Epoch 566: val_loss improved from 0.10332 to 0.10328, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0795 - accuracy: 0.9776 - val_loss: 0.1033 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 567/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9774\n",
      "Epoch 567: val_loss improved from 0.10328 to 0.10325, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9776 - val_loss: 0.1033 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 568/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9774\n",
      "Epoch 568: val_loss improved from 0.10325 to 0.10322, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9776 - val_loss: 0.1032 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 569/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9774\n",
      "Epoch 569: val_loss improved from 0.10322 to 0.10318, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0791 - accuracy: 0.9776 - val_loss: 0.1032 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 570/600\n",
      "52/63 [=======================>......] - ETA: 0s - loss: 0.0832 - accuracy: 0.9769\n",
      "Epoch 570: val_loss improved from 0.10318 to 0.10313, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9776 - val_loss: 0.1031 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 571/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0815 - accuracy: 0.9763\n",
      "Epoch 571: val_loss improved from 0.10313 to 0.10310, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0788 - accuracy: 0.9776 - val_loss: 0.1031 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 572/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0803 - accuracy: 0.9778\n",
      "Epoch 572: val_loss improved from 0.10310 to 0.10306, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9776 - val_loss: 0.1031 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 573/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0841 - accuracy: 0.9750\n",
      "Epoch 573: val_loss improved from 0.10306 to 0.10302, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0785 - accuracy: 0.9776 - val_loss: 0.1030 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 574/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0809 - accuracy: 0.9767\n",
      "Epoch 574: val_loss improved from 0.10302 to 0.10300, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0784 - accuracy: 0.9776 - val_loss: 0.1030 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 575/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9774\n",
      "Epoch 575: val_loss improved from 0.10300 to 0.10297, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9776 - val_loss: 0.1030 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 576/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9803\n",
      "Epoch 576: val_loss did not improve from 0.10297\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9776 - val_loss: 0.1030 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 577/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0624 - accuracy: 0.9855\n",
      "Epoch 577: val_loss did not improve from 0.10297\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9808 - val_loss: 0.1030 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 578/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9806\n",
      "Epoch 578: val_loss improved from 0.10297 to 0.10294, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0779 - accuracy: 0.9808 - val_loss: 0.1029 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 579/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9808\n",
      "Epoch 579: val_loss improved from 0.10294 to 0.10290, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0777 - accuracy: 0.9808 - val_loss: 0.1029 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 580/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9808\n",
      "Epoch 580: val_loss improved from 0.10290 to 0.10286, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9808 - val_loss: 0.1029 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 581/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9806\n",
      "Epoch 581: val_loss improved from 0.10286 to 0.10283, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9808 - val_loss: 0.1028 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 582/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9808\n",
      "Epoch 582: val_loss improved from 0.10283 to 0.10280, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9808 - val_loss: 0.1028 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 583/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0676 - accuracy: 0.9855\n",
      "Epoch 583: val_loss improved from 0.10280 to 0.10270, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0772 - accuracy: 0.9808 - val_loss: 0.1027 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 584/600\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0804 - accuracy: 0.9793\n",
      "Epoch 584: val_loss improved from 0.10270 to 0.10267, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0770 - accuracy: 0.9808 - val_loss: 0.1027 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 585/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0829 - accuracy: 0.9778\n",
      "Epoch 585: val_loss improved from 0.10267 to 0.10264, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9808 - val_loss: 0.1026 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 586/600\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0798 - accuracy: 0.9797\n",
      "Epoch 586: val_loss improved from 0.10264 to 0.10260, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0768 - accuracy: 0.9808 - val_loss: 0.1026 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 587/600\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0825 - accuracy: 0.9774\n",
      "Epoch 587: val_loss improved from 0.10260 to 0.10256, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9808 - val_loss: 0.1026 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 588/600\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0788 - accuracy: 0.9800\n",
      "Epoch 588: val_loss improved from 0.10256 to 0.10253, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0765 - accuracy: 0.9808 - val_loss: 0.1025 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 589/600\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9806\n",
      "Epoch 589: val_loss improved from 0.10253 to 0.10251, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9808 - val_loss: 0.1025 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 590/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0784 - accuracy: 0.9821\n",
      "Epoch 590: val_loss improved from 0.10251 to 0.10246, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9808 - val_loss: 0.1025 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 591/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9803\n",
      "Epoch 591: val_loss improved from 0.10246 to 0.10241, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9808 - val_loss: 0.1024 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 592/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9803\n",
      "Epoch 592: val_loss improved from 0.10241 to 0.10238, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9808 - val_loss: 0.1024 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 593/600\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0784 - accuracy: 0.9818\n",
      "Epoch 593: val_loss improved from 0.10238 to 0.10235, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9808 - val_loss: 0.1023 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 594/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9803\n",
      "Epoch 594: val_loss improved from 0.10235 to 0.10232, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 0.9808 - val_loss: 0.1023 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 595/600\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0636 - accuracy: 0.9852\n",
      "Epoch 595: val_loss improved from 0.10232 to 0.10228, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9808 - val_loss: 0.1023 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 596/600\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9808\n",
      "Epoch 596: val_loss improved from 0.10228 to 0.10225, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9808 - val_loss: 0.1022 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 597/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0802 - accuracy: 0.9786\n",
      "Epoch 597: val_loss improved from 0.10225 to 0.10223, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0753 - accuracy: 0.9808 - val_loss: 0.1022 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 598/600\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.0804 - accuracy: 0.9765\n",
      "Epoch 598: val_loss improved from 0.10223 to 0.10219, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9808 - val_loss: 0.1022 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 599/600\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0795 - accuracy: 0.9786\n",
      "Epoch 599: val_loss improved from 0.10219 to 0.10215, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.1022 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 600/600\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9836\n",
      "Epoch 600: val_loss improved from 0.10215 to 0.10213, saving model to model_checkpoint\\GRU_2 layer_SGD.h5\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9808 - val_loss: 0.1021 - val_accuracy: 0.9702 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_15 (GRU)                (None, None, 32)          11520     \n",
      "                                                                 \n",
      " gru_16 (GRU)                (None, 32)                6336      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,889\n",
      "Trainable params: 17,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9702\n",
      "Test Loss: 0.1021304801106453\n",
      "Test Accuracy: 0.9702380895614624\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'GRU_2 layer_SGD.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, x_train.shape[-1]),return_sequences=True))\n",
    "model.add(layers.GRU(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a SGD optimizer with an exponential decaying learning rate\n",
    "optimizer, lr_schedule = optimizer_SGD(0.001, 1000, 0.1)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=5, epochs=600, validation_data=(x_val, y_val), callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule), callbacks_list])\n",
    "\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.7122 - accuracy: 0.2803\n",
      "Epoch 1: val_loss improved from inf to 0.70895, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 5s 24ms/step - loss: 0.7124 - accuracy: 0.2780 - val_loss: 0.7090 - val_accuracy: 0.3036 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.7102 - accuracy: 0.2812\n",
      "Epoch 2: val_loss improved from 0.70895 to 0.70690, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.7102 - accuracy: 0.2907 - val_loss: 0.7069 - val_accuracy: 0.3155 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.7083 - accuracy: 0.2805\n",
      "Epoch 3: val_loss improved from 0.70690 to 0.70484, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.7081 - accuracy: 0.2971 - val_loss: 0.7048 - val_accuracy: 0.3274 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.7065 - accuracy: 0.3077\n",
      "Epoch 4: val_loss improved from 0.70484 to 0.70281, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.7060 - accuracy: 0.3099 - val_loss: 0.7028 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.7029 - accuracy: 0.3133\n",
      "Epoch 5: val_loss improved from 0.70281 to 0.70080, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.7039 - accuracy: 0.3099 - val_loss: 0.7008 - val_accuracy: 0.3452 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.7018 - accuracy: 0.3419\n",
      "Epoch 6: val_loss improved from 0.70080 to 0.69888, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.7018 - accuracy: 0.3419 - val_loss: 0.6989 - val_accuracy: 0.3452 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.6997 - accuracy: 0.3686\n",
      "Epoch 7: val_loss improved from 0.69888 to 0.69691, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6997 - accuracy: 0.3674 - val_loss: 0.6969 - val_accuracy: 0.3631 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.6984 - accuracy: 0.3833\n",
      "Epoch 8: val_loss improved from 0.69691 to 0.69495, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.3866 - val_loss: 0.6949 - val_accuracy: 0.3631 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6950 - accuracy: 0.4146\n",
      "Epoch 9: val_loss improved from 0.69495 to 0.69303, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.4121 - val_loss: 0.6930 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.6933 - accuracy: 0.4184\n",
      "Epoch 10: val_loss improved from 0.69303 to 0.69111, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.4185 - val_loss: 0.6911 - val_accuracy: 0.4048 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.6911 - accuracy: 0.4444\n",
      "Epoch 11: val_loss improved from 0.69111 to 0.68921, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.4441 - val_loss: 0.6892 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6892 - accuracy: 0.4473\n",
      "Epoch 12: val_loss improved from 0.68921 to 0.68728, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6892 - accuracy: 0.4473 - val_loss: 0.6873 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6903 - accuracy: 0.4512\n",
      "Epoch 13: val_loss improved from 0.68728 to 0.68528, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.4728 - val_loss: 0.6853 - val_accuracy: 0.4881 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.6845 - accuracy: 0.4767\n",
      "Epoch 14: val_loss improved from 0.68528 to 0.68328, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6848 - accuracy: 0.4888 - val_loss: 0.6833 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.5256\n",
      "Epoch 15: val_loss improved from 0.68328 to 0.68122, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.5240 - val_loss: 0.6812 - val_accuracy: 0.5476 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.6803 - accuracy: 0.5686\n",
      "Epoch 16: val_loss improved from 0.68122 to 0.67907, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5719 - val_loss: 0.6791 - val_accuracy: 0.6071 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.6778 - accuracy: 0.6474\n",
      "Epoch 17: val_loss improved from 0.67907 to 0.67688, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.6779 - accuracy: 0.6486 - val_loss: 0.6769 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.6755 - accuracy: 0.6827\n",
      "Epoch 18: val_loss improved from 0.67688 to 0.67466, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6755 - accuracy: 0.6837 - val_loss: 0.6747 - val_accuracy: 0.7083 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.7348\n",
      "Epoch 19: val_loss improved from 0.67466 to 0.67245, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.7348 - val_loss: 0.6724 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.6702 - accuracy: 0.7778\n",
      "Epoch 20: val_loss improved from 0.67245 to 0.67024, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6708 - accuracy: 0.7572 - val_loss: 0.6702 - val_accuracy: 0.7440 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.6690 - accuracy: 0.7875\n",
      "Epoch 21: val_loss improved from 0.67024 to 0.66802, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6685 - accuracy: 0.7700 - val_loss: 0.6680 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.6651 - accuracy: 0.8016\n",
      "Epoch 22: val_loss improved from 0.66802 to 0.66584, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6662 - accuracy: 0.7923 - val_loss: 0.6658 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6660 - accuracy: 0.7846\n",
      "Epoch 23: val_loss improved from 0.66584 to 0.66370, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.8019 - val_loss: 0.6637 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.6631 - accuracy: 0.8214\n",
      "Epoch 24: val_loss improved from 0.66370 to 0.66148, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6616 - accuracy: 0.8211 - val_loss: 0.6615 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.6583 - accuracy: 0.8217\n",
      "Epoch 25: val_loss improved from 0.66148 to 0.65928, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.8339 - val_loss: 0.6593 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.6579 - accuracy: 0.8367\n",
      "Epoch 26: val_loss improved from 0.65928 to 0.65716, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6571 - accuracy: 0.8403 - val_loss: 0.6572 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.6554 - accuracy: 0.8399\n",
      "Epoch 27: val_loss improved from 0.65716 to 0.65503, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6549 - accuracy: 0.8403 - val_loss: 0.6550 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.6527 - accuracy: 0.8462\n",
      "Epoch 28: val_loss improved from 0.65503 to 0.65294, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.8466 - val_loss: 0.6529 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.6506 - accuracy: 0.8431\n",
      "Epoch 29: val_loss improved from 0.65294 to 0.65083, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6505 - accuracy: 0.8435 - val_loss: 0.6508 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.8466\n",
      "Epoch 30: val_loss improved from 0.65083 to 0.64875, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6482 - accuracy: 0.8466 - val_loss: 0.6488 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6478 - accuracy: 0.8374\n",
      "Epoch 31: val_loss improved from 0.64875 to 0.64674, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6460 - accuracy: 0.8498 - val_loss: 0.6467 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.6434 - accuracy: 0.8529\n",
      "Epoch 32: val_loss improved from 0.64674 to 0.64473, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6439 - accuracy: 0.8530 - val_loss: 0.6447 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.6428 - accuracy: 0.8533\n",
      "Epoch 33: val_loss improved from 0.64473 to 0.64265, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6417 - accuracy: 0.8594 - val_loss: 0.6427 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.8658\n",
      "Epoch 34: val_loss improved from 0.64265 to 0.64060, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.8658 - val_loss: 0.6406 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.6375 - accuracy: 0.8686\n",
      "Epoch 35: val_loss improved from 0.64060 to 0.63853, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6375 - accuracy: 0.8690 - val_loss: 0.6385 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.6346 - accuracy: 0.8750\n",
      "Epoch 36: val_loss improved from 0.63853 to 0.63645, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6354 - accuracy: 0.8722 - val_loss: 0.6365 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.6339 - accuracy: 0.8732\n",
      "Epoch 37: val_loss improved from 0.63645 to 0.63437, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6333 - accuracy: 0.8722 - val_loss: 0.6344 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6316 - accuracy: 0.8699\n",
      "Epoch 38: val_loss improved from 0.63437 to 0.63231, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6311 - accuracy: 0.8690 - val_loss: 0.6323 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.6287 - accuracy: 0.8733\n",
      "Epoch 39: val_loss improved from 0.63231 to 0.63017, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6290 - accuracy: 0.8722 - val_loss: 0.6302 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.6258 - accuracy: 0.8824\n",
      "Epoch 40: val_loss improved from 0.63017 to 0.62802, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.8754 - val_loss: 0.6280 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6228 - accuracy: 0.9065\n",
      "Epoch 41: val_loss improved from 0.62802 to 0.62585, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6247 - accuracy: 0.8754 - val_loss: 0.6258 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6208 - accuracy: 0.8943\n",
      "Epoch 42: val_loss improved from 0.62585 to 0.62372, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.8818 - val_loss: 0.6237 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.6197 - accuracy: 0.8833\n",
      "Epoch 43: val_loss improved from 0.62372 to 0.62150, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6203 - accuracy: 0.8850 - val_loss: 0.6215 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6150 - accuracy: 0.8984\n",
      "Epoch 44: val_loss improved from 0.62150 to 0.61928, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6181 - accuracy: 0.8850 - val_loss: 0.6193 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6165 - accuracy: 0.8862\n",
      "Epoch 45: val_loss improved from 0.61928 to 0.61702, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6158 - accuracy: 0.8850 - val_loss: 0.6170 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.6142 - accuracy: 0.8875\n",
      "Epoch 46: val_loss improved from 0.61702 to 0.61473, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.8850 - val_loss: 0.6147 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6119 - accuracy: 0.8862\n",
      "Epoch 47: val_loss improved from 0.61473 to 0.61241, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.8850 - val_loss: 0.6124 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6083 - accuracy: 0.8821\n",
      "Epoch 48: val_loss improved from 0.61241 to 0.61009, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6089 - accuracy: 0.8850 - val_loss: 0.6101 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6065 - accuracy: 0.8850\n",
      "Epoch 49: val_loss improved from 0.61009 to 0.60776, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6065 - accuracy: 0.8850 - val_loss: 0.6078 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.6035 - accuracy: 0.8912\n",
      "Epoch 50: val_loss improved from 0.60776 to 0.60537, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.6041 - accuracy: 0.8882 - val_loss: 0.6054 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.6019 - accuracy: 0.8943\n",
      "Epoch 51: val_loss improved from 0.60537 to 0.60296, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.6017 - accuracy: 0.8882 - val_loss: 0.6030 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.5954 - accuracy: 0.8862\n",
      "Epoch 52: val_loss improved from 0.60296 to 0.60055, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5992 - accuracy: 0.8882 - val_loss: 0.6005 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.5968 - accuracy: 0.8878\n",
      "Epoch 53: val_loss improved from 0.60055 to 0.59811, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.8882 - val_loss: 0.5981 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.5947 - accuracy: 0.8889\n",
      "Epoch 54: val_loss improved from 0.59811 to 0.59570, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5943 - accuracy: 0.8914 - val_loss: 0.5957 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.8978\n",
      "Epoch 55: val_loss improved from 0.59570 to 0.59326, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5918 - accuracy: 0.8978 - val_loss: 0.5933 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.5891 - accuracy: 0.8924\n",
      "Epoch 56: val_loss improved from 0.59326 to 0.59082, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.5894 - accuracy: 0.8978 - val_loss: 0.5908 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.5869 - accuracy: 0.9000\n",
      "Epoch 57: val_loss improved from 0.59082 to 0.58837, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.5869 - accuracy: 0.8978 - val_loss: 0.5884 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.5798 - accuracy: 0.9024\n",
      "Epoch 58: val_loss improved from 0.58837 to 0.58591, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5844 - accuracy: 0.8978 - val_loss: 0.5859 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.8974\n",
      "Epoch 59: val_loss improved from 0.58591 to 0.58343, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5819 - accuracy: 0.8978 - val_loss: 0.5834 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.8978\n",
      "Epoch 60: val_loss improved from 0.58343 to 0.58090, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5794 - accuracy: 0.8978 - val_loss: 0.5809 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.5757 - accuracy: 0.9020\n",
      "Epoch 61: val_loss improved from 0.58090 to 0.57836, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.8978 - val_loss: 0.5784 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.5755 - accuracy: 0.8877\n",
      "Epoch 62: val_loss improved from 0.57836 to 0.57582, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.8978 - val_loss: 0.5758 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.5738 - accuracy: 0.8849\n",
      "Epoch 63: val_loss improved from 0.57582 to 0.57324, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5718 - accuracy: 0.8978 - val_loss: 0.5732 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.5662 - accuracy: 0.9083\n",
      "Epoch 64: val_loss improved from 0.57324 to 0.57066, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.8978 - val_loss: 0.5707 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.5641 - accuracy: 0.9024\n",
      "Epoch 65: val_loss improved from 0.57066 to 0.56805, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.8978 - val_loss: 0.5681 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.5649 - accuracy: 0.8968\n",
      "Epoch 66: val_loss improved from 0.56805 to 0.56544, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.8978 - val_loss: 0.5654 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.5655 - accuracy: 0.8902\n",
      "Epoch 67: val_loss improved from 0.56544 to 0.56280, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.8978 - val_loss: 0.5628 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.5580 - accuracy: 0.8902\n",
      "Epoch 68: val_loss improved from 0.56280 to 0.56013, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.8978 - val_loss: 0.5601 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.5542 - accuracy: 0.9000\n",
      "Epoch 69: val_loss improved from 0.56013 to 0.55745, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.5559 - accuracy: 0.8978 - val_loss: 0.5574 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.5526 - accuracy: 0.9008\n",
      "Epoch 70: val_loss improved from 0.55745 to 0.55477, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.9010 - val_loss: 0.5548 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.5513 - accuracy: 0.9083\n",
      "Epoch 71: val_loss improved from 0.55477 to 0.55215, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.9010 - val_loss: 0.5521 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.5539 - accuracy: 0.8917\n",
      "Epoch 72: val_loss improved from 0.55215 to 0.54942, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 0.9010 - val_loss: 0.5494 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.5491 - accuracy: 0.8917\n",
      "Epoch 73: val_loss improved from 0.54942 to 0.54670, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5452 - accuracy: 0.9010 - val_loss: 0.5467 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.5420 - accuracy: 0.9020\n",
      "Epoch 74: val_loss improved from 0.54670 to 0.54393, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.9010 - val_loss: 0.5439 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.5395 - accuracy: 0.9028\n",
      "Epoch 75: val_loss improved from 0.54393 to 0.54115, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.5397 - accuracy: 0.9010 - val_loss: 0.5411 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.5384 - accuracy: 0.8913\n",
      "Epoch 76: val_loss improved from 0.54115 to 0.53834, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.9010 - val_loss: 0.5383 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.5338 - accuracy: 0.8939\n",
      "Epoch 77: val_loss improved from 0.53834 to 0.53555, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.8978 - val_loss: 0.5356 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.5344 - accuracy: 0.8929\n",
      "Epoch 78: val_loss improved from 0.53555 to 0.53269, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.8978 - val_loss: 0.5327 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.5273 - accuracy: 0.9031\n",
      "Epoch 79: val_loss improved from 0.53269 to 0.52983, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.9042 - val_loss: 0.5298 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.5261 - accuracy: 0.9000\n",
      "Epoch 80: val_loss improved from 0.52983 to 0.52696, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.9010 - val_loss: 0.5270 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.5304 - accuracy: 0.8862\n",
      "Epoch 81: val_loss improved from 0.52696 to 0.52406, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.9042 - val_loss: 0.5241 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.5197 - accuracy: 0.9087\n",
      "Epoch 82: val_loss improved from 0.52406 to 0.52124, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5199 - accuracy: 0.9010 - val_loss: 0.5212 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.5119 - accuracy: 0.9147\n",
      "Epoch 83: val_loss improved from 0.52124 to 0.51836, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.9042 - val_loss: 0.5184 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.9006\n",
      "Epoch 84: val_loss improved from 0.51836 to 0.51547, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.9010 - val_loss: 0.5155 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.5099 - accuracy: 0.9031\n",
      "Epoch 85: val_loss improved from 0.51547 to 0.51252, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.9010 - val_loss: 0.5125 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.5113 - accuracy: 0.8953\n",
      "Epoch 86: val_loss improved from 0.51252 to 0.50957, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.9010 - val_loss: 0.5096 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.5098 - accuracy: 0.8915\n",
      "Epoch 87: val_loss improved from 0.50957 to 0.50660, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.9010 - val_loss: 0.5066 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.5026 - accuracy: 0.9109\n",
      "Epoch 88: val_loss improved from 0.50660 to 0.50364, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.9042 - val_loss: 0.5036 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.5025 - accuracy: 0.8939\n",
      "Epoch 89: val_loss improved from 0.50364 to 0.50071, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.9010 - val_loss: 0.5007 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.4966 - accuracy: 0.9038\n",
      "Epoch 90: val_loss improved from 0.50071 to 0.49772, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.9042 - val_loss: 0.4977 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.9010\n",
      "Epoch 91: val_loss improved from 0.49772 to 0.49472, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.9010 - val_loss: 0.4947 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.4875 - accuracy: 0.9087\n",
      "Epoch 92: val_loss improved from 0.49472 to 0.49172, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.9042 - val_loss: 0.4917 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.4914 - accuracy: 0.9048\n",
      "Epoch 93: val_loss improved from 0.49172 to 0.48873, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.9042 - val_loss: 0.4887 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4880 - accuracy: 0.8992\n",
      "Epoch 94: val_loss improved from 0.48873 to 0.48573, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.9042 - val_loss: 0.4857 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4817 - accuracy: 0.9031\n",
      "Epoch 95: val_loss improved from 0.48573 to 0.48279, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.9042 - val_loss: 0.4828 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.4806 - accuracy: 0.9078\n",
      "Epoch 96: val_loss improved from 0.48279 to 0.47981, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.9073 - val_loss: 0.4798 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.4769 - accuracy: 0.9015\n",
      "Epoch 97: val_loss improved from 0.47981 to 0.47681, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.9073 - val_loss: 0.4768 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.4761 - accuracy: 0.8984\n",
      "Epoch 98: val_loss improved from 0.47681 to 0.47383, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.9073 - val_loss: 0.4738 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.4658 - accuracy: 0.9148\n",
      "Epoch 99: val_loss improved from 0.47383 to 0.47084, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.9073 - val_loss: 0.4708 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.4620 - accuracy: 0.9129\n",
      "Epoch 100: val_loss improved from 0.47084 to 0.46786, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.9073 - val_loss: 0.4679 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.4586 - accuracy: 0.9187\n",
      "Epoch 101: val_loss improved from 0.46786 to 0.46487, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.9105 - val_loss: 0.4649 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.4611 - accuracy: 0.9129\n",
      "Epoch 102: val_loss improved from 0.46487 to 0.46188, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.9105 - val_loss: 0.4619 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.4546 - accuracy: 0.9167\n",
      "Epoch 103: val_loss improved from 0.46188 to 0.45890, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.9105 - val_loss: 0.4589 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.4555 - accuracy: 0.9148\n",
      "Epoch 104: val_loss improved from 0.45890 to 0.45594, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.9105 - val_loss: 0.4559 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.4544 - accuracy: 0.9129\n",
      "Epoch 105: val_loss improved from 0.45594 to 0.45299, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.9105 - val_loss: 0.4530 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.4480 - accuracy: 0.9187\n",
      "Epoch 106: val_loss improved from 0.45299 to 0.45003, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.9105 - val_loss: 0.4500 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.4471 - accuracy: 0.9067\n",
      "Epoch 107: val_loss improved from 0.45003 to 0.44708, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.9105 - val_loss: 0.4471 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.4415 - accuracy: 0.9106\n",
      "Epoch 108: val_loss improved from 0.44708 to 0.44414, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.9105 - val_loss: 0.4441 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4387 - accuracy: 0.9031\n",
      "Epoch 109: val_loss improved from 0.44414 to 0.44120, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.9105 - val_loss: 0.4412 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.4339 - accuracy: 0.9208\n",
      "Epoch 110: val_loss improved from 0.44120 to 0.43827, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.9105 - val_loss: 0.4383 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4276 - accuracy: 0.9186\n",
      "Epoch 111: val_loss improved from 0.43827 to 0.43535, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.9105 - val_loss: 0.4353 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4356 - accuracy: 0.8953\n",
      "Epoch 112: val_loss improved from 0.43535 to 0.43243, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.9105 - val_loss: 0.4324 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.9103\n",
      "Epoch 113: val_loss improved from 0.43243 to 0.42954, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9105 - val_loss: 0.4295 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.4189 - accuracy: 0.9129\n",
      "Epoch 114: val_loss improved from 0.42954 to 0.42665, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.9105 - val_loss: 0.4267 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.4241 - accuracy: 0.8968\n",
      "Epoch 115: val_loss improved from 0.42665 to 0.42379, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.9105 - val_loss: 0.4238 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4235 - accuracy: 0.9070\n",
      "Epoch 116: val_loss improved from 0.42379 to 0.42094, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.9105 - val_loss: 0.4209 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4126 - accuracy: 0.9109\n",
      "Epoch 117: val_loss improved from 0.42094 to 0.41808, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.9105 - val_loss: 0.4181 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.4194 - accuracy: 0.9031\n",
      "Epoch 118: val_loss improved from 0.41808 to 0.41526, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.9105 - val_loss: 0.4153 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.4050 - accuracy: 0.9206\n",
      "Epoch 119: val_loss improved from 0.41526 to 0.41242, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.9105 - val_loss: 0.4124 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.4080 - accuracy: 0.9103\n",
      "Epoch 120: val_loss improved from 0.41242 to 0.40962, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.9105 - val_loss: 0.4096 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.4061 - accuracy: 0.9087\n",
      "Epoch 121: val_loss improved from 0.40962 to 0.40685, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.9105 - val_loss: 0.4068 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.4078 - accuracy: 0.9087\n",
      "Epoch 122: val_loss improved from 0.40685 to 0.40418, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.9105 - val_loss: 0.4042 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.9105\n",
      "Epoch 123: val_loss improved from 0.40418 to 0.40141, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.9105 - val_loss: 0.4014 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.3967 - accuracy: 0.9103\n",
      "Epoch 124: val_loss improved from 0.40141 to 0.39867, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.9105 - val_loss: 0.3987 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.4008 - accuracy: 0.8984\n",
      "Epoch 125: val_loss improved from 0.39867 to 0.39594, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.9105 - val_loss: 0.3959 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.3884 - accuracy: 0.9146\n",
      "Epoch 126: val_loss improved from 0.39594 to 0.39325, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.9105 - val_loss: 0.3932 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.9105\n",
      "Epoch 127: val_loss improved from 0.39325 to 0.39057, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.9105 - val_loss: 0.3906 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.3889 - accuracy: 0.9106\n",
      "Epoch 128: val_loss improved from 0.39057 to 0.38798, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.9137 - val_loss: 0.3880 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.9137\n",
      "Epoch 129: val_loss improved from 0.38798 to 0.38534, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.9137 - val_loss: 0.3853 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.3846 - accuracy: 0.9062\n",
      "Epoch 130: val_loss improved from 0.38534 to 0.38272, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.9137 - val_loss: 0.3827 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.3815 - accuracy: 0.9094\n",
      "Epoch 131: val_loss improved from 0.38272 to 0.38013, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.9137 - val_loss: 0.3801 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.3741 - accuracy: 0.9150\n",
      "Epoch 132: val_loss improved from 0.38013 to 0.37758, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.9137 - val_loss: 0.3776 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.3705 - accuracy: 0.9150\n",
      "Epoch 133: val_loss improved from 0.37758 to 0.37503, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.9137 - val_loss: 0.3750 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.3761 - accuracy: 0.9111\n",
      "Epoch 134: val_loss improved from 0.37503 to 0.37251, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.9137 - val_loss: 0.3725 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.3639 - accuracy: 0.9184\n",
      "Epoch 135: val_loss improved from 0.37251 to 0.36999, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.9137 - val_loss: 0.3700 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.3680 - accuracy: 0.9100\n",
      "Epoch 136: val_loss improved from 0.36999 to 0.36752, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3647 - accuracy: 0.9137 - val_loss: 0.3675 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.3624 - accuracy: 0.9130\n",
      "Epoch 137: val_loss improved from 0.36752 to 0.36508, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3622 - accuracy: 0.9137 - val_loss: 0.3651 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.3617 - accuracy: 0.9094\n",
      "Epoch 138: val_loss improved from 0.36508 to 0.36265, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.9137 - val_loss: 0.3627 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.3456 - accuracy: 0.9242\n",
      "Epoch 139: val_loss improved from 0.36265 to 0.36045, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3572 - accuracy: 0.9137 - val_loss: 0.3605 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.3554 - accuracy: 0.9149\n",
      "Epoch 140: val_loss improved from 0.36045 to 0.35804, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3550 - accuracy: 0.9137 - val_loss: 0.3580 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.3469 - accuracy: 0.9200\n",
      "Epoch 141: val_loss improved from 0.35804 to 0.35569, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.9137 - val_loss: 0.3557 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.3537 - accuracy: 0.9074\n",
      "Epoch 142: val_loss improved from 0.35569 to 0.35333, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.9137 - val_loss: 0.3533 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.3518 - accuracy: 0.9167\n",
      "Epoch 143: val_loss improved from 0.35333 to 0.35102, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3478 - accuracy: 0.9201 - val_loss: 0.3510 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.3446 - accuracy: 0.9167\n",
      "Epoch 144: val_loss improved from 0.35102 to 0.34871, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.9201 - val_loss: 0.3487 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.3431 - accuracy: 0.9233\n",
      "Epoch 145: val_loss improved from 0.34871 to 0.34643, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3431 - accuracy: 0.9201 - val_loss: 0.3464 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.3426 - accuracy: 0.9183\n",
      "Epoch 146: val_loss improved from 0.34643 to 0.34418, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.3408 - accuracy: 0.9201 - val_loss: 0.3442 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.3427 - accuracy: 0.9091\n",
      "Epoch 147: val_loss improved from 0.34418 to 0.34199, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.3385 - accuracy: 0.9201 - val_loss: 0.3420 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.3360 - accuracy: 0.9218\n",
      "Epoch 148: val_loss improved from 0.34199 to 0.33979, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3363 - accuracy: 0.9201 - val_loss: 0.3398 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.3335 - accuracy: 0.9236\n",
      "Epoch 149: val_loss improved from 0.33979 to 0.33760, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3340 - accuracy: 0.9233 - val_loss: 0.3376 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.3319 - accuracy: 0.9231\n",
      "Epoch 150: val_loss improved from 0.33760 to 0.33543, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.3318 - accuracy: 0.9233 - val_loss: 0.3354 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.3282 - accuracy: 0.9233\n",
      "Epoch 151: val_loss improved from 0.33543 to 0.33328, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.9233 - val_loss: 0.3333 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.9233\n",
      "Epoch 152: val_loss improved from 0.33328 to 0.33118, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.9233 - val_loss: 0.3312 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.3271 - accuracy: 0.9216\n",
      "Epoch 153: val_loss improved from 0.33118 to 0.32909, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3251 - accuracy: 0.9233 - val_loss: 0.3291 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.3331 - accuracy: 0.9186\n",
      "Epoch 154: val_loss improved from 0.32909 to 0.32703, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.9233 - val_loss: 0.3270 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.3228 - accuracy: 0.9225\n",
      "Epoch 155: val_loss improved from 0.32703 to 0.32497, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3209 - accuracy: 0.9233 - val_loss: 0.3250 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.3248 - accuracy: 0.9206\n",
      "Epoch 156: val_loss improved from 0.32497 to 0.32302, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3188 - accuracy: 0.9233 - val_loss: 0.3230 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.3301 - accuracy: 0.9111\n",
      "Epoch 157: val_loss improved from 0.32302 to 0.32102, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.9233 - val_loss: 0.3210 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.3226 - accuracy: 0.9167\n",
      "Epoch 158: val_loss improved from 0.32102 to 0.31905, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.9233 - val_loss: 0.3191 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.3143 - accuracy: 0.9236\n",
      "Epoch 159: val_loss improved from 0.31905 to 0.31710, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.9233 - val_loss: 0.3171 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.3016 - accuracy: 0.9318\n",
      "Epoch 160: val_loss improved from 0.31710 to 0.31516, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.9233 - val_loss: 0.3152 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9220\n",
      "Epoch 161: val_loss improved from 0.31516 to 0.31325, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3088 - accuracy: 0.9265 - val_loss: 0.3132 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.3116 - accuracy: 0.9185\n",
      "Epoch 162: val_loss improved from 0.31325 to 0.31132, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.9265 - val_loss: 0.3113 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.3083 - accuracy: 0.9264\n",
      "Epoch 163: val_loss improved from 0.31132 to 0.30954, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.9265 - val_loss: 0.3095 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.3059 - accuracy: 0.9242\n",
      "Epoch 164: val_loss improved from 0.30954 to 0.30769, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.9265 - val_loss: 0.3077 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.3099 - accuracy: 0.9167\n",
      "Epoch 165: val_loss improved from 0.30769 to 0.30586, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3012 - accuracy: 0.9265 - val_loss: 0.3059 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.3082 - accuracy: 0.9203\n",
      "Epoch 166: val_loss improved from 0.30586 to 0.30407, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2994 - accuracy: 0.9265 - val_loss: 0.3041 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2946 - accuracy: 0.9239\n",
      "Epoch 167: val_loss improved from 0.30407 to 0.30229, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.9265 - val_loss: 0.3023 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2917 - accuracy: 0.9275\n",
      "Epoch 168: val_loss improved from 0.30229 to 0.30055, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.9265 - val_loss: 0.3005 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2909 - accuracy: 0.9286\n",
      "Epoch 169: val_loss improved from 0.30055 to 0.29881, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2940 - accuracy: 0.9265 - val_loss: 0.2988 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2741 - accuracy: 0.9397\n",
      "Epoch 170: val_loss improved from 0.29881 to 0.29710, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.9265 - val_loss: 0.2971 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2972 - accuracy: 0.9201\n",
      "Epoch 171: val_loss improved from 0.29710 to 0.29541, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2905 - accuracy: 0.9265 - val_loss: 0.2954 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2905 - accuracy: 0.9275\n",
      "Epoch 172: val_loss improved from 0.29541 to 0.29375, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2887 - accuracy: 0.9265 - val_loss: 0.2938 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2914 - accuracy: 0.9205\n",
      "Epoch 173: val_loss improved from 0.29375 to 0.29210, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.9265 - val_loss: 0.2921 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2873 - accuracy: 0.9206\n",
      "Epoch 174: val_loss improved from 0.29210 to 0.29046, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2854 - accuracy: 0.9265 - val_loss: 0.2905 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2862 - accuracy: 0.9206\n",
      "Epoch 175: val_loss improved from 0.29046 to 0.28884, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2837 - accuracy: 0.9265 - val_loss: 0.2888 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2883 - accuracy: 0.9201\n",
      "Epoch 176: val_loss improved from 0.28884 to 0.28725, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2820 - accuracy: 0.9265 - val_loss: 0.2872 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2714 - accuracy: 0.9312\n",
      "Epoch 177: val_loss improved from 0.28725 to 0.28567, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.9265 - val_loss: 0.2857 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.2696 - accuracy: 0.9390\n",
      "Epoch 178: val_loss improved from 0.28567 to 0.28414, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2788 - accuracy: 0.9265 - val_loss: 0.2841 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.2772 - accuracy: 0.9225\n",
      "Epoch 179: val_loss improved from 0.28414 to 0.28262, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.9265 - val_loss: 0.2826 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2687 - accuracy: 0.9306\n",
      "Epoch 180: val_loss improved from 0.28262 to 0.28127, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.9265 - val_loss: 0.2813 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2762 - accuracy: 0.9306\n",
      "Epoch 181: val_loss improved from 0.28127 to 0.27977, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.9297 - val_loss: 0.2798 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2819 - accuracy: 0.9259\n",
      "Epoch 182: val_loss improved from 0.27977 to 0.27829, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2727 - accuracy: 0.9297 - val_loss: 0.2783 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2789 - accuracy: 0.9259\n",
      "Epoch 183: val_loss improved from 0.27829 to 0.27684, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2712 - accuracy: 0.9297 - val_loss: 0.2768 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2696 - accuracy: 0.9306\n",
      "Epoch 184: val_loss improved from 0.27684 to 0.27539, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.9297 - val_loss: 0.2754 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2692 - accuracy: 0.9275\n",
      "Epoch 185: val_loss improved from 0.27539 to 0.27397, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2682 - accuracy: 0.9329 - val_loss: 0.2740 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2717 - accuracy: 0.9271\n",
      "Epoch 186: val_loss improved from 0.27397 to 0.27256, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.9329 - val_loss: 0.2726 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.2617 - accuracy: 0.9341\n",
      "Epoch 187: val_loss improved from 0.27256 to 0.27117, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2653 - accuracy: 0.9329 - val_loss: 0.2712 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2616 - accuracy: 0.9370\n",
      "Epoch 188: val_loss improved from 0.27117 to 0.26981, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2639 - accuracy: 0.9361 - val_loss: 0.2698 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2593 - accuracy: 0.9397\n",
      "Epoch 189: val_loss improved from 0.26981 to 0.26846, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.9361 - val_loss: 0.2685 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.2565 - accuracy: 0.9388\n",
      "Epoch 190: val_loss improved from 0.26846 to 0.26711, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9361 - val_loss: 0.2671 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 191/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2660 - accuracy: 0.9326\n",
      "Epoch 191: val_loss improved from 0.26711 to 0.26579, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2597 - accuracy: 0.9361 - val_loss: 0.2658 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 192/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2707 - accuracy: 0.9259\n",
      "Epoch 192: val_loss improved from 0.26579 to 0.26449, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2584 - accuracy: 0.9361 - val_loss: 0.2645 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 193/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2706 - accuracy: 0.9242\n",
      "Epoch 193: val_loss improved from 0.26449 to 0.26320, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9361 - val_loss: 0.2632 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 194/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2537 - accuracy: 0.9397\n",
      "Epoch 194: val_loss improved from 0.26320 to 0.26189, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.9361 - val_loss: 0.2619 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 195/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2621 - accuracy: 0.9296\n",
      "Epoch 195: val_loss improved from 0.26189 to 0.26064, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.9361 - val_loss: 0.2606 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 196/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2562 - accuracy: 0.9348\n",
      "Epoch 196: val_loss improved from 0.26064 to 0.25941, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2531 - accuracy: 0.9361 - val_loss: 0.2594 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 197/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2509 - accuracy: 0.9375\n",
      "Epoch 197: val_loss improved from 0.25941 to 0.25817, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2518 - accuracy: 0.9361 - val_loss: 0.2582 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 198/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2519 - accuracy: 0.9362\n",
      "Epoch 198: val_loss improved from 0.25817 to 0.25696, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.9361 - val_loss: 0.2570 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 199/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2504 - accuracy: 0.9348\n",
      "Epoch 199: val_loss improved from 0.25696 to 0.25577, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.9361 - val_loss: 0.2558 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 200/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.2519 - accuracy: 0.9264\n",
      "Epoch 200: val_loss improved from 0.25577 to 0.25459, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.9361 - val_loss: 0.2546 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 201/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2393 - accuracy: 0.9405\n",
      "Epoch 201: val_loss improved from 0.25459 to 0.25342, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2468 - accuracy: 0.9361 - val_loss: 0.2534 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 202/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2483 - accuracy: 0.9326\n",
      "Epoch 202: val_loss improved from 0.25342 to 0.25226, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2456 - accuracy: 0.9361 - val_loss: 0.2523 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 203/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2429 - accuracy: 0.9356\n",
      "Epoch 203: val_loss improved from 0.25226 to 0.25115, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2444 - accuracy: 0.9361 - val_loss: 0.2512 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 204/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2402 - accuracy: 0.9397\n",
      "Epoch 204: val_loss improved from 0.25115 to 0.25002, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.9361 - val_loss: 0.2500 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 205/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.2444 - accuracy: 0.9302\n",
      "Epoch 205: val_loss improved from 0.25002 to 0.24891, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2420 - accuracy: 0.9361 - val_loss: 0.2489 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 206/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2496 - accuracy: 0.9291\n",
      "Epoch 206: val_loss improved from 0.24891 to 0.24787, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2409 - accuracy: 0.9361 - val_loss: 0.2479 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 207/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2463 - accuracy: 0.9306\n",
      "Epoch 207: val_loss improved from 0.24787 to 0.24680, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2397 - accuracy: 0.9361 - val_loss: 0.2468 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 208/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.2381 - accuracy: 0.9379\n",
      "Epoch 208: val_loss improved from 0.24680 to 0.24572, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2386 - accuracy: 0.9361 - val_loss: 0.2457 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 209/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2408 - accuracy: 0.9340\n",
      "Epoch 209: val_loss improved from 0.24572 to 0.24466, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9361 - val_loss: 0.2447 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 210/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2397 - accuracy: 0.9318\n",
      "Epoch 210: val_loss improved from 0.24466 to 0.24362, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.9361 - val_loss: 0.2436 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 211/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.2342 - accuracy: 0.9354\n",
      "Epoch 211: val_loss improved from 0.24362 to 0.24258, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2353 - accuracy: 0.9361 - val_loss: 0.2426 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 212/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2331 - accuracy: 0.9333\n",
      "Epoch 212: val_loss improved from 0.24258 to 0.24156, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9361 - val_loss: 0.2416 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 213/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2434 - accuracy: 0.9291\n",
      "Epoch 213: val_loss improved from 0.24156 to 0.24055, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9361 - val_loss: 0.2406 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 214/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2268 - accuracy: 0.9325\n",
      "Epoch 214: val_loss improved from 0.24055 to 0.23956, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2321 - accuracy: 0.9361 - val_loss: 0.2396 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 215/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2204 - accuracy: 0.9420\n",
      "Epoch 215: val_loss improved from 0.23956 to 0.23857, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2311 - accuracy: 0.9361 - val_loss: 0.2386 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 216/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2285 - accuracy: 0.9370\n",
      "Epoch 216: val_loss improved from 0.23857 to 0.23759, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2300 - accuracy: 0.9361 - val_loss: 0.2376 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 217/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.2265 - accuracy: 0.9367\n",
      "Epoch 217: val_loss improved from 0.23759 to 0.23663, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9361 - val_loss: 0.2366 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 218/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2202 - accuracy: 0.9420\n",
      "Epoch 218: val_loss improved from 0.23663 to 0.23568, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2280 - accuracy: 0.9361 - val_loss: 0.2357 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 219/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2295 - accuracy: 0.9340\n",
      "Epoch 219: val_loss improved from 0.23568 to 0.23474, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2270 - accuracy: 0.9361 - val_loss: 0.2347 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 220/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2240 - accuracy: 0.9375\n",
      "Epoch 220: val_loss improved from 0.23474 to 0.23395, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9361 - val_loss: 0.2340 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 221/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2218 - accuracy: 0.9375\n",
      "Epoch 221: val_loss improved from 0.23395 to 0.23303, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9361 - val_loss: 0.2330 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 222/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2239 - accuracy: 0.9333\n",
      "Epoch 222: val_loss improved from 0.23303 to 0.23210, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9361 - val_loss: 0.2321 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 223/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2340 - accuracy: 0.9242\n",
      "Epoch 223: val_loss improved from 0.23210 to 0.23121, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9361 - val_loss: 0.2312 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 224/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.2208 - accuracy: 0.9354\n",
      "Epoch 224: val_loss improved from 0.23121 to 0.23032, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9361 - val_loss: 0.2303 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 225/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2252 - accuracy: 0.9348\n",
      "Epoch 225: val_loss improved from 0.23032 to 0.22944, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2214 - accuracy: 0.9361 - val_loss: 0.2294 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 226/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2184 - accuracy: 0.9410\n",
      "Epoch 226: val_loss improved from 0.22944 to 0.22857, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2205 - accuracy: 0.9393 - val_loss: 0.2286 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 227/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2143 - accuracy: 0.9394\n",
      "Epoch 227: val_loss improved from 0.22857 to 0.22771, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2195 - accuracy: 0.9393 - val_loss: 0.2277 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 228/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2170 - accuracy: 0.9444\n",
      "Epoch 228: val_loss improved from 0.22771 to 0.22686, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2186 - accuracy: 0.9393 - val_loss: 0.2269 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 229/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2131 - accuracy: 0.9444\n",
      "Epoch 229: val_loss improved from 0.22686 to 0.22603, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2178 - accuracy: 0.9393 - val_loss: 0.2260 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 230/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.2167 - accuracy: 0.9422\n",
      "Epoch 230: val_loss improved from 0.22603 to 0.22519, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2169 - accuracy: 0.9393 - val_loss: 0.2252 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 231/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.2163 - accuracy: 0.9375\n",
      "Epoch 231: val_loss improved from 0.22519 to 0.22437, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2160 - accuracy: 0.9393 - val_loss: 0.2244 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 232/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.2066 - accuracy: 0.9493\n",
      "Epoch 232: val_loss improved from 0.22437 to 0.22356, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2152 - accuracy: 0.9393 - val_loss: 0.2236 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 233/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2183 - accuracy: 0.9397\n",
      "Epoch 233: val_loss improved from 0.22356 to 0.22276, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9393 - val_loss: 0.2228 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 234/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2167 - accuracy: 0.9362\n",
      "Epoch 234: val_loss improved from 0.22276 to 0.22195, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9393 - val_loss: 0.2220 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 235/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.2180 - accuracy: 0.9370\n",
      "Epoch 235: val_loss improved from 0.22195 to 0.22117, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2126 - accuracy: 0.9393 - val_loss: 0.2212 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 236/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2151 - accuracy: 0.9397\n",
      "Epoch 236: val_loss improved from 0.22117 to 0.22038, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2118 - accuracy: 0.9393 - val_loss: 0.2204 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 237/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.2095 - accuracy: 0.9400\n",
      "Epoch 237: val_loss improved from 0.22038 to 0.21966, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2110 - accuracy: 0.9393 - val_loss: 0.2197 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 238/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2014 - accuracy: 0.9468\n",
      "Epoch 238: val_loss improved from 0.21966 to 0.21891, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2102 - accuracy: 0.9393 - val_loss: 0.2189 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9393\n",
      "Epoch 239: val_loss improved from 0.21891 to 0.21817, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2094 - accuracy: 0.9393 - val_loss: 0.2182 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 240/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.2120 - accuracy: 0.9380\n",
      "Epoch 240: val_loss improved from 0.21817 to 0.21743, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2086 - accuracy: 0.9393 - val_loss: 0.2174 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 241/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2055 - accuracy: 0.9394\n",
      "Epoch 241: val_loss improved from 0.21743 to 0.21669, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2078 - accuracy: 0.9393 - val_loss: 0.2167 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 242/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1903 - accuracy: 0.9496\n",
      "Epoch 242: val_loss improved from 0.21669 to 0.21597, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2070 - accuracy: 0.9393 - val_loss: 0.2160 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 243/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.2059 - accuracy: 0.9394\n",
      "Epoch 243: val_loss improved from 0.21597 to 0.21524, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2062 - accuracy: 0.9393 - val_loss: 0.2152 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 244/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1822 - accuracy: 0.9593\n",
      "Epoch 244: val_loss improved from 0.21524 to 0.21453, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2055 - accuracy: 0.9393 - val_loss: 0.2145 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 245/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.2103 - accuracy: 0.9354\n",
      "Epoch 245: val_loss improved from 0.21453 to 0.21383, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.2047 - accuracy: 0.9393 - val_loss: 0.2138 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 246/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1955 - accuracy: 0.9432\n",
      "Epoch 246: val_loss improved from 0.21383 to 0.21313, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2040 - accuracy: 0.9393 - val_loss: 0.2131 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 247/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1991 - accuracy: 0.9397\n",
      "Epoch 247: val_loss improved from 0.21313 to 0.21244, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2033 - accuracy: 0.9393 - val_loss: 0.2124 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 248/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1961 - accuracy: 0.9422\n",
      "Epoch 248: val_loss improved from 0.21244 to 0.21187, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2025 - accuracy: 0.9393 - val_loss: 0.2119 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 249/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.2023 - accuracy: 0.9391\n",
      "Epoch 249: val_loss improved from 0.21187 to 0.21119, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2019 - accuracy: 0.9393 - val_loss: 0.2112 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 250/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.2034 - accuracy: 0.9379\n",
      "Epoch 250: val_loss improved from 0.21119 to 0.21052, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.2012 - accuracy: 0.9393 - val_loss: 0.2105 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 251/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1995 - accuracy: 0.9407\n",
      "Epoch 251: val_loss improved from 0.21052 to 0.20986, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.2005 - accuracy: 0.9393 - val_loss: 0.2099 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 252/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1942 - accuracy: 0.9390\n",
      "Epoch 252: val_loss improved from 0.20986 to 0.20931, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1998 - accuracy: 0.9393 - val_loss: 0.2093 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 253/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.2022 - accuracy: 0.9380\n",
      "Epoch 253: val_loss improved from 0.20931 to 0.20866, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1992 - accuracy: 0.9393 - val_loss: 0.2087 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 254/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1881 - accuracy: 0.9512\n",
      "Epoch 254: val_loss improved from 0.20866 to 0.20801, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1985 - accuracy: 0.9393 - val_loss: 0.2080 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 255/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2028 - accuracy: 0.9362\n",
      "Epoch 255: val_loss improved from 0.20801 to 0.20737, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1978 - accuracy: 0.9393 - val_loss: 0.2074 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 256/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.2003 - accuracy: 0.9362\n",
      "Epoch 256: val_loss improved from 0.20737 to 0.20672, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1971 - accuracy: 0.9393 - val_loss: 0.2067 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 257/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1711 - accuracy: 0.9535\n",
      "Epoch 257: val_loss improved from 0.20672 to 0.20610, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1964 - accuracy: 0.9393 - val_loss: 0.2061 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 258/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1792 - accuracy: 0.9493\n",
      "Epoch 258: val_loss improved from 0.20610 to 0.20548, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1957 - accuracy: 0.9393 - val_loss: 0.2055 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 259/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1871 - accuracy: 0.9444\n",
      "Epoch 259: val_loss improved from 0.20548 to 0.20488, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1951 - accuracy: 0.9393 - val_loss: 0.2049 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 260/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1997 - accuracy: 0.9333\n",
      "Epoch 260: val_loss improved from 0.20488 to 0.20427, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9393 - val_loss: 0.2043 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 261/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1971 - accuracy: 0.9375\n",
      "Epoch 261: val_loss improved from 0.20427 to 0.20366, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.9393 - val_loss: 0.2037 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 262/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.2082 - accuracy: 0.9286\n",
      "Epoch 262: val_loss improved from 0.20366 to 0.20306, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1931 - accuracy: 0.9393 - val_loss: 0.2031 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 263/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1846 - accuracy: 0.9444\n",
      "Epoch 263: val_loss improved from 0.20306 to 0.20247, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1925 - accuracy: 0.9393 - val_loss: 0.2025 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 264/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1903 - accuracy: 0.9348\n",
      "Epoch 264: val_loss improved from 0.20247 to 0.20189, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.9393 - val_loss: 0.2019 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 265/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1769 - accuracy: 0.9493\n",
      "Epoch 265: val_loss improved from 0.20189 to 0.20131, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9425 - val_loss: 0.2013 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 266/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1853 - accuracy: 0.9477\n",
      "Epoch 266: val_loss improved from 0.20131 to 0.20072, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1906 - accuracy: 0.9425 - val_loss: 0.2007 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 267/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1749 - accuracy: 0.9524\n",
      "Epoch 267: val_loss improved from 0.20072 to 0.20015, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1900 - accuracy: 0.9425 - val_loss: 0.2002 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 268/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1999 - accuracy: 0.9365\n",
      "Epoch 268: val_loss improved from 0.20015 to 0.19960, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1894 - accuracy: 0.9425 - val_loss: 0.1996 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 269/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9423\n",
      "Epoch 269: val_loss improved from 0.19960 to 0.19904, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1888 - accuracy: 0.9425 - val_loss: 0.1990 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 270/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1979 - accuracy: 0.9333\n",
      "Epoch 270: val_loss improved from 0.19904 to 0.19850, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.9425 - val_loss: 0.1985 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 271/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1868 - accuracy: 0.9405\n",
      "Epoch 271: val_loss improved from 0.19850 to 0.19796, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1876 - accuracy: 0.9425 - val_loss: 0.1980 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 272/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1919 - accuracy: 0.9420\n",
      "Epoch 272: val_loss improved from 0.19796 to 0.19742, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1870 - accuracy: 0.9425 - val_loss: 0.1974 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 273/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1960 - accuracy: 0.9325\n",
      "Epoch 273: val_loss improved from 0.19742 to 0.19689, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1865 - accuracy: 0.9425 - val_loss: 0.1969 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 274/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1900 - accuracy: 0.9397\n",
      "Epoch 274: val_loss improved from 0.19689 to 0.19636, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1859 - accuracy: 0.9425 - val_loss: 0.1964 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 275/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1910 - accuracy: 0.9384\n",
      "Epoch 275: val_loss improved from 0.19636 to 0.19583, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1853 - accuracy: 0.9425 - val_loss: 0.1958 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 276/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1878 - accuracy: 0.9388\n",
      "Epoch 276: val_loss improved from 0.19583 to 0.19532, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1848 - accuracy: 0.9425 - val_loss: 0.1953 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 277/1000\n",
      "38/53 [====================>.........] - ETA: 0s - loss: 0.1679 - accuracy: 0.9518\n",
      "Epoch 277: val_loss improved from 0.19532 to 0.19480, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1842 - accuracy: 0.9425 - val_loss: 0.1948 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 278/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1935 - accuracy: 0.9362\n",
      "Epoch 278: val_loss improved from 0.19480 to 0.19430, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9425 - val_loss: 0.1943 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 279/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1899 - accuracy: 0.9333\n",
      "Epoch 279: val_loss improved from 0.19430 to 0.19379, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1831 - accuracy: 0.9393 - val_loss: 0.1938 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 280/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1845 - accuracy: 0.9354\n",
      "Epoch 280: val_loss improved from 0.19379 to 0.19329, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.9393 - val_loss: 0.1933 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 281/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1830 - accuracy: 0.9388\n",
      "Epoch 281: val_loss improved from 0.19329 to 0.19280, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9393 - val_loss: 0.1928 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 282/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1860 - accuracy: 0.9367\n",
      "Epoch 282: val_loss improved from 0.19280 to 0.19230, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1815 - accuracy: 0.9393 - val_loss: 0.1923 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 283/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1812 - accuracy: 0.9420\n",
      "Epoch 283: val_loss improved from 0.19230 to 0.19182, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.9393 - val_loss: 0.1918 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 284/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1857 - accuracy: 0.9354\n",
      "Epoch 284: val_loss improved from 0.19182 to 0.19133, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9393 - val_loss: 0.1913 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 285/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1766 - accuracy: 0.9407\n",
      "Epoch 285: val_loss improved from 0.19133 to 0.19085, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9393 - val_loss: 0.1909 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 286/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1757 - accuracy: 0.9433\n",
      "Epoch 286: val_loss improved from 0.19085 to 0.19038, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1794 - accuracy: 0.9393 - val_loss: 0.1904 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 287/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1823 - accuracy: 0.9397\n",
      "Epoch 287: val_loss improved from 0.19038 to 0.18991, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9393 - val_loss: 0.1899 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 288/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1716 - accuracy: 0.9444\n",
      "Epoch 288: val_loss improved from 0.18991 to 0.18945, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.9393 - val_loss: 0.1894 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 289/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1821 - accuracy: 0.9354\n",
      "Epoch 289: val_loss improved from 0.18945 to 0.18898, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1779 - accuracy: 0.9393 - val_loss: 0.1890 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 290/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1890 - accuracy: 0.9326\n",
      "Epoch 290: val_loss improved from 0.18898 to 0.18853, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9393 - val_loss: 0.1885 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 291/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1763 - accuracy: 0.9370\n",
      "Epoch 291: val_loss improved from 0.18853 to 0.18806, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9393 - val_loss: 0.1881 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 292/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1811 - accuracy: 0.9341\n",
      "Epoch 292: val_loss improved from 0.18806 to 0.18761, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1764 - accuracy: 0.9393 - val_loss: 0.1876 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 293/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1732 - accuracy: 0.9365\n",
      "Epoch 293: val_loss improved from 0.18761 to 0.18722, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1759 - accuracy: 0.9393 - val_loss: 0.1872 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9393\n",
      "Epoch 294: val_loss improved from 0.18722 to 0.18677, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.9393 - val_loss: 0.1868 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 295/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1683 - accuracy: 0.9444\n",
      "Epoch 295: val_loss improved from 0.18677 to 0.18633, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9425 - val_loss: 0.1863 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 296/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1745 - accuracy: 0.9456\n",
      "Epoch 296: val_loss improved from 0.18633 to 0.18590, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1745 - accuracy: 0.9457 - val_loss: 0.1859 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 297/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1714 - accuracy: 0.9458\n",
      "Epoch 297: val_loss improved from 0.18590 to 0.18547, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9457 - val_loss: 0.1855 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 298/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1637 - accuracy: 0.9535\n",
      "Epoch 298: val_loss improved from 0.18547 to 0.18501, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9457 - val_loss: 0.1850 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 299/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1707 - accuracy: 0.9456\n",
      "Epoch 299: val_loss improved from 0.18501 to 0.18459, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9457 - val_loss: 0.1846 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 300/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1705 - accuracy: 0.9468\n",
      "Epoch 300: val_loss improved from 0.18459 to 0.18417, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.9457 - val_loss: 0.1842 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9457\n",
      "Epoch 301: val_loss improved from 0.18417 to 0.18376, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1722 - accuracy: 0.9457 - val_loss: 0.1838 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 302/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1827 - accuracy: 0.9432\n",
      "Epoch 302: val_loss improved from 0.18376 to 0.18335, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1718 - accuracy: 0.9489 - val_loss: 0.1833 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 303/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1643 - accuracy: 0.9519\n",
      "Epoch 303: val_loss improved from 0.18335 to 0.18290, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1713 - accuracy: 0.9489 - val_loss: 0.1829 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 304/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1682 - accuracy: 0.9508\n",
      "Epoch 304: val_loss improved from 0.18290 to 0.18250, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1709 - accuracy: 0.9489 - val_loss: 0.1825 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 305/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1728 - accuracy: 0.9477\n",
      "Epoch 305: val_loss improved from 0.18250 to 0.18210, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1704 - accuracy: 0.9489 - val_loss: 0.1821 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 306/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1679 - accuracy: 0.9504\n",
      "Epoch 306: val_loss improved from 0.18210 to 0.18170, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9489 - val_loss: 0.1817 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 307/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1694 - accuracy: 0.9508\n",
      "Epoch 307: val_loss improved from 0.18170 to 0.18130, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9489 - val_loss: 0.1813 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 308/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1522 - accuracy: 0.9593\n",
      "Epoch 308: val_loss improved from 0.18130 to 0.18090, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9489 - val_loss: 0.1809 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 309/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1661 - accuracy: 0.9481\n",
      "Epoch 309: val_loss improved from 0.18090 to 0.18050, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1687 - accuracy: 0.9489 - val_loss: 0.1805 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 310/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1748 - accuracy: 0.9444\n",
      "Epoch 310: val_loss improved from 0.18050 to 0.18011, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1683 - accuracy: 0.9489 - val_loss: 0.1801 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 311/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1825 - accuracy: 0.9394\n",
      "Epoch 311: val_loss improved from 0.18011 to 0.17973, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1678 - accuracy: 0.9489 - val_loss: 0.1797 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 312/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1646 - accuracy: 0.9504\n",
      "Epoch 312: val_loss improved from 0.17973 to 0.17937, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1674 - accuracy: 0.9489 - val_loss: 0.1794 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 313/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1751 - accuracy: 0.9433\n",
      "Epoch 313: val_loss improved from 0.17937 to 0.17900, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1670 - accuracy: 0.9489 - val_loss: 0.1790 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 314/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1620 - accuracy: 0.9535\n",
      "Epoch 314: val_loss improved from 0.17900 to 0.17862, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1666 - accuracy: 0.9489 - val_loss: 0.1786 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 315/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1616 - accuracy: 0.9574\n",
      "Epoch 315: val_loss improved from 0.17862 to 0.17829, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.9489 - val_loss: 0.1783 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 316/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1608 - accuracy: 0.9493\n",
      "Epoch 316: val_loss improved from 0.17829 to 0.17792, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.9489 - val_loss: 0.1779 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 317/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1754 - accuracy: 0.9433\n",
      "Epoch 317: val_loss improved from 0.17792 to 0.17755, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1654 - accuracy: 0.9489 - val_loss: 0.1775 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 318/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1635 - accuracy: 0.9479\n",
      "Epoch 318: val_loss improved from 0.17755 to 0.17716, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9489 - val_loss: 0.1772 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9489\n",
      "Epoch 319: val_loss improved from 0.17716 to 0.17681, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1645 - accuracy: 0.9489 - val_loss: 0.1768 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 320/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1458 - accuracy: 0.9593\n",
      "Epoch 320: val_loss improved from 0.17681 to 0.17645, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.9489 - val_loss: 0.1764 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 321/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1663 - accuracy: 0.9504\n",
      "Epoch 321: val_loss improved from 0.17645 to 0.17609, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1637 - accuracy: 0.9489 - val_loss: 0.1761 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 322/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1639 - accuracy: 0.9490\n",
      "Epoch 322: val_loss improved from 0.17609 to 0.17574, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1633 - accuracy: 0.9489 - val_loss: 0.1757 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 323/1000\n",
      "39/53 [=====================>........] - ETA: 0s - loss: 0.1563 - accuracy: 0.9530\n",
      "Epoch 323: val_loss improved from 0.17574 to 0.17539, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9489 - val_loss: 0.1754 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 324/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1666 - accuracy: 0.9457\n",
      "Epoch 324: val_loss improved from 0.17539 to 0.17505, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1625 - accuracy: 0.9489 - val_loss: 0.1750 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 325/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1697 - accuracy: 0.9468\n",
      "Epoch 325: val_loss improved from 0.17505 to 0.17470, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9489 - val_loss: 0.1747 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 326/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1649 - accuracy: 0.9493\n",
      "Epoch 326: val_loss improved from 0.17470 to 0.17436, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1618 - accuracy: 0.9489 - val_loss: 0.1744 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 327/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1671 - accuracy: 0.9456\n",
      "Epoch 327: val_loss improved from 0.17436 to 0.17403, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1614 - accuracy: 0.9489 - val_loss: 0.1740 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 328/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1554 - accuracy: 0.9457\n",
      "Epoch 328: val_loss improved from 0.17403 to 0.17369, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1610 - accuracy: 0.9489 - val_loss: 0.1737 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 329/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1638 - accuracy: 0.9508\n",
      "Epoch 329: val_loss improved from 0.17369 to 0.17336, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1607 - accuracy: 0.9489 - val_loss: 0.1734 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 330/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1676 - accuracy: 0.9431\n",
      "Epoch 330: val_loss improved from 0.17336 to 0.17303, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1603 - accuracy: 0.9489 - val_loss: 0.1730 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 331/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1667 - accuracy: 0.9481\n",
      "Epoch 331: val_loss improved from 0.17303 to 0.17270, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1600 - accuracy: 0.9489 - val_loss: 0.1727 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 332/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1710 - accuracy: 0.9407\n",
      "Epoch 332: val_loss improved from 0.17270 to 0.17238, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1596 - accuracy: 0.9489 - val_loss: 0.1724 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 333/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1382 - accuracy: 0.9545\n",
      "Epoch 333: val_loss improved from 0.17238 to 0.17206, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9489 - val_loss: 0.1721 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 334/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1438 - accuracy: 0.9556\n",
      "Epoch 334: val_loss improved from 0.17206 to 0.17173, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1589 - accuracy: 0.9489 - val_loss: 0.1717 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 335/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1587 - accuracy: 0.9487\n",
      "Epoch 335: val_loss improved from 0.17173 to 0.17141, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9489 - val_loss: 0.1714 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 336/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1678 - accuracy: 0.9417\n",
      "Epoch 336: val_loss improved from 0.17141 to 0.17110, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1581 - accuracy: 0.9489 - val_loss: 0.1711 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 337/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1725 - accuracy: 0.9432\n",
      "Epoch 337: val_loss improved from 0.17110 to 0.17079, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1577 - accuracy: 0.9489 - val_loss: 0.1708 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 338/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1597 - accuracy: 0.9419\n",
      "Epoch 338: val_loss improved from 0.17079 to 0.17048, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.9489 - val_loss: 0.1705 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 339/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1558 - accuracy: 0.9479\n",
      "Epoch 339: val_loss improved from 0.17048 to 0.17017, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9489 - val_loss: 0.1702 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 340/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1620 - accuracy: 0.9468\n",
      "Epoch 340: val_loss improved from 0.17017 to 0.16987, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9489 - val_loss: 0.1699 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 341/1000\n",
      "39/53 [=====================>........] - ETA: 0s - loss: 0.1618 - accuracy: 0.9444\n",
      "Epoch 341: val_loss improved from 0.16987 to 0.16956, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1563 - accuracy: 0.9489 - val_loss: 0.1696 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 342/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1502 - accuracy: 0.9508\n",
      "Epoch 342: val_loss improved from 0.16956 to 0.16926, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.9489 - val_loss: 0.1693 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 343/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1577 - accuracy: 0.9470\n",
      "Epoch 343: val_loss improved from 0.16926 to 0.16897, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.9489 - val_loss: 0.1690 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 344/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1627 - accuracy: 0.9479\n",
      "Epoch 344: val_loss improved from 0.16897 to 0.16867, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1553 - accuracy: 0.9521 - val_loss: 0.1687 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 345/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1608 - accuracy: 0.9470\n",
      "Epoch 345: val_loss improved from 0.16867 to 0.16838, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1550 - accuracy: 0.9521 - val_loss: 0.1684 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 346/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1582 - accuracy: 0.9535\n",
      "Epoch 346: val_loss improved from 0.16838 to 0.16809, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.9521 - val_loss: 0.1681 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 347/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1657 - accuracy: 0.9444\n",
      "Epoch 347: val_loss improved from 0.16809 to 0.16780, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9521 - val_loss: 0.1678 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 348/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1549 - accuracy: 0.9524\n",
      "Epoch 348: val_loss improved from 0.16780 to 0.16752, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.9521 - val_loss: 0.1675 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 349/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1510 - accuracy: 0.9565\n",
      "Epoch 349: val_loss improved from 0.16752 to 0.16724, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1536 - accuracy: 0.9521 - val_loss: 0.1672 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 350/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1578 - accuracy: 0.9508\n",
      "Epoch 350: val_loss improved from 0.16724 to 0.16695, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1533 - accuracy: 0.9521 - val_loss: 0.1670 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9521\n",
      "Epoch 351: val_loss improved from 0.16695 to 0.16667, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.9521 - val_loss: 0.1667 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 352/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1465 - accuracy: 0.9556\n",
      "Epoch 352: val_loss improved from 0.16667 to 0.16639, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.9521 - val_loss: 0.1664 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 353/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1474 - accuracy: 0.9533\n",
      "Epoch 353: val_loss improved from 0.16639 to 0.16612, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1524 - accuracy: 0.9521 - val_loss: 0.1661 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 354/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1591 - accuracy: 0.9493\n",
      "Epoch 354: val_loss improved from 0.16612 to 0.16584, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1521 - accuracy: 0.9521 - val_loss: 0.1658 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 355/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1493 - accuracy: 0.9565\n",
      "Epoch 355: val_loss improved from 0.16584 to 0.16557, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9521 - val_loss: 0.1656 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 356/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1563 - accuracy: 0.9493\n",
      "Epoch 356: val_loss improved from 0.16557 to 0.16531, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1514 - accuracy: 0.9521 - val_loss: 0.1653 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 357/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1465 - accuracy: 0.9549\n",
      "Epoch 357: val_loss improved from 0.16531 to 0.16504, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.9521 - val_loss: 0.1650 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 358/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1531 - accuracy: 0.9510\n",
      "Epoch 358: val_loss improved from 0.16504 to 0.16477, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 0.9521 - val_loss: 0.1648 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 359/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1514 - accuracy: 0.9510\n",
      "Epoch 359: val_loss improved from 0.16477 to 0.16451, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1505 - accuracy: 0.9521 - val_loss: 0.1645 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 360/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9519\n",
      "Epoch 360: val_loss improved from 0.16451 to 0.16425, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1502 - accuracy: 0.9521 - val_loss: 0.1642 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 361/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1504 - accuracy: 0.9510\n",
      "Epoch 361: val_loss improved from 0.16425 to 0.16398, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.9521 - val_loss: 0.1640 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 362/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1519 - accuracy: 0.9490\n",
      "Epoch 362: val_loss improved from 0.16398 to 0.16373, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1496 - accuracy: 0.9521 - val_loss: 0.1637 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 363/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1495 - accuracy: 0.9563\n",
      "Epoch 363: val_loss improved from 0.16373 to 0.16347, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.9521 - val_loss: 0.1635 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 364/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1615 - accuracy: 0.9405\n",
      "Epoch 364: val_loss improved from 0.16347 to 0.16322, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1490 - accuracy: 0.9521 - val_loss: 0.1632 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 365/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1552 - accuracy: 0.9470\n",
      "Epoch 365: val_loss improved from 0.16322 to 0.16297, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1487 - accuracy: 0.9521 - val_loss: 0.1630 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 366/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1578 - accuracy: 0.9457\n",
      "Epoch 366: val_loss improved from 0.16297 to 0.16272, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9521 - val_loss: 0.1627 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 367/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1481 - accuracy: 0.9583\n",
      "Epoch 367: val_loss improved from 0.16272 to 0.16247, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1482 - accuracy: 0.9521 - val_loss: 0.1625 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 368/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9519\n",
      "Epoch 368: val_loss improved from 0.16247 to 0.16220, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1479 - accuracy: 0.9521 - val_loss: 0.1622 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 369/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1468 - accuracy: 0.9542\n",
      "Epoch 369: val_loss improved from 0.16220 to 0.16196, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.9521 - val_loss: 0.1620 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 370/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9519\n",
      "Epoch 370: val_loss improved from 0.16196 to 0.16171, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9521 - val_loss: 0.1617 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 371/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1449 - accuracy: 0.9553\n",
      "Epoch 371: val_loss improved from 0.16171 to 0.16151, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.9521 - val_loss: 0.1615 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 372/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1493 - accuracy: 0.9500\n",
      "Epoch 372: val_loss improved from 0.16151 to 0.16126, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1467 - accuracy: 0.9521 - val_loss: 0.1613 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 373/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1445 - accuracy: 0.9484\n",
      "Epoch 373: val_loss improved from 0.16126 to 0.16102, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.9521 - val_loss: 0.1610 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9521\n",
      "Epoch 374: val_loss improved from 0.16102 to 0.16079, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.9521 - val_loss: 0.1608 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 375/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1549 - accuracy: 0.9481\n",
      "Epoch 375: val_loss improved from 0.16079 to 0.16055, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.9521 - val_loss: 0.1606 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 376/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1575 - accuracy: 0.9431\n",
      "Epoch 376: val_loss improved from 0.16055 to 0.16032, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1456 - accuracy: 0.9521 - val_loss: 0.1603 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 377/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1395 - accuracy: 0.9553\n",
      "Epoch 377: val_loss improved from 0.16032 to 0.16008, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9521 - val_loss: 0.1601 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 378/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1479 - accuracy: 0.9556\n",
      "Epoch 378: val_loss improved from 0.16008 to 0.15986, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9521 - val_loss: 0.1599 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 379/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1500 - accuracy: 0.9468\n",
      "Epoch 379: val_loss improved from 0.15986 to 0.15963, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9521 - val_loss: 0.1596 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 380/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1544 - accuracy: 0.9468\n",
      "Epoch 380: val_loss improved from 0.15963 to 0.15940, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9521 - val_loss: 0.1594 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 381/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1520 - accuracy: 0.9493\n",
      "Epoch 381: val_loss improved from 0.15940 to 0.15917, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1443 - accuracy: 0.9521 - val_loss: 0.1592 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 382/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1434 - accuracy: 0.9512\n",
      "Epoch 382: val_loss improved from 0.15917 to 0.15895, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1441 - accuracy: 0.9521 - val_loss: 0.1589 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9521\n",
      "Epoch 383: val_loss improved from 0.15895 to 0.15873, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.9521 - val_loss: 0.1587 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 384/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1282 - accuracy: 0.9618\n",
      "Epoch 384: val_loss improved from 0.15873 to 0.15850, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.9521 - val_loss: 0.1585 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 385/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1609 - accuracy: 0.9458\n",
      "Epoch 385: val_loss improved from 0.15850 to 0.15828, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1433 - accuracy: 0.9521 - val_loss: 0.1583 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 386/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1531 - accuracy: 0.9458\n",
      "Epoch 386: val_loss improved from 0.15828 to 0.15806, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1430 - accuracy: 0.9521 - val_loss: 0.1581 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 387/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1450 - accuracy: 0.9470\n",
      "Epoch 387: val_loss improved from 0.15806 to 0.15785, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1428 - accuracy: 0.9521 - val_loss: 0.1578 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 388/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1464 - accuracy: 0.9504\n",
      "Epoch 388: val_loss improved from 0.15785 to 0.15763, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1425 - accuracy: 0.9521 - val_loss: 0.1576 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 389/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1492 - accuracy: 0.9493\n",
      "Epoch 389: val_loss improved from 0.15763 to 0.15739, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.9521 - val_loss: 0.1574 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 390/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1435 - accuracy: 0.9545\n",
      "Epoch 390: val_loss improved from 0.15739 to 0.15718, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.9521 - val_loss: 0.1572 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 391/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1440 - accuracy: 0.9500\n",
      "Epoch 391: val_loss improved from 0.15718 to 0.15697, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9521 - val_loss: 0.1570 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 392/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1479 - accuracy: 0.9514\n",
      "Epoch 392: val_loss improved from 0.15697 to 0.15676, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9553 - val_loss: 0.1568 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 393/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1345 - accuracy: 0.9574\n",
      "Epoch 393: val_loss improved from 0.15676 to 0.15656, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.9553 - val_loss: 0.1566 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 394/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1396 - accuracy: 0.9556\n",
      "Epoch 394: val_loss improved from 0.15656 to 0.15636, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9553 - val_loss: 0.1564 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 395/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1470 - accuracy: 0.9529\n",
      "Epoch 395: val_loss improved from 0.15636 to 0.15613, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1407 - accuracy: 0.9553 - val_loss: 0.1561 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 396/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1157 - accuracy: 0.9674\n",
      "Epoch 396: val_loss improved from 0.15613 to 0.15593, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1405 - accuracy: 0.9553 - val_loss: 0.1559 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 397/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1363 - accuracy: 0.9535\n",
      "Epoch 397: val_loss improved from 0.15593 to 0.15571, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1402 - accuracy: 0.9553 - val_loss: 0.1557 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 398/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1326 - accuracy: 0.9601\n",
      "Epoch 398: val_loss improved from 0.15571 to 0.15550, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.9553 - val_loss: 0.1555 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 399/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1410 - accuracy: 0.9565\n",
      "Epoch 399: val_loss improved from 0.15550 to 0.15530, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9553 - val_loss: 0.1553 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 400/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1273 - accuracy: 0.9592\n",
      "Epoch 400: val_loss improved from 0.15530 to 0.15510, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1395 - accuracy: 0.9553 - val_loss: 0.1551 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 401/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1444 - accuracy: 0.9535\n",
      "Epoch 401: val_loss improved from 0.15510 to 0.15490, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1393 - accuracy: 0.9553 - val_loss: 0.1549 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 402/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1492 - accuracy: 0.9504\n",
      "Epoch 402: val_loss improved from 0.15490 to 0.15470, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.9553 - val_loss: 0.1547 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 403/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1230 - accuracy: 0.9593\n",
      "Epoch 403: val_loss improved from 0.15470 to 0.15450, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1388 - accuracy: 0.9553 - val_loss: 0.1545 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 404/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1376 - accuracy: 0.9556\n",
      "Epoch 404: val_loss improved from 0.15450 to 0.15431, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1386 - accuracy: 0.9553 - val_loss: 0.1543 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 405/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1304 - accuracy: 0.9556\n",
      "Epoch 405: val_loss improved from 0.15431 to 0.15411, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1383 - accuracy: 0.9553 - val_loss: 0.1541 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 406/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1277 - accuracy: 0.9601\n",
      "Epoch 406: val_loss improved from 0.15411 to 0.15391, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1381 - accuracy: 0.9553 - val_loss: 0.1539 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 407/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1444 - accuracy: 0.9593\n",
      "Epoch 407: val_loss improved from 0.15391 to 0.15372, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9617 - val_loss: 0.1537 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 408/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1419 - accuracy: 0.9601\n",
      "Epoch 408: val_loss improved from 0.15372 to 0.15353, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9617 - val_loss: 0.1535 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 409/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1347 - accuracy: 0.9630\n",
      "Epoch 409: val_loss improved from 0.15353 to 0.15335, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9617 - val_loss: 0.1533 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 410/1000\n",
      "39/53 [=====================>........] - ETA: 0s - loss: 0.1230 - accuracy: 0.9658\n",
      "Epoch 410: val_loss improved from 0.15335 to 0.15316, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1372 - accuracy: 0.9617 - val_loss: 0.1532 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 411/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1459 - accuracy: 0.9574\n",
      "Epoch 411: val_loss improved from 0.15316 to 0.15297, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.9617 - val_loss: 0.1530 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 412/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1370 - accuracy: 0.9593\n",
      "Epoch 412: val_loss improved from 0.15297 to 0.15278, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1367 - accuracy: 0.9617 - val_loss: 0.1528 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 413/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1433 - accuracy: 0.9593\n",
      "Epoch 413: val_loss improved from 0.15278 to 0.15260, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1365 - accuracy: 0.9617 - val_loss: 0.1526 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 414/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1314 - accuracy: 0.9630\n",
      "Epoch 414: val_loss improved from 0.15260 to 0.15241, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9617 - val_loss: 0.1524 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 415/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1324 - accuracy: 0.9651\n",
      "Epoch 415: val_loss improved from 0.15241 to 0.15223, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1361 - accuracy: 0.9617 - val_loss: 0.1522 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9617\n",
      "Epoch 416: val_loss improved from 0.15223 to 0.15205, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.9617 - val_loss: 0.1520 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 417/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1488 - accuracy: 0.9583\n",
      "Epoch 417: val_loss improved from 0.15205 to 0.15187, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1356 - accuracy: 0.9617 - val_loss: 0.1519 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9617\n",
      "Epoch 418: val_loss improved from 0.15187 to 0.15169, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1354 - accuracy: 0.9617 - val_loss: 0.1517 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 419/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1276 - accuracy: 0.9651\n",
      "Epoch 419: val_loss improved from 0.15169 to 0.15151, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9617 - val_loss: 0.1515 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9617\n",
      "Epoch 420: val_loss improved from 0.15151 to 0.15133, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1350 - accuracy: 0.9617 - val_loss: 0.1513 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 421/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1266 - accuracy: 0.9651\n",
      "Epoch 421: val_loss improved from 0.15133 to 0.15115, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1348 - accuracy: 0.9617 - val_loss: 0.1512 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 422/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1409 - accuracy: 0.9574\n",
      "Epoch 422: val_loss improved from 0.15115 to 0.15097, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1345 - accuracy: 0.9617 - val_loss: 0.1510 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 423/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9615\n",
      "Epoch 423: val_loss improved from 0.15097 to 0.15080, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.9617 - val_loss: 0.1508 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 424/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1363 - accuracy: 0.9608\n",
      "Epoch 424: val_loss improved from 0.15080 to 0.15063, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9617 - val_loss: 0.1506 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 425/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1238 - accuracy: 0.9697\n",
      "Epoch 425: val_loss improved from 0.15063 to 0.15046, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1339 - accuracy: 0.9617 - val_loss: 0.1505 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 426/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1395 - accuracy: 0.9583\n",
      "Epoch 426: val_loss improved from 0.15046 to 0.15028, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1337 - accuracy: 0.9617 - val_loss: 0.1503 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 427/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1371 - accuracy: 0.9600\n",
      "Epoch 427: val_loss improved from 0.15028 to 0.15011, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9617 - val_loss: 0.1501 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 428/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1314 - accuracy: 0.9601\n",
      "Epoch 428: val_loss improved from 0.15011 to 0.14994, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1333 - accuracy: 0.9617 - val_loss: 0.1499 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 429/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1272 - accuracy: 0.9659\n",
      "Epoch 429: val_loss improved from 0.14994 to 0.14977, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9617 - val_loss: 0.1498 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 430/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1333 - accuracy: 0.9608\n",
      "Epoch 430: val_loss improved from 0.14977 to 0.14956, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9617 - val_loss: 0.1496 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 431/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1451 - accuracy: 0.9574\n",
      "Epoch 431: val_loss improved from 0.14956 to 0.14940, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9649 - val_loss: 0.1494 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 432/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1274 - accuracy: 0.9667\n",
      "Epoch 432: val_loss improved from 0.14940 to 0.14923, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.9649 - val_loss: 0.1492 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 433/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1356 - accuracy: 0.9667\n",
      "Epoch 433: val_loss improved from 0.14923 to 0.14906, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9649 - val_loss: 0.1491 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 434/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1198 - accuracy: 0.9729\n",
      "Epoch 434: val_loss improved from 0.14906 to 0.14888, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1320 - accuracy: 0.9649 - val_loss: 0.1489 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 435/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1250 - accuracy: 0.9715\n",
      "Epoch 435: val_loss improved from 0.14888 to 0.14872, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1318 - accuracy: 0.9649 - val_loss: 0.1487 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 436/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1261 - accuracy: 0.9653\n",
      "Epoch 436: val_loss improved from 0.14872 to 0.14856, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9649 - val_loss: 0.1486 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 437/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1467 - accuracy: 0.9574\n",
      "Epoch 437: val_loss improved from 0.14856 to 0.14839, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1314 - accuracy: 0.9649 - val_loss: 0.1484 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 438/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1298 - accuracy: 0.9630\n",
      "Epoch 438: val_loss improved from 0.14839 to 0.14822, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9649 - val_loss: 0.1482 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 439/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1330 - accuracy: 0.9667\n",
      "Epoch 439: val_loss improved from 0.14822 to 0.14806, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9649 - val_loss: 0.1481 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 440/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1251 - accuracy: 0.9673\n",
      "Epoch 440: val_loss improved from 0.14806 to 0.14790, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1308 - accuracy: 0.9649 - val_loss: 0.1479 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 441/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1371 - accuracy: 0.9659\n",
      "Epoch 441: val_loss improved from 0.14790 to 0.14774, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1306 - accuracy: 0.9649 - val_loss: 0.1477 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 442/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1322 - accuracy: 0.9645\n",
      "Epoch 442: val_loss improved from 0.14774 to 0.14759, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.9649 - val_loss: 0.1476 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 443/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1195 - accuracy: 0.9708\n",
      "Epoch 443: val_loss improved from 0.14759 to 0.14743, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1302 - accuracy: 0.9649 - val_loss: 0.1474 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 444/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1277 - accuracy: 0.9681\n",
      "Epoch 444: val_loss improved from 0.14743 to 0.14727, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1300 - accuracy: 0.9649 - val_loss: 0.1473 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 445/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1237 - accuracy: 0.9681\n",
      "Epoch 445: val_loss improved from 0.14727 to 0.14712, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.9649 - val_loss: 0.1471 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 446/1000\n",
      "39/53 [=====================>........] - ETA: 0s - loss: 0.1177 - accuracy: 0.9701\n",
      "Epoch 446: val_loss improved from 0.14712 to 0.14697, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9649 - val_loss: 0.1470 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 447/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1349 - accuracy: 0.9610\n",
      "Epoch 447: val_loss improved from 0.14697 to 0.14681, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9649 - val_loss: 0.1468 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 448/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1359 - accuracy: 0.9621\n",
      "Epoch 448: val_loss improved from 0.14681 to 0.14666, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9649 - val_loss: 0.1467 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 449/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1292 - accuracy: 0.9641\n",
      "Epoch 449: val_loss improved from 0.14666 to 0.14651, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1290 - accuracy: 0.9649 - val_loss: 0.1465 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 450/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1227 - accuracy: 0.9674\n",
      "Epoch 450: val_loss improved from 0.14651 to 0.14636, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9649 - val_loss: 0.1464 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 451/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1257 - accuracy: 0.9688\n",
      "Epoch 451: val_loss improved from 0.14636 to 0.14621, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9649 - val_loss: 0.1462 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 452/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1333 - accuracy: 0.9638\n",
      "Epoch 452: val_loss improved from 0.14621 to 0.14607, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.9649 - val_loss: 0.1461 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 453/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1193 - accuracy: 0.9674\n",
      "Epoch 453: val_loss improved from 0.14607 to 0.14592, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1282 - accuracy: 0.9649 - val_loss: 0.1459 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 454/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1347 - accuracy: 0.9601\n",
      "Epoch 454: val_loss improved from 0.14592 to 0.14577, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9649 - val_loss: 0.1458 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 455/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9647\n",
      "Epoch 455: val_loss improved from 0.14577 to 0.14562, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9649 - val_loss: 0.1456 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 456/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1255 - accuracy: 0.9674\n",
      "Epoch 456: val_loss improved from 0.14562 to 0.14547, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.9649 - val_loss: 0.1455 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 457/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1294 - accuracy: 0.9610\n",
      "Epoch 457: val_loss improved from 0.14547 to 0.14533, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9649 - val_loss: 0.1453 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 458/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1315 - accuracy: 0.9638\n",
      "Epoch 458: val_loss improved from 0.14533 to 0.14519, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9649 - val_loss: 0.1452 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 459/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1328 - accuracy: 0.9621\n",
      "Epoch 459: val_loss improved from 0.14519 to 0.14504, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1271 - accuracy: 0.9649 - val_loss: 0.1450 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 460/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1413 - accuracy: 0.9553\n",
      "Epoch 460: val_loss improved from 0.14504 to 0.14490, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1269 - accuracy: 0.9649 - val_loss: 0.1449 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 461/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1279 - accuracy: 0.9641\n",
      "Epoch 461: val_loss improved from 0.14490 to 0.14479, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1267 - accuracy: 0.9649 - val_loss: 0.1448 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 462/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1194 - accuracy: 0.9638\n",
      "Epoch 462: val_loss improved from 0.14479 to 0.14464, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1265 - accuracy: 0.9649 - val_loss: 0.1446 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 463/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1250 - accuracy: 0.9674\n",
      "Epoch 463: val_loss improved from 0.14464 to 0.14450, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9649 - val_loss: 0.1445 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 464/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1383 - accuracy: 0.9603\n",
      "Epoch 464: val_loss improved from 0.14450 to 0.14436, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9649 - val_loss: 0.1444 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 465/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1388 - accuracy: 0.9574\n",
      "Epoch 465: val_loss improved from 0.14436 to 0.14422, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9649 - val_loss: 0.1442 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 466/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1274 - accuracy: 0.9667\n",
      "Epoch 466: val_loss improved from 0.14422 to 0.14408, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1258 - accuracy: 0.9649 - val_loss: 0.1441 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 467/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1293 - accuracy: 0.9659\n",
      "Epoch 467: val_loss improved from 0.14408 to 0.14394, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1256 - accuracy: 0.9649 - val_loss: 0.1439 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 468/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1315 - accuracy: 0.9610\n",
      "Epoch 468: val_loss improved from 0.14394 to 0.14381, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9649 - val_loss: 0.1438 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 469/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1078 - accuracy: 0.9741\n",
      "Epoch 469: val_loss improved from 0.14381 to 0.14367, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9649 - val_loss: 0.1437 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 470/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1230 - accuracy: 0.9683\n",
      "Epoch 470: val_loss improved from 0.14367 to 0.14353, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9649 - val_loss: 0.1435 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 471/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1279 - accuracy: 0.9630\n",
      "Epoch 471: val_loss improved from 0.14353 to 0.14340, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1249 - accuracy: 0.9649 - val_loss: 0.1434 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 472/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9647\n",
      "Epoch 472: val_loss improved from 0.14340 to 0.14325, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1247 - accuracy: 0.9649 - val_loss: 0.1432 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 473/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1291 - accuracy: 0.9645\n",
      "Epoch 473: val_loss improved from 0.14325 to 0.14309, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9649 - val_loss: 0.1431 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 474/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1291 - accuracy: 0.9630\n",
      "Epoch 474: val_loss improved from 0.14309 to 0.14296, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.9649 - val_loss: 0.1430 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 475/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1281 - accuracy: 0.9643\n",
      "Epoch 475: val_loss improved from 0.14296 to 0.14284, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9649 - val_loss: 0.1428 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 476/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1306 - accuracy: 0.9618\n",
      "Epoch 476: val_loss improved from 0.14284 to 0.14271, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.9649 - val_loss: 0.1427 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 477/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1214 - accuracy: 0.9681\n",
      "Epoch 477: val_loss improved from 0.14271 to 0.14258, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1238 - accuracy: 0.9649 - val_loss: 0.1426 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 478/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1235 - accuracy: 0.9641\n",
      "Epoch 478: val_loss improved from 0.14258 to 0.14244, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.9649 - val_loss: 0.1424 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 479/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1202 - accuracy: 0.9688\n",
      "Epoch 479: val_loss improved from 0.14244 to 0.14231, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9649 - val_loss: 0.1423 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 480/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1072 - accuracy: 0.9722\n",
      "Epoch 480: val_loss improved from 0.14231 to 0.14215, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9649 - val_loss: 0.1421 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 481/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1229 - accuracy: 0.9647\n",
      "Epoch 481: val_loss improved from 0.14215 to 0.14201, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1231 - accuracy: 0.9649 - val_loss: 0.1420 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 482/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1248 - accuracy: 0.9630\n",
      "Epoch 482: val_loss improved from 0.14201 to 0.14188, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9649 - val_loss: 0.1419 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 483/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1119 - accuracy: 0.9710\n",
      "Epoch 483: val_loss improved from 0.14188 to 0.14175, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9649 - val_loss: 0.1418 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 484/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1324 - accuracy: 0.9601\n",
      "Epoch 484: val_loss improved from 0.14175 to 0.14163, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9649 - val_loss: 0.1416 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 485/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1291 - accuracy: 0.9630\n",
      "Epoch 485: val_loss improved from 0.14163 to 0.14150, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1224 - accuracy: 0.9649 - val_loss: 0.1415 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 486/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1206 - accuracy: 0.9630\n",
      "Epoch 486: val_loss improved from 0.14150 to 0.14137, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9649 - val_loss: 0.1414 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 487/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1292 - accuracy: 0.9621\n",
      "Epoch 487: val_loss improved from 0.14137 to 0.14125, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9649 - val_loss: 0.1412 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 488/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1184 - accuracy: 0.9674\n",
      "Epoch 488: val_loss improved from 0.14125 to 0.14113, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9649 - val_loss: 0.1411 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9649\n",
      "Epoch 489: val_loss improved from 0.14113 to 0.14100, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 0.9649 - val_loss: 0.1410 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 490/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9681\n",
      "Epoch 490: val_loss improved from 0.14100 to 0.14088, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1215 - accuracy: 0.9649 - val_loss: 0.1409 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 491/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1260 - accuracy: 0.9626\n",
      "Epoch 491: val_loss improved from 0.14088 to 0.14076, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9649 - val_loss: 0.1408 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 492/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1004 - accuracy: 0.9715\n",
      "Epoch 492: val_loss improved from 0.14076 to 0.14065, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1212 - accuracy: 0.9649 - val_loss: 0.1407 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 493/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1245 - accuracy: 0.9651\n",
      "Epoch 493: val_loss improved from 0.14065 to 0.14053, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 0.9649 - val_loss: 0.1405 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 494/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1109 - accuracy: 0.9667\n",
      "Epoch 494: val_loss improved from 0.14053 to 0.14041, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.9649 - val_loss: 0.1404 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 495/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1213 - accuracy: 0.9660\n",
      "Epoch 495: val_loss improved from 0.14041 to 0.14030, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9649 - val_loss: 0.1403 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 496/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1101 - accuracy: 0.9710\n",
      "Epoch 496: val_loss improved from 0.14030 to 0.14018, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9649 - val_loss: 0.1402 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 497/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1264 - accuracy: 0.9612\n",
      "Epoch 497: val_loss improved from 0.14018 to 0.14006, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.9649 - val_loss: 0.1401 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 498/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1262 - accuracy: 0.9603\n",
      "Epoch 498: val_loss improved from 0.14006 to 0.13995, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9649 - val_loss: 0.1399 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 499/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1262 - accuracy: 0.9638\n",
      "Epoch 499: val_loss improved from 0.13995 to 0.13982, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9649 - val_loss: 0.1398 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 500/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9647\n",
      "Epoch 500: val_loss improved from 0.13982 to 0.13970, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.9649 - val_loss: 0.1397 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 501/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1171 - accuracy: 0.9667\n",
      "Epoch 501: val_loss improved from 0.13970 to 0.13960, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9649 - val_loss: 0.1396 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 502/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9681\n",
      "Epoch 502: val_loss improved from 0.13960 to 0.13952, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.9649 - val_loss: 0.1395 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 503/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1172 - accuracy: 0.9653\n",
      "Epoch 503: val_loss improved from 0.13952 to 0.13941, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9649 - val_loss: 0.1394 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 504/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1288 - accuracy: 0.9634\n",
      "Epoch 504: val_loss improved from 0.13941 to 0.13929, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9649 - val_loss: 0.1393 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 505/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1205 - accuracy: 0.9641\n",
      "Epoch 505: val_loss improved from 0.13929 to 0.13918, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 0.9649 - val_loss: 0.1392 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 506/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9647\n",
      "Epoch 506: val_loss improved from 0.13918 to 0.13907, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9649 - val_loss: 0.1391 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 507/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9653\n",
      "Epoch 507: val_loss improved from 0.13907 to 0.13896, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1187 - accuracy: 0.9649 - val_loss: 0.1390 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 508/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1175 - accuracy: 0.9603\n",
      "Epoch 508: val_loss improved from 0.13896 to 0.13885, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9649 - val_loss: 0.1388 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 509/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1103 - accuracy: 0.9675\n",
      "Epoch 509: val_loss improved from 0.13885 to 0.13873, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1183 - accuracy: 0.9649 - val_loss: 0.1387 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9649\n",
      "Epoch 510: val_loss improved from 0.13873 to 0.13861, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.9649 - val_loss: 0.1386 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 511/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1283 - accuracy: 0.9634\n",
      "Epoch 511: val_loss improved from 0.13861 to 0.13851, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.9649 - val_loss: 0.1385 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 512/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1214 - accuracy: 0.9626\n",
      "Epoch 512: val_loss improved from 0.13851 to 0.13840, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9649 - val_loss: 0.1384 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 513/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1203 - accuracy: 0.9633\n",
      "Epoch 513: val_loss improved from 0.13840 to 0.13829, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1177 - accuracy: 0.9649 - val_loss: 0.1383 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 514/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9647\n",
      "Epoch 514: val_loss improved from 0.13829 to 0.13818, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.9649 - val_loss: 0.1382 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 515/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9674\n",
      "Epoch 515: val_loss improved from 0.13818 to 0.13807, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1174 - accuracy: 0.9649 - val_loss: 0.1381 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 516/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1261 - accuracy: 0.9634\n",
      "Epoch 516: val_loss improved from 0.13807 to 0.13796, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.9649 - val_loss: 0.1380 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 517/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1206 - accuracy: 0.9651\n",
      "Epoch 517: val_loss improved from 0.13796 to 0.13786, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.9649 - val_loss: 0.1379 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 518/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1203 - accuracy: 0.9633\n",
      "Epoch 518: val_loss improved from 0.13786 to 0.13775, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9649 - val_loss: 0.1377 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 519/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1184 - accuracy: 0.9634\n",
      "Epoch 519: val_loss improved from 0.13775 to 0.13764, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.9649 - val_loss: 0.1376 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 520/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.9641\n",
      "Epoch 520: val_loss improved from 0.13764 to 0.13754, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1165 - accuracy: 0.9649 - val_loss: 0.1375 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 521/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1317 - accuracy: 0.9583\n",
      "Epoch 521: val_loss improved from 0.13754 to 0.13743, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.9649 - val_loss: 0.1374 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 522/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1120 - accuracy: 0.9688\n",
      "Epoch 522: val_loss improved from 0.13743 to 0.13732, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1162 - accuracy: 0.9649 - val_loss: 0.1373 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 523/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1204 - accuracy: 0.9612\n",
      "Epoch 523: val_loss improved from 0.13732 to 0.13722, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9649 - val_loss: 0.1372 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 524/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9645\n",
      "Epoch 524: val_loss improved from 0.13722 to 0.13711, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1159 - accuracy: 0.9649 - val_loss: 0.1371 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 525/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1084 - accuracy: 0.9683\n",
      "Epoch 525: val_loss improved from 0.13711 to 0.13701, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.9649 - val_loss: 0.1370 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 526/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1266 - accuracy: 0.9603\n",
      "Epoch 526: val_loss improved from 0.13701 to 0.13693, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.9649 - val_loss: 0.1369 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 527/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1110 - accuracy: 0.9674\n",
      "Epoch 527: val_loss improved from 0.13693 to 0.13679, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1154 - accuracy: 0.9649 - val_loss: 0.1368 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 528/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9647\n",
      "Epoch 528: val_loss improved from 0.13679 to 0.13669, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9649 - val_loss: 0.1367 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 529/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1067 - accuracy: 0.9667\n",
      "Epoch 529: val_loss improved from 0.13669 to 0.13659, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.9649 - val_loss: 0.1366 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 530/1000\n",
      "39/53 [=====================>........] - ETA: 0s - loss: 0.1133 - accuracy: 0.9701\n",
      "Epoch 530: val_loss improved from 0.13659 to 0.13649, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9649 - val_loss: 0.1365 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 531/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1156 - accuracy: 0.9645\n",
      "Epoch 531: val_loss improved from 0.13649 to 0.13639, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1148 - accuracy: 0.9649 - val_loss: 0.1364 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 532/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1034 - accuracy: 0.9708\n",
      "Epoch 532: val_loss improved from 0.13639 to 0.13628, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.9649 - val_loss: 0.1363 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 533/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1199 - accuracy: 0.9626\n",
      "Epoch 533: val_loss improved from 0.13628 to 0.13618, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1145 - accuracy: 0.9649 - val_loss: 0.1362 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 534/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1058 - accuracy: 0.9690\n",
      "Epoch 534: val_loss improved from 0.13618 to 0.13608, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1144 - accuracy: 0.9649 - val_loss: 0.1361 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 535/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1197 - accuracy: 0.9675\n",
      "Epoch 535: val_loss improved from 0.13608 to 0.13598, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9649 - val_loss: 0.1360 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9649\n",
      "Epoch 536: val_loss improved from 0.13598 to 0.13592, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9649 - val_loss: 0.1359 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 537/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0977 - accuracy: 0.9715\n",
      "Epoch 537: val_loss improved from 0.13592 to 0.13583, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9649 - val_loss: 0.1358 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 538/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1149 - accuracy: 0.9621\n",
      "Epoch 538: val_loss improved from 0.13583 to 0.13570, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1137 - accuracy: 0.9649 - val_loss: 0.1357 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 539/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1113 - accuracy: 0.9638\n",
      "Epoch 539: val_loss improved from 0.13570 to 0.13560, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9649 - val_loss: 0.1356 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9649\n",
      "Epoch 540: val_loss improved from 0.13560 to 0.13551, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.1355 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 541/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0965 - accuracy: 0.9722\n",
      "Epoch 541: val_loss improved from 0.13551 to 0.13541, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1132 - accuracy: 0.9649 - val_loss: 0.1354 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 542/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1121 - accuracy: 0.9612\n",
      "Epoch 542: val_loss improved from 0.13541 to 0.13531, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1131 - accuracy: 0.9649 - val_loss: 0.1353 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 543/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1098 - accuracy: 0.9659\n",
      "Epoch 543: val_loss improved from 0.13531 to 0.13522, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1129 - accuracy: 0.9649 - val_loss: 0.1352 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 544/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1204 - accuracy: 0.9612\n",
      "Epoch 544: val_loss improved from 0.13522 to 0.13512, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9649 - val_loss: 0.1351 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 545/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1119 - accuracy: 0.9690\n",
      "Epoch 545: val_loss improved from 0.13512 to 0.13504, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9649 - val_loss: 0.1350 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 546/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1147 - accuracy: 0.9641\n",
      "Epoch 546: val_loss improved from 0.13504 to 0.13495, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1125 - accuracy: 0.9649 - val_loss: 0.1349 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 547/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1260 - accuracy: 0.9593\n",
      "Epoch 547: val_loss improved from 0.13495 to 0.13485, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9649 - val_loss: 0.1349 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 548/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1088 - accuracy: 0.9659\n",
      "Epoch 548: val_loss improved from 0.13485 to 0.13476, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.9649 - val_loss: 0.1348 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9649\n",
      "Epoch 549: val_loss improved from 0.13476 to 0.13475, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.9649 - val_loss: 0.1348 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 550/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1186 - accuracy: 0.9621\n",
      "Epoch 550: val_loss improved from 0.13475 to 0.13466, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9649 - val_loss: 0.1347 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 551/1000\n",
      "39/53 [=====================>........] - ETA: 0s - loss: 0.1107 - accuracy: 0.9701\n",
      "Epoch 551: val_loss improved from 0.13466 to 0.13457, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 0.9649 - val_loss: 0.1346 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 552/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1177 - accuracy: 0.9630\n",
      "Epoch 552: val_loss improved from 0.13457 to 0.13448, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9649 - val_loss: 0.1345 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 553/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9647\n",
      "Epoch 553: val_loss improved from 0.13448 to 0.13438, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9649 - val_loss: 0.1344 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 554/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1160 - accuracy: 0.9618\n",
      "Epoch 554: val_loss improved from 0.13438 to 0.13429, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9649 - val_loss: 0.1343 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 555/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1132 - accuracy: 0.9641\n",
      "Epoch 555: val_loss improved from 0.13429 to 0.13420, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1111 - accuracy: 0.9649 - val_loss: 0.1342 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 556/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1012 - accuracy: 0.9690\n",
      "Epoch 556: val_loss improved from 0.13420 to 0.13411, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.9649 - val_loss: 0.1341 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 557/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.1145 - accuracy: 0.9633\n",
      "Epoch 557: val_loss improved from 0.13411 to 0.13402, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.9649 - val_loss: 0.1340 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9649\n",
      "Epoch 558: val_loss improved from 0.13402 to 0.13394, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1107 - accuracy: 0.9649 - val_loss: 0.1339 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 559/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1206 - accuracy: 0.9574\n",
      "Epoch 559: val_loss improved from 0.13394 to 0.13385, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9649 - val_loss: 0.1338 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 560/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1118 - accuracy: 0.9630\n",
      "Epoch 560: val_loss improved from 0.13385 to 0.13376, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.9649 - val_loss: 0.1338 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 561/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9630\n",
      "Epoch 561: val_loss improved from 0.13376 to 0.13367, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9649 - val_loss: 0.1337 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 562/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1157 - accuracy: 0.9643\n",
      "Epoch 562: val_loss improved from 0.13367 to 0.13358, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9649 - val_loss: 0.1336 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 563/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1287 - accuracy: 0.9553\n",
      "Epoch 563: val_loss improved from 0.13358 to 0.13349, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9649 - val_loss: 0.1335 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 564/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.1140 - accuracy: 0.9626\n",
      "Epoch 564: val_loss improved from 0.13349 to 0.13340, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.1334 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 565/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1061 - accuracy: 0.9704\n",
      "Epoch 565: val_loss improved from 0.13340 to 0.13331, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.9649 - val_loss: 0.1333 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 566/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1043 - accuracy: 0.9675\n",
      "Epoch 566: val_loss improved from 0.13331 to 0.13322, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9649 - val_loss: 0.1332 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 567/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1163 - accuracy: 0.9612\n",
      "Epoch 567: val_loss improved from 0.13322 to 0.13313, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9649 - val_loss: 0.1331 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 568/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0939 - accuracy: 0.9708\n",
      "Epoch 568: val_loss improved from 0.13313 to 0.13304, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.9649 - val_loss: 0.1330 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 569/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1097 - accuracy: 0.9603\n",
      "Epoch 569: val_loss improved from 0.13304 to 0.13296, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9649 - val_loss: 0.1330 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 570/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1165 - accuracy: 0.9593\n",
      "Epoch 570: val_loss improved from 0.13296 to 0.13287, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9649 - val_loss: 0.1329 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 571/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1131 - accuracy: 0.9645\n",
      "Epoch 571: val_loss improved from 0.13287 to 0.13278, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9649 - val_loss: 0.1328 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 572/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1149 - accuracy: 0.9618\n",
      "Epoch 572: val_loss improved from 0.13278 to 0.13270, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9649 - val_loss: 0.1327 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 573/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1115 - accuracy: 0.9675\n",
      "Epoch 573: val_loss improved from 0.13270 to 0.13258, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 0.9649 - val_loss: 0.1326 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 574/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9630\n",
      "Epoch 574: val_loss improved from 0.13258 to 0.13250, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1084 - accuracy: 0.9649 - val_loss: 0.1325 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 575/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1079 - accuracy: 0.9630\n",
      "Epoch 575: val_loss improved from 0.13250 to 0.13242, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.9649 - val_loss: 0.1324 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 576/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1080 - accuracy: 0.9621\n",
      "Epoch 576: val_loss improved from 0.13242 to 0.13233, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9649 - val_loss: 0.1323 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 577/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1066 - accuracy: 0.9630\n",
      "Epoch 577: val_loss improved from 0.13233 to 0.13226, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9649 - val_loss: 0.1323 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 578/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1135 - accuracy: 0.9610\n",
      "Epoch 578: val_loss improved from 0.13226 to 0.13216, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9649 - val_loss: 0.1322 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 579/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1117 - accuracy: 0.9651\n",
      "Epoch 579: val_loss improved from 0.13216 to 0.13207, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.9649 - val_loss: 0.1321 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 580/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1111 - accuracy: 0.9645\n",
      "Epoch 580: val_loss improved from 0.13207 to 0.13199, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9649 - val_loss: 0.1320 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 581/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1096 - accuracy: 0.9667\n",
      "Epoch 581: val_loss improved from 0.13199 to 0.13188, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.9649 - val_loss: 0.1319 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 582/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1086 - accuracy: 0.9641\n",
      "Epoch 582: val_loss improved from 0.13188 to 0.13180, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9649 - val_loss: 0.1318 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 583/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1047 - accuracy: 0.9653\n",
      "Epoch 583: val_loss improved from 0.13180 to 0.13170, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1071 - accuracy: 0.9649 - val_loss: 0.1317 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 584/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1115 - accuracy: 0.9638\n",
      "Epoch 584: val_loss improved from 0.13170 to 0.13163, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9649 - val_loss: 0.1316 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 585/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1122 - accuracy: 0.9630\n",
      "Epoch 585: val_loss improved from 0.13163 to 0.13155, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9649 - val_loss: 0.1315 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 586/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.0965 - accuracy: 0.9674\n",
      "Epoch 586: val_loss improved from 0.13155 to 0.13147, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9649 - val_loss: 0.1315 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 587/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1047 - accuracy: 0.9643\n",
      "Epoch 587: val_loss improved from 0.13147 to 0.13139, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9649 - val_loss: 0.1314 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 588/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1123 - accuracy: 0.9601\n",
      "Epoch 588: val_loss improved from 0.13139 to 0.13125, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9649 - val_loss: 0.1313 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 589/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1005 - accuracy: 0.9651\n",
      "Epoch 589: val_loss improved from 0.13125 to 0.13117, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9649 - val_loss: 0.1312 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 590/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1072 - accuracy: 0.9638\n",
      "Epoch 590: val_loss improved from 0.13117 to 0.13110, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1061 - accuracy: 0.9649 - val_loss: 0.1311 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 591/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0965 - accuracy: 0.9697\n",
      "Epoch 591: val_loss improved from 0.13110 to 0.13103, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.9649 - val_loss: 0.1310 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 592/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1057 - accuracy: 0.9667\n",
      "Epoch 592: val_loss improved from 0.13103 to 0.13095, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9649 - val_loss: 0.1309 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 593/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1013 - accuracy: 0.9722\n",
      "Epoch 593: val_loss improved from 0.13095 to 0.13087, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9649 - val_loss: 0.1309 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 594/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1153 - accuracy: 0.9634\n",
      "Epoch 594: val_loss improved from 0.13087 to 0.13080, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9649 - val_loss: 0.1308 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 595/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1138 - accuracy: 0.9643\n",
      "Epoch 595: val_loss improved from 0.13080 to 0.13073, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9649 - val_loss: 0.1307 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 596/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0835 - accuracy: 0.9756\n",
      "Epoch 596: val_loss improved from 0.13073 to 0.13066, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9649 - val_loss: 0.1307 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 597/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0911 - accuracy: 0.9704\n",
      "Epoch 597: val_loss improved from 0.13066 to 0.13060, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9649 - val_loss: 0.1306 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 598/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1026 - accuracy: 0.9643\n",
      "Epoch 598: val_loss improved from 0.13060 to 0.13053, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9649 - val_loss: 0.1305 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 599/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1047 - accuracy: 0.9667\n",
      "Epoch 599: val_loss improved from 0.13053 to 0.13046, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1048 - accuracy: 0.9649 - val_loss: 0.1305 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 600/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1077 - accuracy: 0.9651\n",
      "Epoch 600: val_loss improved from 0.13046 to 0.13038, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9649 - val_loss: 0.1304 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 601/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0986 - accuracy: 0.9659\n",
      "Epoch 601: val_loss improved from 0.13038 to 0.13031, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9649 - val_loss: 0.1303 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 602/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1148 - accuracy: 0.9612\n",
      "Epoch 602: val_loss improved from 0.13031 to 0.13024, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.9649 - val_loss: 0.1302 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 603/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1120 - accuracy: 0.9630\n",
      "Epoch 603: val_loss improved from 0.13024 to 0.13017, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9649 - val_loss: 0.1302 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 604/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1044 - accuracy: 0.9647\n",
      "Epoch 604: val_loss improved from 0.13017 to 0.13010, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.9649 - val_loss: 0.1301 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 605/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1017 - accuracy: 0.9675\n",
      "Epoch 605: val_loss improved from 0.13010 to 0.13003, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9649 - val_loss: 0.1300 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 606/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1104 - accuracy: 0.9630\n",
      "Epoch 606: val_loss did not improve from 0.13003\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9649 - val_loss: 0.1301 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 607/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.1090 - accuracy: 0.9638\n",
      "Epoch 607: val_loss improved from 0.13003 to 0.12999, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9649 - val_loss: 0.1300 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 608/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1029 - accuracy: 0.9634\n",
      "Epoch 608: val_loss improved from 0.12999 to 0.12992, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9649 - val_loss: 0.1299 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 609/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1130 - accuracy: 0.9612\n",
      "Epoch 609: val_loss improved from 0.12992 to 0.12985, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9649 - val_loss: 0.1298 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 610/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1009 - accuracy: 0.9634\n",
      "Epoch 610: val_loss improved from 0.12985 to 0.12974, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.9649 - val_loss: 0.1297 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 611/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0967 - accuracy: 0.9675\n",
      "Epoch 611: val_loss improved from 0.12974 to 0.12967, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 0.9649 - val_loss: 0.1297 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9649\n",
      "Epoch 612: val_loss did not improve from 0.12967\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.9649 - val_loss: 0.1297 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 613/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1143 - accuracy: 0.9593\n",
      "Epoch 613: val_loss improved from 0.12967 to 0.12960, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9649 - val_loss: 0.1296 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 614/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1039 - accuracy: 0.9634\n",
      "Epoch 614: val_loss improved from 0.12960 to 0.12954, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9649 - val_loss: 0.1295 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 615/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1123 - accuracy: 0.9593\n",
      "Epoch 615: val_loss improved from 0.12954 to 0.12946, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.9649 - val_loss: 0.1295 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 616/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1116 - accuracy: 0.9603\n",
      "Epoch 616: val_loss improved from 0.12946 to 0.12939, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.9649 - val_loss: 0.1294 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 617/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0909 - accuracy: 0.9683\n",
      "Epoch 617: val_loss improved from 0.12939 to 0.12931, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9649 - val_loss: 0.1293 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 618/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.9647\n",
      "Epoch 618: val_loss improved from 0.12931 to 0.12925, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9649 - val_loss: 0.1292 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 619/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1122 - accuracy: 0.9574\n",
      "Epoch 619: val_loss improved from 0.12925 to 0.12917, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9649 - val_loss: 0.1292 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 620/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1069 - accuracy: 0.9651\n",
      "Epoch 620: val_loss improved from 0.12917 to 0.12911, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9649 - val_loss: 0.1291 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 621/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0951 - accuracy: 0.9690\n",
      "Epoch 621: val_loss improved from 0.12911 to 0.12904, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9649 - val_loss: 0.1290 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 622/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1024 - accuracy: 0.9683\n",
      "Epoch 622: val_loss improved from 0.12904 to 0.12897, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9649 - val_loss: 0.1290 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 623/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1002 - accuracy: 0.9651\n",
      "Epoch 623: val_loss improved from 0.12897 to 0.12889, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.9649 - val_loss: 0.1289 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 624/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.1036 - accuracy: 0.9630\n",
      "Epoch 624: val_loss improved from 0.12889 to 0.12883, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9649 - val_loss: 0.1288 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 625/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1106 - accuracy: 0.9603\n",
      "Epoch 625: val_loss improved from 0.12883 to 0.12876, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9681 - val_loss: 0.1288 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 626/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0949 - accuracy: 0.9667\n",
      "Epoch 626: val_loss did not improve from 0.12876\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1012 - accuracy: 0.9649 - val_loss: 0.1288 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 627/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1112 - accuracy: 0.9612\n",
      "Epoch 627: val_loss improved from 0.12876 to 0.12870, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9681 - val_loss: 0.1287 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 628/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1145 - accuracy: 0.9634\n",
      "Epoch 628: val_loss improved from 0.12870 to 0.12863, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9681 - val_loss: 0.1286 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 629/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0945 - accuracy: 0.9690\n",
      "Epoch 629: val_loss improved from 0.12863 to 0.12857, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1009 - accuracy: 0.9649 - val_loss: 0.1286 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 630/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0764 - accuracy: 0.9806\n",
      "Epoch 630: val_loss improved from 0.12857 to 0.12850, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1007 - accuracy: 0.9681 - val_loss: 0.1285 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 631/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1000 - accuracy: 0.9697\n",
      "Epoch 631: val_loss improved from 0.12850 to 0.12843, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9681 - val_loss: 0.1284 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 632/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1108 - accuracy: 0.9621\n",
      "Epoch 632: val_loss improved from 0.12843 to 0.12836, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.9681 - val_loss: 0.1284 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 633/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0989 - accuracy: 0.9722\n",
      "Epoch 633: val_loss improved from 0.12836 to 0.12829, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9681 - val_loss: 0.1283 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 634/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1038 - accuracy: 0.9690\n",
      "Epoch 634: val_loss improved from 0.12829 to 0.12823, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.9681 - val_loss: 0.1282 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 635/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9679\n",
      "Epoch 635: val_loss improved from 0.12823 to 0.12816, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9681 - val_loss: 0.1282 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 636/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1097 - accuracy: 0.9643\n",
      "Epoch 636: val_loss improved from 0.12816 to 0.12810, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.9681 - val_loss: 0.1281 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9681\n",
      "Epoch 637: val_loss improved from 0.12810 to 0.12803, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9681 - val_loss: 0.1280 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 638/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.1015 - accuracy: 0.9673\n",
      "Epoch 638: val_loss improved from 0.12803 to 0.12797, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9681 - val_loss: 0.1280 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 639/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9679\n",
      "Epoch 639: val_loss improved from 0.12797 to 0.12790, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.9681 - val_loss: 0.1279 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 640/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9679\n",
      "Epoch 640: val_loss improved from 0.12790 to 0.12784, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9681 - val_loss: 0.1278 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 641/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0882 - accuracy: 0.9735\n",
      "Epoch 641: val_loss improved from 0.12784 to 0.12773, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 0.9681 - val_loss: 0.1277 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 642/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1078 - accuracy: 0.9651\n",
      "Epoch 642: val_loss improved from 0.12773 to 0.12767, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9681 - val_loss: 0.1277 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 643/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9679\n",
      "Epoch 643: val_loss improved from 0.12767 to 0.12761, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9681 - val_loss: 0.1276 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 644/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0991 - accuracy: 0.9679\n",
      "Epoch 644: val_loss improved from 0.12761 to 0.12755, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0990 - accuracy: 0.9681 - val_loss: 0.1275 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 645/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0993 - accuracy: 0.9683\n",
      "Epoch 645: val_loss improved from 0.12755 to 0.12749, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0989 - accuracy: 0.9681 - val_loss: 0.1275 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 646/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0913 - accuracy: 0.9706\n",
      "Epoch 646: val_loss improved from 0.12749 to 0.12743, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9681 - val_loss: 0.1274 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 647/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0912 - accuracy: 0.9690\n",
      "Epoch 647: val_loss improved from 0.12743 to 0.12737, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9681 - val_loss: 0.1274 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 648/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.1018 - accuracy: 0.9675\n",
      "Epoch 648: val_loss improved from 0.12737 to 0.12730, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9681 - val_loss: 0.1273 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 649/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.1017 - accuracy: 0.9653\n",
      "Epoch 649: val_loss improved from 0.12730 to 0.12724, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0984 - accuracy: 0.9681 - val_loss: 0.1272 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 650/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.1037 - accuracy: 0.9645\n",
      "Epoch 650: val_loss improved from 0.12724 to 0.12718, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0983 - accuracy: 0.9681 - val_loss: 0.1272 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 651/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9679\n",
      "Epoch 651: val_loss improved from 0.12718 to 0.12713, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9681 - val_loss: 0.1271 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 652/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9679\n",
      "Epoch 652: val_loss improved from 0.12713 to 0.12707, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0980 - accuracy: 0.9681 - val_loss: 0.1271 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 653/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.1095 - accuracy: 0.9625\n",
      "Epoch 653: val_loss improved from 0.12707 to 0.12700, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9681 - val_loss: 0.1270 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 654/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0977 - accuracy: 0.9673\n",
      "Epoch 654: val_loss improved from 0.12700 to 0.12695, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0978 - accuracy: 0.9681 - val_loss: 0.1269 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9681\n",
      "Epoch 655: val_loss improved from 0.12695 to 0.12689, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0977 - accuracy: 0.9681 - val_loss: 0.1269 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 656/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0988 - accuracy: 0.9683\n",
      "Epoch 656: val_loss improved from 0.12689 to 0.12684, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.9681 - val_loss: 0.1268 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 657/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1017 - accuracy: 0.9643\n",
      "Epoch 657: val_loss improved from 0.12684 to 0.12678, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.9681 - val_loss: 0.1268 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 658/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0897 - accuracy: 0.9706\n",
      "Epoch 658: val_loss did not improve from 0.12678\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9681 - val_loss: 0.1268 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 659/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1093 - accuracy: 0.9603\n",
      "Epoch 659: val_loss improved from 0.12678 to 0.12675, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0972 - accuracy: 0.9681 - val_loss: 0.1267 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 660/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0990 - accuracy: 0.9667\n",
      "Epoch 660: val_loss improved from 0.12675 to 0.12669, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9681 - val_loss: 0.1267 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 661/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1090 - accuracy: 0.9603\n",
      "Epoch 661: val_loss improved from 0.12669 to 0.12663, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9681 - val_loss: 0.1266 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9681\n",
      "Epoch 662: val_loss improved from 0.12663 to 0.12658, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9681 - val_loss: 0.1266 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 663/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1032 - accuracy: 0.9651\n",
      "Epoch 663: val_loss improved from 0.12658 to 0.12651, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9681 - val_loss: 0.1265 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 664/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0887 - accuracy: 0.9683\n",
      "Epoch 664: val_loss improved from 0.12651 to 0.12645, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9681 - val_loss: 0.1265 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 665/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0910 - accuracy: 0.9690\n",
      "Epoch 665: val_loss improved from 0.12645 to 0.12639, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9681 - val_loss: 0.1264 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9681\n",
      "Epoch 666: val_loss improved from 0.12639 to 0.12632, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9681 - val_loss: 0.1263 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 667/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0975 - accuracy: 0.9673\n",
      "Epoch 667: val_loss improved from 0.12632 to 0.12627, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9681 - val_loss: 0.1263 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 668/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0945 - accuracy: 0.9706\n",
      "Epoch 668: val_loss improved from 0.12627 to 0.12621, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0961 - accuracy: 0.9681 - val_loss: 0.1262 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9681\n",
      "Epoch 669: val_loss improved from 0.12621 to 0.12615, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9681 - val_loss: 0.1262 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 670/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0915 - accuracy: 0.9729\n",
      "Epoch 670: val_loss improved from 0.12615 to 0.12610, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9681 - val_loss: 0.1261 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 671/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0941 - accuracy: 0.9643\n",
      "Epoch 671: val_loss improved from 0.12610 to 0.12604, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9681 - val_loss: 0.1260 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 672/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0899 - accuracy: 0.9722\n",
      "Epoch 672: val_loss improved from 0.12604 to 0.12595, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9681 - val_loss: 0.1260 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 673/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0937 - accuracy: 0.9651\n",
      "Epoch 673: val_loss improved from 0.12595 to 0.12590, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9681 - val_loss: 0.1259 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 674/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1042 - accuracy: 0.9621\n",
      "Epoch 674: val_loss improved from 0.12590 to 0.12584, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9681 - val_loss: 0.1258 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 675/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1087 - accuracy: 0.9612\n",
      "Epoch 675: val_loss improved from 0.12584 to 0.12579, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9681 - val_loss: 0.1258 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 676/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1040 - accuracy: 0.9651\n",
      "Epoch 676: val_loss improved from 0.12579 to 0.12573, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9681 - val_loss: 0.1257 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 677/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9679\n",
      "Epoch 677: val_loss improved from 0.12573 to 0.12568, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 0.9681 - val_loss: 0.1257 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 678/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0889 - accuracy: 0.9697\n",
      "Epoch 678: val_loss improved from 0.12568 to 0.12563, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0950 - accuracy: 0.9681 - val_loss: 0.1256 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 679/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9679\n",
      "Epoch 679: val_loss improved from 0.12563 to 0.12558, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9681 - val_loss: 0.1256 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 680/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1041 - accuracy: 0.9659\n",
      "Epoch 680: val_loss improved from 0.12558 to 0.12553, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0947 - accuracy: 0.9681 - val_loss: 0.1255 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 681/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1055 - accuracy: 0.9643\n",
      "Epoch 681: val_loss improved from 0.12553 to 0.12548, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0946 - accuracy: 0.9681 - val_loss: 0.1255 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 682/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1008 - accuracy: 0.9659\n",
      "Epoch 682: val_loss improved from 0.12548 to 0.12542, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9681 - val_loss: 0.1254 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 683/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1001 - accuracy: 0.9643\n",
      "Epoch 683: val_loss improved from 0.12542 to 0.12537, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0944 - accuracy: 0.9681 - val_loss: 0.1254 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 684/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1063 - accuracy: 0.9612\n",
      "Epoch 684: val_loss improved from 0.12537 to 0.12532, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9681 - val_loss: 0.1253 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 685/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0923 - accuracy: 0.9690\n",
      "Epoch 685: val_loss improved from 0.12532 to 0.12528, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9681 - val_loss: 0.1253 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 686/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1049 - accuracy: 0.9643\n",
      "Epoch 686: val_loss improved from 0.12528 to 0.12522, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9681 - val_loss: 0.1252 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 687/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0960 - accuracy: 0.9715\n",
      "Epoch 687: val_loss improved from 0.12522 to 0.12518, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9681 - val_loss: 0.1252 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 688/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0779 - accuracy: 0.9697\n",
      "Epoch 688: val_loss improved from 0.12518 to 0.12513, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9681 - val_loss: 0.1251 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 689/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0872 - accuracy: 0.9729\n",
      "Epoch 689: val_loss improved from 0.12513 to 0.12508, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0937 - accuracy: 0.9681 - val_loss: 0.1251 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 690/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0683 - accuracy: 0.9729\n",
      "Epoch 690: val_loss improved from 0.12508 to 0.12504, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.9681 - val_loss: 0.1250 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 691/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0945 - accuracy: 0.9715\n",
      "Epoch 691: val_loss improved from 0.12504 to 0.12499, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9681 - val_loss: 0.1250 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 692/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0955 - accuracy: 0.9690\n",
      "Epoch 692: val_loss improved from 0.12499 to 0.12495, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9681 - val_loss: 0.1249 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 693/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0956 - accuracy: 0.9634\n",
      "Epoch 693: val_loss improved from 0.12495 to 0.12490, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9681 - val_loss: 0.1249 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 694/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0887 - accuracy: 0.9690\n",
      "Epoch 694: val_loss improved from 0.12490 to 0.12486, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9681 - val_loss: 0.1249 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 695/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.1021 - accuracy: 0.9612\n",
      "Epoch 695: val_loss improved from 0.12486 to 0.12481, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9681 - val_loss: 0.1248 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 696/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0959 - accuracy: 0.9690\n",
      "Epoch 696: val_loss improved from 0.12481 to 0.12476, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9681 - val_loss: 0.1248 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 697/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0976 - accuracy: 0.9651\n",
      "Epoch 697: val_loss improved from 0.12476 to 0.12471, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9681 - val_loss: 0.1247 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 698/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0851 - accuracy: 0.9729\n",
      "Epoch 698: val_loss improved from 0.12471 to 0.12467, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9681 - val_loss: 0.1247 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 699/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0856 - accuracy: 0.9729\n",
      "Epoch 699: val_loss improved from 0.12467 to 0.12462, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 0.9681 - val_loss: 0.1246 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 700/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.1049 - accuracy: 0.9643\n",
      "Epoch 700: val_loss improved from 0.12462 to 0.12458, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9681 - val_loss: 0.1246 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 701/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0900 - accuracy: 0.9643\n",
      "Epoch 701: val_loss improved from 0.12458 to 0.12454, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9681 - val_loss: 0.1245 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 702/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0858 - accuracy: 0.9683\n",
      "Epoch 702: val_loss improved from 0.12454 to 0.12449, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9681 - val_loss: 0.1245 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 703/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0768 - accuracy: 0.9802\n",
      "Epoch 703: val_loss improved from 0.12449 to 0.12445, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9681 - val_loss: 0.1244 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 704/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0925 - accuracy: 0.9690\n",
      "Epoch 704: val_loss improved from 0.12445 to 0.12440, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.9681 - val_loss: 0.1244 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 705/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0946 - accuracy: 0.9683\n",
      "Epoch 705: val_loss improved from 0.12440 to 0.12436, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9681 - val_loss: 0.1244 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 706/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0975 - accuracy: 0.9651\n",
      "Epoch 706: val_loss improved from 0.12436 to 0.12433, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.1243 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 707/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0952 - accuracy: 0.9683\n",
      "Epoch 707: val_loss improved from 0.12433 to 0.12428, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9681 - val_loss: 0.1243 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 708/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0876 - accuracy: 0.9659\n",
      "Epoch 708: val_loss improved from 0.12428 to 0.12424, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9681 - val_loss: 0.1242 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 709/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0961 - accuracy: 0.9612\n",
      "Epoch 709: val_loss improved from 0.12424 to 0.12419, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9681 - val_loss: 0.1242 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 710/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0942 - accuracy: 0.9683\n",
      "Epoch 710: val_loss improved from 0.12419 to 0.12415, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9681 - val_loss: 0.1241 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 711/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0890 - accuracy: 0.9690\n",
      "Epoch 711: val_loss improved from 0.12415 to 0.12410, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9681 - val_loss: 0.1241 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 712/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0973 - accuracy: 0.9690\n",
      "Epoch 712: val_loss improved from 0.12410 to 0.12405, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0912 - accuracy: 0.9681 - val_loss: 0.1241 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 713/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0876 - accuracy: 0.9741\n",
      "Epoch 713: val_loss improved from 0.12405 to 0.12401, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9681 - val_loss: 0.1240 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 714/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0940 - accuracy: 0.9697\n",
      "Epoch 714: val_loss did not improve from 0.12401\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9681 - val_loss: 0.1240 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 715/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0903 - accuracy: 0.9729\n",
      "Epoch 715: val_loss improved from 0.12401 to 0.12398, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9681 - val_loss: 0.1240 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 716/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0889 - accuracy: 0.9767\n",
      "Epoch 716: val_loss improved from 0.12398 to 0.12394, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0907 - accuracy: 0.9681 - val_loss: 0.1239 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 717/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0940 - accuracy: 0.9690\n",
      "Epoch 717: val_loss improved from 0.12394 to 0.12393, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9681 - val_loss: 0.1239 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 718/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0916 - accuracy: 0.9673\n",
      "Epoch 718: val_loss improved from 0.12393 to 0.12389, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9681 - val_loss: 0.1239 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 719/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0938 - accuracy: 0.9675\n",
      "Epoch 719: val_loss improved from 0.12389 to 0.12386, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0904 - accuracy: 0.9681 - val_loss: 0.1239 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 720/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0850 - accuracy: 0.9735\n",
      "Epoch 720: val_loss improved from 0.12386 to 0.12382, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9681 - val_loss: 0.1238 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 721/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0831 - accuracy: 0.9729\n",
      "Epoch 721: val_loss improved from 0.12382 to 0.12378, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9681 - val_loss: 0.1238 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 722/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0956 - accuracy: 0.9667\n",
      "Epoch 722: val_loss improved from 0.12378 to 0.12372, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9681 - val_loss: 0.1237 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 723/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0847 - accuracy: 0.9715\n",
      "Epoch 723: val_loss improved from 0.12372 to 0.12368, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9681 - val_loss: 0.1237 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 724/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0953 - accuracy: 0.9651\n",
      "Epoch 724: val_loss improved from 0.12368 to 0.12364, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9681 - val_loss: 0.1236 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 725/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0918 - accuracy: 0.9683\n",
      "Epoch 725: val_loss improved from 0.12364 to 0.12359, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0898 - accuracy: 0.9681 - val_loss: 0.1236 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 726/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0898 - accuracy: 0.9735\n",
      "Epoch 726: val_loss improved from 0.12359 to 0.12355, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0897 - accuracy: 0.9681 - val_loss: 0.1236 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 727/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0980 - accuracy: 0.9621\n",
      "Epoch 727: val_loss improved from 0.12355 to 0.12351, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.1235 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 728/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0997 - accuracy: 0.9634\n",
      "Epoch 728: val_loss did not improve from 0.12351\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9681 - val_loss: 0.1236 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 729/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0905 - accuracy: 0.9690\n",
      "Epoch 729: val_loss did not improve from 0.12351\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9681 - val_loss: 0.1236 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 730/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.1004 - accuracy: 0.9621\n",
      "Epoch 730: val_loss did not improve from 0.12351\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9681 - val_loss: 0.1235 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 731/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0900 - accuracy: 0.9634\n",
      "Epoch 731: val_loss improved from 0.12351 to 0.12349, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.1235 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 732/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0976 - accuracy: 0.9621\n",
      "Epoch 732: val_loss improved from 0.12349 to 0.12345, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9681 - val_loss: 0.1235 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 733/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0963 - accuracy: 0.9630\n",
      "Epoch 733: val_loss improved from 0.12345 to 0.12341, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9681 - val_loss: 0.1234 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 734/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0871 - accuracy: 0.9683\n",
      "Epoch 734: val_loss improved from 0.12341 to 0.12337, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9681 - val_loss: 0.1234 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 735/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0876 - accuracy: 0.9643\n",
      "Epoch 735: val_loss improved from 0.12337 to 0.12333, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9681 - val_loss: 0.1233 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 736/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0784 - accuracy: 0.9735\n",
      "Epoch 736: val_loss improved from 0.12333 to 0.12328, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9681 - val_loss: 0.1233 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 737/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0947 - accuracy: 0.9683\n",
      "Epoch 737: val_loss improved from 0.12328 to 0.12325, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.9681 - val_loss: 0.1232 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 738/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0977 - accuracy: 0.9675\n",
      "Epoch 738: val_loss improved from 0.12325 to 0.12320, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9712 - val_loss: 0.1232 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 739/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0890 - accuracy: 0.9683\n",
      "Epoch 739: val_loss improved from 0.12320 to 0.12316, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9681 - val_loss: 0.1232 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 740/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0865 - accuracy: 0.9690\n",
      "Epoch 740: val_loss improved from 0.12316 to 0.12307, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9712 - val_loss: 0.1231 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 741/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0910 - accuracy: 0.9700\n",
      "Epoch 741: val_loss improved from 0.12307 to 0.12302, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0881 - accuracy: 0.9712 - val_loss: 0.1230 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 742/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0836 - accuracy: 0.9729\n",
      "Epoch 742: val_loss did not improve from 0.12302\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9712 - val_loss: 0.1231 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 743/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0725 - accuracy: 0.9875\n",
      "Epoch 743: val_loss did not improve from 0.12302\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9744 - val_loss: 0.1231 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 744/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0987 - accuracy: 0.9683\n",
      "Epoch 744: val_loss improved from 0.12302 to 0.12302, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9744 - val_loss: 0.1230 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 745/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0812 - accuracy: 0.9715\n",
      "Epoch 745: val_loss improved from 0.12302 to 0.12297, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9744 - val_loss: 0.1230 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 746/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 0.9744\n",
      "Epoch 746: val_loss improved from 0.12297 to 0.12292, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9744 - val_loss: 0.1229 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 747/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.0896 - accuracy: 0.9722\n",
      "Epoch 747: val_loss improved from 0.12292 to 0.12288, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0876 - accuracy: 0.9744 - val_loss: 0.1229 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 748/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0890 - accuracy: 0.9739\n",
      "Epoch 748: val_loss improved from 0.12288 to 0.12284, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9744 - val_loss: 0.1228 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 749/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9744\n",
      "Epoch 749: val_loss improved from 0.12284 to 0.12279, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9744 - val_loss: 0.1228 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 750/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0769 - accuracy: 0.9797\n",
      "Epoch 750: val_loss improved from 0.12279 to 0.12275, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9744 - val_loss: 0.1228 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 751/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9744\n",
      "Epoch 751: val_loss improved from 0.12275 to 0.12273, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0871 - accuracy: 0.9744 - val_loss: 0.1227 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 752/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0883 - accuracy: 0.9739\n",
      "Epoch 752: val_loss improved from 0.12273 to 0.12269, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9744 - val_loss: 0.1227 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 753/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0845 - accuracy: 0.9739\n",
      "Epoch 753: val_loss improved from 0.12269 to 0.12263, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9744 - val_loss: 0.1226 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 754/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0885 - accuracy: 0.9739\n",
      "Epoch 754: val_loss improved from 0.12263 to 0.12259, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9744 - val_loss: 0.1226 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 755/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0855 - accuracy: 0.9722\n",
      "Epoch 755: val_loss improved from 0.12259 to 0.12255, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9744 - val_loss: 0.1226 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 756/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0880 - accuracy: 0.9739\n",
      "Epoch 756: val_loss improved from 0.12255 to 0.12251, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9744 - val_loss: 0.1225 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 757/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0863 - accuracy: 0.9729\n",
      "Epoch 757: val_loss improved from 0.12251 to 0.12242, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9744 - val_loss: 0.1224 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 758/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0875 - accuracy: 0.9739\n",
      "Epoch 758: val_loss improved from 0.12242 to 0.12239, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9744 - val_loss: 0.1224 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 759/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0985 - accuracy: 0.9690\n",
      "Epoch 759: val_loss improved from 0.12239 to 0.12225, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9744 - val_loss: 0.1222 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 760/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0863 - accuracy: 0.9739\n",
      "Epoch 760: val_loss did not improve from 0.12225\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9744 - val_loss: 0.1223 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 761/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 0.9744\n",
      "Epoch 761: val_loss improved from 0.12225 to 0.12223, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9744 - val_loss: 0.1222 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 762/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0895 - accuracy: 0.9756\n",
      "Epoch 762: val_loss improved from 0.12223 to 0.12219, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9744 - val_loss: 0.1222 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 763/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0845 - accuracy: 0.9767\n",
      "Epoch 763: val_loss improved from 0.12219 to 0.12215, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9744 - val_loss: 0.1222 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 764/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0951 - accuracy: 0.9675\n",
      "Epoch 764: val_loss improved from 0.12215 to 0.12212, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9744 - val_loss: 0.1221 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 765/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0887 - accuracy: 0.9733\n",
      "Epoch 765: val_loss improved from 0.12212 to 0.12209, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9744 - val_loss: 0.1221 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 766/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0699 - accuracy: 0.9756\n",
      "Epoch 766: val_loss improved from 0.12209 to 0.12209, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9744 - val_loss: 0.1221 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 767/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0870 - accuracy: 0.9733\n",
      "Epoch 767: val_loss improved from 0.12209 to 0.12204, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0856 - accuracy: 0.9744 - val_loss: 0.1220 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9744\n",
      "Epoch 768: val_loss improved from 0.12204 to 0.12201, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9744 - val_loss: 0.1220 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 769/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0768 - accuracy: 0.9767\n",
      "Epoch 769: val_loss improved from 0.12201 to 0.12196, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0854 - accuracy: 0.9744 - val_loss: 0.1220 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 770/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0864 - accuracy: 0.9722\n",
      "Epoch 770: val_loss improved from 0.12196 to 0.12193, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0853 - accuracy: 0.9744 - val_loss: 0.1219 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9744\n",
      "Epoch 771: val_loss improved from 0.12193 to 0.12189, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0852 - accuracy: 0.9744 - val_loss: 0.1219 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 772/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0869 - accuracy: 0.9752\n",
      "Epoch 772: val_loss improved from 0.12189 to 0.12186, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0851 - accuracy: 0.9744 - val_loss: 0.1219 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 773/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0799 - accuracy: 0.9762\n",
      "Epoch 773: val_loss improved from 0.12186 to 0.12183, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0850 - accuracy: 0.9744 - val_loss: 0.1218 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 774/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0840 - accuracy: 0.9767\n",
      "Epoch 774: val_loss improved from 0.12183 to 0.12170, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9744 - val_loss: 0.1217 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 775/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0785 - accuracy: 0.9796\n",
      "Epoch 775: val_loss improved from 0.12170 to 0.12166, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 0.9776 - val_loss: 0.1217 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 776/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0846 - accuracy: 0.9767\n",
      "Epoch 776: val_loss improved from 0.12166 to 0.12163, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9776 - val_loss: 0.1216 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 777/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0864 - accuracy: 0.9771\n",
      "Epoch 777: val_loss improved from 0.12163 to 0.12160, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9776 - val_loss: 0.1216 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 778/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0823 - accuracy: 0.9792\n",
      "Epoch 778: val_loss improved from 0.12160 to 0.12156, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9776 - val_loss: 0.1216 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 779/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0871 - accuracy: 0.9787\n",
      "Epoch 779: val_loss improved from 0.12156 to 0.12153, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0844 - accuracy: 0.9776 - val_loss: 0.1215 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 780/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0923 - accuracy: 0.9767\n",
      "Epoch 780: val_loss improved from 0.12153 to 0.12150, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9776 - val_loss: 0.1215 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 781/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0766 - accuracy: 0.9833\n",
      "Epoch 781: val_loss improved from 0.12150 to 0.12147, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9776 - val_loss: 0.1215 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 782/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0849 - accuracy: 0.9771\n",
      "Epoch 782: val_loss improved from 0.12147 to 0.12145, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9776 - val_loss: 0.1214 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 783/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0914 - accuracy: 0.9797\n",
      "Epoch 783: val_loss improved from 0.12145 to 0.12141, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0841 - accuracy: 0.9776 - val_loss: 0.1214 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 784/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9776\n",
      "Epoch 784: val_loss improved from 0.12141 to 0.12138, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9776 - val_loss: 0.1214 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 785/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0853 - accuracy: 0.9771\n",
      "Epoch 785: val_loss improved from 0.12138 to 0.12136, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9776 - val_loss: 0.1214 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9776\n",
      "Epoch 786: val_loss improved from 0.12136 to 0.12127, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9776 - val_loss: 0.1213 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9776\n",
      "Epoch 787: val_loss improved from 0.12127 to 0.12123, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9776 - val_loss: 0.1212 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 788/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0880 - accuracy: 0.9756\n",
      "Epoch 788: val_loss improved from 0.12123 to 0.12120, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9776 - val_loss: 0.1212 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 789/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0906 - accuracy: 0.9708\n",
      "Epoch 789: val_loss improved from 0.12120 to 0.12117, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0835 - accuracy: 0.9776 - val_loss: 0.1212 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 790/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0848 - accuracy: 0.9762\n",
      "Epoch 790: val_loss improved from 0.12117 to 0.12114, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9776 - val_loss: 0.1211 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 791/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9776\n",
      "Epoch 791: val_loss improved from 0.12114 to 0.12112, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9776 - val_loss: 0.1211 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 792/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.0789 - accuracy: 0.9792\n",
      "Epoch 792: val_loss improved from 0.12112 to 0.12108, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0833 - accuracy: 0.9776 - val_loss: 0.1211 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 793/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0728 - accuracy: 0.9878\n",
      "Epoch 793: val_loss improved from 0.12108 to 0.12106, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9776 - val_loss: 0.1211 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 794/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0819 - accuracy: 0.9800\n",
      "Epoch 794: val_loss improved from 0.12106 to 0.12103, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9776 - val_loss: 0.1210 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9776\n",
      "Epoch 795: val_loss improved from 0.12103 to 0.12101, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9776 - val_loss: 0.1210 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 796/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.0719 - accuracy: 0.9826\n",
      "Epoch 796: val_loss improved from 0.12101 to 0.12098, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9776 - val_loss: 0.1210 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 797/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9776\n",
      "Epoch 797: val_loss improved from 0.12098 to 0.12095, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9776 - val_loss: 0.1209 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9776\n",
      "Epoch 798: val_loss improved from 0.12095 to 0.12092, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9776 - val_loss: 0.1209 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9776\n",
      "Epoch 799: val_loss improved from 0.12092 to 0.12089, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0826 - accuracy: 0.9776 - val_loss: 0.1209 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 800/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0599 - accuracy: 0.9881\n",
      "Epoch 800: val_loss improved from 0.12089 to 0.12086, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9776 - val_loss: 0.1209 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 801/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0853 - accuracy: 0.9767\n",
      "Epoch 801: val_loss improved from 0.12086 to 0.12084, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9776 - val_loss: 0.1208 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9776\n",
      "Epoch 802: val_loss improved from 0.12084 to 0.12081, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9776 - val_loss: 0.1208 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 803/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0798 - accuracy: 0.9767\n",
      "Epoch 803: val_loss improved from 0.12081 to 0.12077, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9776 - val_loss: 0.1208 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 804/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.0820 - accuracy: 0.9792\n",
      "Epoch 804: val_loss improved from 0.12077 to 0.12074, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: 0.1207 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9776\n",
      "Epoch 805: val_loss improved from 0.12074 to 0.12061, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9776 - val_loss: 0.1206 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 806/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0835 - accuracy: 0.9771\n",
      "Epoch 806: val_loss improved from 0.12061 to 0.12059, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9776 - val_loss: 0.1206 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 807/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0850 - accuracy: 0.9767\n",
      "Epoch 807: val_loss improved from 0.12059 to 0.12057, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9776 - val_loss: 0.1206 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 808/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0741 - accuracy: 0.9837\n",
      "Epoch 808: val_loss improved from 0.12057 to 0.12054, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9776 - val_loss: 0.1205 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 809/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0839 - accuracy: 0.9797\n",
      "Epoch 809: val_loss improved from 0.12054 to 0.12051, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9776 - val_loss: 0.1205 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 810/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0893 - accuracy: 0.9797\n",
      "Epoch 810: val_loss improved from 0.12051 to 0.12048, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9808 - val_loss: 0.1205 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 811/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0839 - accuracy: 0.9800\n",
      "Epoch 811: val_loss improved from 0.12048 to 0.12045, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 812/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0735 - accuracy: 0.9845\n",
      "Epoch 812: val_loss improved from 0.12045 to 0.12042, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 813/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0827 - accuracy: 0.9804\n",
      "Epoch 813: val_loss improved from 0.12042 to 0.12040, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 814/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0793 - accuracy: 0.9806\n",
      "Epoch 814: val_loss improved from 0.12040 to 0.12038, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 815/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0629 - accuracy: 0.9837\n",
      "Epoch 815: val_loss improved from 0.12038 to 0.12036, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9808\n",
      "Epoch 816: val_loss improved from 0.12036 to 0.12033, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 817/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0636 - accuracy: 0.9884\n",
      "Epoch 817: val_loss did not improve from 0.12033\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 818/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0835 - accuracy: 0.9797\n",
      "Epoch 818: val_loss did not improve from 0.12033\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 819/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0908 - accuracy: 0.9767\n",
      "Epoch 819: val_loss did not improve from 0.12033\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9808\n",
      "Epoch 820: val_loss improved from 0.12033 to 0.12031, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 821/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0848 - accuracy: 0.9833\n",
      "Epoch 821: val_loss improved from 0.12031 to 0.12028, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 822/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0781 - accuracy: 0.9802\n",
      "Epoch 822: val_loss did not improve from 0.12028\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 823/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0767 - accuracy: 0.9815\n",
      "Epoch 823: val_loss did not improve from 0.12028\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 824/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0735 - accuracy: 0.9845\n",
      "Epoch 824: val_loss did not improve from 0.12028\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 825/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0866 - accuracy: 0.9767\n",
      "Epoch 825: val_loss did not improve from 0.12028\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 826/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0698 - accuracy: 0.9797\n",
      "Epoch 826: val_loss did not improve from 0.12028\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 827/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0841 - accuracy: 0.9797\n",
      "Epoch 827: val_loss improved from 0.12028 to 0.12027, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 828/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9808\n",
      "Epoch 828: val_loss improved from 0.12027 to 0.12023, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9808 - val_loss: 0.1202 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 829/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0648 - accuracy: 0.9881\n",
      "Epoch 829: val_loss improved from 0.12023 to 0.12020, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9808 - val_loss: 0.1202 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 830/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0911 - accuracy: 0.9762\n",
      "Epoch 830: val_loss improved from 0.12020 to 0.12017, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9808 - val_loss: 0.1202 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 831/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0704 - accuracy: 0.9837\n",
      "Epoch 831: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9808 - val_loss: 0.1205 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 832/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0896 - accuracy: 0.9762\n",
      "Epoch 832: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 833/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0746 - accuracy: 0.9878\n",
      "Epoch 833: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 834/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0772 - accuracy: 0.9845\n",
      "Epoch 834: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9808 - val_loss: 0.1204 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 835/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0549 - accuracy: 0.9921\n",
      "Epoch 835: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 836/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0910 - accuracy: 0.9756\n",
      "Epoch 836: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9808 - val_loss: 0.1203 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 837/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0731 - accuracy: 0.9841\n",
      "Epoch 837: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9808 - val_loss: 0.1202 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 838/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9808\n",
      "Epoch 838: val_loss did not improve from 0.12017\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9808 - val_loss: 0.1202 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9808\n",
      "Epoch 839: val_loss improved from 0.12017 to 0.12008, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9808 - val_loss: 0.1201 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 840/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0896 - accuracy: 0.9750\n",
      "Epoch 840: val_loss improved from 0.12008 to 0.12005, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9808 - val_loss: 0.1201 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 841/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0945 - accuracy: 0.9756\n",
      "Epoch 841: val_loss improved from 0.12005 to 0.12001, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9808 - val_loss: 0.1200 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 842/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0870 - accuracy: 0.9767\n",
      "Epoch 842: val_loss improved from 0.12001 to 0.11998, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9808 - val_loss: 0.1200 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9808\n",
      "Epoch 843: val_loss improved from 0.11998 to 0.11995, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9808 - val_loss: 0.1200 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 844/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0873 - accuracy: 0.9762\n",
      "Epoch 844: val_loss improved from 0.11995 to 0.11992, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9808 - val_loss: 0.1199 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 845/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0900 - accuracy: 0.9762\n",
      "Epoch 845: val_loss improved from 0.11992 to 0.11989, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9808 - val_loss: 0.1199 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 846/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0654 - accuracy: 0.9867\n",
      "Epoch 846: val_loss improved from 0.11989 to 0.11987, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9808 - val_loss: 0.1199 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 847/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0813 - accuracy: 0.9800\n",
      "Epoch 847: val_loss improved from 0.11987 to 0.11984, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9808 - val_loss: 0.1198 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 848/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0736 - accuracy: 0.9802\n",
      "Epoch 848: val_loss did not improve from 0.11984\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9808 - val_loss: 0.1199 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9808\n",
      "Epoch 849: val_loss improved from 0.11984 to 0.11979, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9808 - val_loss: 0.1198 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 850/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0866 - accuracy: 0.9797\n",
      "Epoch 850: val_loss improved from 0.11979 to 0.11976, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 0.9808 - val_loss: 0.1198 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9808\n",
      "Epoch 851: val_loss improved from 0.11976 to 0.11973, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9808 - val_loss: 0.1197 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 852/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0696 - accuracy: 0.9806\n",
      "Epoch 852: val_loss improved from 0.11973 to 0.11969, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9808 - val_loss: 0.1197 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 853/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0829 - accuracy: 0.9806\n",
      "Epoch 853: val_loss improved from 0.11969 to 0.11966, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9808 - val_loss: 0.1197 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 854/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0788 - accuracy: 0.9804\n",
      "Epoch 854: val_loss improved from 0.11966 to 0.11963, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9808 - val_loss: 0.1196 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 855/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0595 - accuracy: 0.9881\n",
      "Epoch 855: val_loss improved from 0.11963 to 0.11959, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9808 - val_loss: 0.1196 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 856/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0725 - accuracy: 0.9837\n",
      "Epoch 856: val_loss improved from 0.11959 to 0.11957, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9808 - val_loss: 0.1196 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 857/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0770 - accuracy: 0.9833\n",
      "Epoch 857: val_loss improved from 0.11957 to 0.11954, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9808 - val_loss: 0.1195 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9808\n",
      "Epoch 858: val_loss improved from 0.11954 to 0.11951, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9808 - val_loss: 0.1195 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 859/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0794 - accuracy: 0.9833\n",
      "Epoch 859: val_loss improved from 0.11951 to 0.11948, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9808 - val_loss: 0.1195 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9808\n",
      "Epoch 860: val_loss improved from 0.11948 to 0.11945, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9808 - val_loss: 0.1195 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 861/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9808\n",
      "Epoch 861: val_loss improved from 0.11945 to 0.11932, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 0.9808 - val_loss: 0.1193 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 862/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0622 - accuracy: 0.9878\n",
      "Epoch 862: val_loss improved from 0.11932 to 0.11928, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9808 - val_loss: 0.1193 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 863/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0788 - accuracy: 0.9797\n",
      "Epoch 863: val_loss improved from 0.11928 to 0.11926, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9808 - val_loss: 0.1193 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 864/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0895 - accuracy: 0.9750\n",
      "Epoch 864: val_loss improved from 0.11926 to 0.11923, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9808 - val_loss: 0.1192 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 865/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0774 - accuracy: 0.9800\n",
      "Epoch 865: val_loss improved from 0.11923 to 0.11921, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9808 - val_loss: 0.1192 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 866/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0844 - accuracy: 0.9802\n",
      "Epoch 866: val_loss improved from 0.11921 to 0.11919, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9808 - val_loss: 0.1192 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 867/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0672 - accuracy: 0.9802\n",
      "Epoch 867: val_loss improved from 0.11919 to 0.11917, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9808 - val_loss: 0.1192 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 868/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0855 - accuracy: 0.9750\n",
      "Epoch 868: val_loss improved from 0.11917 to 0.11914, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 869/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0845 - accuracy: 0.9797\n",
      "Epoch 869: val_loss improved from 0.11914 to 0.11912, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 870/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9808\n",
      "Epoch 870: val_loss improved from 0.11912 to 0.11910, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 871/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0600 - accuracy: 0.9878\n",
      "Epoch 871: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9808 - val_loss: 0.1193 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 872/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0808 - accuracy: 0.9802\n",
      "Epoch 872: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9808 - val_loss: 0.1193 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 873/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0791 - accuracy: 0.9800\n",
      "Epoch 873: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9808 - val_loss: 0.1193 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 874/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0849 - accuracy: 0.9756\n",
      "Epoch 874: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9808 - val_loss: 0.1192 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 875/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0872 - accuracy: 0.9762\n",
      "Epoch 875: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9808 - val_loss: 0.1192 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 876/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9808\n",
      "Epoch 876: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9808 - val_loss: 0.1192 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 877/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0769 - accuracy: 0.9806\n",
      "Epoch 877: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9808\n",
      "Epoch 878: val_loss did not improve from 0.11910\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 879/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0776 - accuracy: 0.9800\n",
      "Epoch 879: val_loss improved from 0.11910 to 0.11908, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 880/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0783 - accuracy: 0.9802\n",
      "Epoch 880: val_loss did not improve from 0.11908\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9808\n",
      "Epoch 881: val_loss did not improve from 0.11908\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 882/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0811 - accuracy: 0.9797\n",
      "Epoch 882: val_loss improved from 0.11908 to 0.11906, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9808 - val_loss: 0.1191 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 883/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0751 - accuracy: 0.9797\n",
      "Epoch 883: val_loss improved from 0.11906 to 0.11903, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9808 - val_loss: 0.1190 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9808\n",
      "Epoch 884: val_loss improved from 0.11903 to 0.11900, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9808 - val_loss: 0.1190 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 885/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0734 - accuracy: 0.9806\n",
      "Epoch 885: val_loss improved from 0.11900 to 0.11893, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9808 - val_loss: 0.1189 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 886/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0775 - accuracy: 0.9837\n",
      "Epoch 886: val_loss improved from 0.11893 to 0.11890, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9808 - val_loss: 0.1189 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 887/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0644 - accuracy: 0.9837\n",
      "Epoch 887: val_loss improved from 0.11890 to 0.11884, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9808 - val_loss: 0.1188 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 888/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0778 - accuracy: 0.9800\n",
      "Epoch 888: val_loss improved from 0.11884 to 0.11881, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0754 - accuracy: 0.9808 - val_loss: 0.1188 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 889/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0760 - accuracy: 0.9804\n",
      "Epoch 889: val_loss improved from 0.11881 to 0.11879, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0753 - accuracy: 0.9808 - val_loss: 0.1188 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 890/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0766 - accuracy: 0.9800\n",
      "Epoch 890: val_loss did not improve from 0.11879\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9808 - val_loss: 0.1188 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 891/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0861 - accuracy: 0.9762\n",
      "Epoch 891: val_loss improved from 0.11879 to 0.11877, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.1188 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 892/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0815 - accuracy: 0.9802\n",
      "Epoch 892: val_loss improved from 0.11877 to 0.11874, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.1187 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 893/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0824 - accuracy: 0.9802\n",
      "Epoch 893: val_loss improved from 0.11874 to 0.11869, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9808 - val_loss: 0.1187 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 894/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0780 - accuracy: 0.9845\n",
      "Epoch 894: val_loss improved from 0.11869 to 0.11867, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9808 - val_loss: 0.1187 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 895/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0840 - accuracy: 0.9773\n",
      "Epoch 895: val_loss improved from 0.11867 to 0.11863, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9808 - val_loss: 0.1186 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 896/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0632 - accuracy: 0.9833\n",
      "Epoch 896: val_loss improved from 0.11863 to 0.11861, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9808 - val_loss: 0.1186 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 897/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0725 - accuracy: 0.9852\n",
      "Epoch 897: val_loss improved from 0.11861 to 0.11859, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9808 - val_loss: 0.1186 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 898/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0648 - accuracy: 0.9837\n",
      "Epoch 898: val_loss improved from 0.11859 to 0.11856, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9808 - val_loss: 0.1186 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 899/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0514 - accuracy: 0.9878\n",
      "Epoch 899: val_loss improved from 0.11856 to 0.11853, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9808 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 900/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0858 - accuracy: 0.9756\n",
      "Epoch 900: val_loss improved from 0.11853 to 0.11851, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9808 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 901/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9808\n",
      "Epoch 901: val_loss did not improve from 0.11851\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9808 - val_loss: 0.1186 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 902/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0840 - accuracy: 0.9762\n",
      "Epoch 902: val_loss did not improve from 0.11851\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9808 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 903/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0731 - accuracy: 0.9802\n",
      "Epoch 903: val_loss did not improve from 0.11851\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9808 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 904/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0743 - accuracy: 0.9804\n",
      "Epoch 904: val_loss improved from 0.11851 to 0.11849, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9808 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 905/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0683 - accuracy: 0.9802\n",
      "Epoch 905: val_loss improved from 0.11849 to 0.11846, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9808 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 906/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0834 - accuracy: 0.9797\n",
      "Epoch 906: val_loss did not improve from 0.11846\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9808 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9808\n",
      "Epoch 907: val_loss improved from 0.11846 to 0.11844, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0740 - accuracy: 0.9808 - val_loss: 0.1184 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 908/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0722 - accuracy: 0.9830\n",
      "Epoch 908: val_loss improved from 0.11844 to 0.11841, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9808 - val_loss: 0.1184 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 909/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0854 - accuracy: 0.9756\n",
      "Epoch 909: val_loss improved from 0.11841 to 0.11839, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9808 - val_loss: 0.1184 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 910/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0728 - accuracy: 0.9833\n",
      "Epoch 910: val_loss improved from 0.11839 to 0.11836, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9808 - val_loss: 0.1184 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 911/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0751 - accuracy: 0.9800\n",
      "Epoch 911: val_loss improved from 0.11836 to 0.11834, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9808 - val_loss: 0.1183 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 912/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0715 - accuracy: 0.9837\n",
      "Epoch 912: val_loss improved from 0.11834 to 0.11832, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9808 - val_loss: 0.1183 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 913/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0746 - accuracy: 0.9804\n",
      "Epoch 913: val_loss improved from 0.11832 to 0.11829, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9808 - val_loss: 0.1183 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 914/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0721 - accuracy: 0.9804\n",
      "Epoch 914: val_loss did not improve from 0.11829\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9808 - val_loss: 0.1183 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 915/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9808\n",
      "Epoch 915: val_loss did not improve from 0.11829\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9808 - val_loss: 0.1183 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9808\n",
      "Epoch 916: val_loss improved from 0.11829 to 0.11827, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0733 - accuracy: 0.9808 - val_loss: 0.1183 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 917/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.0794 - accuracy: 0.9783\n",
      "Epoch 917: val_loss improved from 0.11827 to 0.11825, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0733 - accuracy: 0.9808 - val_loss: 0.1182 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 918/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0725 - accuracy: 0.9804\n",
      "Epoch 918: val_loss improved from 0.11825 to 0.11823, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0732 - accuracy: 0.9808 - val_loss: 0.1182 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 919/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0741 - accuracy: 0.9797\n",
      "Epoch 919: val_loss improved from 0.11823 to 0.11820, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9808 - val_loss: 0.1182 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 920/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0738 - accuracy: 0.9804\n",
      "Epoch 920: val_loss improved from 0.11820 to 0.11818, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9808 - val_loss: 0.1182 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 921/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0779 - accuracy: 0.9802\n",
      "Epoch 921: val_loss improved from 0.11818 to 0.11815, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9808 - val_loss: 0.1181 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9808\n",
      "Epoch 922: val_loss improved from 0.11815 to 0.11813, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9808 - val_loss: 0.1181 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 923/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0753 - accuracy: 0.9800\n",
      "Epoch 923: val_loss improved from 0.11813 to 0.11807, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9808 - val_loss: 0.1181 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9808\n",
      "Epoch 924: val_loss improved from 0.11807 to 0.11803, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9808 - val_loss: 0.1180 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 925/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0802 - accuracy: 0.9797\n",
      "Epoch 925: val_loss improved from 0.11803 to 0.11801, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9808 - val_loss: 0.1180 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 926/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0750 - accuracy: 0.9796\n",
      "Epoch 926: val_loss improved from 0.11801 to 0.11798, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9808 - val_loss: 0.1180 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 927/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9808\n",
      "Epoch 927: val_loss improved from 0.11798 to 0.11796, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9808 - val_loss: 0.1180 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 928/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.0696 - accuracy: 0.9819\n",
      "Epoch 928: val_loss improved from 0.11796 to 0.11795, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0725 - accuracy: 0.9808 - val_loss: 0.1180 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 929/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0747 - accuracy: 0.9800\n",
      "Epoch 929: val_loss improved from 0.11795 to 0.11794, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9808 - val_loss: 0.1179 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 930/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0769 - accuracy: 0.9787\n",
      "Epoch 930: val_loss improved from 0.11794 to 0.11791, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9808 - val_loss: 0.1179 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 931/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0711 - accuracy: 0.9830\n",
      "Epoch 931: val_loss improved from 0.11791 to 0.11789, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0723 - accuracy: 0.9808 - val_loss: 0.1179 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 932/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0804 - accuracy: 0.9773\n",
      "Epoch 932: val_loss improved from 0.11789 to 0.11784, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9808 - val_loss: 0.1178 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9808\n",
      "Epoch 933: val_loss improved from 0.11784 to 0.11783, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9808 - val_loss: 0.1178 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 934/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9808\n",
      "Epoch 934: val_loss improved from 0.11783 to 0.11782, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9808 - val_loss: 0.1178 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9808\n",
      "Epoch 935: val_loss improved from 0.11782 to 0.11779, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9808 - val_loss: 0.1178 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 936/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0768 - accuracy: 0.9837\n",
      "Epoch 936: val_loss improved from 0.11779 to 0.11778, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9808 - val_loss: 0.1178 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 937/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0633 - accuracy: 0.9833\n",
      "Epoch 937: val_loss improved from 0.11778 to 0.11777, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9808 - val_loss: 0.1178 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 938/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0694 - accuracy: 0.9845\n",
      "Epoch 938: val_loss improved from 0.11777 to 0.11774, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9808 - val_loss: 0.1177 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9808\n",
      "Epoch 939: val_loss improved from 0.11774 to 0.11772, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9808 - val_loss: 0.1177 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 940/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.0760 - accuracy: 0.9792\n",
      "Epoch 940: val_loss improved from 0.11772 to 0.11771, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9808 - val_loss: 0.1177 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 941/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0691 - accuracy: 0.9823\n",
      "Epoch 941: val_loss improved from 0.11771 to 0.11769, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9808 - val_loss: 0.1177 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 942/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0703 - accuracy: 0.9833\n",
      "Epoch 942: val_loss improved from 0.11769 to 0.11767, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9808 - val_loss: 0.1177 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 943/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0726 - accuracy: 0.9806\n",
      "Epoch 943: val_loss improved from 0.11767 to 0.11766, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9808 - val_loss: 0.1177 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 944/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0726 - accuracy: 0.9804\n",
      "Epoch 944: val_loss improved from 0.11766 to 0.11764, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9808 - val_loss: 0.1176 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 945/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0714 - accuracy: 0.9792\n",
      "Epoch 945: val_loss improved from 0.11764 to 0.11760, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9808 - val_loss: 0.1176 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 946/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0776 - accuracy: 0.9787\n",
      "Epoch 946: val_loss improved from 0.11760 to 0.11758, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9808 - val_loss: 0.1176 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 947/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.0714 - accuracy: 0.9819\n",
      "Epoch 947: val_loss improved from 0.11758 to 0.11757, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9808 - val_loss: 0.1176 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 948/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0647 - accuracy: 0.9837\n",
      "Epoch 948: val_loss improved from 0.11757 to 0.11753, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9808 - val_loss: 0.1175 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 949/1000\n",
      "46/53 [=========================>....] - ETA: 0s - loss: 0.0737 - accuracy: 0.9819\n",
      "Epoch 949: val_loss improved from 0.11753 to 0.11752, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9808 - val_loss: 0.1175 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 950/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0723 - accuracy: 0.9804\n",
      "Epoch 950: val_loss improved from 0.11752 to 0.11749, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9808 - val_loss: 0.1175 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 951/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0713 - accuracy: 0.9804\n",
      "Epoch 951: val_loss improved from 0.11749 to 0.11748, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9808 - val_loss: 0.1175 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 952/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0523 - accuracy: 0.9926\n",
      "Epoch 952: val_loss improved from 0.11748 to 0.11747, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9808 - val_loss: 0.1175 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 953/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0713 - accuracy: 0.9804\n",
      "Epoch 953: val_loss improved from 0.11747 to 0.11746, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9808 - val_loss: 0.1175 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 954/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0595 - accuracy: 0.9833\n",
      "Epoch 954: val_loss improved from 0.11746 to 0.11743, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 955/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 0.9808\n",
      "Epoch 955: val_loss improved from 0.11743 to 0.11742, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0708 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 956/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0719 - accuracy: 0.9800\n",
      "Epoch 956: val_loss improved from 0.11742 to 0.11739, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 957/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0735 - accuracy: 0.9796\n",
      "Epoch 957: val_loss improved from 0.11739 to 0.11739, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 958/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0717 - accuracy: 0.9800\n",
      "Epoch 958: val_loss did not improve from 0.11739\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9808\n",
      "Epoch 959: val_loss improved from 0.11739 to 0.11738, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 960/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0763 - accuracy: 0.9787\n",
      "Epoch 960: val_loss improved from 0.11738 to 0.11736, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 961/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0737 - accuracy: 0.9837\n",
      "Epoch 961: val_loss improved from 0.11736 to 0.11735, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.1174 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 962/1000\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0702 - accuracy: 0.9800\n",
      "Epoch 962: val_loss improved from 0.11735 to 0.11735, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 963/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0723 - accuracy: 0.9806\n",
      "Epoch 963: val_loss improved from 0.11735 to 0.11734, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 964/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0733 - accuracy: 0.9787\n",
      "Epoch 964: val_loss improved from 0.11734 to 0.11733, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 965/1000\n",
      "48/53 [==========================>...] - ETA: 0s - loss: 0.0712 - accuracy: 0.9792\n",
      "Epoch 965: val_loss improved from 0.11733 to 0.11732, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 966/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0747 - accuracy: 0.9787\n",
      "Epoch 966: val_loss improved from 0.11732 to 0.11728, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 967/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0711 - accuracy: 0.9796\n",
      "Epoch 967: val_loss improved from 0.11728 to 0.11727, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 968/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0702 - accuracy: 0.9804\n",
      "Epoch 968: val_loss improved from 0.11727 to 0.11725, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 969/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0726 - accuracy: 0.9796\n",
      "Epoch 969: val_loss improved from 0.11725 to 0.11725, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0698 - accuracy: 0.9808 - val_loss: 0.1172 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 970/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0811 - accuracy: 0.9762\n",
      "Epoch 970: val_loss did not improve from 0.11725\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 971/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0709 - accuracy: 0.9804\n",
      "Epoch 971: val_loss did not improve from 0.11725\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 972/1000\n",
      "49/53 [==========================>...] - ETA: 0s - loss: 0.0601 - accuracy: 0.9830\n",
      "Epoch 972: val_loss did not improve from 0.11725\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 973/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0770 - accuracy: 0.9797\n",
      "Epoch 973: val_loss did not improve from 0.11725\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 974/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9808\n",
      "Epoch 974: val_loss did not improve from 0.11725\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9808 - val_loss: 0.1173 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 975/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 0.9808\n",
      "Epoch 975: val_loss improved from 0.11725 to 0.11724, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.1172 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 976/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0622 - accuracy: 0.9815\n",
      "Epoch 976: val_loss improved from 0.11724 to 0.11723, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.1172 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 977/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0786 - accuracy: 0.9773\n",
      "Epoch 977: val_loss improved from 0.11723 to 0.11719, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0693 - accuracy: 0.9808 - val_loss: 0.1172 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9808\n",
      "Epoch 978: val_loss did not improve from 0.11719\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9808 - val_loss: 0.1172 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 979/1000\n",
      "44/53 [=======================>......] - ETA: 0s - loss: 0.0743 - accuracy: 0.9811\n",
      "Epoch 979: val_loss did not improve from 0.11719\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.9808 - val_loss: 0.1172 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9808\n",
      "Epoch 980: val_loss improved from 0.11719 to 0.11713, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 0.9808 - val_loss: 0.1171 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9808\n",
      "Epoch 981: val_loss improved from 0.11713 to 0.11711, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0691 - accuracy: 0.9808 - val_loss: 0.1171 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 982/1000\n",
      "47/53 [=========================>....] - ETA: 0s - loss: 0.0734 - accuracy: 0.9787\n",
      "Epoch 982: val_loss improved from 0.11711 to 0.11709, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9808 - val_loss: 0.1171 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9808\n",
      "Epoch 983: val_loss improved from 0.11709 to 0.11707, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9808 - val_loss: 0.1171 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9808\n",
      "Epoch 984: val_loss improved from 0.11707 to 0.11706, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9808 - val_loss: 0.1171 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 985/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.9808\n",
      "Epoch 985: val_loss improved from 0.11706 to 0.11704, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0688 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 986/1000\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 0.0575 - accuracy: 0.9837\n",
      "Epoch 986: val_loss improved from 0.11704 to 0.11703, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.0688 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9808\n",
      "Epoch 987: val_loss improved from 0.11703 to 0.11700, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 988/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0566 - accuracy: 0.9884\n",
      "Epoch 988: val_loss improved from 0.11700 to 0.11699, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 989/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0761 - accuracy: 0.9767\n",
      "Epoch 989: val_loss improved from 0.11699 to 0.11697, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 990/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0667 - accuracy: 0.9837\n",
      "Epoch 990: val_loss improved from 0.11697 to 0.11696, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 991/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0570 - accuracy: 0.9845\n",
      "Epoch 991: val_loss did not improve from 0.11696\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 992/1000\n",
      "45/53 [========================>.....] - ETA: 0s - loss: 0.0571 - accuracy: 0.9852\n",
      "Epoch 992: val_loss improved from 0.11696 to 0.11695, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9808 - val_loss: 0.1170 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 993/1000\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9808\n",
      "Epoch 993: val_loss improved from 0.11695 to 0.11694, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9808 - val_loss: 0.1169 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 994/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0590 - accuracy: 0.9837\n",
      "Epoch 994: val_loss improved from 0.11694 to 0.11693, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9808 - val_loss: 0.1169 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 995/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0662 - accuracy: 0.9806\n",
      "Epoch 995: val_loss improved from 0.11693 to 0.11691, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9808 - val_loss: 0.1169 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 996/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0759 - accuracy: 0.9797\n",
      "Epoch 996: val_loss improved from 0.11691 to 0.11690, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9808 - val_loss: 0.1169 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 997/1000\n",
      "43/53 [=======================>......] - ETA: 0s - loss: 0.0748 - accuracy: 0.9767\n",
      "Epoch 997: val_loss improved from 0.11690 to 0.11688, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9808 - val_loss: 0.1169 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 998/1000\n",
      "41/53 [======================>.......] - ETA: 0s - loss: 0.0702 - accuracy: 0.9797\n",
      "Epoch 998: val_loss improved from 0.11688 to 0.11686, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9808 - val_loss: 0.1169 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 999/1000\n",
      "40/53 [=====================>........] - ETA: 0s - loss: 0.0687 - accuracy: 0.9792\n",
      "Epoch 999: val_loss improved from 0.11686 to 0.11685, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9808 - val_loss: 0.1168 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 1000/1000\n",
      "42/53 [======================>.......] - ETA: 0s - loss: 0.0695 - accuracy: 0.9802\n",
      "Epoch 1000: val_loss improved from 0.11685 to 0.11683, saving model to model_checkpoint\\LSTM + GRU_SGD 3.h5\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9808 - val_loss: 0.1168 - val_accuracy: 0.9702 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, None, 32)          15232     \n",
      "                                                                 \n",
      " gru_10 (GRU)                (None, 32)                6336      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,601\n",
      "Trainable params: 21,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.9702\n",
      "Test Loss: 0.1168321967124939\n",
      "Test Accuracy: 0.9702380895614624\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'LSTM + GRU_SGD.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Definition of the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,input_shape=(None, x_train.shape[-1])))\n",
    "model.add(layers.GRU(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a SGD optimizer with an exponential decaying learning rate\n",
    "optimizer, lr_schedule = optimizer_SGD(0.001, 1000, 0.1)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training of the model\n",
    "history = model.fit(x_train, y_train, batch_size=6, epochs=1000, validation_data=(x_val, y_val), callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule),callbacks_list])\n",
    "\n",
    "plot_2(history)\n",
    "\n",
    "# Evaluation of the model on the testing set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM + GRU K FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing GRU with K-fold\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67037, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67037 to 0.66491, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.66491 to 0.65949, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.65949 to 0.65410, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.65410 to 0.64870, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.64870 to 0.64327, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.64327 to 0.63779, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.63779 to 0.63225, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.63225 to 0.62670, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.62670 to 0.62115, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.62115 to 0.61563, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.61563 to 0.61012, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.61012 to 0.60463, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.60463 to 0.59916, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.59916 to 0.59369, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.59369 to 0.58822, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.58822 to 0.58275, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.58275 to 0.57728, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.57728 to 0.57180, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.57180 to 0.56631, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.56631 to 0.56081, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.56081 to 0.55531, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.55531 to 0.54980, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.54980 to 0.54430, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.54430 to 0.53880, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.53880 to 0.53332, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.53332 to 0.52787, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.52787 to 0.52244, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.52244 to 0.51705, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.51705 to 0.51170, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.51170 to 0.50641, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.50641 to 0.50118, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.50118 to 0.49601, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.49601 to 0.49093, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.49093 to 0.48594, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.48594 to 0.48103, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.48103 to 0.47622, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.47622 to 0.47151, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.47151 to 0.46688, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.46688 to 0.46235, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.46235 to 0.45791, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 42: val_loss improved from 0.45791 to 0.45358, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 43: val_loss improved from 0.45358 to 0.44934, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 44: val_loss improved from 0.44934 to 0.44522, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.44522 to 0.44120, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 46: val_loss improved from 0.44120 to 0.43728, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.43728 to 0.43345, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 48: val_loss improved from 0.43345 to 0.42974, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 49: val_loss improved from 0.42974 to 0.42612, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 50: val_loss improved from 0.42612 to 0.42260, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 51: val_loss improved from 0.42260 to 0.41918, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 52: val_loss improved from 0.41918 to 0.41585, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 53: val_loss improved from 0.41585 to 0.41263, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 54: val_loss improved from 0.41263 to 0.40949, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 55: val_loss improved from 0.40949 to 0.40645, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 56: val_loss improved from 0.40645 to 0.40349, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 57: val_loss improved from 0.40349 to 0.40062, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 58: val_loss improved from 0.40062 to 0.39784, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 59: val_loss improved from 0.39784 to 0.39512, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 60: val_loss improved from 0.39512 to 0.39249, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 61: val_loss improved from 0.39249 to 0.38992, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 62: val_loss improved from 0.38992 to 0.38744, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 63: val_loss improved from 0.38744 to 0.38502, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 64: val_loss improved from 0.38502 to 0.38267, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 65: val_loss improved from 0.38267 to 0.38038, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 66: val_loss improved from 0.38038 to 0.37815, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 67: val_loss improved from 0.37815 to 0.37598, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 68: val_loss improved from 0.37598 to 0.37386, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 69: val_loss improved from 0.37386 to 0.37181, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 70: val_loss improved from 0.37181 to 0.36982, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 71: val_loss improved from 0.36982 to 0.36786, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 72: val_loss improved from 0.36786 to 0.36597, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 73: val_loss improved from 0.36597 to 0.36412, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 74: val_loss improved from 0.36412 to 0.36231, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 75: val_loss improved from 0.36231 to 0.36055, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 76: val_loss improved from 0.36055 to 0.35883, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 77: val_loss improved from 0.35883 to 0.35714, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 78: val_loss improved from 0.35714 to 0.35548, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 79: val_loss improved from 0.35548 to 0.35387, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 80: val_loss improved from 0.35387 to 0.35231, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 81: val_loss improved from 0.35231 to 0.35077, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 82: val_loss improved from 0.35077 to 0.34924, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 83: val_loss improved from 0.34924 to 0.34775, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 84: val_loss improved from 0.34775 to 0.34630, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 85: val_loss improved from 0.34630 to 0.34487, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 86: val_loss improved from 0.34487 to 0.34347, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 87: val_loss improved from 0.34347 to 0.34210, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 88: val_loss improved from 0.34210 to 0.34074, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 89: val_loss improved from 0.34074 to 0.33941, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 90: val_loss improved from 0.33941 to 0.33810, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 91: val_loss improved from 0.33810 to 0.33682, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 92: val_loss improved from 0.33682 to 0.33556, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 93: val_loss improved from 0.33556 to 0.33430, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 94: val_loss improved from 0.33430 to 0.33308, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 95: val_loss improved from 0.33308 to 0.33187, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 96: val_loss improved from 0.33187 to 0.33068, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 97: val_loss improved from 0.33068 to 0.32950, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 98: val_loss improved from 0.32950 to 0.32835, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 99: val_loss improved from 0.32835 to 0.32721, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 100: val_loss improved from 0.32721 to 0.32607, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 101: val_loss improved from 0.32607 to 0.32496, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 102: val_loss improved from 0.32496 to 0.32386, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 103: val_loss improved from 0.32386 to 0.32277, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 104: val_loss improved from 0.32277 to 0.32168, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 105: val_loss improved from 0.32168 to 0.32063, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 106: val_loss improved from 0.32063 to 0.31957, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 107: val_loss improved from 0.31957 to 0.31852, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 108: val_loss improved from 0.31852 to 0.31750, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 109: val_loss improved from 0.31750 to 0.31649, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 110: val_loss improved from 0.31649 to 0.31548, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 111: val_loss improved from 0.31548 to 0.31449, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 112: val_loss improved from 0.31449 to 0.31350, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 113: val_loss improved from 0.31350 to 0.31253, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 114: val_loss improved from 0.31253 to 0.31157, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 115: val_loss improved from 0.31157 to 0.31061, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 116: val_loss improved from 0.31061 to 0.30967, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 117: val_loss improved from 0.30967 to 0.30872, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 118: val_loss improved from 0.30872 to 0.30779, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 119: val_loss improved from 0.30779 to 0.30687, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 120: val_loss improved from 0.30687 to 0.30595, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 121: val_loss improved from 0.30595 to 0.30502, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 122: val_loss improved from 0.30502 to 0.30413, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 123: val_loss improved from 0.30413 to 0.30324, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 124: val_loss improved from 0.30324 to 0.30236, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 125: val_loss improved from 0.30236 to 0.30149, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 126: val_loss improved from 0.30149 to 0.30062, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 127: val_loss improved from 0.30062 to 0.29977, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 128: val_loss improved from 0.29977 to 0.29891, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 129: val_loss improved from 0.29891 to 0.29807, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 130: val_loss improved from 0.29807 to 0.29724, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 131: val_loss improved from 0.29724 to 0.29640, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 132: val_loss improved from 0.29640 to 0.29559, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 133: val_loss improved from 0.29559 to 0.29478, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 134: val_loss improved from 0.29478 to 0.29398, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 135: val_loss improved from 0.29398 to 0.29318, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 136: val_loss improved from 0.29318 to 0.29240, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 137: val_loss improved from 0.29240 to 0.29161, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 138: val_loss improved from 0.29161 to 0.29082, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 139: val_loss improved from 0.29082 to 0.29006, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 140: val_loss improved from 0.29006 to 0.28929, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 141: val_loss improved from 0.28929 to 0.28852, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 142: val_loss improved from 0.28852 to 0.28777, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 143: val_loss improved from 0.28777 to 0.28703, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 144: val_loss improved from 0.28703 to 0.28628, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 145: val_loss improved from 0.28628 to 0.28556, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 146: val_loss improved from 0.28556 to 0.28484, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 147: val_loss improved from 0.28484 to 0.28411, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 148: val_loss improved from 0.28411 to 0.28339, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 149: val_loss improved from 0.28339 to 0.28267, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 150: val_loss improved from 0.28267 to 0.28197, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 151: val_loss improved from 0.28197 to 0.28127, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 152: val_loss improved from 0.28127 to 0.28057, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 153: val_loss improved from 0.28057 to 0.27986, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 154: val_loss improved from 0.27986 to 0.27915, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 155: val_loss improved from 0.27915 to 0.27846, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 156: val_loss improved from 0.27846 to 0.27779, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 157: val_loss improved from 0.27779 to 0.27712, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 158: val_loss improved from 0.27712 to 0.27645, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 159: val_loss improved from 0.27645 to 0.27577, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 160: val_loss improved from 0.27577 to 0.27509, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 161: val_loss improved from 0.27509 to 0.27441, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 162: val_loss improved from 0.27441 to 0.27375, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 163: val_loss improved from 0.27375 to 0.27310, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 164: val_loss improved from 0.27310 to 0.27246, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 165: val_loss improved from 0.27246 to 0.27183, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 166: val_loss improved from 0.27183 to 0.27119, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 167: val_loss improved from 0.27119 to 0.27056, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 168: val_loss improved from 0.27056 to 0.26992, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 169: val_loss improved from 0.26992 to 0.26928, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 170: val_loss improved from 0.26928 to 0.26866, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 171: val_loss improved from 0.26866 to 0.26805, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 172: val_loss improved from 0.26805 to 0.26742, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 173: val_loss improved from 0.26742 to 0.26681, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 174: val_loss improved from 0.26681 to 0.26622, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 175: val_loss improved from 0.26622 to 0.26562, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 176: val_loss improved from 0.26562 to 0.26501, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 177: val_loss improved from 0.26501 to 0.26440, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 178: val_loss improved from 0.26440 to 0.26383, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 179: val_loss improved from 0.26383 to 0.26325, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 180: val_loss improved from 0.26325 to 0.26267, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 181: val_loss improved from 0.26267 to 0.26210, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 182: val_loss improved from 0.26210 to 0.26154, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 183: val_loss improved from 0.26154 to 0.26100, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 184: val_loss improved from 0.26100 to 0.26043, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 185: val_loss improved from 0.26043 to 0.25987, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 186: val_loss improved from 0.25987 to 0.25933, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 187: val_loss improved from 0.25933 to 0.25878, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 188: val_loss improved from 0.25878 to 0.25823, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 189: val_loss improved from 0.25823 to 0.25769, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 190: val_loss improved from 0.25769 to 0.25716, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 191: val_loss improved from 0.25716 to 0.25662, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 192: val_loss improved from 0.25662 to 0.25606, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 193: val_loss improved from 0.25606 to 0.25553, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 194: val_loss improved from 0.25553 to 0.25501, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 195: val_loss improved from 0.25501 to 0.25448, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 196: val_loss improved from 0.25448 to 0.25396, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 197: val_loss improved from 0.25396 to 0.25344, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 198: val_loss improved from 0.25344 to 0.25293, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 199: val_loss improved from 0.25293 to 0.25243, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 200: val_loss improved from 0.25243 to 0.25192, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 201: val_loss improved from 0.25192 to 0.25141, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 202: val_loss improved from 0.25141 to 0.25091, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 203: val_loss improved from 0.25091 to 0.25040, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 204: val_loss improved from 0.25040 to 0.24990, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 205: val_loss improved from 0.24990 to 0.24941, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 206: val_loss improved from 0.24941 to 0.24892, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 207: val_loss improved from 0.24892 to 0.24843, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 208: val_loss improved from 0.24843 to 0.24793, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 209: val_loss improved from 0.24793 to 0.24743, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 210: val_loss improved from 0.24743 to 0.24696, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 211: val_loss improved from 0.24696 to 0.24649, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 212: val_loss improved from 0.24649 to 0.24601, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 213: val_loss improved from 0.24601 to 0.24555, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 214: val_loss improved from 0.24555 to 0.24509, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 215: val_loss improved from 0.24509 to 0.24462, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 216: val_loss improved from 0.24462 to 0.24416, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 217: val_loss improved from 0.24416 to 0.24370, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 218: val_loss improved from 0.24370 to 0.24325, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 219: val_loss improved from 0.24325 to 0.24279, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 220: val_loss improved from 0.24279 to 0.24231, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 221: val_loss improved from 0.24231 to 0.24187, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 222: val_loss improved from 0.24187 to 0.24144, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 223: val_loss improved from 0.24144 to 0.24099, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 224: val_loss improved from 0.24099 to 0.24056, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 225: val_loss improved from 0.24056 to 0.24012, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 226: val_loss improved from 0.24012 to 0.23968, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 227: val_loss improved from 0.23968 to 0.23925, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 228: val_loss improved from 0.23925 to 0.23882, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 229: val_loss improved from 0.23882 to 0.23839, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 230: val_loss improved from 0.23839 to 0.23798, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 231: val_loss improved from 0.23798 to 0.23757, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 232: val_loss improved from 0.23757 to 0.23715, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 233: val_loss improved from 0.23715 to 0.23674, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 234: val_loss improved from 0.23674 to 0.23633, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 235: val_loss improved from 0.23633 to 0.23594, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 236: val_loss improved from 0.23594 to 0.23553, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 237: val_loss improved from 0.23553 to 0.23512, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 238: val_loss improved from 0.23512 to 0.23470, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 239: val_loss improved from 0.23470 to 0.23428, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 240: val_loss improved from 0.23428 to 0.23383, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 241: val_loss improved from 0.23383 to 0.23343, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 242: val_loss improved from 0.23343 to 0.23301, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 243: val_loss improved from 0.23301 to 0.23262, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 244: val_loss improved from 0.23262 to 0.23223, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 245: val_loss improved from 0.23223 to 0.23184, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 246: val_loss improved from 0.23184 to 0.23145, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 247: val_loss improved from 0.23145 to 0.23106, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 248: val_loss improved from 0.23106 to 0.23067, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 249: val_loss improved from 0.23067 to 0.23030, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 250: val_loss improved from 0.23030 to 0.22992, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 251: val_loss improved from 0.22992 to 0.22954, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 252: val_loss improved from 0.22954 to 0.22917, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 253: val_loss improved from 0.22917 to 0.22880, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 254: val_loss improved from 0.22880 to 0.22844, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 255: val_loss improved from 0.22844 to 0.22807, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 256: val_loss improved from 0.22807 to 0.22770, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 257: val_loss improved from 0.22770 to 0.22734, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 258: val_loss improved from 0.22734 to 0.22697, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 259: val_loss improved from 0.22697 to 0.22660, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 260: val_loss improved from 0.22660 to 0.22624, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 261: val_loss improved from 0.22624 to 0.22588, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 262: val_loss improved from 0.22588 to 0.22550, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 263: val_loss improved from 0.22550 to 0.22515, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 264: val_loss improved from 0.22515 to 0.22476, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 265: val_loss improved from 0.22476 to 0.22440, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 266: val_loss improved from 0.22440 to 0.22405, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 267: val_loss improved from 0.22405 to 0.22368, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 268: val_loss improved from 0.22368 to 0.22330, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 269: val_loss improved from 0.22330 to 0.22296, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 270: val_loss improved from 0.22296 to 0.22262, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 271: val_loss improved from 0.22262 to 0.22227, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 272: val_loss improved from 0.22227 to 0.22193, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 273: val_loss improved from 0.22193 to 0.22159, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 274: val_loss improved from 0.22159 to 0.22126, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 275: val_loss improved from 0.22126 to 0.22093, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 276: val_loss improved from 0.22093 to 0.22060, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 277: val_loss improved from 0.22060 to 0.22026, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 278: val_loss improved from 0.22026 to 0.21993, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 279: val_loss improved from 0.21993 to 0.21960, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 280: val_loss improved from 0.21960 to 0.21927, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 281: val_loss improved from 0.21927 to 0.21894, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 282: val_loss improved from 0.21894 to 0.21857, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 283: val_loss improved from 0.21857 to 0.21825, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 284: val_loss improved from 0.21825 to 0.21792, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 285: val_loss improved from 0.21792 to 0.21759, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 286: val_loss improved from 0.21759 to 0.21728, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 287: val_loss improved from 0.21728 to 0.21696, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 288: val_loss improved from 0.21696 to 0.21665, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 289: val_loss improved from 0.21665 to 0.21634, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 290: val_loss improved from 0.21634 to 0.21602, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 291: val_loss improved from 0.21602 to 0.21571, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 292: val_loss improved from 0.21571 to 0.21540, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 293: val_loss improved from 0.21540 to 0.21509, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 294: val_loss improved from 0.21509 to 0.21479, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 295: val_loss improved from 0.21479 to 0.21447, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 296: val_loss improved from 0.21447 to 0.21417, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 297: val_loss improved from 0.21417 to 0.21386, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 298: val_loss improved from 0.21386 to 0.21356, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 299: val_loss improved from 0.21356 to 0.21325, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 300: val_loss improved from 0.21325 to 0.21291, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 301: val_loss improved from 0.21291 to 0.21260, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 302: val_loss improved from 0.21260 to 0.21230, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 303: val_loss improved from 0.21230 to 0.21197, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 304: val_loss improved from 0.21197 to 0.21167, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 305: val_loss improved from 0.21167 to 0.21138, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 306: val_loss improved from 0.21138 to 0.21108, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 307: val_loss improved from 0.21108 to 0.21078, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 308: val_loss improved from 0.21078 to 0.21052, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 309: val_loss improved from 0.21052 to 0.21023, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 310: val_loss improved from 0.21023 to 0.20993, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 311: val_loss improved from 0.20993 to 0.20959, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 312: val_loss improved from 0.20959 to 0.20930, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 313: val_loss improved from 0.20930 to 0.20900, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 314: val_loss improved from 0.20900 to 0.20871, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 315: val_loss improved from 0.20871 to 0.20844, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 316: val_loss improved from 0.20844 to 0.20815, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 317: val_loss improved from 0.20815 to 0.20788, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 318: val_loss improved from 0.20788 to 0.20759, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 319: val_loss improved from 0.20759 to 0.20732, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 320: val_loss improved from 0.20732 to 0.20704, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 321: val_loss improved from 0.20704 to 0.20676, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 322: val_loss improved from 0.20676 to 0.20647, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 323: val_loss improved from 0.20647 to 0.20620, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 324: val_loss improved from 0.20620 to 0.20593, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 325: val_loss improved from 0.20593 to 0.20564, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 326: val_loss improved from 0.20564 to 0.20537, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 327: val_loss improved from 0.20537 to 0.20511, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 328: val_loss improved from 0.20511 to 0.20485, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 329: val_loss improved from 0.20485 to 0.20458, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 330: val_loss improved from 0.20458 to 0.20431, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 331: val_loss improved from 0.20431 to 0.20404, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 332: val_loss improved from 0.20404 to 0.20378, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 333: val_loss improved from 0.20378 to 0.20350, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 334: val_loss improved from 0.20350 to 0.20323, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 335: val_loss improved from 0.20323 to 0.20294, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 336: val_loss improved from 0.20294 to 0.20267, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 337: val_loss improved from 0.20267 to 0.20241, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 338: val_loss improved from 0.20241 to 0.20214, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 339: val_loss improved from 0.20214 to 0.20188, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 340: val_loss improved from 0.20188 to 0.20162, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 341: val_loss improved from 0.20162 to 0.20136, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 342: val_loss improved from 0.20136 to 0.20109, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 343: val_loss improved from 0.20109 to 0.20083, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 344: val_loss improved from 0.20083 to 0.20057, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 345: val_loss improved from 0.20057 to 0.20031, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 346: val_loss improved from 0.20031 to 0.20005, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 347: val_loss improved from 0.20005 to 0.19979, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 348: val_loss improved from 0.19979 to 0.19954, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 349: val_loss improved from 0.19954 to 0.19930, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 350: val_loss improved from 0.19930 to 0.19904, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 351: val_loss improved from 0.19904 to 0.19879, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 352: val_loss improved from 0.19879 to 0.19853, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 353: val_loss improved from 0.19853 to 0.19825, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 354: val_loss improved from 0.19825 to 0.19801, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 355: val_loss improved from 0.19801 to 0.19773, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 356: val_loss improved from 0.19773 to 0.19748, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 357: val_loss improved from 0.19748 to 0.19724, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 358: val_loss improved from 0.19724 to 0.19697, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 359: val_loss improved from 0.19697 to 0.19672, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 360: val_loss improved from 0.19672 to 0.19648, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 361: val_loss improved from 0.19648 to 0.19624, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 362: val_loss improved from 0.19624 to 0.19598, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 363: val_loss improved from 0.19598 to 0.19574, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 364: val_loss improved from 0.19574 to 0.19549, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 365: val_loss improved from 0.19549 to 0.19521, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 366: val_loss improved from 0.19521 to 0.19498, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 367: val_loss improved from 0.19498 to 0.19474, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 368: val_loss improved from 0.19474 to 0.19451, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 369: val_loss improved from 0.19451 to 0.19427, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 370: val_loss improved from 0.19427 to 0.19404, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 371: val_loss improved from 0.19404 to 0.19379, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 372: val_loss improved from 0.19379 to 0.19357, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 373: val_loss improved from 0.19357 to 0.19333, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 374: val_loss improved from 0.19333 to 0.19309, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 375: val_loss improved from 0.19309 to 0.19286, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 376: val_loss improved from 0.19286 to 0.19262, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 377: val_loss improved from 0.19262 to 0.19238, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 378: val_loss improved from 0.19238 to 0.19213, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 379: val_loss improved from 0.19213 to 0.19191, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 380: val_loss improved from 0.19191 to 0.19162, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 381: val_loss improved from 0.19162 to 0.19138, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 382: val_loss improved from 0.19138 to 0.19115, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 383: val_loss improved from 0.19115 to 0.19092, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 384: val_loss improved from 0.19092 to 0.19068, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 385: val_loss improved from 0.19068 to 0.19045, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 386: val_loss improved from 0.19045 to 0.19021, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 387: val_loss improved from 0.19021 to 0.18999, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 388: val_loss improved from 0.18999 to 0.18976, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 389: val_loss improved from 0.18976 to 0.18953, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 390: val_loss improved from 0.18953 to 0.18931, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 391: val_loss improved from 0.18931 to 0.18908, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 392: val_loss improved from 0.18908 to 0.18885, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 393: val_loss improved from 0.18885 to 0.18863, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 394: val_loss improved from 0.18863 to 0.18841, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 395: val_loss improved from 0.18841 to 0.18814, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 396: val_loss improved from 0.18814 to 0.18792, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 397: val_loss improved from 0.18792 to 0.18769, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 398: val_loss improved from 0.18769 to 0.18746, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 399: val_loss improved from 0.18746 to 0.18724, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 400: val_loss improved from 0.18724 to 0.18703, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 401: val_loss improved from 0.18703 to 0.18681, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 402: val_loss improved from 0.18681 to 0.18658, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 403: val_loss improved from 0.18658 to 0.18637, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 404: val_loss improved from 0.18637 to 0.18615, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 405: val_loss improved from 0.18615 to 0.18594, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 406: val_loss improved from 0.18594 to 0.18572, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 407: val_loss improved from 0.18572 to 0.18550, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 408: val_loss improved from 0.18550 to 0.18528, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 409: val_loss improved from 0.18528 to 0.18506, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 410: val_loss improved from 0.18506 to 0.18476, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 411: val_loss improved from 0.18476 to 0.18454, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 412: val_loss improved from 0.18454 to 0.18434, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 413: val_loss improved from 0.18434 to 0.18412, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 414: val_loss improved from 0.18412 to 0.18391, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 415: val_loss improved from 0.18391 to 0.18369, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 416: val_loss improved from 0.18369 to 0.18348, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 417: val_loss improved from 0.18348 to 0.18327, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 418: val_loss improved from 0.18327 to 0.18306, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 419: val_loss improved from 0.18306 to 0.18286, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 420: val_loss improved from 0.18286 to 0.18263, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 421: val_loss improved from 0.18263 to 0.18239, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 422: val_loss improved from 0.18239 to 0.18218, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 423: val_loss improved from 0.18218 to 0.18198, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 424: val_loss improved from 0.18198 to 0.18175, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 425: val_loss improved from 0.18175 to 0.18155, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 426: val_loss improved from 0.18155 to 0.18133, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 427: val_loss improved from 0.18133 to 0.18112, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 428: val_loss improved from 0.18112 to 0.18092, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 429: val_loss improved from 0.18092 to 0.18070, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 430: val_loss improved from 0.18070 to 0.18048, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 431: val_loss improved from 0.18048 to 0.18028, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 432: val_loss improved from 0.18028 to 0.18007, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 433: val_loss improved from 0.18007 to 0.17986, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 434: val_loss improved from 0.17986 to 0.17964, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 435: val_loss improved from 0.17964 to 0.17943, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 436: val_loss improved from 0.17943 to 0.17922, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 437: val_loss improved from 0.17922 to 0.17901, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 438: val_loss improved from 0.17901 to 0.17880, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 439: val_loss improved from 0.17880 to 0.17860, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 440: val_loss improved from 0.17860 to 0.17840, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 441: val_loss improved from 0.17840 to 0.17818, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 442: val_loss improved from 0.17818 to 0.17797, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 443: val_loss improved from 0.17797 to 0.17776, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 444: val_loss improved from 0.17776 to 0.17755, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 445: val_loss improved from 0.17755 to 0.17735, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 446: val_loss improved from 0.17735 to 0.17713, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 447: val_loss improved from 0.17713 to 0.17691, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 448: val_loss improved from 0.17691 to 0.17671, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 449: val_loss improved from 0.17671 to 0.17651, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 450: val_loss improved from 0.17651 to 0.17630, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 451: val_loss improved from 0.17630 to 0.17609, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 452: val_loss improved from 0.17609 to 0.17587, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 453: val_loss improved from 0.17587 to 0.17567, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 454: val_loss improved from 0.17567 to 0.17546, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 455: val_loss improved from 0.17546 to 0.17525, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 456: val_loss improved from 0.17525 to 0.17504, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 457: val_loss improved from 0.17504 to 0.17483, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 458: val_loss improved from 0.17483 to 0.17462, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 459: val_loss improved from 0.17462 to 0.17442, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 460: val_loss improved from 0.17442 to 0.17421, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 461: val_loss improved from 0.17421 to 0.17399, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 462: val_loss improved from 0.17399 to 0.17379, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 463: val_loss improved from 0.17379 to 0.17359, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 464: val_loss improved from 0.17359 to 0.17333, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 465: val_loss improved from 0.17333 to 0.17314, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 466: val_loss improved from 0.17314 to 0.17292, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 467: val_loss improved from 0.17292 to 0.17272, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 468: val_loss improved from 0.17272 to 0.17252, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 469: val_loss improved from 0.17252 to 0.17233, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 470: val_loss improved from 0.17233 to 0.17212, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 471: val_loss improved from 0.17212 to 0.17189, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 472: val_loss improved from 0.17189 to 0.17170, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 473: val_loss improved from 0.17170 to 0.17149, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 474: val_loss improved from 0.17149 to 0.17128, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 475: val_loss improved from 0.17128 to 0.17104, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 476: val_loss improved from 0.17104 to 0.17083, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 477: val_loss improved from 0.17083 to 0.17063, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 478: val_loss improved from 0.17063 to 0.17044, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 479: val_loss improved from 0.17044 to 0.17023, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 480: val_loss improved from 0.17023 to 0.17004, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 481: val_loss improved from 0.17004 to 0.16984, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 482: val_loss improved from 0.16984 to 0.16965, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 483: val_loss improved from 0.16965 to 0.16944, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 484: val_loss improved from 0.16944 to 0.16924, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 485: val_loss improved from 0.16924 to 0.16903, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 486: val_loss improved from 0.16903 to 0.16882, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 487: val_loss improved from 0.16882 to 0.16863, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 488: val_loss improved from 0.16863 to 0.16841, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 489: val_loss improved from 0.16841 to 0.16821, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 490: val_loss improved from 0.16821 to 0.16801, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 491: val_loss improved from 0.16801 to 0.16781, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 492: val_loss improved from 0.16781 to 0.16761, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 493: val_loss improved from 0.16761 to 0.16740, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 494: val_loss improved from 0.16740 to 0.16719, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 495: val_loss improved from 0.16719 to 0.16696, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 496: val_loss improved from 0.16696 to 0.16677, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 497: val_loss improved from 0.16677 to 0.16658, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 498: val_loss improved from 0.16658 to 0.16639, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 499: val_loss improved from 0.16639 to 0.16620, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 500: val_loss improved from 0.16620 to 0.16601, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 501: val_loss improved from 0.16601 to 0.16584, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 502: val_loss improved from 0.16584 to 0.16565, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 503: val_loss improved from 0.16565 to 0.16546, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 504: val_loss improved from 0.16546 to 0.16527, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 505: val_loss improved from 0.16527 to 0.16507, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 506: val_loss improved from 0.16507 to 0.16488, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 507: val_loss improved from 0.16488 to 0.16466, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 508: val_loss improved from 0.16466 to 0.16443, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 509: val_loss improved from 0.16443 to 0.16421, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 510: val_loss improved from 0.16421 to 0.16402, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 511: val_loss improved from 0.16402 to 0.16383, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 512: val_loss improved from 0.16383 to 0.16363, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 513: val_loss improved from 0.16363 to 0.16342, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 514: val_loss improved from 0.16342 to 0.16319, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 515: val_loss improved from 0.16319 to 0.16299, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 516: val_loss improved from 0.16299 to 0.16280, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 517: val_loss improved from 0.16280 to 0.16262, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 518: val_loss improved from 0.16262 to 0.16243, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 519: val_loss improved from 0.16243 to 0.16224, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 520: val_loss improved from 0.16224 to 0.16207, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 521: val_loss improved from 0.16207 to 0.16188, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 522: val_loss improved from 0.16188 to 0.16168, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 523: val_loss improved from 0.16168 to 0.16150, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 524: val_loss improved from 0.16150 to 0.16132, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 525: val_loss improved from 0.16132 to 0.16114, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 526: val_loss improved from 0.16114 to 0.16096, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 527: val_loss improved from 0.16096 to 0.16077, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 528: val_loss improved from 0.16077 to 0.16058, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 529: val_loss improved from 0.16058 to 0.16040, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 530: val_loss improved from 0.16040 to 0.16019, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 531: val_loss improved from 0.16019 to 0.16000, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 532: val_loss improved from 0.16000 to 0.15980, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 533: val_loss improved from 0.15980 to 0.15955, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 534: val_loss improved from 0.15955 to 0.15936, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 535: val_loss improved from 0.15936 to 0.15916, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 536: val_loss improved from 0.15916 to 0.15898, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 537: val_loss improved from 0.15898 to 0.15879, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 538: val_loss improved from 0.15879 to 0.15861, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 539: val_loss improved from 0.15861 to 0.15842, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 540: val_loss improved from 0.15842 to 0.15821, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 541: val_loss improved from 0.15821 to 0.15804, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 542: val_loss improved from 0.15804 to 0.15779, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 543: val_loss improved from 0.15779 to 0.15760, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 544: val_loss improved from 0.15760 to 0.15742, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 545: val_loss improved from 0.15742 to 0.15723, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 546: val_loss improved from 0.15723 to 0.15705, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 547: val_loss improved from 0.15705 to 0.15685, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 548: val_loss improved from 0.15685 to 0.15668, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 549: val_loss improved from 0.15668 to 0.15650, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 550: val_loss improved from 0.15650 to 0.15632, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 551: val_loss improved from 0.15632 to 0.15613, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 552: val_loss improved from 0.15613 to 0.15595, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 553: val_loss improved from 0.15595 to 0.15578, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 554: val_loss improved from 0.15578 to 0.15559, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 555: val_loss improved from 0.15559 to 0.15541, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 556: val_loss improved from 0.15541 to 0.15522, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 557: val_loss improved from 0.15522 to 0.15506, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 558: val_loss improved from 0.15506 to 0.15485, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 559: val_loss improved from 0.15485 to 0.15467, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 560: val_loss improved from 0.15467 to 0.15450, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 561: val_loss improved from 0.15450 to 0.15432, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 562: val_loss improved from 0.15432 to 0.15416, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 563: val_loss improved from 0.15416 to 0.15400, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 564: val_loss improved from 0.15400 to 0.15382, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 565: val_loss improved from 0.15382 to 0.15364, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 566: val_loss improved from 0.15364 to 0.15346, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 567: val_loss improved from 0.15346 to 0.15331, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 568: val_loss improved from 0.15331 to 0.15313, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 569: val_loss improved from 0.15313 to 0.15298, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 570: val_loss improved from 0.15298 to 0.15280, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 571: val_loss improved from 0.15280 to 0.15260, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 572: val_loss improved from 0.15260 to 0.15243, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 573: val_loss improved from 0.15243 to 0.15227, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 574: val_loss improved from 0.15227 to 0.15211, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 575: val_loss improved from 0.15211 to 0.15193, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 576: val_loss improved from 0.15193 to 0.15175, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 577: val_loss improved from 0.15175 to 0.15159, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 578: val_loss improved from 0.15159 to 0.15143, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 579: val_loss improved from 0.15143 to 0.15126, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 580: val_loss improved from 0.15126 to 0.15109, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 581: val_loss improved from 0.15109 to 0.15093, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 582: val_loss improved from 0.15093 to 0.15076, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 583: val_loss improved from 0.15076 to 0.15060, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 584: val_loss improved from 0.15060 to 0.15042, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 585: val_loss improved from 0.15042 to 0.15025, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 586: val_loss improved from 0.15025 to 0.15007, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 587: val_loss improved from 0.15007 to 0.14993, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 588: val_loss improved from 0.14993 to 0.14976, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 589: val_loss improved from 0.14976 to 0.14956, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 590: val_loss improved from 0.14956 to 0.14939, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 591: val_loss improved from 0.14939 to 0.14923, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 592: val_loss improved from 0.14923 to 0.14904, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 593: val_loss improved from 0.14904 to 0.14888, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 594: val_loss improved from 0.14888 to 0.14871, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 595: val_loss improved from 0.14871 to 0.14855, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 596: val_loss improved from 0.14855 to 0.14839, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 597: val_loss improved from 0.14839 to 0.14821, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 598: val_loss improved from 0.14821 to 0.14804, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 599: val_loss improved from 0.14804 to 0.14789, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 600: val_loss improved from 0.14789 to 0.14772, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 601: val_loss improved from 0.14772 to 0.14755, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 602: val_loss improved from 0.14755 to 0.14740, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 603: val_loss improved from 0.14740 to 0.14723, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 604: val_loss improved from 0.14723 to 0.14709, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 605: val_loss improved from 0.14709 to 0.14691, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 606: val_loss improved from 0.14691 to 0.14674, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 607: val_loss improved from 0.14674 to 0.14655, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 608: val_loss improved from 0.14655 to 0.14637, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 609: val_loss improved from 0.14637 to 0.14622, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 610: val_loss improved from 0.14622 to 0.14607, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 611: val_loss improved from 0.14607 to 0.14591, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 612: val_loss improved from 0.14591 to 0.14575, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 613: val_loss improved from 0.14575 to 0.14559, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 614: val_loss improved from 0.14559 to 0.14544, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 615: val_loss improved from 0.14544 to 0.14529, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 616: val_loss improved from 0.14529 to 0.14514, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 617: val_loss improved from 0.14514 to 0.14498, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 618: val_loss improved from 0.14498 to 0.14480, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 619: val_loss improved from 0.14480 to 0.14466, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 620: val_loss improved from 0.14466 to 0.14451, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 621: val_loss improved from 0.14451 to 0.14436, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 622: val_loss improved from 0.14436 to 0.14419, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 623: val_loss improved from 0.14419 to 0.14405, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 624: val_loss improved from 0.14405 to 0.14389, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 625: val_loss improved from 0.14389 to 0.14375, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 626: val_loss improved from 0.14375 to 0.14361, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 627: val_loss improved from 0.14361 to 0.14347, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 628: val_loss improved from 0.14347 to 0.14331, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 629: val_loss improved from 0.14331 to 0.14316, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 630: val_loss improved from 0.14316 to 0.14298, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 631: val_loss improved from 0.14298 to 0.14283, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 632: val_loss improved from 0.14283 to 0.14268, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 633: val_loss improved from 0.14268 to 0.14252, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 634: val_loss improved from 0.14252 to 0.14238, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 635: val_loss improved from 0.14238 to 0.14223, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 636: val_loss improved from 0.14223 to 0.14200, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 637: val_loss improved from 0.14200 to 0.14187, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 638: val_loss improved from 0.14187 to 0.14172, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 639: val_loss improved from 0.14172 to 0.14150, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 640: val_loss improved from 0.14150 to 0.14136, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 641: val_loss improved from 0.14136 to 0.14122, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 642: val_loss improved from 0.14122 to 0.14108, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 643: val_loss improved from 0.14108 to 0.14094, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 644: val_loss improved from 0.14094 to 0.14075, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 645: val_loss improved from 0.14075 to 0.14062, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 646: val_loss improved from 0.14062 to 0.14049, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 647: val_loss improved from 0.14049 to 0.14036, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 648: val_loss improved from 0.14036 to 0.14019, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 649: val_loss improved from 0.14019 to 0.14005, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 650: val_loss improved from 0.14005 to 0.13992, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 651: val_loss improved from 0.13992 to 0.13978, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 652: val_loss improved from 0.13978 to 0.13965, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 653: val_loss improved from 0.13965 to 0.13952, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 654: val_loss improved from 0.13952 to 0.13937, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 655: val_loss improved from 0.13937 to 0.13928, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 656: val_loss improved from 0.13928 to 0.13914, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 657: val_loss improved from 0.13914 to 0.13900, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 658: val_loss improved from 0.13900 to 0.13887, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 659: val_loss improved from 0.13887 to 0.13875, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 660: val_loss improved from 0.13875 to 0.13861, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 661: val_loss improved from 0.13861 to 0.13847, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 662: val_loss improved from 0.13847 to 0.13834, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 663: val_loss improved from 0.13834 to 0.13822, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 664: val_loss improved from 0.13822 to 0.13805, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 665: val_loss improved from 0.13805 to 0.13793, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 666: val_loss improved from 0.13793 to 0.13780, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 667: val_loss improved from 0.13780 to 0.13769, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 668: val_loss improved from 0.13769 to 0.13757, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 669: val_loss improved from 0.13757 to 0.13743, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 670: val_loss improved from 0.13743 to 0.13728, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 671: val_loss improved from 0.13728 to 0.13714, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 672: val_loss improved from 0.13714 to 0.13700, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 673: val_loss improved from 0.13700 to 0.13688, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 674: val_loss improved from 0.13688 to 0.13675, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 675: val_loss improved from 0.13675 to 0.13660, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 676: val_loss improved from 0.13660 to 0.13648, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 677: val_loss improved from 0.13648 to 0.13637, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 678: val_loss improved from 0.13637 to 0.13623, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 679: val_loss improved from 0.13623 to 0.13610, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 680: val_loss improved from 0.13610 to 0.13599, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 681: val_loss improved from 0.13599 to 0.13588, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 682: val_loss improved from 0.13588 to 0.13575, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 683: val_loss improved from 0.13575 to 0.13562, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 684: val_loss improved from 0.13562 to 0.13549, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 685: val_loss improved from 0.13549 to 0.13537, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 686: val_loss improved from 0.13537 to 0.13525, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 687: val_loss improved from 0.13525 to 0.13512, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 688: val_loss improved from 0.13512 to 0.13499, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 689: val_loss improved from 0.13499 to 0.13482, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 690: val_loss improved from 0.13482 to 0.13470, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 691: val_loss improved from 0.13470 to 0.13457, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 692: val_loss improved from 0.13457 to 0.13445, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 693: val_loss improved from 0.13445 to 0.13432, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 694: val_loss improved from 0.13432 to 0.13419, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 695: val_loss improved from 0.13419 to 0.13407, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 696: val_loss improved from 0.13407 to 0.13396, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 697: val_loss improved from 0.13396 to 0.13378, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 698: val_loss improved from 0.13378 to 0.13366, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 699: val_loss improved from 0.13366 to 0.13354, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 700: val_loss improved from 0.13354 to 0.13342, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "Loss: 0.1334, Accuracy: 94.64%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.13342\n",
      "\n",
      "Epoch 207: val_loss improved from 0.13342 to 0.13324, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 208: val_loss improved from 0.13324 to 0.13286, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 209: val_loss improved from 0.13286 to 0.13247, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 210: val_loss improved from 0.13247 to 0.13209, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 211: val_loss improved from 0.13209 to 0.13171, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 212: val_loss improved from 0.13171 to 0.13134, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 213: val_loss improved from 0.13134 to 0.13098, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 214: val_loss improved from 0.13098 to 0.13061, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 215: val_loss improved from 0.13061 to 0.13025, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 216: val_loss improved from 0.13025 to 0.12989, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 217: val_loss improved from 0.12989 to 0.12953, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 218: val_loss improved from 0.12953 to 0.12917, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 219: val_loss improved from 0.12917 to 0.12883, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 220: val_loss improved from 0.12883 to 0.12847, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 221: val_loss improved from 0.12847 to 0.12812, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 222: val_loss improved from 0.12812 to 0.12778, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 223: val_loss improved from 0.12778 to 0.12745, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 224: val_loss improved from 0.12745 to 0.12712, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 225: val_loss improved from 0.12712 to 0.12677, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 226: val_loss improved from 0.12677 to 0.12644, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 227: val_loss improved from 0.12644 to 0.12610, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 228: val_loss improved from 0.12610 to 0.12577, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 229: val_loss improved from 0.12577 to 0.12545, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 230: val_loss improved from 0.12545 to 0.12512, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 231: val_loss improved from 0.12512 to 0.12480, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 232: val_loss improved from 0.12480 to 0.12447, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 233: val_loss improved from 0.12447 to 0.12415, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 234: val_loss improved from 0.12415 to 0.12383, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 235: val_loss improved from 0.12383 to 0.12352, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 236: val_loss improved from 0.12352 to 0.12321, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 237: val_loss improved from 0.12321 to 0.12289, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 238: val_loss improved from 0.12289 to 0.12258, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 239: val_loss improved from 0.12258 to 0.12227, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 240: val_loss improved from 0.12227 to 0.12196, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 241: val_loss improved from 0.12196 to 0.12167, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 242: val_loss improved from 0.12167 to 0.12136, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 243: val_loss improved from 0.12136 to 0.12106, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 244: val_loss improved from 0.12106 to 0.12076, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 245: val_loss improved from 0.12076 to 0.12047, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 246: val_loss improved from 0.12047 to 0.12018, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 247: val_loss improved from 0.12018 to 0.11987, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 248: val_loss improved from 0.11987 to 0.11958, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 249: val_loss improved from 0.11958 to 0.11930, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 250: val_loss improved from 0.11930 to 0.11902, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 251: val_loss improved from 0.11902 to 0.11873, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 252: val_loss improved from 0.11873 to 0.11845, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 253: val_loss improved from 0.11845 to 0.11817, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 254: val_loss improved from 0.11817 to 0.11790, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 255: val_loss improved from 0.11790 to 0.11762, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 256: val_loss improved from 0.11762 to 0.11735, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 257: val_loss improved from 0.11735 to 0.11707, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 258: val_loss improved from 0.11707 to 0.11680, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 259: val_loss improved from 0.11680 to 0.11653, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 260: val_loss improved from 0.11653 to 0.11626, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 261: val_loss improved from 0.11626 to 0.11600, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 262: val_loss improved from 0.11600 to 0.11573, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 263: val_loss improved from 0.11573 to 0.11547, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 264: val_loss improved from 0.11547 to 0.11521, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 265: val_loss improved from 0.11521 to 0.11495, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 266: val_loss improved from 0.11495 to 0.11470, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 267: val_loss improved from 0.11470 to 0.11445, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 268: val_loss improved from 0.11445 to 0.11419, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 269: val_loss improved from 0.11419 to 0.11394, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 270: val_loss improved from 0.11394 to 0.11368, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 271: val_loss improved from 0.11368 to 0.11344, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 272: val_loss improved from 0.11344 to 0.11319, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 273: val_loss improved from 0.11319 to 0.11296, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 274: val_loss improved from 0.11296 to 0.11270, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 275: val_loss improved from 0.11270 to 0.11245, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 276: val_loss improved from 0.11245 to 0.11220, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 277: val_loss improved from 0.11220 to 0.11196, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 278: val_loss improved from 0.11196 to 0.11172, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 279: val_loss improved from 0.11172 to 0.11148, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 280: val_loss improved from 0.11148 to 0.11124, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 281: val_loss improved from 0.11124 to 0.11100, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 282: val_loss improved from 0.11100 to 0.11076, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 283: val_loss improved from 0.11076 to 0.11053, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 284: val_loss improved from 0.11053 to 0.11030, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 285: val_loss improved from 0.11030 to 0.11007, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 286: val_loss improved from 0.11007 to 0.10984, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 287: val_loss improved from 0.10984 to 0.10961, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 288: val_loss improved from 0.10961 to 0.10937, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 289: val_loss improved from 0.10937 to 0.10914, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 290: val_loss improved from 0.10914 to 0.10891, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 291: val_loss improved from 0.10891 to 0.10868, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 292: val_loss improved from 0.10868 to 0.10846, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 293: val_loss improved from 0.10846 to 0.10824, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 294: val_loss improved from 0.10824 to 0.10802, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 295: val_loss improved from 0.10802 to 0.10780, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 296: val_loss improved from 0.10780 to 0.10757, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 297: val_loss improved from 0.10757 to 0.10735, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 298: val_loss improved from 0.10735 to 0.10713, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 299: val_loss improved from 0.10713 to 0.10691, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 300: val_loss improved from 0.10691 to 0.10671, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 301: val_loss improved from 0.10671 to 0.10649, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 302: val_loss improved from 0.10649 to 0.10628, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 303: val_loss improved from 0.10628 to 0.10605, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 304: val_loss improved from 0.10605 to 0.10584, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 305: val_loss improved from 0.10584 to 0.10563, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 306: val_loss improved from 0.10563 to 0.10542, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 307: val_loss improved from 0.10542 to 0.10522, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 308: val_loss improved from 0.10522 to 0.10501, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 309: val_loss improved from 0.10501 to 0.10481, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 310: val_loss improved from 0.10481 to 0.10460, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 311: val_loss improved from 0.10460 to 0.10440, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 312: val_loss improved from 0.10440 to 0.10420, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 313: val_loss improved from 0.10420 to 0.10400, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 314: val_loss improved from 0.10400 to 0.10379, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 315: val_loss improved from 0.10379 to 0.10360, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 316: val_loss improved from 0.10360 to 0.10340, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 317: val_loss improved from 0.10340 to 0.10321, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 318: val_loss improved from 0.10321 to 0.10301, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 319: val_loss improved from 0.10301 to 0.10282, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 320: val_loss improved from 0.10282 to 0.10263, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 321: val_loss improved from 0.10263 to 0.10243, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 322: val_loss improved from 0.10243 to 0.10224, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 323: val_loss improved from 0.10224 to 0.10206, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 324: val_loss improved from 0.10206 to 0.10187, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 325: val_loss improved from 0.10187 to 0.10168, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 326: val_loss improved from 0.10168 to 0.10148, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 327: val_loss improved from 0.10148 to 0.10129, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 328: val_loss improved from 0.10129 to 0.10110, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 329: val_loss improved from 0.10110 to 0.10092, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 330: val_loss improved from 0.10092 to 0.10073, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 331: val_loss improved from 0.10073 to 0.10055, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 332: val_loss improved from 0.10055 to 0.10037, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 333: val_loss improved from 0.10037 to 0.10018, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 334: val_loss improved from 0.10018 to 0.10000, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 335: val_loss improved from 0.10000 to 0.09982, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 336: val_loss improved from 0.09982 to 0.09964, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 337: val_loss improved from 0.09964 to 0.09947, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 338: val_loss improved from 0.09947 to 0.09929, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 339: val_loss improved from 0.09929 to 0.09911, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 340: val_loss improved from 0.09911 to 0.09894, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 341: val_loss improved from 0.09894 to 0.09877, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 342: val_loss improved from 0.09877 to 0.09859, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 343: val_loss improved from 0.09859 to 0.09842, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 344: val_loss improved from 0.09842 to 0.09824, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 345: val_loss improved from 0.09824 to 0.09807, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 346: val_loss improved from 0.09807 to 0.09790, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 347: val_loss improved from 0.09790 to 0.09773, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 348: val_loss improved from 0.09773 to 0.09756, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 349: val_loss improved from 0.09756 to 0.09739, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 350: val_loss improved from 0.09739 to 0.09722, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 351: val_loss improved from 0.09722 to 0.09705, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 352: val_loss improved from 0.09705 to 0.09688, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 353: val_loss improved from 0.09688 to 0.09671, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 354: val_loss improved from 0.09671 to 0.09655, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 355: val_loss improved from 0.09655 to 0.09640, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 356: val_loss improved from 0.09640 to 0.09624, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 357: val_loss improved from 0.09624 to 0.09608, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 358: val_loss improved from 0.09608 to 0.09592, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 359: val_loss improved from 0.09592 to 0.09576, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 360: val_loss improved from 0.09576 to 0.09559, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 361: val_loss improved from 0.09559 to 0.09543, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 362: val_loss improved from 0.09543 to 0.09527, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 363: val_loss improved from 0.09527 to 0.09512, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 364: val_loss improved from 0.09512 to 0.09496, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 365: val_loss improved from 0.09496 to 0.09480, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 366: val_loss improved from 0.09480 to 0.09464, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 367: val_loss improved from 0.09464 to 0.09449, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 368: val_loss improved from 0.09449 to 0.09433, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 369: val_loss improved from 0.09433 to 0.09418, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 370: val_loss improved from 0.09418 to 0.09402, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 371: val_loss improved from 0.09402 to 0.09386, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 372: val_loss improved from 0.09386 to 0.09371, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 373: val_loss improved from 0.09371 to 0.09355, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 374: val_loss improved from 0.09355 to 0.09339, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 375: val_loss improved from 0.09339 to 0.09324, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 376: val_loss improved from 0.09324 to 0.09309, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 377: val_loss improved from 0.09309 to 0.09294, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 378: val_loss improved from 0.09294 to 0.09280, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 379: val_loss improved from 0.09280 to 0.09265, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 380: val_loss improved from 0.09265 to 0.09250, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 381: val_loss improved from 0.09250 to 0.09236, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 382: val_loss improved from 0.09236 to 0.09222, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 383: val_loss improved from 0.09222 to 0.09207, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 384: val_loss improved from 0.09207 to 0.09193, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 385: val_loss improved from 0.09193 to 0.09179, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 386: val_loss improved from 0.09179 to 0.09164, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 387: val_loss improved from 0.09164 to 0.09149, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 388: val_loss improved from 0.09149 to 0.09135, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 389: val_loss improved from 0.09135 to 0.09121, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 390: val_loss improved from 0.09121 to 0.09106, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 391: val_loss improved from 0.09106 to 0.09092, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 392: val_loss improved from 0.09092 to 0.09078, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 393: val_loss improved from 0.09078 to 0.09064, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 394: val_loss improved from 0.09064 to 0.09050, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 395: val_loss improved from 0.09050 to 0.09035, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 396: val_loss improved from 0.09035 to 0.09021, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 397: val_loss improved from 0.09021 to 0.09007, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 398: val_loss improved from 0.09007 to 0.08994, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 399: val_loss improved from 0.08994 to 0.08980, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 400: val_loss improved from 0.08980 to 0.08966, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 401: val_loss improved from 0.08966 to 0.08953, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 402: val_loss improved from 0.08953 to 0.08939, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 403: val_loss improved from 0.08939 to 0.08927, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 404: val_loss improved from 0.08927 to 0.08914, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 405: val_loss improved from 0.08914 to 0.08901, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 406: val_loss improved from 0.08901 to 0.08888, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 407: val_loss improved from 0.08888 to 0.08874, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 408: val_loss improved from 0.08874 to 0.08861, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 409: val_loss improved from 0.08861 to 0.08848, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 410: val_loss improved from 0.08848 to 0.08836, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 411: val_loss improved from 0.08836 to 0.08823, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 412: val_loss improved from 0.08823 to 0.08810, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 413: val_loss improved from 0.08810 to 0.08796, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 414: val_loss improved from 0.08796 to 0.08783, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 415: val_loss improved from 0.08783 to 0.08769, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 416: val_loss improved from 0.08769 to 0.08756, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 417: val_loss improved from 0.08756 to 0.08742, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 418: val_loss improved from 0.08742 to 0.08729, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 419: val_loss improved from 0.08729 to 0.08717, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 420: val_loss improved from 0.08717 to 0.08704, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 421: val_loss improved from 0.08704 to 0.08692, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 422: val_loss improved from 0.08692 to 0.08679, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 423: val_loss improved from 0.08679 to 0.08666, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 424: val_loss improved from 0.08666 to 0.08653, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 425: val_loss improved from 0.08653 to 0.08641, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 426: val_loss improved from 0.08641 to 0.08628, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 427: val_loss improved from 0.08628 to 0.08616, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 428: val_loss improved from 0.08616 to 0.08603, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 429: val_loss improved from 0.08603 to 0.08590, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 430: val_loss improved from 0.08590 to 0.08579, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 431: val_loss improved from 0.08579 to 0.08568, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 432: val_loss improved from 0.08568 to 0.08555, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 433: val_loss improved from 0.08555 to 0.08543, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 434: val_loss improved from 0.08543 to 0.08531, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 435: val_loss improved from 0.08531 to 0.08519, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 436: val_loss improved from 0.08519 to 0.08506, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 437: val_loss improved from 0.08506 to 0.08494, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 438: val_loss improved from 0.08494 to 0.08482, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 439: val_loss improved from 0.08482 to 0.08470, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 440: val_loss improved from 0.08470 to 0.08457, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 441: val_loss improved from 0.08457 to 0.08445, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 442: val_loss improved from 0.08445 to 0.08433, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 443: val_loss improved from 0.08433 to 0.08422, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 444: val_loss improved from 0.08422 to 0.08410, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 445: val_loss improved from 0.08410 to 0.08399, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 446: val_loss improved from 0.08399 to 0.08388, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 447: val_loss improved from 0.08388 to 0.08375, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 448: val_loss improved from 0.08375 to 0.08362, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 449: val_loss improved from 0.08362 to 0.08350, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 450: val_loss improved from 0.08350 to 0.08339, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 451: val_loss improved from 0.08339 to 0.08327, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 452: val_loss improved from 0.08327 to 0.08316, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 453: val_loss improved from 0.08316 to 0.08304, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 454: val_loss improved from 0.08304 to 0.08293, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 455: val_loss improved from 0.08293 to 0.08280, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 456: val_loss improved from 0.08280 to 0.08269, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 457: val_loss improved from 0.08269 to 0.08259, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 458: val_loss improved from 0.08259 to 0.08248, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 459: val_loss improved from 0.08248 to 0.08236, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 460: val_loss improved from 0.08236 to 0.08225, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 461: val_loss improved from 0.08225 to 0.08215, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 462: val_loss improved from 0.08215 to 0.08204, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 463: val_loss improved from 0.08204 to 0.08192, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 464: val_loss improved from 0.08192 to 0.08180, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 465: val_loss improved from 0.08180 to 0.08169, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 466: val_loss improved from 0.08169 to 0.08159, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 467: val_loss improved from 0.08159 to 0.08148, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 468: val_loss improved from 0.08148 to 0.08136, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 469: val_loss improved from 0.08136 to 0.08124, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 470: val_loss improved from 0.08124 to 0.08113, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 471: val_loss improved from 0.08113 to 0.08101, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 472: val_loss improved from 0.08101 to 0.08090, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 473: val_loss improved from 0.08090 to 0.08080, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 474: val_loss improved from 0.08080 to 0.08070, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 475: val_loss improved from 0.08070 to 0.08059, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 476: val_loss improved from 0.08059 to 0.08049, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 477: val_loss improved from 0.08049 to 0.08039, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 478: val_loss improved from 0.08039 to 0.08029, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 479: val_loss improved from 0.08029 to 0.08017, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 480: val_loss improved from 0.08017 to 0.08007, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 481: val_loss improved from 0.08007 to 0.07996, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 482: val_loss improved from 0.07996 to 0.07986, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 483: val_loss improved from 0.07986 to 0.07975, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 484: val_loss improved from 0.07975 to 0.07965, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 485: val_loss improved from 0.07965 to 0.07954, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 486: val_loss improved from 0.07954 to 0.07943, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 487: val_loss improved from 0.07943 to 0.07932, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 488: val_loss improved from 0.07932 to 0.07922, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 489: val_loss improved from 0.07922 to 0.07912, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 490: val_loss improved from 0.07912 to 0.07901, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 491: val_loss improved from 0.07901 to 0.07890, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 492: val_loss improved from 0.07890 to 0.07879, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 493: val_loss improved from 0.07879 to 0.07870, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 494: val_loss improved from 0.07870 to 0.07860, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 495: val_loss improved from 0.07860 to 0.07849, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 496: val_loss improved from 0.07849 to 0.07839, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 497: val_loss improved from 0.07839 to 0.07831, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 498: val_loss improved from 0.07831 to 0.07820, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 499: val_loss improved from 0.07820 to 0.07809, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 500: val_loss improved from 0.07809 to 0.07799, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 501: val_loss improved from 0.07799 to 0.07789, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 502: val_loss improved from 0.07789 to 0.07780, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 503: val_loss improved from 0.07780 to 0.07768, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 504: val_loss improved from 0.07768 to 0.07757, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 505: val_loss improved from 0.07757 to 0.07746, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 506: val_loss improved from 0.07746 to 0.07736, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 507: val_loss improved from 0.07736 to 0.07727, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 508: val_loss improved from 0.07727 to 0.07718, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 509: val_loss improved from 0.07718 to 0.07708, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 510: val_loss improved from 0.07708 to 0.07698, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 511: val_loss improved from 0.07698 to 0.07688, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 512: val_loss improved from 0.07688 to 0.07678, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 513: val_loss improved from 0.07678 to 0.07668, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 514: val_loss improved from 0.07668 to 0.07658, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 515: val_loss improved from 0.07658 to 0.07649, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 516: val_loss improved from 0.07649 to 0.07639, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 517: val_loss improved from 0.07639 to 0.07629, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 518: val_loss improved from 0.07629 to 0.07620, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 519: val_loss improved from 0.07620 to 0.07611, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 520: val_loss improved from 0.07611 to 0.07601, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 521: val_loss improved from 0.07601 to 0.07592, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 522: val_loss improved from 0.07592 to 0.07584, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 523: val_loss improved from 0.07584 to 0.07575, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 524: val_loss improved from 0.07575 to 0.07566, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 525: val_loss improved from 0.07566 to 0.07556, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 526: val_loss improved from 0.07556 to 0.07547, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 527: val_loss improved from 0.07547 to 0.07537, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 528: val_loss improved from 0.07537 to 0.07528, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 529: val_loss improved from 0.07528 to 0.07518, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 530: val_loss improved from 0.07518 to 0.07509, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 531: val_loss improved from 0.07509 to 0.07499, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 532: val_loss improved from 0.07499 to 0.07490, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 533: val_loss improved from 0.07490 to 0.07480, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 534: val_loss improved from 0.07480 to 0.07470, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 535: val_loss improved from 0.07470 to 0.07461, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 536: val_loss improved from 0.07461 to 0.07453, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 537: val_loss improved from 0.07453 to 0.07444, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 538: val_loss improved from 0.07444 to 0.07434, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 539: val_loss improved from 0.07434 to 0.07425, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 540: val_loss improved from 0.07425 to 0.07416, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 541: val_loss improved from 0.07416 to 0.07405, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 542: val_loss improved from 0.07405 to 0.07396, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 543: val_loss improved from 0.07396 to 0.07387, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 544: val_loss improved from 0.07387 to 0.07378, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 545: val_loss improved from 0.07378 to 0.07370, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 546: val_loss improved from 0.07370 to 0.07361, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 547: val_loss improved from 0.07361 to 0.07351, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 548: val_loss improved from 0.07351 to 0.07343, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 549: val_loss improved from 0.07343 to 0.07334, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 550: val_loss improved from 0.07334 to 0.07327, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 551: val_loss improved from 0.07327 to 0.07318, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 552: val_loss improved from 0.07318 to 0.07309, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 553: val_loss improved from 0.07309 to 0.07300, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 554: val_loss improved from 0.07300 to 0.07291, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 555: val_loss improved from 0.07291 to 0.07281, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 556: val_loss improved from 0.07281 to 0.07273, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 557: val_loss improved from 0.07273 to 0.07264, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 558: val_loss improved from 0.07264 to 0.07255, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 559: val_loss improved from 0.07255 to 0.07247, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 560: val_loss improved from 0.07247 to 0.07238, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 561: val_loss improved from 0.07238 to 0.07230, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 562: val_loss improved from 0.07230 to 0.07221, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 563: val_loss improved from 0.07221 to 0.07211, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 564: val_loss improved from 0.07211 to 0.07202, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 565: val_loss improved from 0.07202 to 0.07193, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 566: val_loss improved from 0.07193 to 0.07185, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 567: val_loss improved from 0.07185 to 0.07176, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 568: val_loss improved from 0.07176 to 0.07167, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 569: val_loss improved from 0.07167 to 0.07158, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 570: val_loss improved from 0.07158 to 0.07149, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 571: val_loss improved from 0.07149 to 0.07141, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 572: val_loss improved from 0.07141 to 0.07132, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 573: val_loss improved from 0.07132 to 0.07121, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 574: val_loss improved from 0.07121 to 0.07113, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 575: val_loss improved from 0.07113 to 0.07104, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 576: val_loss improved from 0.07104 to 0.07096, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 577: val_loss improved from 0.07096 to 0.07089, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 578: val_loss improved from 0.07089 to 0.07081, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 579: val_loss improved from 0.07081 to 0.07071, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 580: val_loss improved from 0.07071 to 0.07063, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 581: val_loss improved from 0.07063 to 0.07054, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 582: val_loss improved from 0.07054 to 0.07046, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 583: val_loss improved from 0.07046 to 0.07037, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 584: val_loss improved from 0.07037 to 0.07028, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 585: val_loss improved from 0.07028 to 0.07020, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 586: val_loss improved from 0.07020 to 0.07012, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 587: val_loss improved from 0.07012 to 0.07003, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 588: val_loss improved from 0.07003 to 0.06994, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 589: val_loss improved from 0.06994 to 0.06985, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 590: val_loss improved from 0.06985 to 0.06978, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 591: val_loss improved from 0.06978 to 0.06968, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 592: val_loss improved from 0.06968 to 0.06960, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 593: val_loss improved from 0.06960 to 0.06951, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 594: val_loss improved from 0.06951 to 0.06943, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 595: val_loss improved from 0.06943 to 0.06934, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 596: val_loss improved from 0.06934 to 0.06926, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 597: val_loss improved from 0.06926 to 0.06919, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 598: val_loss improved from 0.06919 to 0.06911, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 599: val_loss improved from 0.06911 to 0.06904, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 600: val_loss improved from 0.06904 to 0.06895, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 601: val_loss improved from 0.06895 to 0.06886, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 602: val_loss improved from 0.06886 to 0.06878, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 603: val_loss improved from 0.06878 to 0.06869, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 604: val_loss improved from 0.06869 to 0.06861, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 605: val_loss improved from 0.06861 to 0.06853, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 606: val_loss improved from 0.06853 to 0.06844, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 607: val_loss improved from 0.06844 to 0.06836, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 608: val_loss improved from 0.06836 to 0.06828, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 609: val_loss improved from 0.06828 to 0.06819, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 610: val_loss improved from 0.06819 to 0.06811, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 611: val_loss improved from 0.06811 to 0.06802, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 612: val_loss improved from 0.06802 to 0.06795, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 613: val_loss improved from 0.06795 to 0.06787, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 614: val_loss improved from 0.06787 to 0.06778, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 615: val_loss improved from 0.06778 to 0.06770, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 616: val_loss improved from 0.06770 to 0.06759, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 617: val_loss improved from 0.06759 to 0.06751, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 618: val_loss improved from 0.06751 to 0.06744, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 619: val_loss improved from 0.06744 to 0.06736, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 620: val_loss improved from 0.06736 to 0.06728, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 621: val_loss improved from 0.06728 to 0.06721, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 622: val_loss improved from 0.06721 to 0.06714, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 623: val_loss improved from 0.06714 to 0.06706, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 624: val_loss improved from 0.06706 to 0.06697, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 625: val_loss improved from 0.06697 to 0.06689, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 626: val_loss improved from 0.06689 to 0.06682, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 627: val_loss improved from 0.06682 to 0.06674, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 628: val_loss improved from 0.06674 to 0.06666, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 629: val_loss improved from 0.06666 to 0.06659, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 630: val_loss improved from 0.06659 to 0.06652, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 631: val_loss improved from 0.06652 to 0.06644, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 632: val_loss improved from 0.06644 to 0.06636, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 633: val_loss improved from 0.06636 to 0.06629, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 634: val_loss improved from 0.06629 to 0.06620, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 635: val_loss improved from 0.06620 to 0.06613, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 636: val_loss improved from 0.06613 to 0.06605, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 637: val_loss improved from 0.06605 to 0.06597, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 638: val_loss improved from 0.06597 to 0.06590, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 639: val_loss improved from 0.06590 to 0.06583, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 640: val_loss improved from 0.06583 to 0.06574, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 641: val_loss improved from 0.06574 to 0.06567, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 642: val_loss improved from 0.06567 to 0.06559, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 643: val_loss improved from 0.06559 to 0.06551, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 644: val_loss improved from 0.06551 to 0.06543, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 645: val_loss improved from 0.06543 to 0.06536, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 646: val_loss improved from 0.06536 to 0.06529, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 647: val_loss improved from 0.06529 to 0.06518, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 648: val_loss improved from 0.06518 to 0.06511, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 649: val_loss improved from 0.06511 to 0.06504, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 650: val_loss improved from 0.06504 to 0.06496, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 651: val_loss improved from 0.06496 to 0.06489, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 652: val_loss improved from 0.06489 to 0.06484, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 653: val_loss improved from 0.06484 to 0.06476, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 654: val_loss improved from 0.06476 to 0.06469, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 655: val_loss improved from 0.06469 to 0.06462, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 656: val_loss improved from 0.06462 to 0.06454, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 657: val_loss improved from 0.06454 to 0.06447, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 658: val_loss improved from 0.06447 to 0.06440, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 659: val_loss improved from 0.06440 to 0.06432, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 660: val_loss improved from 0.06432 to 0.06422, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 661: val_loss improved from 0.06422 to 0.06415, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 662: val_loss improved from 0.06415 to 0.06408, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 663: val_loss improved from 0.06408 to 0.06401, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 664: val_loss improved from 0.06401 to 0.06394, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 665: val_loss improved from 0.06394 to 0.06386, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 666: val_loss improved from 0.06386 to 0.06376, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 667: val_loss improved from 0.06376 to 0.06370, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 668: val_loss improved from 0.06370 to 0.06364, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 669: val_loss improved from 0.06364 to 0.06357, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 670: val_loss improved from 0.06357 to 0.06350, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 671: val_loss improved from 0.06350 to 0.06342, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 672: val_loss improved from 0.06342 to 0.06335, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 673: val_loss improved from 0.06335 to 0.06328, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 674: val_loss improved from 0.06328 to 0.06320, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 675: val_loss improved from 0.06320 to 0.06313, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 676: val_loss improved from 0.06313 to 0.06307, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 677: val_loss improved from 0.06307 to 0.06299, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 678: val_loss improved from 0.06299 to 0.06292, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 679: val_loss improved from 0.06292 to 0.06285, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 680: val_loss improved from 0.06285 to 0.06278, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 681: val_loss improved from 0.06278 to 0.06271, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 682: val_loss improved from 0.06271 to 0.06264, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 683: val_loss improved from 0.06264 to 0.06257, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 684: val_loss improved from 0.06257 to 0.06251, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 685: val_loss improved from 0.06251 to 0.06243, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 686: val_loss improved from 0.06243 to 0.06239, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 687: val_loss improved from 0.06239 to 0.06232, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 688: val_loss improved from 0.06232 to 0.06225, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 689: val_loss improved from 0.06225 to 0.06219, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 690: val_loss improved from 0.06219 to 0.06212, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 691: val_loss improved from 0.06212 to 0.06206, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 692: val_loss improved from 0.06206 to 0.06199, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 693: val_loss improved from 0.06199 to 0.06192, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 694: val_loss improved from 0.06192 to 0.06184, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 695: val_loss improved from 0.06184 to 0.06177, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 696: val_loss improved from 0.06177 to 0.06170, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 697: val_loss improved from 0.06170 to 0.06163, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 698: val_loss improved from 0.06163 to 0.06156, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 699: val_loss improved from 0.06156 to 0.06149, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 700: val_loss improved from 0.06149 to 0.06142, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "Loss: 0.0614, Accuracy: 98.21%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 558: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 561: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 601: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 609: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 612: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 628: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 629: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 631: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 632: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 633: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 634: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 636: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 637: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 638: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 639: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 641: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 642: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 643: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 644: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 646: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 647: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 648: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 649: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 651: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 652: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 653: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 654: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 656: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 657: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 658: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 659: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 661: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 662: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 663: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 664: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 666: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 667: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 668: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 669: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 671: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 672: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 673: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 674: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 676: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 677: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 678: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 679: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 681: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 682: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 683: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 684: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 686: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 687: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 688: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 689: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 691: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 692: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 693: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 694: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 696: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 697: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 698: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 699: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.06142\n",
      "Loss: 0.1367, Accuracy: 96.43%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 558: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 561: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 601: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 609: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 612: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 628: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 629: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 631: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 632: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 633: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 634: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 636: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 637: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 638: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 639: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 641: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 642: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 643: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 644: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 646: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 647: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 648: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 649: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 651: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 652: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 653: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 654: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 656: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 657: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 658: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 659: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 661: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 662: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 663: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 664: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 666: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 667: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 668: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 669: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 671: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 672: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 673: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 674: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 676: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 677: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 678: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 679: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 681: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 682: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 683: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 684: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 686: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 687: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 688: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 689: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 691: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 692: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 693: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 694: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 696: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 697: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 698: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 699: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.06142\n",
      "Loss: 0.0937, Accuracy: 94.64%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 558: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 561: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 601: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 609: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 612: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 628: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 629: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 631: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 632: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 633: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 634: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 636: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 637: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 638: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 639: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 641: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 642: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 643: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 644: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 646: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 647: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 648: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 649: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 651: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 652: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 653: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 654: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 656: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 657: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 658: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 659: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 661: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 662: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 663: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 664: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 666: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 667: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 668: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 669: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 671: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 672: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 673: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 674: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 676: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 677: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 678: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 679: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 681: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 682: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 683: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 684: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 686: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 687: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 688: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 689: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 691: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 692: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 693: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 694: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 696: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 697: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 698: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 699: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.06142\n",
      "Loss: 0.1185, Accuracy: 96.43%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 558: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 561: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 601: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 609: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 612: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.06142\n",
      "\n",
      "Epoch 628: val_loss improved from 0.06142 to 0.06136, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 629: val_loss improved from 0.06136 to 0.06129, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 630: val_loss improved from 0.06129 to 0.06120, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 631: val_loss improved from 0.06120 to 0.06109, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 632: val_loss improved from 0.06109 to 0.06100, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 633: val_loss improved from 0.06100 to 0.06093, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 634: val_loss improved from 0.06093 to 0.06085, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 635: val_loss improved from 0.06085 to 0.06076, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 636: val_loss improved from 0.06076 to 0.06069, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 637: val_loss improved from 0.06069 to 0.06062, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 638: val_loss improved from 0.06062 to 0.06054, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 639: val_loss improved from 0.06054 to 0.06046, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 640: val_loss improved from 0.06046 to 0.06038, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 641: val_loss improved from 0.06038 to 0.06028, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 642: val_loss improved from 0.06028 to 0.06021, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 643: val_loss improved from 0.06021 to 0.06014, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 644: val_loss improved from 0.06014 to 0.06004, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 645: val_loss improved from 0.06004 to 0.05996, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 646: val_loss improved from 0.05996 to 0.05989, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 647: val_loss improved from 0.05989 to 0.05982, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 648: val_loss improved from 0.05982 to 0.05975, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 649: val_loss improved from 0.05975 to 0.05967, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 650: val_loss improved from 0.05967 to 0.05956, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 651: val_loss improved from 0.05956 to 0.05950, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 652: val_loss improved from 0.05950 to 0.05945, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 653: val_loss improved from 0.05945 to 0.05937, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 654: val_loss improved from 0.05937 to 0.05929, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 655: val_loss improved from 0.05929 to 0.05920, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 656: val_loss improved from 0.05920 to 0.05908, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 657: val_loss improved from 0.05908 to 0.05900, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 658: val_loss improved from 0.05900 to 0.05892, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 659: val_loss improved from 0.05892 to 0.05884, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 660: val_loss improved from 0.05884 to 0.05875, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 661: val_loss improved from 0.05875 to 0.05866, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 662: val_loss improved from 0.05866 to 0.05857, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 663: val_loss improved from 0.05857 to 0.05851, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 664: val_loss improved from 0.05851 to 0.05845, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 665: val_loss improved from 0.05845 to 0.05839, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 666: val_loss improved from 0.05839 to 0.05832, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 667: val_loss improved from 0.05832 to 0.05825, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 668: val_loss improved from 0.05825 to 0.05818, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 669: val_loss improved from 0.05818 to 0.05812, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 670: val_loss improved from 0.05812 to 0.05804, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 671: val_loss improved from 0.05804 to 0.05797, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 672: val_loss improved from 0.05797 to 0.05788, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 673: val_loss improved from 0.05788 to 0.05781, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 674: val_loss improved from 0.05781 to 0.05774, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 675: val_loss improved from 0.05774 to 0.05767, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 676: val_loss improved from 0.05767 to 0.05761, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 677: val_loss improved from 0.05761 to 0.05755, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 678: val_loss improved from 0.05755 to 0.05745, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 679: val_loss improved from 0.05745 to 0.05737, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 680: val_loss improved from 0.05737 to 0.05731, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 681: val_loss improved from 0.05731 to 0.05724, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 682: val_loss improved from 0.05724 to 0.05717, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 683: val_loss improved from 0.05717 to 0.05710, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 684: val_loss improved from 0.05710 to 0.05703, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 685: val_loss improved from 0.05703 to 0.05697, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 686: val_loss improved from 0.05697 to 0.05690, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 687: val_loss improved from 0.05690 to 0.05682, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 688: val_loss improved from 0.05682 to 0.05675, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 689: val_loss improved from 0.05675 to 0.05668, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 690: val_loss improved from 0.05668 to 0.05661, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 691: val_loss improved from 0.05661 to 0.05653, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 692: val_loss improved from 0.05653 to 0.05644, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 693: val_loss improved from 0.05644 to 0.05636, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 694: val_loss improved from 0.05636 to 0.05628, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 695: val_loss improved from 0.05628 to 0.05619, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 696: val_loss improved from 0.05619 to 0.05613, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 697: val_loss improved from 0.05613 to 0.05607, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 698: val_loss improved from 0.05607 to 0.05599, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 699: val_loss improved from 0.05599 to 0.05589, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 700: val_loss improved from 0.05589 to 0.05579, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "Loss: 0.0558, Accuracy: 100.00%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 558: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 561: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 601: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 609: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 612: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 628: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 629: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 631: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 632: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 633: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 634: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 636: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 637: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 638: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 639: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 641: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 642: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 643: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 644: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 646: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 647: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 648: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 649: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 651: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 652: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 653: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 654: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 656: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 657: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 658: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 659: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 661: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 662: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 663: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 664: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 666: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 667: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 668: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 669: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 671: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 672: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 673: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 674: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 676: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 677: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 678: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 679: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 681: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 682: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 683: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 684: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 686: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 687: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 688: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 689: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 691: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 692: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 693: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 694: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 696: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 697: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 698: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 699: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.05579\n",
      "Loss: 0.0948, Accuracy: 96.43%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 558: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 561: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 601: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 609: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 612: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 628: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 629: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 631: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 632: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 633: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 634: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 636: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 637: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 638: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 639: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 641: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 642: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 643: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 644: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 646: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 647: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 648: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 649: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 651: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 652: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 653: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 654: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 656: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 657: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 658: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 659: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 661: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 662: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 663: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 664: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 666: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 667: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 668: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 669: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 671: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 672: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 673: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 674: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 676: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 677: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 678: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 679: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 681: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 682: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 683: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 684: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 686: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 687: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 688: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 689: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 691: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 692: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 693: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 694: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 696: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 697: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 698: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 699: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.05579\n",
      "Loss: 0.1216, Accuracy: 96.43%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 555: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 558: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 561: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 601: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 609: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 612: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 628: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 629: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 631: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 632: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 633: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 634: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 636: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 637: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 638: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 639: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 641: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 642: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 643: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 644: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 646: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 647: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 648: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 649: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 651: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 652: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 653: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 654: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 656: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 657: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 658: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 659: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 661: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 662: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 663: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 664: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 666: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 667: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 668: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 669: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 671: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 672: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 673: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 674: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 676: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 677: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 678: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 679: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 681: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 682: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 683: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 684: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 686: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 687: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 688: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 689: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 691: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 692: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 693: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 694: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 696: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 697: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 698: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 699: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.05579\n",
      "Loss: 0.0889, Accuracy: 96.43%\n",
      "\n",
      "Epoch 1: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 373: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.05579\n",
      "\n",
      "Epoch 529: val_loss improved from 0.05579 to 0.05579, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 530: val_loss improved from 0.05579 to 0.05569, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 531: val_loss improved from 0.05569 to 0.05563, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 532: val_loss improved from 0.05563 to 0.05552, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 533: val_loss improved from 0.05552 to 0.05542, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 534: val_loss improved from 0.05542 to 0.05533, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 535: val_loss improved from 0.05533 to 0.05525, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 536: val_loss improved from 0.05525 to 0.05515, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 537: val_loss improved from 0.05515 to 0.05504, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 538: val_loss improved from 0.05504 to 0.05492, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 539: val_loss improved from 0.05492 to 0.05483, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 540: val_loss improved from 0.05483 to 0.05475, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 541: val_loss improved from 0.05475 to 0.05465, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 542: val_loss improved from 0.05465 to 0.05454, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 543: val_loss improved from 0.05454 to 0.05444, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 544: val_loss improved from 0.05444 to 0.05432, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 545: val_loss improved from 0.05432 to 0.05423, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 546: val_loss improved from 0.05423 to 0.05414, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 547: val_loss improved from 0.05414 to 0.05405, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 548: val_loss improved from 0.05405 to 0.05396, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 549: val_loss improved from 0.05396 to 0.05387, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 550: val_loss improved from 0.05387 to 0.05378, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 551: val_loss improved from 0.05378 to 0.05369, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 552: val_loss improved from 0.05369 to 0.05362, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 553: val_loss improved from 0.05362 to 0.05350, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 554: val_loss improved from 0.05350 to 0.05342, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 555: val_loss improved from 0.05342 to 0.05333, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 556: val_loss improved from 0.05333 to 0.05322, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 557: val_loss improved from 0.05322 to 0.05313, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 558: val_loss improved from 0.05313 to 0.05304, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 559: val_loss improved from 0.05304 to 0.05295, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 560: val_loss improved from 0.05295 to 0.05286, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 561: val_loss improved from 0.05286 to 0.05278, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 562: val_loss improved from 0.05278 to 0.05269, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 563: val_loss improved from 0.05269 to 0.05259, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 564: val_loss improved from 0.05259 to 0.05250, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 565: val_loss improved from 0.05250 to 0.05240, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 566: val_loss improved from 0.05240 to 0.05231, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 567: val_loss improved from 0.05231 to 0.05224, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 568: val_loss improved from 0.05224 to 0.05217, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 569: val_loss improved from 0.05217 to 0.05209, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 570: val_loss improved from 0.05209 to 0.05202, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 571: val_loss improved from 0.05202 to 0.05192, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 572: val_loss improved from 0.05192 to 0.05183, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 573: val_loss improved from 0.05183 to 0.05172, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 574: val_loss improved from 0.05172 to 0.05162, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 575: val_loss improved from 0.05162 to 0.05152, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 576: val_loss improved from 0.05152 to 0.05144, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 577: val_loss improved from 0.05144 to 0.05136, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 578: val_loss improved from 0.05136 to 0.05126, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 579: val_loss improved from 0.05126 to 0.05118, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 580: val_loss improved from 0.05118 to 0.05109, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 581: val_loss improved from 0.05109 to 0.05102, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 582: val_loss improved from 0.05102 to 0.05094, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 583: val_loss improved from 0.05094 to 0.05085, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 584: val_loss improved from 0.05085 to 0.05077, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 585: val_loss improved from 0.05077 to 0.05069, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 586: val_loss improved from 0.05069 to 0.05061, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 587: val_loss improved from 0.05061 to 0.05052, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 588: val_loss improved from 0.05052 to 0.05044, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 589: val_loss improved from 0.05044 to 0.05039, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 590: val_loss improved from 0.05039 to 0.05030, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 591: val_loss improved from 0.05030 to 0.05019, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 592: val_loss improved from 0.05019 to 0.05011, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 593: val_loss improved from 0.05011 to 0.05002, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 594: val_loss improved from 0.05002 to 0.04993, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 595: val_loss improved from 0.04993 to 0.04985, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 596: val_loss improved from 0.04985 to 0.04979, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 597: val_loss improved from 0.04979 to 0.04971, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 598: val_loss improved from 0.04971 to 0.04962, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 599: val_loss improved from 0.04962 to 0.04953, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 600: val_loss improved from 0.04953 to 0.04945, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 601: val_loss improved from 0.04945 to 0.04937, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 602: val_loss improved from 0.04937 to 0.04928, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 603: val_loss improved from 0.04928 to 0.04919, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 604: val_loss improved from 0.04919 to 0.04911, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 605: val_loss improved from 0.04911 to 0.04903, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 606: val_loss improved from 0.04903 to 0.04895, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 607: val_loss improved from 0.04895 to 0.04885, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 608: val_loss improved from 0.04885 to 0.04879, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 609: val_loss improved from 0.04879 to 0.04869, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 610: val_loss improved from 0.04869 to 0.04861, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 611: val_loss improved from 0.04861 to 0.04855, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 612: val_loss improved from 0.04855 to 0.04847, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 613: val_loss improved from 0.04847 to 0.04839, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 614: val_loss improved from 0.04839 to 0.04831, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 615: val_loss improved from 0.04831 to 0.04822, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 616: val_loss improved from 0.04822 to 0.04813, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 617: val_loss improved from 0.04813 to 0.04805, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 618: val_loss improved from 0.04805 to 0.04797, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 619: val_loss improved from 0.04797 to 0.04789, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 620: val_loss improved from 0.04789 to 0.04782, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 621: val_loss improved from 0.04782 to 0.04774, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 622: val_loss improved from 0.04774 to 0.04765, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 623: val_loss improved from 0.04765 to 0.04756, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 624: val_loss improved from 0.04756 to 0.04749, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 625: val_loss improved from 0.04749 to 0.04740, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 626: val_loss improved from 0.04740 to 0.04731, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 627: val_loss improved from 0.04731 to 0.04723, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 628: val_loss improved from 0.04723 to 0.04712, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 629: val_loss improved from 0.04712 to 0.04705, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 630: val_loss improved from 0.04705 to 0.04698, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 631: val_loss improved from 0.04698 to 0.04691, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 632: val_loss improved from 0.04691 to 0.04684, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 633: val_loss improved from 0.04684 to 0.04679, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 634: val_loss improved from 0.04679 to 0.04672, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 635: val_loss improved from 0.04672 to 0.04663, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 636: val_loss improved from 0.04663 to 0.04659, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 637: val_loss improved from 0.04659 to 0.04651, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 638: val_loss improved from 0.04651 to 0.04645, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 639: val_loss improved from 0.04645 to 0.04636, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 640: val_loss improved from 0.04636 to 0.04629, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 641: val_loss improved from 0.04629 to 0.04620, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 642: val_loss improved from 0.04620 to 0.04611, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 643: val_loss improved from 0.04611 to 0.04604, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 644: val_loss improved from 0.04604 to 0.04595, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 645: val_loss improved from 0.04595 to 0.04588, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 646: val_loss improved from 0.04588 to 0.04581, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 647: val_loss improved from 0.04581 to 0.04573, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 648: val_loss improved from 0.04573 to 0.04562, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 649: val_loss improved from 0.04562 to 0.04556, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 650: val_loss improved from 0.04556 to 0.04548, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 651: val_loss improved from 0.04548 to 0.04545, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 652: val_loss improved from 0.04545 to 0.04536, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 653: val_loss improved from 0.04536 to 0.04529, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 654: val_loss improved from 0.04529 to 0.04520, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 655: val_loss improved from 0.04520 to 0.04512, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 656: val_loss improved from 0.04512 to 0.04504, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 657: val_loss improved from 0.04504 to 0.04496, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 658: val_loss improved from 0.04496 to 0.04488, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 659: val_loss improved from 0.04488 to 0.04478, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 660: val_loss improved from 0.04478 to 0.04471, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 661: val_loss improved from 0.04471 to 0.04465, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 662: val_loss improved from 0.04465 to 0.04457, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 663: val_loss improved from 0.04457 to 0.04450, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 664: val_loss improved from 0.04450 to 0.04442, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 665: val_loss improved from 0.04442 to 0.04434, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 666: val_loss improved from 0.04434 to 0.04427, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 667: val_loss improved from 0.04427 to 0.04421, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 668: val_loss improved from 0.04421 to 0.04415, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 669: val_loss improved from 0.04415 to 0.04407, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 670: val_loss improved from 0.04407 to 0.04400, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 671: val_loss improved from 0.04400 to 0.04393, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 672: val_loss improved from 0.04393 to 0.04386, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 673: val_loss improved from 0.04386 to 0.04378, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 674: val_loss improved from 0.04378 to 0.04369, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 675: val_loss improved from 0.04369 to 0.04361, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 676: val_loss improved from 0.04361 to 0.04354, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 677: val_loss improved from 0.04354 to 0.04348, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 678: val_loss improved from 0.04348 to 0.04342, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 679: val_loss improved from 0.04342 to 0.04334, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 680: val_loss improved from 0.04334 to 0.04328, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 681: val_loss improved from 0.04328 to 0.04321, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 682: val_loss improved from 0.04321 to 0.04313, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 683: val_loss improved from 0.04313 to 0.04306, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 684: val_loss improved from 0.04306 to 0.04298, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 685: val_loss improved from 0.04298 to 0.04289, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 686: val_loss improved from 0.04289 to 0.04284, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 687: val_loss improved from 0.04284 to 0.04277, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 688: val_loss improved from 0.04277 to 0.04268, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 689: val_loss improved from 0.04268 to 0.04262, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 690: val_loss improved from 0.04262 to 0.04257, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 691: val_loss improved from 0.04257 to 0.04248, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 692: val_loss improved from 0.04248 to 0.04242, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 693: val_loss improved from 0.04242 to 0.04236, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 694: val_loss improved from 0.04236 to 0.04231, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 695: val_loss improved from 0.04231 to 0.04223, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 696: val_loss improved from 0.04223 to 0.04215, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 697: val_loss improved from 0.04215 to 0.04206, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 698: val_loss improved from 0.04206 to 0.04197, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 699: val_loss improved from 0.04197 to 0.04190, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "\n",
      "Epoch 700: val_loss improved from 0.04190 to 0.04184, saving model to model_checkpoint\\LSTM + GRU_10-fold.h5\n",
      "Loss: 0.0418, Accuracy: 98.21%\n",
      "Vanilla_RNN finished in 2742.13 sec\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\irene\\OneDrive\\Documenti\\GitHub\\Fuzzy-Project\\Main-Mari_3 copy.ipynb Cell 71\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/irene/OneDrive/Documenti/GitHub/Fuzzy-Project/Main-Mari_3%20copy.ipynb#Y130sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mVanilla_RNN finished in\u001b[39m\u001b[39m'\u001b[39m, t,\u001b[39m'\u001b[39m\u001b[39msec\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/irene/OneDrive/Documenti/GitHub/Fuzzy-Project/Main-Mari_3%20copy.ipynb#Y130sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Plot of the average learning curves\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/irene/OneDrive/Documenti/GitHub/Fuzzy-Project/Main-Mari_3%20copy.ipynb#Y130sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m plot_1(train_loss, train_acc, val_loss, val_acc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/irene/OneDrive/Documenti/GitHub/Fuzzy-Project/Main-Mari_3%20copy.ipynb#Y130sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# Calculate average performance\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/irene/OneDrive/Documenti/GitHub/Fuzzy-Project/Main-Mari_3%20copy.ipynb#Y130sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m avg_accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(test_acc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_1' is not defined"
     ]
    }
   ],
   "source": [
    "dir_name = 'model_checkpoint'\n",
    "if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "save_path = os.path.join(dir_name, 'LSTM + GRU_10-fold.h5')\n",
    "\n",
    "callbacks_list = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "k_fold = 10 # number of folds for the K-fold cross validation\n",
    "x_train, x_test, y_train, y_test, kf = trainTestData_1 (ft, test_ratio, k_fold)\n",
    "\n",
    "# Arrays to store the learning curves at each k-th iteration\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "print('Implementing GRU with K-fold')\n",
    "start = time.time()\n",
    "for train, test in kf.split(ft):\n",
    "    x_train = ft.iloc[train,:ft.shape[1]-1]\n",
    "    x_train = np.reshape(x_train.values, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "    y_train = ft.loc[train,'seizure'].values.astype(int)\n",
    "    x_test = ft.iloc[test,:ft.shape[1]-1]\n",
    "    x_test = np.reshape(x_test.values, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "    y_test = ft.loc[test,'seizure'].values.astype(int)\n",
    "\n",
    "    # Definition of the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True,input_shape=(None, x_train.shape[-1])))\n",
    "    model.add(layers.GRU(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with a SGD optimizer with an exponential decaying learning rate\n",
    "    optimizer, lr_schedule = optimizer_SGD(0.001, 1000, 0.1)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Training of the model\n",
    "    history = model.fit(x_train, y_train, batch_size = 5, epochs = 700, verbose = 0, validation_data=(x_test,y_test), callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_schedule), callbacks_list])\n",
    "\n",
    "    # Store the metrics values for each epoch and for each fold\n",
    "    train_loss.append(history.history['loss'])\n",
    "    train_acc.append(history.history['accuracy'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    val_acc.append(history.history['val_accuracy'])\n",
    "\n",
    "    # Evaluation of the model\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    test_acc.append(accuracy)\n",
    "    test_loss.append(loss)\n",
    "\n",
    "    # Print of the loss and accuracy scores at the end of each fold\n",
    "    print(\"Loss: {:.4f}, Accuracy: {:.2f}%\".format(loss, accuracy * 100))\n",
    "\n",
    "end = time.time()\n",
    "t = round(end - start,2)\n",
    "print('Vanilla_RNN finished in', t,'sec\\n')\n",
    "\n",
    "# Plot of the average learning curves\n",
    "plot_1(train_loss, train_acc, val_loss, val_acc)\n",
    "\n",
    "# Calculate average performance\n",
    "avg_accuracy = np.mean(test_acc)\n",
    "avg_loss = np.mean(test_loss)\n",
    "print(f'Average accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average loss: {avg_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
